{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"_rubert_mp3.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bl-lyyIztPZM"},"source":["Important, start fresh session before running. Else, the NN may not learn"]},{"cell_type":"code","metadata":{"id":"vme8XO_YChGk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606582814853,"user_tz":300,"elapsed":24432,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}},"outputId":"0246f521-7e9d-4b81-b1f3-88f600cf6c6a"},"source":["from google.colab import drive\n","import sys\n","drive.mount('/content/gdrive' )\n","sys.path.append('/content/gdrive/MyDrive/Colab Notebooks/Mini Project 3 ECSE 551 Team 20')\n","%cd '/content/gdrive/MyDrive/Colab Notebooks/Mini Project 3 ECSE 551 Team 20'\n","\n","import pickle\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from PIL import Image\n","import torch\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import ShuffleSplit\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from tqdm import tqdm\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/Colab Notebooks/Mini Project 3 ECSE 551 Team 20\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V3GZ4LAuqo9S","executionInfo":{"status":"ok","timestamp":1606582814856,"user_tz":300,"elapsed":24428,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}}},"source":["# Constants\n","\n","TRAIN_LABELS_FILE = \"./TrainLabels.csv\"\n","TRAIN_DATA_FILE = './Train.pkl'\n","TEST_DATA_FILE = './Test.pkl'\n","\n","BATCH_SIZE = 2**6\n","N_EPOCHS = 20\n","LEARNING_RATE = 0.001\n","RANDOM_SEED = 42\n","N_CLASSES = 9\n","IMG_SIZE_X = 128\n","IMG_SIZE_Y = 64\n","\n","torch.manual_seed(RANDOM_SEED)\n","torch.cuda.manual_seed(RANDOM_SEED)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lgP_cyeST6fe"},"source":["## Auxiliary functions"]},{"cell_type":"code","metadata":{"id":"KQRDzjFkecBc","executionInfo":{"status":"ok","timestamp":1606582815499,"user_tz":300,"elapsed":25066,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}}},"source":["#-------------------------------DATA INSPECTION--------------------------------------------\n","def inspect_data():\n","  train = pd.read_csv(TRAIN_LABELS_FILE)\n","\n","  fig = plt.figure()\n","  train['class'].value_counts().plot.bar()\n","  plt.ylabel(\"Observation count\")\n","  plt.show()\n","\n","  print((train['class'].value_counts()))\n","  print(\"Each class has the same number of observation ±1 data\")\n","\n","  # Read a pickle file and dispaly its samples\n","  # Note that image data are stored as unit8 so each element is an integer value between 0 and 255\n","  data = pickle.load( open( TRAIN_DATA_FILE, 'rb' ), encoding='bytes')\n","  targets = np.genfromtxt(TRAIN_LABELS_FILE, delimiter=',', skip_header=1)[:,1:]\n","  plt.imshow(data[1234,:,:],cmap='gray', vmin=0, vmax=256)\n","  print(data.shape, targets.shape)\n","\n","#------------------------------DATASET CLASS--------------------------------------------------\n","class MyDataset(Dataset):\n","  # img_file: the pickle file containing the images\n","# label_file: the .csv file containing the labels\n","# transform: We use it for normalizing images (see above)\n","# idx: This is a binary vector that is useful for creating training and validation set.\n","# It return only samples where idx is True\n","  def __init__(self, img_file, targets, transform=None, idx = None):\n","      self.data = pickle.load(open( img_file, 'rb' ), encoding='bytes')\n","      self.targets = targets\n","      # self.targets = np.genfromtxt(label_file, delimiter=',', skip_header=1)[:,1:]\n","      if idx is not None:\n","        self.targets = self.targets[idx]\n","        self.data = self.data[idx]\n","      if transform is not None:\n","        self.transform = transform\n","\n","  def __len__(self):\n","      return len(self.targets)\n","\n","  def __getitem__(self, index):\n","      img, target = self.data[index], int(self.targets[index])\n","      img = Image.fromarray(img.astype('uint8'), mode='L')\n","\n","      if self.transform is not None:\n","          img = self.transform(img)\n","\n","      return img, target\n","\n","#-----------------------------------------TRANSFORMS--------------------------------------------\n","# Transforms are common image transformations. They can be chained together using Compose.\n","# Here we normalize images img=(img-0.5)/0.5\n","img_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5], [0.5])\n","])\n","\n","#-------------------------------------DATA EXTRACTION, PROCESSING AND DIVISION INTRO TRAINING/TEST SETS ------------------------------\n","def extract_data(train_labels_file, train_data_file, batch_size, train_ratio):\n","  \n","  #Create the train dataset\n","  targets = np.genfromtxt(train_labels_file, delimiter=',', skip_header=1)[:,1:]\n","\n","\n","  #rescale so that target goes from 0 to 9\n","  min_target = min(targets)\n","  targets = targets - min_target\n","\n","\n","  train_size = int(len(targets) * train_ratio)\n","  test_size = len(targets) - train_size\n","\n","\n","\n","  # Split the data into the training set and the test set  \n","  SS = ShuffleSplit(n_splits=1, train_size=train_size, test_size=test_size, random_state=RANDOM_SEED)\n","\n","\n","  train_index, test_index = next(SS.split(targets)) \n","\n","  train_dataset = MyDataset(train_data_file, targets , idx=train_index, transform=img_transform)\n","  test_dataset = MyDataset(train_data_file, targets , idx=test_index, transform=img_transform)\n","\n","  train_loader = DataLoader(train_dataset ,batch_size=batch_size, shuffle=True)\n","  test_loader = DataLoader(test_dataset ,batch_size=batch_size, shuffle=True)\n","\n","  return train_loader, test_loader\n","# --------------------------------------Other NEural network --------Le Net5------------------\n","# \"https://towardsdatascience.com/implementing-yann-lecuns-lenet-5-in-pytorch-5e05a0911320\"\n","\n","\n","# -------------------------------VGG--------------------------------------\n","# --------------------------------------Other NEural network --------Le VGG------------------\n","# \"https://www.youtube.com/watch?v=ACmuBbuXn20&ab_channel=AladdinPersson\n","VGG11 = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,512,'M']\n","VGG16 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,'M', 512, 512, 512, 'M']\n","class VGG_Net(nn.Module):\n","\n","  def __init__(self, in_channels= 1, num_classes= N_CLASSES):\n","    super(VGG_Net, self).__init__()        \n","    self.in_channels = in_channels  \n","    self.conv_layers = self.create_conv_layers(VGG11)\n","    self.to_linear = 4096\n","    \n","    self.fcs = nn.Sequential(\n","        nn.Linear(self.to_linear,4096),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(4096,4096),\n","        nn.ReLU(),\n","        nn.Dropout(p=0.5),\n","        nn.Linear(4096,num_classes)\n","    )      \n","\n","  def forward(self,x):\n","    x= self.conv_layers(x)\n","    x = x.reshape(x.shape[0],-1)\n"," \n","    x = self.fcs(x)\n","    return x\n","\n","  def create_conv_layers(self, architecture):\n","    layers = []\n","    in_channels = self.in_channels\n","\n","    for x in architecture:\n","      if type(x) == int:\n","        out_channels = x\n","        layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n","                             kernel_size = (3,3), stride=(1,1), padding=(1,1)),\n","                             nn.BatchNorm2d(x),\n","                             nn.ReLU()]\n","        in_channels = x\n","      elif x =='M':\n","        layers += [nn.MaxPool2d(kernel_size=(2,2), stride = (2,2))]\n","    \n","    return nn.Sequential(*layers)\n","\n","#-----------------------------------------NEURAL NETWORK -------------------------------------------------------\n","class Net(nn.Module):\n","    # This part defines the layers\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # At first there is only 1 channel (greyscale). The next channel size will be 10. \n","        input_sz_h = IMG_SIZE_Y\n","        input_sz_v = IMG_SIZE_X\n","\n","        fltr_sz_cv_1 = 3\n","        fltr_num_cv_1 = 10\n","        fltr_sz_cv_2 = 3\n","        fltr_num_cv_2 = 10\n","        final_sz_h = np.floor(((input_sz_h-fltr_sz_cv_1+1)/2-fltr_sz_cv_2+1)/2)\n","        final_sz_v = np.floor(((input_sz_v-fltr_sz_cv_1+1)/2-fltr_sz_cv_2+1)/2)\n","        self.img_sz = int(fltr_num_cv_2 * final_sz_h * final_sz_v)\n","\n","        self.conv1 = nn.Conv2d(1, fltr_num_cv_1, kernel_size=fltr_sz_cv_1)\n","        self.conv2 = nn.Conv2d(fltr_num_cv_1, fltr_num_cv_2, kernel_size=fltr_sz_cv_2)\n","        self.conv2_drop = nn.Dropout2d()\n","\n","        self.fc1 = nn.Linear(self.img_sz, 40)\n","        self.fc2 = nn.Linear(40, N_CLASES)\n","\n","    # And this part defines the way they are connected to each other\n","    # (In reality, it is our foreward pass)\n","    def forward(self, x):\n","        \n","\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n","        x = x.view(-1, self.img_sz)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","\n","        return F.log_softmax(x,dim=0)\n","\n","# ----------------------------------TRAINING -----------------------------------------\n","def train(network, optimizer,loss_function,train_loader, train_losses, train_accuracies):     \n","  network.train()\n","  no_of_correct_predictions = 0\n","  for batch_idx, (X, y_truth) in enumerate(train_loader):\n","    optimizer.zero_grad()\n","    X = X.to(device)\n","    y_truth = y_truth.to(device)\n","    y_hat = network(X)     \n","    loss = loss_function(y_hat, y_truth)  \n","\n","    \n","    \n","    loss.backward() \n","    optimizer.step() \n","    \n","    label_hat = y_hat.data.max(1, keepdim=True)[1]  \n","    no_of_correct_predictions += label_hat.eq(y_truth.data.view_as(label_hat)).sum()    \n","    accuracy = float(100. * no_of_correct_predictions / len(train_loader.dataset))\n","\n","    print('Current batch: Loss-> {:6.4f}, Train accuracy-> {:6.2f}%'.format(loss.item(),accuracy) )\n","\n","  train_losses.append(loss.item())\n","  train_accuracies.append(accuracy)\n","\n","#-----------------------------------------TEST------------------------------------------\n","\n","\n","def test(network,loss_function, test_loader, test_losses, test_accuracies): \n","  network.eval()\n","  \n","  no_of_correct_predictions = 0\n","\n","  with torch.no_grad():\n","    for X, y_truth in tqdm(test_loader): \n","      X = X.to(device)\n","      y_truth = y_truth.to(device)\n","\n","      y_hat = network(X)      \n","      \n","      predicted_targets_batch = y_hat.data.max(1, keepdim=True)[1]  \n","\n","      no_of_correct_predictions += predicted_targets_batch.eq(y_truth.data.view_as(predicted_targets_batch)).sum()  \n","  \n","  test_loss = loss_function( y_hat, y_truth).item()      \n","  \n","  test_accuracy = 100. * no_of_correct_predictions / len(test_loader.dataset)\n","\n","  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","    test_loss, no_of_correct_predictions, len(test_loader.dataset),test_accuracy ))  \n","  \n","  test_losses.append(test_loss)\n","  test_accuracies.append(float(test_accuracy))\n","\n","\n","\n","# each number in train_losses vector correspond to a batch, while each on the test_losses correspond to an epoch\n","def plot_metrics(train_metrics,test_metrics,ylabel):\n","  fig = plt.figure()\n","  plt.scatter(np.arange(len(test_metrics)), test_metrics, color='blue', label= 'Test')\n","  plt.scatter(np.arange(len(train_metrics)), train_metrics, color='red', label = 'Train')\n","  plt.xlabel('Epochs')\n","  plt.ylabel(ylabel)\n","  plt.legend()\n","\n","  plt.show()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wmmk_xuXT91Q"},"source":["## Training and Testing"]},{"cell_type":"code","metadata":{"id":"l5PhuAwXC5Nl","executionInfo":{"status":"ok","timestamp":1606582832013,"user_tz":300,"elapsed":41576,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}}},"source":["train_loader, test_loader = extract_data(TRAIN_LABELS_FILE, TRAIN_DATA_FILE, BATCH_SIZE,0.8)\n","network = VGG_Net(in_channels=1,num_classes=N_CLASSES).to(device)\n","\n","#loss_function = F.nll_loss\n","#optimizer = optim.SGD(network.parameters(), lr=LEARNING_RATE, momentum=0.5)\n","\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(network.parameters(), lr=LEARNING_RATE)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"6IzFF9I97ZbC","executionInfo":{"status":"ok","timestamp":1606582832015,"user_tz":300,"elapsed":41576,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}}},"source":["train_losses = []\n","test_losses = []\n","train_accuracy_epochs = []\n","test_accuracy_epochs = []"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"oG5IrtUiQ75d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606584048166,"user_tz":300,"elapsed":1257722,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}},"outputId":"9f230895-c7c2-42fc-e43c-08913b4b80d0"},"source":["for epoch in range(N_EPOCHS):\n","  train(network,optimizer,loss_function, train_loader, train_losses, train_accuracy_epochs)   \n","  test(network,loss_function, test_loader, test_losses, test_accuracy_epochs)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Current batch: Loss-> 2.1965, Train accuracy->   0.02%\n","Current batch: Loss-> 16.0262, Train accuracy->   0.03%\n","Current batch: Loss-> 11.7221, Train accuracy->   0.04%\n","Current batch: Loss-> 11.3637, Train accuracy->   0.05%\n","Current batch: Loss-> 7.5557, Train accuracy->   0.06%\n","Current batch: Loss-> 4.7065, Train accuracy->   0.08%\n","Current batch: Loss-> 3.7966, Train accuracy->   0.09%\n","Current batch: Loss-> 2.3769, Train accuracy->   0.11%\n","Current batch: Loss-> 2.3951, Train accuracy->   0.11%\n","Current batch: Loss-> 2.2053, Train accuracy->   0.13%\n","Current batch: Loss-> 2.2293, Train accuracy->   0.15%\n","Current batch: Loss-> 2.1636, Train accuracy->   0.17%\n","Current batch: Loss-> 2.2936, Train accuracy->   0.18%\n","Current batch: Loss-> 2.2739, Train accuracy->   0.19%\n","Current batch: Loss-> 2.1541, Train accuracy->   0.21%\n","Current batch: Loss-> 2.2125, Train accuracy->   0.22%\n","Current batch: Loss-> 2.2011, Train accuracy->   0.24%\n","Current batch: Loss-> 2.2343, Train accuracy->   0.25%\n","Current batch: Loss-> 2.2148, Train accuracy->   0.26%\n","Current batch: Loss-> 2.2689, Train accuracy->   0.28%\n","Current batch: Loss-> 2.2284, Train accuracy->   0.29%\n","Current batch: Loss-> 2.1779, Train accuracy->   0.31%\n","Current batch: Loss-> 2.2442, Train accuracy->   0.32%\n","Current batch: Loss-> 2.2367, Train accuracy->   0.33%\n","Current batch: Loss-> 2.2376, Train accuracy->   0.34%\n","Current batch: Loss-> 2.1819, Train accuracy->   0.35%\n","Current batch: Loss-> 2.2588, Train accuracy->   0.37%\n","Current batch: Loss-> 2.1809, Train accuracy->   0.39%\n","Current batch: Loss-> 2.1988, Train accuracy->   0.41%\n","Current batch: Loss-> 2.2142, Train accuracy->   0.42%\n","Current batch: Loss-> 2.2042, Train accuracy->   0.43%\n","Current batch: Loss-> 2.1963, Train accuracy->   0.44%\n","Current batch: Loss-> 2.1869, Train accuracy->   0.46%\n","Current batch: Loss-> 2.1967, Train accuracy->   0.47%\n","Current batch: Loss-> 2.1499, Train accuracy->   0.49%\n","Current batch: Loss-> 2.2066, Train accuracy->   0.51%\n","Current batch: Loss-> 2.2361, Train accuracy->   0.51%\n","Current batch: Loss-> 2.2543, Train accuracy->   0.52%\n","Current batch: Loss-> 2.2454, Train accuracy->   0.53%\n","Current batch: Loss-> 2.2106, Train accuracy->   0.55%\n","Current batch: Loss-> 2.2151, Train accuracy->   0.56%\n","Current batch: Loss-> 2.2299, Train accuracy->   0.58%\n","Current batch: Loss-> 2.2189, Train accuracy->   0.60%\n","Current batch: Loss-> 2.2198, Train accuracy->   0.61%\n","Current batch: Loss-> 2.1980, Train accuracy->   0.62%\n","Current batch: Loss-> 2.1792, Train accuracy->   0.64%\n","Current batch: Loss-> 2.1746, Train accuracy->   0.66%\n","Current batch: Loss-> 2.1747, Train accuracy->   0.68%\n","Current batch: Loss-> 2.1901, Train accuracy->   0.70%\n","Current batch: Loss-> 2.1896, Train accuracy->   0.71%\n","Current batch: Loss-> 2.2188, Train accuracy->   0.73%\n","Current batch: Loss-> 2.2154, Train accuracy->   0.75%\n","Current batch: Loss-> 2.2046, Train accuracy->   0.76%\n","Current batch: Loss-> 2.2245, Train accuracy->   0.77%\n","Current batch: Loss-> 2.2068, Train accuracy->   0.79%\n","Current batch: Loss-> 2.2199, Train accuracy->   0.81%\n","Current batch: Loss-> 2.2058, Train accuracy->   0.83%\n","Current batch: Loss-> 2.1998, Train accuracy->   0.83%\n","Current batch: Loss-> 2.1694, Train accuracy->   0.85%\n","Current batch: Loss-> 2.2279, Train accuracy->   0.86%\n","Current batch: Loss-> 2.2137, Train accuracy->   0.88%\n","Current batch: Loss-> 2.2619, Train accuracy->   0.89%\n","Current batch: Loss-> 2.2611, Train accuracy->   0.90%\n","Current batch: Loss-> 2.2368, Train accuracy->   0.91%\n","Current batch: Loss-> 2.1745, Train accuracy->   0.93%\n","Current batch: Loss-> 2.2283, Train accuracy->   0.94%\n","Current batch: Loss-> 2.2243, Train accuracy->   0.95%\n","Current batch: Loss-> 2.1990, Train accuracy->   0.96%\n","Current batch: Loss-> 2.2056, Train accuracy->   0.97%\n","Current batch: Loss-> 2.1910, Train accuracy->   0.98%\n","Current batch: Loss-> 2.1914, Train accuracy->   0.99%\n","Current batch: Loss-> 2.2003, Train accuracy->   1.01%\n","Current batch: Loss-> 2.1921, Train accuracy->   1.03%\n","Current batch: Loss-> 2.1940, Train accuracy->   1.04%\n","Current batch: Loss-> 2.1897, Train accuracy->   1.06%\n","Current batch: Loss-> 2.2036, Train accuracy->   1.08%\n","Current batch: Loss-> 2.2088, Train accuracy->   1.09%\n","Current batch: Loss-> 2.1976, Train accuracy->   1.10%\n","Current batch: Loss-> 2.2172, Train accuracy->   1.12%\n","Current batch: Loss-> 2.1963, Train accuracy->   1.14%\n","Current batch: Loss-> 2.2179, Train accuracy->   1.15%\n","Current batch: Loss-> 2.2178, Train accuracy->   1.17%\n","Current batch: Loss-> 2.1895, Train accuracy->   1.19%\n","Current batch: Loss-> 2.1970, Train accuracy->   1.20%\n","Current batch: Loss-> 2.1880, Train accuracy->   1.22%\n","Current batch: Loss-> 2.2181, Train accuracy->   1.23%\n","Current batch: Loss-> 2.2080, Train accuracy->   1.24%\n","Current batch: Loss-> 2.1860, Train accuracy->   1.26%\n","Current batch: Loss-> 2.2158, Train accuracy->   1.28%\n","Current batch: Loss-> 2.2178, Train accuracy->   1.29%\n","Current batch: Loss-> 2.1992, Train accuracy->   1.30%\n","Current batch: Loss-> 2.1950, Train accuracy->   1.31%\n","Current batch: Loss-> 2.1802, Train accuracy->   1.32%\n","Current batch: Loss-> 2.1913, Train accuracy->   1.35%\n","Current batch: Loss-> 2.2015, Train accuracy->   1.36%\n","Current batch: Loss-> 2.1919, Train accuracy->   1.37%\n","Current batch: Loss-> 2.1951, Train accuracy->   1.39%\n","Current batch: Loss-> 2.1986, Train accuracy->   1.41%\n","Current batch: Loss-> 2.1952, Train accuracy->   1.43%\n","Current batch: Loss-> 2.2034, Train accuracy->   1.44%\n","Current batch: Loss-> 2.2164, Train accuracy->   1.45%\n","Current batch: Loss-> 2.2087, Train accuracy->   1.47%\n","Current batch: Loss-> 2.2173, Train accuracy->   1.49%\n","Current batch: Loss-> 2.2079, Train accuracy->   1.50%\n","Current batch: Loss-> 2.1870, Train accuracy->   1.52%\n","Current batch: Loss-> 2.2077, Train accuracy->   1.54%\n","Current batch: Loss-> 2.2072, Train accuracy->   1.55%\n","Current batch: Loss-> 2.1878, Train accuracy->   1.57%\n","Current batch: Loss-> 2.2095, Train accuracy->   1.58%\n","Current batch: Loss-> 2.1955, Train accuracy->   1.60%\n","Current batch: Loss-> 2.1946, Train accuracy->   1.61%\n","Current batch: Loss-> 2.1992, Train accuracy->   1.62%\n","Current batch: Loss-> 2.2018, Train accuracy->   1.65%\n","Current batch: Loss-> 2.1899, Train accuracy->   1.66%\n","Current batch: Loss-> 2.1947, Train accuracy->   1.68%\n","Current batch: Loss-> 2.1881, Train accuracy->   1.70%\n","Current batch: Loss-> 2.2013, Train accuracy->   1.71%\n","Current batch: Loss-> 2.1837, Train accuracy->   1.72%\n","Current batch: Loss-> 2.1887, Train accuracy->   1.74%\n","Current batch: Loss-> 2.1897, Train accuracy->   1.76%\n","Current batch: Loss-> 2.1924, Train accuracy->   1.77%\n","Current batch: Loss-> 2.1905, Train accuracy->   1.79%\n","Current batch: Loss-> 2.1863, Train accuracy->   1.81%\n","Current batch: Loss-> 2.1888, Train accuracy->   1.82%\n","Current batch: Loss-> 2.1938, Train accuracy->   1.84%\n","Current batch: Loss-> 2.1994, Train accuracy->   1.86%\n","Current batch: Loss-> 2.2415, Train accuracy->   1.87%\n","Current batch: Loss-> 2.2098, Train accuracy->   1.89%\n","Current batch: Loss-> 2.2036, Train accuracy->   1.91%\n","Current batch: Loss-> 2.2322, Train accuracy->   1.92%\n","Current batch: Loss-> 2.2000, Train accuracy->   1.93%\n","Current batch: Loss-> 2.2133, Train accuracy->   1.95%\n","Current batch: Loss-> 2.2188, Train accuracy->   1.96%\n","Current batch: Loss-> 2.1723, Train accuracy->   1.97%\n","Current batch: Loss-> 2.2003, Train accuracy->   1.99%\n","Current batch: Loss-> 2.1786, Train accuracy->   2.01%\n","Current batch: Loss-> 2.1993, Train accuracy->   2.02%\n","Current batch: Loss-> 2.2063, Train accuracy->   2.04%\n","Current batch: Loss-> 2.2032, Train accuracy->   2.05%\n","Current batch: Loss-> 2.1923, Train accuracy->   2.07%\n","Current batch: Loss-> 2.1961, Train accuracy->   2.08%\n","Current batch: Loss-> 2.1969, Train accuracy->   2.10%\n","Current batch: Loss-> 2.1943, Train accuracy->   2.13%\n","Current batch: Loss-> 2.1915, Train accuracy->   2.14%\n","Current batch: Loss-> 2.1915, Train accuracy->   2.16%\n","Current batch: Loss-> 2.2085, Train accuracy->   2.17%\n","Current batch: Loss-> 2.1992, Train accuracy->   2.19%\n","Current batch: Loss-> 2.2093, Train accuracy->   2.19%\n","Current batch: Loss-> 2.1948, Train accuracy->   2.21%\n","Current batch: Loss-> 2.1666, Train accuracy->   2.24%\n","Current batch: Loss-> 2.2027, Train accuracy->   2.24%\n","Current batch: Loss-> 2.1947, Train accuracy->   2.26%\n","Current batch: Loss-> 2.1930, Train accuracy->   2.28%\n","Current batch: Loss-> 2.1856, Train accuracy->   2.30%\n","Current batch: Loss-> 2.1913, Train accuracy->   2.32%\n","Current batch: Loss-> 2.2097, Train accuracy->   2.33%\n","Current batch: Loss-> 2.2068, Train accuracy->   2.35%\n","Current batch: Loss-> 2.2241, Train accuracy->   2.36%\n","Current batch: Loss-> 2.2207, Train accuracy->   2.37%\n","Current batch: Loss-> 2.1970, Train accuracy->   2.39%\n","Current batch: Loss-> 2.2331, Train accuracy->   2.39%\n","Current batch: Loss-> 2.1995, Train accuracy->   2.41%\n","Current batch: Loss-> 2.2092, Train accuracy->   2.42%\n","Current batch: Loss-> 2.2018, Train accuracy->   2.44%\n","Current batch: Loss-> 2.1947, Train accuracy->   2.46%\n","Current batch: Loss-> 2.1900, Train accuracy->   2.48%\n","Current batch: Loss-> 2.1954, Train accuracy->   2.50%\n","Current batch: Loss-> 2.2022, Train accuracy->   2.51%\n","Current batch: Loss-> 2.2001, Train accuracy->   2.53%\n","Current batch: Loss-> 2.2018, Train accuracy->   2.54%\n","Current batch: Loss-> 2.1997, Train accuracy->   2.56%\n","Current batch: Loss-> 2.1997, Train accuracy->   2.58%\n","Current batch: Loss-> 2.1957, Train accuracy->   2.60%\n","Current batch: Loss-> 2.1952, Train accuracy->   2.62%\n","Current batch: Loss-> 2.1977, Train accuracy->   2.63%\n","Current batch: Loss-> 2.1989, Train accuracy->   2.64%\n","Current batch: Loss-> 2.1833, Train accuracy->   2.67%\n","Current batch: Loss-> 2.2045, Train accuracy->   2.68%\n","Current batch: Loss-> 2.1749, Train accuracy->   2.71%\n","Current batch: Loss-> 2.2339, Train accuracy->   2.72%\n","Current batch: Loss-> 2.2189, Train accuracy->   2.73%\n","Current batch: Loss-> 2.2043, Train accuracy->   2.74%\n","Current batch: Loss-> 2.1989, Train accuracy->   2.76%\n","Current batch: Loss-> 2.2029, Train accuracy->   2.78%\n","Current batch: Loss-> 2.1921, Train accuracy->   2.80%\n","Current batch: Loss-> 2.2053, Train accuracy->   2.81%\n","Current batch: Loss-> 2.1946, Train accuracy->   2.83%\n","Current batch: Loss-> 2.2206, Train accuracy->   2.84%\n","Current batch: Loss-> 2.1905, Train accuracy->   2.85%\n","Current batch: Loss-> 2.2008, Train accuracy->   2.86%\n","Current batch: Loss-> 2.2026, Train accuracy->   2.88%\n","Current batch: Loss-> 2.1931, Train accuracy->   2.89%\n","Current batch: Loss-> 2.1931, Train accuracy->   2.91%\n","Current batch: Loss-> 2.2087, Train accuracy->   2.92%\n","Current batch: Loss-> 2.1850, Train accuracy->   2.94%\n","Current batch: Loss-> 2.2100, Train accuracy->   2.95%\n","Current batch: Loss-> 2.1990, Train accuracy->   2.96%\n","Current batch: Loss-> 2.1883, Train accuracy->   2.98%\n","Current batch: Loss-> 2.2084, Train accuracy->   2.99%\n","Current batch: Loss-> 2.1942, Train accuracy->   3.01%\n","Current batch: Loss-> 2.1928, Train accuracy->   3.02%\n","Current batch: Loss-> 2.1929, Train accuracy->   3.04%\n","Current batch: Loss-> 2.1940, Train accuracy->   3.05%\n","Current batch: Loss-> 2.2052, Train accuracy->   3.06%\n","Current batch: Loss-> 2.2324, Train accuracy->   3.07%\n","Current batch: Loss-> 2.2148, Train accuracy->   3.07%\n","Current batch: Loss-> 2.1903, Train accuracy->   3.09%\n","Current batch: Loss-> 2.1830, Train accuracy->   3.11%\n","Current batch: Loss-> 2.1760, Train accuracy->   3.13%\n","Current batch: Loss-> 2.1974, Train accuracy->   3.15%\n","Current batch: Loss-> 2.2192, Train accuracy->   3.17%\n","Current batch: Loss-> 2.1810, Train accuracy->   3.18%\n","Current batch: Loss-> 2.2144, Train accuracy->   3.19%\n","Current batch: Loss-> 2.1876, Train accuracy->   3.21%\n","Current batch: Loss-> 2.2000, Train accuracy->   3.22%\n","Current batch: Loss-> 2.1760, Train accuracy->   3.25%\n","Current batch: Loss-> 2.1938, Train accuracy->   3.27%\n","Current batch: Loss-> 2.1831, Train accuracy->   3.30%\n","Current batch: Loss-> 2.1523, Train accuracy->   3.32%\n","Current batch: Loss-> 2.2564, Train accuracy->   3.33%\n","Current batch: Loss-> 2.2036, Train accuracy->   3.35%\n","Current batch: Loss-> 2.2151, Train accuracy->   3.37%\n","Current batch: Loss-> 2.2410, Train accuracy->   3.39%\n","Current batch: Loss-> 2.2283, Train accuracy->   3.41%\n","Current batch: Loss-> 2.1791, Train accuracy->   3.42%\n","Current batch: Loss-> 2.1909, Train accuracy->   3.43%\n","Current batch: Loss-> 2.1927, Train accuracy->   3.45%\n","Current batch: Loss-> 2.1870, Train accuracy->   3.47%\n","Current batch: Loss-> 2.1924, Train accuracy->   3.49%\n","Current batch: Loss-> 2.1899, Train accuracy->   3.50%\n","Current batch: Loss-> 2.1931, Train accuracy->   3.52%\n","Current batch: Loss-> 2.1961, Train accuracy->   3.54%\n","Current batch: Loss-> 2.2027, Train accuracy->   3.54%\n","Current batch: Loss-> 2.1923, Train accuracy->   3.55%\n","Current batch: Loss-> 2.1638, Train accuracy->   3.57%\n","Current batch: Loss-> 2.2104, Train accuracy->   3.59%\n","Current batch: Loss-> 2.2291, Train accuracy->   3.60%\n","Current batch: Loss-> 2.2023, Train accuracy->   3.62%\n","Current batch: Loss-> 2.2033, Train accuracy->   3.65%\n","Current batch: Loss-> 2.2257, Train accuracy->   3.66%\n","Current batch: Loss-> 2.1814, Train accuracy->   3.68%\n","Current batch: Loss-> 2.2240, Train accuracy->   3.70%\n","Current batch: Loss-> 2.2086, Train accuracy->   3.73%\n","Current batch: Loss-> 2.2362, Train accuracy->   3.74%\n","Current batch: Loss-> 2.2314, Train accuracy->   3.75%\n","Current batch: Loss-> 2.2093, Train accuracy->   3.76%\n","Current batch: Loss-> 2.1947, Train accuracy->   3.77%\n","Current batch: Loss-> 2.1634, Train accuracy->   3.80%\n","Current batch: Loss-> 2.1603, Train accuracy->   3.82%\n","Current batch: Loss-> 2.1755, Train accuracy->   3.84%\n","Current batch: Loss-> 2.3026, Train accuracy->   3.85%\n","Current batch: Loss-> 2.2340, Train accuracy->   3.87%\n","Current batch: Loss-> 2.1967, Train accuracy->   3.90%\n","Current batch: Loss-> 2.2086, Train accuracy->   3.91%\n","Current batch: Loss-> 2.2007, Train accuracy->   3.92%\n","Current batch: Loss-> 2.1874, Train accuracy->   3.94%\n","Current batch: Loss-> 2.1917, Train accuracy->   3.94%\n","Current batch: Loss-> 2.1839, Train accuracy->   3.97%\n","Current batch: Loss-> 2.1998, Train accuracy->   3.98%\n","Current batch: Loss-> 2.2056, Train accuracy->   3.99%\n","Current batch: Loss-> 2.1707, Train accuracy->   4.01%\n","Current batch: Loss-> 2.2023, Train accuracy->   4.02%\n","Current batch: Loss-> 2.1649, Train accuracy->   4.04%\n","Current batch: Loss-> 2.1623, Train accuracy->   4.06%\n","Current batch: Loss-> 2.1819, Train accuracy->   4.07%\n","Current batch: Loss-> 2.2005, Train accuracy->   4.08%\n","Current batch: Loss-> 2.1963, Train accuracy->   4.09%\n","Current batch: Loss-> 2.1773, Train accuracy->   4.12%\n","Current batch: Loss-> 2.1667, Train accuracy->   4.14%\n","Current batch: Loss-> 2.1586, Train accuracy->   4.15%\n","Current batch: Loss-> 2.2444, Train accuracy->   4.18%\n","Current batch: Loss-> 2.1949, Train accuracy->   4.19%\n","Current batch: Loss-> 2.1136, Train accuracy->   4.23%\n","Current batch: Loss-> 2.1176, Train accuracy->   4.26%\n","Current batch: Loss-> 2.1216, Train accuracy->   4.29%\n","Current batch: Loss-> 2.2053, Train accuracy->   4.30%\n","Current batch: Loss-> 2.2338, Train accuracy->   4.32%\n","Current batch: Loss-> 2.1747, Train accuracy->   4.33%\n","Current batch: Loss-> 2.1185, Train accuracy->   4.35%\n","Current batch: Loss-> 2.1900, Train accuracy->   4.36%\n","Current batch: Loss-> 2.0923, Train accuracy->   4.38%\n","Current batch: Loss-> 2.2474, Train accuracy->   4.39%\n","Current batch: Loss-> 2.1455, Train accuracy->   4.41%\n","Current batch: Loss-> 2.1394, Train accuracy->   4.42%\n","Current batch: Loss-> 2.0861, Train accuracy->   4.45%\n","Current batch: Loss-> 2.0880, Train accuracy->   4.48%\n","Current batch: Loss-> 2.0868, Train accuracy->   4.50%\n","Current batch: Loss-> 2.1829, Train accuracy->   4.53%\n","Current batch: Loss-> 2.2306, Train accuracy->   4.55%\n","Current batch: Loss-> 2.1662, Train accuracy->   4.56%\n","Current batch: Loss-> 2.1041, Train accuracy->   4.58%\n","Current batch: Loss-> 2.1773, Train accuracy->   4.60%\n","Current batch: Loss-> 2.1469, Train accuracy->   4.61%\n","Current batch: Loss-> 2.1634, Train accuracy->   4.64%\n","Current batch: Loss-> 2.0888, Train accuracy->   4.66%\n","Current batch: Loss-> 2.1469, Train accuracy->   4.68%\n","Current batch: Loss-> 2.2724, Train accuracy->   4.71%\n","Current batch: Loss-> 2.1672, Train accuracy->   4.73%\n","Current batch: Loss-> 2.1132, Train accuracy->   4.75%\n","Current batch: Loss-> 2.2811, Train accuracy->   4.76%\n","Current batch: Loss-> 2.1457, Train accuracy->   4.78%\n","Current batch: Loss-> 2.1200, Train accuracy->   4.81%\n","Current batch: Loss-> 2.1952, Train accuracy->   4.83%\n","Current batch: Loss-> 2.1231, Train accuracy->   4.85%\n","Current batch: Loss-> 2.1739, Train accuracy->   4.87%\n","Current batch: Loss-> 2.1833, Train accuracy->   4.88%\n","Current batch: Loss-> 2.1637, Train accuracy->   4.90%\n","Current batch: Loss-> 2.1202, Train accuracy->   4.93%\n","Current batch: Loss-> 2.1046, Train accuracy->   4.96%\n","Current batch: Loss-> 2.1541, Train accuracy->   4.98%\n","Current batch: Loss-> 2.1543, Train accuracy->   5.00%\n","Current batch: Loss-> 2.0339, Train accuracy->   5.04%\n","Current batch: Loss-> 2.1537, Train accuracy->   5.06%\n","Current batch: Loss-> 2.0662, Train accuracy->   5.09%\n","Current batch: Loss-> 2.1655, Train accuracy->   5.10%\n","Current batch: Loss-> 2.1409, Train accuracy->   5.11%\n","Current batch: Loss-> 2.2409, Train accuracy->   5.13%\n","Current batch: Loss-> 2.0110, Train accuracy->   5.17%\n","Current batch: Loss-> 2.0341, Train accuracy->   5.19%\n","Current batch: Loss-> 2.2750, Train accuracy->   5.20%\n","Current batch: Loss-> 2.1152, Train accuracy->   5.23%\n","Current batch: Loss-> 2.0915, Train accuracy->   5.25%\n","Current batch: Loss-> 2.1471, Train accuracy->   5.26%\n","Current batch: Loss-> 2.0657, Train accuracy->   5.29%\n","Current batch: Loss-> 2.1092, Train accuracy->   5.31%\n","Current batch: Loss-> 2.0976, Train accuracy->   5.34%\n","Current batch: Loss-> 1.9757, Train accuracy->   5.37%\n","Current batch: Loss-> 2.0095, Train accuracy->   5.40%\n","Current batch: Loss-> 2.1749, Train accuracy->   5.41%\n","Current batch: Loss-> 1.9163, Train accuracy->   5.45%\n","Current batch: Loss-> 2.4605, Train accuracy->   5.47%\n","Current batch: Loss-> 1.9891, Train accuracy->   5.51%\n","Current batch: Loss-> 2.0780, Train accuracy->   5.53%\n","Current batch: Loss-> 2.0938, Train accuracy->   5.56%\n","Current batch: Loss-> 2.0609, Train accuracy->   5.58%\n","Current batch: Loss-> 2.0956, Train accuracy->   5.60%\n","Current batch: Loss-> 2.0395, Train accuracy->   5.63%\n","Current batch: Loss-> 2.1457, Train accuracy->   5.66%\n","Current batch: Loss-> 2.1583, Train accuracy->   5.68%\n","Current batch: Loss-> 2.0765, Train accuracy->   5.70%\n","Current batch: Loss-> 2.1123, Train accuracy->   5.71%\n","Current batch: Loss-> 2.1018, Train accuracy->   5.72%\n","Current batch: Loss-> 2.0022, Train accuracy->   5.75%\n","Current batch: Loss-> 2.0571, Train accuracy->   5.77%\n","Current batch: Loss-> 2.1231, Train accuracy->   5.80%\n","Current batch: Loss-> 2.1653, Train accuracy->   5.83%\n","Current batch: Loss-> 2.0589, Train accuracy->   5.86%\n","Current batch: Loss-> 2.0927, Train accuracy->   5.89%\n","Current batch: Loss-> 2.1607, Train accuracy->   5.91%\n","Current batch: Loss-> 2.0299, Train accuracy->   5.94%\n","Current batch: Loss-> 2.1277, Train accuracy->   5.96%\n","Current batch: Loss-> 2.0364, Train accuracy->   6.00%\n","Current batch: Loss-> 2.2374, Train accuracy->   6.02%\n","Current batch: Loss-> 2.0622, Train accuracy->   6.05%\n","Current batch: Loss-> 2.2685, Train accuracy->   6.07%\n","Current batch: Loss-> 2.0920, Train accuracy->   6.09%\n","Current batch: Loss-> 2.1211, Train accuracy->   6.12%\n","Current batch: Loss-> 2.0355, Train accuracy->   6.14%\n","Current batch: Loss-> 2.0644, Train accuracy->   6.17%\n","Current batch: Loss-> 2.0095, Train accuracy->   6.20%\n","Current batch: Loss-> 2.0768, Train accuracy->   6.21%\n","Current batch: Loss-> 1.9387, Train accuracy->   6.25%\n","Current batch: Loss-> 2.0320, Train accuracy->   6.27%\n","Current batch: Loss-> 2.1659, Train accuracy->   6.29%\n","Current batch: Loss-> 2.2258, Train accuracy->   6.31%\n","Current batch: Loss-> 2.0817, Train accuracy->   6.33%\n","Current batch: Loss-> 2.1182, Train accuracy->   6.35%\n","Current batch: Loss-> 2.0897, Train accuracy->   6.37%\n","Current batch: Loss-> 2.0549, Train accuracy->   6.39%\n","Current batch: Loss-> 2.1007, Train accuracy->   6.41%\n","Current batch: Loss-> 2.0939, Train accuracy->   6.42%\n","Current batch: Loss-> 2.0840, Train accuracy->   6.43%\n","Current batch: Loss-> 2.0564, Train accuracy->   6.45%\n","Current batch: Loss-> 1.8997, Train accuracy->   6.49%\n","Current batch: Loss-> 2.0111, Train accuracy->   6.51%\n","Current batch: Loss-> 2.2384, Train accuracy->   6.52%\n","Current batch: Loss-> 1.9607, Train accuracy->   6.55%\n","Current batch: Loss-> 2.2164, Train accuracy->   6.57%\n","Current batch: Loss-> 2.1315, Train accuracy->   6.58%\n","Current batch: Loss-> 1.9257, Train accuracy->   6.62%\n","Current batch: Loss-> 1.9543, Train accuracy->   6.65%\n","Current batch: Loss-> 2.0798, Train accuracy->   6.67%\n","Current batch: Loss-> 2.1431, Train accuracy->   6.70%\n","Current batch: Loss-> 2.1292, Train accuracy->   6.73%\n","Current batch: Loss-> 1.9510, Train accuracy->   6.76%\n","Current batch: Loss-> 2.0711, Train accuracy->   6.80%\n","Current batch: Loss-> 2.0798, Train accuracy->   6.82%\n","Current batch: Loss-> 2.0461, Train accuracy->   6.86%\n","Current batch: Loss-> 1.9156, Train accuracy->   6.89%\n","Current batch: Loss-> 2.0352, Train accuracy->   6.91%\n","Current batch: Loss-> 2.0317, Train accuracy->   6.94%\n","Current batch: Loss-> 2.0218, Train accuracy->   6.97%\n","Current batch: Loss-> 2.0662, Train accuracy->   7.00%\n","Current batch: Loss-> 1.9232, Train accuracy->   7.03%\n","Current batch: Loss-> 2.1751, Train accuracy->   7.05%\n","Current batch: Loss-> 1.9569, Train accuracy->   7.07%\n","Current batch: Loss-> 2.0248, Train accuracy->   7.10%\n","Current batch: Loss-> 2.0631, Train accuracy->   7.12%\n","Current batch: Loss-> 2.0469, Train accuracy->   7.14%\n","Current batch: Loss-> 2.0643, Train accuracy->   7.16%\n","Current batch: Loss-> 2.0554, Train accuracy->   7.19%\n","Current batch: Loss-> 2.0337, Train accuracy->   7.21%\n","Current batch: Loss-> 2.0061, Train accuracy->   7.25%\n","Current batch: Loss-> 2.0666, Train accuracy->   7.27%\n","Current batch: Loss-> 2.0726, Train accuracy->   7.30%\n","Current batch: Loss-> 2.0850, Train accuracy->   7.32%\n","Current batch: Loss-> 2.0963, Train accuracy->   7.35%\n","Current batch: Loss-> 1.9805, Train accuracy->   7.38%\n","Current batch: Loss-> 2.0908, Train accuracy->   7.40%\n","Current batch: Loss-> 2.0941, Train accuracy->   7.42%\n","Current batch: Loss-> 2.0062, Train accuracy->   7.45%\n","Current batch: Loss-> 2.0651, Train accuracy->   7.47%\n","Current batch: Loss-> 1.9165, Train accuracy->   7.50%\n","Current batch: Loss-> 2.0838, Train accuracy->   7.53%\n","Current batch: Loss-> 1.9631, Train accuracy->   7.55%\n","Current batch: Loss-> 2.0082, Train accuracy->   7.58%\n","Current batch: Loss-> 1.9946, Train accuracy->   7.61%\n","Current batch: Loss-> 2.0070, Train accuracy->   7.64%\n","Current batch: Loss-> 2.0149, Train accuracy->   7.68%\n","Current batch: Loss-> 1.9966, Train accuracy->   7.71%\n","Current batch: Loss-> 1.9637, Train accuracy->   7.73%\n","Current batch: Loss-> 2.0300, Train accuracy->   7.76%\n","Current batch: Loss-> 1.9832, Train accuracy->   7.78%\n","Current batch: Loss-> 1.9183, Train accuracy->   7.82%\n","Current batch: Loss-> 1.8926, Train accuracy->   7.85%\n","Current batch: Loss-> 1.9485, Train accuracy->   7.87%\n","Current batch: Loss-> 1.9997, Train accuracy->   7.91%\n","Current batch: Loss-> 2.0829, Train accuracy->   7.93%\n","Current batch: Loss-> 1.8964, Train accuracy->   7.96%\n","Current batch: Loss-> 1.9886, Train accuracy->   7.98%\n","Current batch: Loss-> 1.9428, Train accuracy->   8.02%\n","Current batch: Loss-> 1.9934, Train accuracy->   8.05%\n","Current batch: Loss-> 2.0129, Train accuracy->   8.07%\n","Current batch: Loss-> 2.1569, Train accuracy->   8.09%\n","Current batch: Loss-> 1.9276, Train accuracy->   8.12%\n","Current batch: Loss-> 1.8818, Train accuracy->   8.15%\n","Current batch: Loss-> 1.9150, Train accuracy->   8.19%\n","Current batch: Loss-> 2.0040, Train accuracy->   8.21%\n","Current batch: Loss-> 2.0163, Train accuracy->   8.25%\n","Current batch: Loss-> 2.1048, Train accuracy->   8.27%\n","Current batch: Loss-> 1.9852, Train accuracy->   8.30%\n","Current batch: Loss-> 1.8853, Train accuracy->   8.32%\n","Current batch: Loss-> 2.0882, Train accuracy->   8.36%\n","Current batch: Loss-> 1.9539, Train accuracy->   8.38%\n","Current batch: Loss-> 2.1145, Train accuracy->   8.40%\n","Current batch: Loss-> 1.9238, Train accuracy->   8.42%\n","Current batch: Loss-> 1.9249, Train accuracy->   8.45%\n","Current batch: Loss-> 1.9736, Train accuracy->   8.48%\n","Current batch: Loss-> 2.0197, Train accuracy->   8.50%\n","Current batch: Loss-> 2.0282, Train accuracy->   8.53%\n","Current batch: Loss-> 1.9795, Train accuracy->   8.57%\n","Current batch: Loss-> 2.0045, Train accuracy->   8.59%\n","Current batch: Loss-> 1.8890, Train accuracy->   8.63%\n","Current batch: Loss-> 1.9460, Train accuracy->   8.66%\n","Current batch: Loss-> 2.0434, Train accuracy->   8.69%\n","Current batch: Loss-> 1.8980, Train accuracy->   8.72%\n","Current batch: Loss-> 2.0047, Train accuracy->   8.75%\n","Current batch: Loss-> 2.0868, Train accuracy->   8.77%\n","Current batch: Loss-> 2.0502, Train accuracy->   8.80%\n","Current batch: Loss-> 2.0369, Train accuracy->   8.83%\n","Current batch: Loss-> 1.9606, Train accuracy->   8.85%\n","Current batch: Loss-> 1.9504, Train accuracy->   8.88%\n","Current batch: Loss-> 2.0455, Train accuracy->   8.90%\n","Current batch: Loss-> 2.1125, Train accuracy->   8.93%\n","Current batch: Loss-> 2.1010, Train accuracy->   8.96%\n","Current batch: Loss-> 1.9302, Train accuracy->   9.00%\n","Current batch: Loss-> 2.0182, Train accuracy->   9.02%\n","Current batch: Loss-> 1.9426, Train accuracy->   9.05%\n","Current batch: Loss-> 2.0689, Train accuracy->   9.07%\n","Current batch: Loss-> 2.1096, Train accuracy->   9.09%\n","Current batch: Loss-> 1.8899, Train accuracy->   9.12%\n","Current batch: Loss-> 1.9900, Train accuracy->   9.15%\n","Current batch: Loss-> 1.9242, Train accuracy->   9.19%\n","Current batch: Loss-> 2.0490, Train accuracy->   9.21%\n","Current batch: Loss-> 1.9588, Train accuracy->   9.24%\n","Current batch: Loss-> 1.9557, Train accuracy->   9.26%\n","Current batch: Loss-> 1.9393, Train accuracy->   9.29%\n","Current batch: Loss-> 1.9865, Train accuracy->   9.32%\n","Current batch: Loss-> 1.9864, Train accuracy->   9.34%\n","Current batch: Loss-> 2.0395, Train accuracy->   9.36%\n","Current batch: Loss-> 1.9515, Train accuracy->   9.39%\n","Current batch: Loss-> 1.8492, Train accuracy->   9.43%\n","Current batch: Loss-> 2.0790, Train accuracy->   9.46%\n","Current batch: Loss-> 1.9887, Train accuracy->   9.48%\n","Current batch: Loss-> 2.0719, Train accuracy->   9.51%\n","Current batch: Loss-> 1.9906, Train accuracy->   9.52%\n","Current batch: Loss-> 1.9497, Train accuracy->   9.56%\n","Current batch: Loss-> 2.1202, Train accuracy->   9.58%\n","Current batch: Loss-> 1.9331, Train accuracy->   9.61%\n","Current batch: Loss-> 2.0006, Train accuracy->   9.64%\n","Current batch: Loss-> 1.9127, Train accuracy->   9.68%\n","Current batch: Loss-> 2.0257, Train accuracy->   9.70%\n","Current batch: Loss-> 2.0524, Train accuracy->   9.72%\n","Current batch: Loss-> 1.9296, Train accuracy->   9.75%\n","Current batch: Loss-> 2.0695, Train accuracy->   9.77%\n","Current batch: Loss-> 1.9426, Train accuracy->   9.81%\n","Current batch: Loss-> 1.9594, Train accuracy->   9.84%\n","Current batch: Loss-> 1.9969, Train accuracy->   9.85%\n","Current batch: Loss-> 2.3831, Train accuracy->   9.87%\n","Current batch: Loss-> 1.8875, Train accuracy->   9.92%\n","Current batch: Loss-> 1.9161, Train accuracy->   9.96%\n","Current batch: Loss-> 1.9277, Train accuracy->   9.99%\n","Current batch: Loss-> 2.0169, Train accuracy->  10.01%\n","Current batch: Loss-> 2.0398, Train accuracy->  10.04%\n","Current batch: Loss-> 1.8345, Train accuracy->  10.08%\n","Current batch: Loss-> 2.0639, Train accuracy->  10.10%\n","Current batch: Loss-> 1.9068, Train accuracy->  10.13%\n","Current batch: Loss-> 2.0393, Train accuracy->  10.16%\n","Current batch: Loss-> 1.8762, Train accuracy->  10.19%\n","Current batch: Loss-> 1.9596, Train accuracy->  10.22%\n","Current batch: Loss-> 1.9785, Train accuracy->  10.24%\n","Current batch: Loss-> 1.9208, Train accuracy->  10.27%\n","Current batch: Loss-> 1.9867, Train accuracy->  10.29%\n","Current batch: Loss-> 1.9330, Train accuracy->  10.33%\n","Current batch: Loss-> 1.9484, Train accuracy->  10.36%\n","Current batch: Loss-> 2.2551, Train accuracy->  10.38%\n","Current batch: Loss-> 1.9497, Train accuracy->  10.41%\n","Current batch: Loss-> 1.8775, Train accuracy->  10.44%\n","Current batch: Loss-> 1.9016, Train accuracy->  10.47%\n","Current batch: Loss-> 1.9459, Train accuracy->  10.50%\n","Current batch: Loss-> 1.9633, Train accuracy->  10.53%\n","Current batch: Loss-> 1.9569, Train accuracy->  10.55%\n","Current batch: Loss-> 1.9847, Train accuracy->  10.58%\n","Current batch: Loss-> 2.0482, Train accuracy->  10.61%\n","Current batch: Loss-> 2.0910, Train accuracy->  10.64%\n","Current batch: Loss-> 1.8437, Train accuracy->  10.67%\n","Current batch: Loss-> 2.0416, Train accuracy->  10.70%\n","Current batch: Loss-> 1.9185, Train accuracy->  10.73%\n","Current batch: Loss-> 1.9761, Train accuracy->  10.76%\n","Current batch: Loss-> 1.9780, Train accuracy->  10.78%\n","Current batch: Loss-> 2.0366, Train accuracy->  10.81%\n","Current batch: Loss-> 1.9172, Train accuracy->  10.82%\n","Current batch: Loss-> 1.9658, Train accuracy->  10.85%\n","Current batch: Loss-> 1.8656, Train accuracy->  10.88%\n","Current batch: Loss-> 1.8767, Train accuracy->  10.91%\n","Current batch: Loss-> 1.8947, Train accuracy->  10.94%\n","Current batch: Loss-> 2.0543, Train accuracy->  10.97%\n","Current batch: Loss-> 1.8863, Train accuracy->  11.00%\n","Current batch: Loss-> 1.9473, Train accuracy->  11.02%\n","Current batch: Loss-> 1.7990, Train accuracy->  11.05%\n","Current batch: Loss-> 1.8789, Train accuracy->  11.07%\n","Current batch: Loss-> 1.9971, Train accuracy->  11.10%\n","Current batch: Loss-> 2.0746, Train accuracy->  11.13%\n","Current batch: Loss-> 1.9260, Train accuracy->  11.14%\n","Current batch: Loss-> 1.9573, Train accuracy->  11.18%\n","Current batch: Loss-> 1.8790, Train accuracy->  11.21%\n","Current batch: Loss-> 1.8558, Train accuracy->  11.24%\n","Current batch: Loss-> 2.0660, Train accuracy->  11.25%\n","Current batch: Loss-> 2.0100, Train accuracy->  11.27%\n","Current batch: Loss-> 1.7991, Train accuracy->  11.31%\n","Current batch: Loss-> 2.0270, Train accuracy->  11.35%\n","Current batch: Loss-> 1.9386, Train accuracy->  11.38%\n","Current batch: Loss-> 2.0860, Train accuracy->  11.40%\n","Current batch: Loss-> 1.8954, Train accuracy->  11.43%\n","Current batch: Loss-> 1.9831, Train accuracy->  11.46%\n","Current batch: Loss-> 1.9334, Train accuracy->  11.49%\n","Current batch: Loss-> 1.9771, Train accuracy->  11.51%\n","Current batch: Loss-> 1.9829, Train accuracy->  11.54%\n","Current batch: Loss-> 1.8260, Train accuracy->  11.57%\n","Current batch: Loss-> 1.9453, Train accuracy->  11.60%\n","Current batch: Loss-> 1.8606, Train accuracy->  11.62%\n","Current batch: Loss-> 2.0478, Train accuracy->  11.65%\n","Current batch: Loss-> 2.0423, Train accuracy->  11.68%\n","Current batch: Loss-> 1.9877, Train accuracy->  11.70%\n","Current batch: Loss-> 1.9395, Train accuracy->  11.72%\n","Current batch: Loss-> 1.9611, Train accuracy->  11.74%\n","Current batch: Loss-> 1.8685, Train accuracy->  11.78%\n","Current batch: Loss-> 1.9070, Train accuracy->  11.82%\n","Current batch: Loss-> 1.8795, Train accuracy->  11.85%\n","Current batch: Loss-> 2.0282, Train accuracy->  11.87%\n","Current batch: Loss-> 1.8126, Train accuracy->  11.90%\n","Current batch: Loss-> 1.8146, Train accuracy->  11.94%\n","Current batch: Loss-> 2.1223, Train accuracy->  11.96%\n","Current batch: Loss-> 2.0008, Train accuracy->  11.99%\n","Current batch: Loss-> 2.0127, Train accuracy->  12.01%\n","Current batch: Loss-> 2.0134, Train accuracy->  12.04%\n","Current batch: Loss-> 1.9676, Train accuracy->  12.05%\n","Current batch: Loss-> 1.8696, Train accuracy->  12.09%\n","Current batch: Loss-> 2.0488, Train accuracy->  12.11%\n","Current batch: Loss-> 2.0114, Train accuracy->  12.12%\n","Current batch: Loss-> 1.8803, Train accuracy->  12.16%\n","Current batch: Loss-> 1.9575, Train accuracy->  12.19%\n","Current batch: Loss-> 2.0730, Train accuracy->  12.20%\n","Current batch: Loss-> 1.9835, Train accuracy->  12.23%\n","Current batch: Loss-> 2.1301, Train accuracy->  12.25%\n","Current batch: Loss-> 1.9858, Train accuracy->  12.27%\n","Current batch: Loss-> 1.9310, Train accuracy->  12.28%\n","Current batch: Loss-> 1.9514, Train accuracy->  12.32%\n","Current batch: Loss-> 1.9469, Train accuracy->  12.35%\n","Current batch: Loss-> 1.9540, Train accuracy->  12.39%\n","Current batch: Loss-> 1.9252, Train accuracy->  12.42%\n","Current batch: Loss-> 1.9483, Train accuracy->  12.44%\n","Current batch: Loss-> 1.9460, Train accuracy->  12.46%\n","Current batch: Loss-> 1.9204, Train accuracy->  12.49%\n","Current batch: Loss-> 1.9229, Train accuracy->  12.52%\n","Current batch: Loss-> 1.8524, Train accuracy->  12.55%\n","Current batch: Loss-> 1.7767, Train accuracy->  12.60%\n","Current batch: Loss-> 1.9453, Train accuracy->  12.62%\n","Current batch: Loss-> 1.9669, Train accuracy->  12.64%\n","Current batch: Loss-> 2.0103, Train accuracy->  12.67%\n","Current batch: Loss-> 2.0575, Train accuracy->  12.70%\n","Current batch: Loss-> 2.0397, Train accuracy->  12.72%\n","Current batch: Loss-> 1.8630, Train accuracy->  12.75%\n","Current batch: Loss-> 2.0168, Train accuracy->  12.77%\n","Current batch: Loss-> 2.0052, Train accuracy->  12.79%\n","Current batch: Loss-> 2.0727, Train accuracy->  12.81%\n","Current batch: Loss-> 1.8961, Train accuracy->  12.84%\n","Current batch: Loss-> 1.9938, Train accuracy->  12.87%\n","Current batch: Loss-> 2.0068, Train accuracy->  12.91%\n","Current batch: Loss-> 1.9979, Train accuracy->  12.94%\n","Current batch: Loss-> 2.0033, Train accuracy->  12.97%\n","Current batch: Loss-> 1.9998, Train accuracy->  13.00%\n","Current batch: Loss-> 2.0098, Train accuracy->  13.02%\n","Current batch: Loss-> 1.9177, Train accuracy->  13.05%\n","Current batch: Loss-> 1.9448, Train accuracy->  13.07%\n","Current batch: Loss-> 1.9544, Train accuracy->  13.11%\n","Current batch: Loss-> 1.9203, Train accuracy->  13.15%\n","Current batch: Loss-> 1.8424, Train accuracy->  13.19%\n","Current batch: Loss-> 1.8849, Train accuracy->  13.21%\n","Current batch: Loss-> 1.8949, Train accuracy->  13.25%\n","Current batch: Loss-> 2.0498, Train accuracy->  13.27%\n","Current batch: Loss-> 1.9851, Train accuracy->  13.29%\n","Current batch: Loss-> 1.9470, Train accuracy->  13.31%\n","Current batch: Loss-> 2.0165, Train accuracy->  13.33%\n","Current batch: Loss-> 2.0257, Train accuracy->  13.36%\n","Current batch: Loss-> 2.0073, Train accuracy->  13.39%\n","Current batch: Loss-> 1.7726, Train accuracy->  13.44%\n","Current batch: Loss-> 1.9751, Train accuracy->  13.47%\n","Current batch: Loss-> 1.8827, Train accuracy->  13.49%\n","Current batch: Loss-> 1.9300, Train accuracy->  13.52%\n","Current batch: Loss-> 2.0410, Train accuracy->  13.54%\n","Current batch: Loss-> 1.9511, Train accuracy->  13.56%\n","Current batch: Loss-> 1.9957, Train accuracy->  13.59%\n","Current batch: Loss-> 1.8958, Train accuracy->  13.61%\n","Current batch: Loss-> 2.0506, Train accuracy->  13.63%\n","Current batch: Loss-> 2.0493, Train accuracy->  13.65%\n","Current batch: Loss-> 1.9855, Train accuracy->  13.67%\n","Current batch: Loss-> 1.9681, Train accuracy->  13.70%\n","Current batch: Loss-> 2.0216, Train accuracy->  13.73%\n","Current batch: Loss-> 1.9297, Train accuracy->  13.75%\n","Current batch: Loss-> 1.8781, Train accuracy->  13.77%\n","Current batch: Loss-> 1.9102, Train accuracy->  13.80%\n","Current batch: Loss-> 1.9350, Train accuracy->  13.83%\n","Current batch: Loss-> 1.9090, Train accuracy->  13.88%\n","Current batch: Loss-> 2.0398, Train accuracy->  13.91%\n","Current batch: Loss-> 1.9049, Train accuracy->  13.95%\n","Current batch: Loss-> 1.9454, Train accuracy->  13.96%\n","Current batch: Loss-> 2.0000, Train accuracy->  13.99%\n","Current batch: Loss-> 2.0096, Train accuracy->  14.02%\n","Current batch: Loss-> 1.9577, Train accuracy->  14.05%\n","Current batch: Loss-> 1.9523, Train accuracy->  14.08%\n","Current batch: Loss-> 1.9947, Train accuracy->  14.11%\n","Current batch: Loss-> 1.9462, Train accuracy->  14.14%\n","Current batch: Loss-> 1.8297, Train accuracy->  14.18%\n","Current batch: Loss-> 1.9822, Train accuracy->  14.21%\n","Current batch: Loss-> 1.8957, Train accuracy->  14.24%\n","Current batch: Loss-> 1.9366, Train accuracy->  14.26%\n","Current batch: Loss-> 1.9961, Train accuracy->  14.28%\n","Current batch: Loss-> 1.8398, Train accuracy->  14.31%\n","Current batch: Loss-> 1.7848, Train accuracy->  14.33%\n","Current batch: Loss-> 1.9186, Train accuracy->  14.36%\n","Current batch: Loss-> 1.7470, Train accuracy->  14.41%\n","Current batch: Loss-> 1.9621, Train accuracy->  14.44%\n","Current batch: Loss-> 1.9042, Train accuracy->  14.47%\n","Current batch: Loss-> 1.9062, Train accuracy->  14.50%\n","Current batch: Loss-> 1.8436, Train accuracy->  14.53%\n","Current batch: Loss-> 1.8181, Train accuracy->  14.56%\n","Current batch: Loss-> 1.9683, Train accuracy->  14.58%\n","Current batch: Loss-> 1.9219, Train accuracy->  14.61%\n","Current batch: Loss-> 1.7394, Train accuracy->  14.65%\n","Current batch: Loss-> 1.9454, Train accuracy->  14.68%\n","Current batch: Loss-> 1.8295, Train accuracy->  14.71%\n","Current batch: Loss-> 1.9074, Train accuracy->  14.74%\n","Current batch: Loss-> 1.9392, Train accuracy->  14.77%\n","Current batch: Loss-> 1.9000, Train accuracy->  14.79%\n","Current batch: Loss-> 1.8621, Train accuracy->  14.82%\n","Current batch: Loss-> 1.7350, Train accuracy->  14.85%\n","Current batch: Loss-> 2.1669, Train accuracy->  14.87%\n","Current batch: Loss-> 2.0645, Train accuracy->  14.90%\n","Current batch: Loss-> 1.8426, Train accuracy->  14.93%\n","Current batch: Loss-> 1.9463, Train accuracy->  14.95%\n","Current batch: Loss-> 1.9888, Train accuracy->  14.97%\n","Current batch: Loss-> 1.8985, Train accuracy->  15.00%\n","Current batch: Loss-> 1.9293, Train accuracy->  15.01%\n","Current batch: Loss-> 1.8858, Train accuracy->  15.04%\n","Current batch: Loss-> 2.0812, Train accuracy->  15.07%\n","Current batch: Loss-> 1.8957, Train accuracy->  15.09%\n","Current batch: Loss-> 1.8723, Train accuracy->  15.12%\n","Current batch: Loss-> 1.9188, Train accuracy->  15.14%\n","Current batch: Loss-> 2.0942, Train accuracy->  15.16%\n","Current batch: Loss-> 1.9748, Train accuracy->  15.20%\n","Current batch: Loss-> 2.0030, Train accuracy->  15.22%\n","Current batch: Loss-> 1.8158, Train accuracy->  15.26%\n","Current batch: Loss-> 1.8500, Train accuracy->  15.30%\n","Current batch: Loss-> 1.9422, Train accuracy->  15.32%\n","Current batch: Loss-> 1.7947, Train accuracy->  15.34%\n","Current batch: Loss-> 1.8798, Train accuracy->  15.37%\n","Current batch: Loss-> 1.9589, Train accuracy->  15.40%\n","Current batch: Loss-> 2.0540, Train accuracy->  15.43%\n","Current batch: Loss-> 1.8826, Train accuracy->  15.46%\n","Current batch: Loss-> 1.8776, Train accuracy->  15.50%\n","Current batch: Loss-> 1.7224, Train accuracy->  15.55%\n","Current batch: Loss-> 1.8507, Train accuracy->  15.57%\n","Current batch: Loss-> 1.9022, Train accuracy->  15.60%\n","Current batch: Loss-> 1.9899, Train accuracy->  15.62%\n","Current batch: Loss-> 1.8413, Train accuracy->  15.66%\n","Current batch: Loss-> 1.9640, Train accuracy->  15.69%\n","Current batch: Loss-> 1.8337, Train accuracy->  15.72%\n","Current batch: Loss-> 2.1114, Train accuracy->  15.75%\n","Current batch: Loss-> 1.8912, Train accuracy->  15.77%\n","Current batch: Loss-> 1.9015, Train accuracy->  15.80%\n","Current batch: Loss-> 1.8470, Train accuracy->  15.84%\n","Current batch: Loss-> 1.8070, Train accuracy->  15.87%\n","Current batch: Loss-> 1.7581, Train accuracy->  15.91%\n","Current batch: Loss-> 1.9954, Train accuracy->  15.94%\n","Current batch: Loss-> 1.9811, Train accuracy->  15.95%\n","Current batch: Loss-> 1.9729, Train accuracy->  15.98%\n","Current batch: Loss-> 1.8479, Train accuracy->  16.00%\n","Current batch: Loss-> 1.8577, Train accuracy->  16.04%\n","Current batch: Loss-> 1.8734, Train accuracy->  16.07%\n","Current batch: Loss-> 2.0024, Train accuracy->  16.08%\n","Current batch: Loss-> 1.9315, Train accuracy->  16.10%\n","Current batch: Loss-> 2.0732, Train accuracy->  16.12%\n","Current batch: Loss-> 1.8919, Train accuracy->  16.15%\n","Current batch: Loss-> 1.8707, Train accuracy->  16.20%\n","Current batch: Loss-> 1.9818, Train accuracy->  16.23%\n","Current batch: Loss-> 1.9314, Train accuracy->  16.26%\n","Current batch: Loss-> 1.8771, Train accuracy->  16.28%\n","Current batch: Loss-> 1.9171, Train accuracy->  16.31%\n","Current batch: Loss-> 1.9124, Train accuracy->  16.35%\n","Current batch: Loss-> 1.8281, Train accuracy->  16.38%\n","Current batch: Loss-> 1.9728, Train accuracy->  16.41%\n","Current batch: Loss-> 1.9509, Train accuracy->  16.45%\n","Current batch: Loss-> 1.9316, Train accuracy->  16.48%\n","Current batch: Loss-> 1.9037, Train accuracy->  16.50%\n","Current batch: Loss-> 1.6768, Train accuracy->  16.54%\n","Current batch: Loss-> 1.7722, Train accuracy->  16.58%\n","Current batch: Loss-> 1.9862, Train accuracy->  16.60%\n","Current batch: Loss-> 1.8004, Train accuracy->  16.64%\n","Current batch: Loss-> 1.7971, Train accuracy->  16.67%\n","Current batch: Loss-> 1.8586, Train accuracy->  16.70%\n","Current batch: Loss-> 1.9574, Train accuracy->  16.73%\n","Current batch: Loss-> 1.8829, Train accuracy->  16.75%\n","Current batch: Loss-> 1.8557, Train accuracy->  16.78%\n","Current batch: Loss-> 1.9907, Train accuracy->  16.80%\n","Current batch: Loss-> 1.7797, Train accuracy->  16.84%\n","Current batch: Loss-> 1.8529, Train accuracy->  16.86%\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/188 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.8586, Train accuracy->  16.89%\n","Current batch: Loss-> 1.9292, Train accuracy->  16.92%\n","Current batch: Loss-> 1.8334, Train accuracy->  16.95%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.98it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.8487, Accuracy: 2958/12000 (25%)\n","\n","Current batch: Loss-> 1.9340, Train accuracy->   0.03%\n","Current batch: Loss-> 1.9836, Train accuracy->   0.05%\n","Current batch: Loss-> 1.8671, Train accuracy->   0.07%\n","Current batch: Loss-> 1.9136, Train accuracy->   0.09%\n","Current batch: Loss-> 1.9517, Train accuracy->   0.11%\n","Current batch: Loss-> 1.8131, Train accuracy->   0.14%\n","Current batch: Loss-> 1.8272, Train accuracy->   0.18%\n","Current batch: Loss-> 1.8898, Train accuracy->   0.20%\n","Current batch: Loss-> 1.8638, Train accuracy->   0.23%\n","Current batch: Loss-> 1.9202, Train accuracy->   0.27%\n","Current batch: Loss-> 1.8832, Train accuracy->   0.31%\n","Current batch: Loss-> 1.8806, Train accuracy->   0.34%\n","Current batch: Loss-> 1.7971, Train accuracy->   0.37%\n","Current batch: Loss-> 1.9194, Train accuracy->   0.40%\n","Current batch: Loss-> 1.8924, Train accuracy->   0.43%\n","Current batch: Loss-> 1.6484, Train accuracy->   0.48%\n","Current batch: Loss-> 1.7734, Train accuracy->   0.51%\n","Current batch: Loss-> 1.8538, Train accuracy->   0.55%\n","Current batch: Loss-> 1.9309, Train accuracy->   0.58%\n","Current batch: Loss-> 1.8079, Train accuracy->   0.61%\n","Current batch: Loss-> 1.8288, Train accuracy->   0.64%\n","Current batch: Loss-> 1.7311, Train accuracy->   0.67%\n","Current batch: Loss-> 1.8950, Train accuracy->   0.69%\n","Current batch: Loss-> 2.0387, Train accuracy->   0.70%\n","Current batch: Loss-> 1.9143, Train accuracy->   0.73%\n","Current batch: Loss-> 1.8497, Train accuracy->   0.77%\n","Current batch: Loss-> 1.8758, Train accuracy->   0.79%\n","Current batch: Loss-> 1.9455, Train accuracy->   0.82%\n","Current batch: Loss-> 1.9353, Train accuracy->   0.85%\n","Current batch: Loss-> 1.8628, Train accuracy->   0.88%\n","Current batch: Loss-> 1.8547, Train accuracy->   0.90%\n","Current batch: Loss-> 1.9682, Train accuracy->   0.94%\n","Current batch: Loss-> 1.9363, Train accuracy->   0.96%\n","Current batch: Loss-> 1.8484, Train accuracy->   1.00%\n","Current batch: Loss-> 1.8710, Train accuracy->   1.03%\n","Current batch: Loss-> 1.8641, Train accuracy->   1.06%\n","Current batch: Loss-> 1.9658, Train accuracy->   1.07%\n","Current batch: Loss-> 1.8889, Train accuracy->   1.09%\n","Current batch: Loss-> 1.8628, Train accuracy->   1.12%\n","Current batch: Loss-> 1.9373, Train accuracy->   1.15%\n","Current batch: Loss-> 1.9417, Train accuracy->   1.18%\n","Current batch: Loss-> 1.8284, Train accuracy->   1.22%\n","Current batch: Loss-> 1.8421, Train accuracy->   1.25%\n","Current batch: Loss-> 1.8703, Train accuracy->   1.27%\n","Current batch: Loss-> 1.9373, Train accuracy->   1.30%\n","Current batch: Loss-> 1.7796, Train accuracy->   1.33%\n","Current batch: Loss-> 1.8371, Train accuracy->   1.37%\n","Current batch: Loss-> 1.9879, Train accuracy->   1.40%\n","Current batch: Loss-> 1.8418, Train accuracy->   1.43%\n","Current batch: Loss-> 1.7475, Train accuracy->   1.47%\n","Current batch: Loss-> 1.8386, Train accuracy->   1.49%\n","Current batch: Loss-> 1.8420, Train accuracy->   1.53%\n","Current batch: Loss-> 2.0291, Train accuracy->   1.55%\n","Current batch: Loss-> 1.9165, Train accuracy->   1.58%\n","Current batch: Loss-> 1.9363, Train accuracy->   1.61%\n","Current batch: Loss-> 1.9064, Train accuracy->   1.65%\n","Current batch: Loss-> 1.8127, Train accuracy->   1.68%\n","Current batch: Loss-> 2.0795, Train accuracy->   1.69%\n","Current batch: Loss-> 2.0117, Train accuracy->   1.72%\n","Current batch: Loss-> 1.8361, Train accuracy->   1.75%\n","Current batch: Loss-> 1.7610, Train accuracy->   1.78%\n","Current batch: Loss-> 2.0107, Train accuracy->   1.81%\n","Current batch: Loss-> 1.9103, Train accuracy->   1.85%\n","Current batch: Loss-> 1.7117, Train accuracy->   1.90%\n","Current batch: Loss-> 1.7670, Train accuracy->   1.94%\n","Current batch: Loss-> 1.8828, Train accuracy->   1.99%\n","Current batch: Loss-> 1.9280, Train accuracy->   2.00%\n","Current batch: Loss-> 1.8599, Train accuracy->   2.03%\n","Current batch: Loss-> 1.8395, Train accuracy->   2.06%\n","Current batch: Loss-> 1.9884, Train accuracy->   2.08%\n","Current batch: Loss-> 2.0411, Train accuracy->   2.11%\n","Current batch: Loss-> 2.1799, Train accuracy->   2.12%\n","Current batch: Loss-> 1.8504, Train accuracy->   2.16%\n","Current batch: Loss-> 1.7346, Train accuracy->   2.20%\n","Current batch: Loss-> 1.7666, Train accuracy->   2.22%\n","Current batch: Loss-> 1.8002, Train accuracy->   2.26%\n","Current batch: Loss-> 1.9259, Train accuracy->   2.29%\n","Current batch: Loss-> 1.8395, Train accuracy->   2.33%\n","Current batch: Loss-> 1.9042, Train accuracy->   2.37%\n","Current batch: Loss-> 1.8742, Train accuracy->   2.41%\n","Current batch: Loss-> 1.8755, Train accuracy->   2.44%\n","Current batch: Loss-> 1.8097, Train accuracy->   2.47%\n","Current batch: Loss-> 2.0642, Train accuracy->   2.49%\n","Current batch: Loss-> 1.7683, Train accuracy->   2.54%\n","Current batch: Loss-> 1.7530, Train accuracy->   2.58%\n","Current batch: Loss-> 1.8445, Train accuracy->   2.61%\n","Current batch: Loss-> 1.8217, Train accuracy->   2.65%\n","Current batch: Loss-> 1.8737, Train accuracy->   2.68%\n","Current batch: Loss-> 1.8005, Train accuracy->   2.71%\n","Current batch: Loss-> 1.7878, Train accuracy->   2.75%\n","Current batch: Loss-> 1.7556, Train accuracy->   2.78%\n","Current batch: Loss-> 1.8619, Train accuracy->   2.81%\n","Current batch: Loss-> 1.9845, Train accuracy->   2.84%\n","Current batch: Loss-> 1.8946, Train accuracy->   2.87%\n","Current batch: Loss-> 2.0414, Train accuracy->   2.90%\n","Current batch: Loss-> 1.7440, Train accuracy->   2.94%\n","Current batch: Loss-> 1.9486, Train accuracy->   2.96%\n","Current batch: Loss-> 1.8746, Train accuracy->   2.99%\n","Current batch: Loss-> 1.9101, Train accuracy->   3.02%\n","Current batch: Loss-> 1.9401, Train accuracy->   3.05%\n","Current batch: Loss-> 1.9328, Train accuracy->   3.08%\n","Current batch: Loss-> 1.8791, Train accuracy->   3.11%\n","Current batch: Loss-> 1.8589, Train accuracy->   3.13%\n","Current batch: Loss-> 1.8832, Train accuracy->   3.17%\n","Current batch: Loss-> 1.8968, Train accuracy->   3.19%\n","Current batch: Loss-> 1.8550, Train accuracy->   3.21%\n","Current batch: Loss-> 1.8334, Train accuracy->   3.26%\n","Current batch: Loss-> 1.8376, Train accuracy->   3.29%\n","Current batch: Loss-> 1.9269, Train accuracy->   3.32%\n","Current batch: Loss-> 1.9636, Train accuracy->   3.34%\n","Current batch: Loss-> 1.7747, Train accuracy->   3.38%\n","Current batch: Loss-> 1.9395, Train accuracy->   3.42%\n","Current batch: Loss-> 1.7105, Train accuracy->   3.45%\n","Current batch: Loss-> 1.8190, Train accuracy->   3.48%\n","Current batch: Loss-> 1.8142, Train accuracy->   3.52%\n","Current batch: Loss-> 1.9100, Train accuracy->   3.55%\n","Current batch: Loss-> 1.9284, Train accuracy->   3.58%\n","Current batch: Loss-> 1.8574, Train accuracy->   3.60%\n","Current batch: Loss-> 1.8441, Train accuracy->   3.63%\n","Current batch: Loss-> 1.8078, Train accuracy->   3.65%\n","Current batch: Loss-> 1.7999, Train accuracy->   3.69%\n","Current batch: Loss-> 1.8801, Train accuracy->   3.74%\n","Current batch: Loss-> 1.8482, Train accuracy->   3.76%\n","Current batch: Loss-> 1.9336, Train accuracy->   3.78%\n","Current batch: Loss-> 1.7922, Train accuracy->   3.82%\n","Current batch: Loss-> 1.8957, Train accuracy->   3.86%\n","Current batch: Loss-> 2.0490, Train accuracy->   3.89%\n","Current batch: Loss-> 1.7653, Train accuracy->   3.93%\n","Current batch: Loss-> 1.8910, Train accuracy->   3.96%\n","Current batch: Loss-> 1.9412, Train accuracy->   3.98%\n","Current batch: Loss-> 1.8012, Train accuracy->   4.01%\n","Current batch: Loss-> 1.9218, Train accuracy->   4.03%\n","Current batch: Loss-> 1.7297, Train accuracy->   4.07%\n","Current batch: Loss-> 1.7657, Train accuracy->   4.10%\n","Current batch: Loss-> 1.7773, Train accuracy->   4.14%\n","Current batch: Loss-> 1.7874, Train accuracy->   4.17%\n","Current batch: Loss-> 1.8935, Train accuracy->   4.21%\n","Current batch: Loss-> 1.7155, Train accuracy->   4.25%\n","Current batch: Loss-> 1.8754, Train accuracy->   4.28%\n","Current batch: Loss-> 1.8117, Train accuracy->   4.32%\n","Current batch: Loss-> 1.9091, Train accuracy->   4.35%\n","Current batch: Loss-> 1.8268, Train accuracy->   4.38%\n","Current batch: Loss-> 1.7846, Train accuracy->   4.41%\n","Current batch: Loss-> 1.9473, Train accuracy->   4.43%\n","Current batch: Loss-> 1.9455, Train accuracy->   4.46%\n","Current batch: Loss-> 1.8327, Train accuracy->   4.50%\n","Current batch: Loss-> 1.8472, Train accuracy->   4.54%\n","Current batch: Loss-> 1.8072, Train accuracy->   4.57%\n","Current batch: Loss-> 1.7604, Train accuracy->   4.61%\n","Current batch: Loss-> 1.8486, Train accuracy->   4.64%\n","Current batch: Loss-> 1.9863, Train accuracy->   4.66%\n","Current batch: Loss-> 1.9293, Train accuracy->   4.69%\n","Current batch: Loss-> 1.8056, Train accuracy->   4.72%\n","Current batch: Loss-> 1.7403, Train accuracy->   4.75%\n","Current batch: Loss-> 1.8312, Train accuracy->   4.79%\n","Current batch: Loss-> 1.8642, Train accuracy->   4.82%\n","Current batch: Loss-> 1.8484, Train accuracy->   4.86%\n","Current batch: Loss-> 1.7905, Train accuracy->   4.89%\n","Current batch: Loss-> 1.8983, Train accuracy->   4.93%\n","Current batch: Loss-> 1.9386, Train accuracy->   4.95%\n","Current batch: Loss-> 1.9094, Train accuracy->   4.98%\n","Current batch: Loss-> 1.8940, Train accuracy->   5.02%\n","Current batch: Loss-> 1.6853, Train accuracy->   5.06%\n","Current batch: Loss-> 1.8761, Train accuracy->   5.08%\n","Current batch: Loss-> 1.7712, Train accuracy->   5.12%\n","Current batch: Loss-> 1.7750, Train accuracy->   5.16%\n","Current batch: Loss-> 1.8233, Train accuracy->   5.20%\n","Current batch: Loss-> 1.9504, Train accuracy->   5.23%\n","Current batch: Loss-> 1.7941, Train accuracy->   5.27%\n","Current batch: Loss-> 1.8885, Train accuracy->   5.30%\n","Current batch: Loss-> 1.7471, Train accuracy->   5.34%\n","Current batch: Loss-> 1.8492, Train accuracy->   5.37%\n","Current batch: Loss-> 1.9087, Train accuracy->   5.41%\n","Current batch: Loss-> 1.8597, Train accuracy->   5.45%\n","Current batch: Loss-> 1.7670, Train accuracy->   5.49%\n","Current batch: Loss-> 1.9108, Train accuracy->   5.53%\n","Current batch: Loss-> 1.8497, Train accuracy->   5.57%\n","Current batch: Loss-> 1.8435, Train accuracy->   5.60%\n","Current batch: Loss-> 1.9829, Train accuracy->   5.64%\n","Current batch: Loss-> 1.8833, Train accuracy->   5.66%\n","Current batch: Loss-> 1.7902, Train accuracy->   5.69%\n","Current batch: Loss-> 2.1004, Train accuracy->   5.72%\n","Current batch: Loss-> 1.7351, Train accuracy->   5.74%\n","Current batch: Loss-> 1.6479, Train accuracy->   5.79%\n","Current batch: Loss-> 1.8843, Train accuracy->   5.82%\n","Current batch: Loss-> 1.8367, Train accuracy->   5.86%\n","Current batch: Loss-> 1.7409, Train accuracy->   5.90%\n","Current batch: Loss-> 2.0092, Train accuracy->   5.92%\n","Current batch: Loss-> 1.6965, Train accuracy->   5.97%\n","Current batch: Loss-> 1.8533, Train accuracy->   6.01%\n","Current batch: Loss-> 1.8659, Train accuracy->   6.04%\n","Current batch: Loss-> 1.8405, Train accuracy->   6.07%\n","Current batch: Loss-> 1.9047, Train accuracy->   6.10%\n","Current batch: Loss-> 1.8452, Train accuracy->   6.13%\n","Current batch: Loss-> 1.7716, Train accuracy->   6.16%\n","Current batch: Loss-> 1.8309, Train accuracy->   6.19%\n","Current batch: Loss-> 1.8516, Train accuracy->   6.23%\n","Current batch: Loss-> 1.8574, Train accuracy->   6.28%\n","Current batch: Loss-> 1.7797, Train accuracy->   6.31%\n","Current batch: Loss-> 1.8019, Train accuracy->   6.35%\n","Current batch: Loss-> 1.7838, Train accuracy->   6.38%\n","Current batch: Loss-> 1.8120, Train accuracy->   6.42%\n","Current batch: Loss-> 1.8141, Train accuracy->   6.46%\n","Current batch: Loss-> 1.8356, Train accuracy->   6.49%\n","Current batch: Loss-> 1.8913, Train accuracy->   6.52%\n","Current batch: Loss-> 1.8435, Train accuracy->   6.54%\n","Current batch: Loss-> 1.8605, Train accuracy->   6.57%\n","Current batch: Loss-> 1.8152, Train accuracy->   6.60%\n","Current batch: Loss-> 1.8552, Train accuracy->   6.63%\n","Current batch: Loss-> 1.7328, Train accuracy->   6.67%\n","Current batch: Loss-> 1.7611, Train accuracy->   6.71%\n","Current batch: Loss-> 1.9767, Train accuracy->   6.74%\n","Current batch: Loss-> 1.7420, Train accuracy->   6.77%\n","Current batch: Loss-> 1.7398, Train accuracy->   6.80%\n","Current batch: Loss-> 1.7556, Train accuracy->   6.84%\n","Current batch: Loss-> 1.7888, Train accuracy->   6.88%\n","Current batch: Loss-> 1.9759, Train accuracy->   6.91%\n","Current batch: Loss-> 1.8354, Train accuracy->   6.94%\n","Current batch: Loss-> 1.9491, Train accuracy->   6.97%\n","Current batch: Loss-> 1.6064, Train accuracy->   7.01%\n","Current batch: Loss-> 1.8653, Train accuracy->   7.04%\n","Current batch: Loss-> 1.9279, Train accuracy->   7.07%\n","Current batch: Loss-> 1.8851, Train accuracy->   7.09%\n","Current batch: Loss-> 1.8966, Train accuracy->   7.12%\n","Current batch: Loss-> 1.7719, Train accuracy->   7.17%\n","Current batch: Loss-> 1.9470, Train accuracy->   7.20%\n","Current batch: Loss-> 2.0283, Train accuracy->   7.21%\n","Current batch: Loss-> 1.8497, Train accuracy->   7.25%\n","Current batch: Loss-> 1.9662, Train accuracy->   7.28%\n","Current batch: Loss-> 1.7854, Train accuracy->   7.31%\n","Current batch: Loss-> 1.7896, Train accuracy->   7.33%\n","Current batch: Loss-> 1.7767, Train accuracy->   7.38%\n","Current batch: Loss-> 1.8631, Train accuracy->   7.41%\n","Current batch: Loss-> 1.8601, Train accuracy->   7.45%\n","Current batch: Loss-> 1.9001, Train accuracy->   7.47%\n","Current batch: Loss-> 1.8508, Train accuracy->   7.50%\n","Current batch: Loss-> 1.8688, Train accuracy->   7.53%\n","Current batch: Loss-> 1.9827, Train accuracy->   7.56%\n","Current batch: Loss-> 1.8601, Train accuracy->   7.59%\n","Current batch: Loss-> 1.7696, Train accuracy->   7.62%\n","Current batch: Loss-> 1.7824, Train accuracy->   7.66%\n","Current batch: Loss-> 1.7598, Train accuracy->   7.71%\n","Current batch: Loss-> 1.7507, Train accuracy->   7.75%\n","Current batch: Loss-> 1.8503, Train accuracy->   7.77%\n","Current batch: Loss-> 1.8514, Train accuracy->   7.80%\n","Current batch: Loss-> 1.7899, Train accuracy->   7.84%\n","Current batch: Loss-> 1.8998, Train accuracy->   7.86%\n","Current batch: Loss-> 1.9459, Train accuracy->   7.89%\n","Current batch: Loss-> 1.9481, Train accuracy->   7.91%\n","Current batch: Loss-> 1.8836, Train accuracy->   7.94%\n","Current batch: Loss-> 1.6977, Train accuracy->   7.98%\n","Current batch: Loss-> 1.7042, Train accuracy->   8.02%\n","Current batch: Loss-> 1.6455, Train accuracy->   8.05%\n","Current batch: Loss-> 1.6914, Train accuracy->   8.09%\n","Current batch: Loss-> 1.7456, Train accuracy->   8.12%\n","Current batch: Loss-> 1.6693, Train accuracy->   8.16%\n","Current batch: Loss-> 1.7005, Train accuracy->   8.20%\n","Current batch: Loss-> 1.9158, Train accuracy->   8.21%\n","Current batch: Loss-> 1.9332, Train accuracy->   8.23%\n","Current batch: Loss-> 1.7109, Train accuracy->   8.27%\n","Current batch: Loss-> 1.6856, Train accuracy->   8.30%\n","Current batch: Loss-> 1.6534, Train accuracy->   8.33%\n","Current batch: Loss-> 1.9663, Train accuracy->   8.36%\n","Current batch: Loss-> 1.7698, Train accuracy->   8.39%\n","Current batch: Loss-> 1.7657, Train accuracy->   8.42%\n","Current batch: Loss-> 1.7598, Train accuracy->   8.46%\n","Current batch: Loss-> 1.8945, Train accuracy->   8.49%\n","Current batch: Loss-> 1.6666, Train accuracy->   8.53%\n","Current batch: Loss-> 1.9637, Train accuracy->   8.56%\n","Current batch: Loss-> 1.7422, Train accuracy->   8.60%\n","Current batch: Loss-> 1.9322, Train accuracy->   8.62%\n","Current batch: Loss-> 1.6694, Train accuracy->   8.67%\n","Current batch: Loss-> 1.7677, Train accuracy->   8.70%\n","Current batch: Loss-> 1.8324, Train accuracy->   8.73%\n","Current batch: Loss-> 1.9615, Train accuracy->   8.77%\n","Current batch: Loss-> 1.7057, Train accuracy->   8.81%\n","Current batch: Loss-> 1.7834, Train accuracy->   8.83%\n","Current batch: Loss-> 1.8343, Train accuracy->   8.86%\n","Current batch: Loss-> 1.7663, Train accuracy->   8.89%\n","Current batch: Loss-> 1.7744, Train accuracy->   8.92%\n","Current batch: Loss-> 1.7773, Train accuracy->   8.96%\n","Current batch: Loss-> 1.8414, Train accuracy->   9.00%\n","Current batch: Loss-> 1.7425, Train accuracy->   9.03%\n","Current batch: Loss-> 1.7247, Train accuracy->   9.06%\n","Current batch: Loss-> 1.8410, Train accuracy->   9.09%\n","Current batch: Loss-> 1.8411, Train accuracy->   9.12%\n","Current batch: Loss-> 1.8139, Train accuracy->   9.15%\n","Current batch: Loss-> 1.8034, Train accuracy->   9.19%\n","Current batch: Loss-> 1.6546, Train accuracy->   9.22%\n","Current batch: Loss-> 1.8129, Train accuracy->   9.26%\n","Current batch: Loss-> 1.9152, Train accuracy->   9.27%\n","Current batch: Loss-> 1.6830, Train accuracy->   9.32%\n","Current batch: Loss-> 1.7340, Train accuracy->   9.35%\n","Current batch: Loss-> 1.7351, Train accuracy->   9.39%\n","Current batch: Loss-> 1.5818, Train accuracy->   9.44%\n","Current batch: Loss-> 1.6388, Train accuracy->   9.48%\n","Current batch: Loss-> 1.6652, Train accuracy->   9.51%\n","Current batch: Loss-> 1.7044, Train accuracy->   9.55%\n","Current batch: Loss-> 1.7552, Train accuracy->   9.58%\n","Current batch: Loss-> 1.7934, Train accuracy->   9.60%\n","Current batch: Loss-> 1.6203, Train accuracy->   9.64%\n","Current batch: Loss-> 1.8069, Train accuracy->   9.67%\n","Current batch: Loss-> 1.8120, Train accuracy->   9.71%\n","Current batch: Loss-> 1.7683, Train accuracy->   9.74%\n","Current batch: Loss-> 1.6332, Train accuracy->   9.77%\n","Current batch: Loss-> 1.8162, Train accuracy->   9.80%\n","Current batch: Loss-> 1.8303, Train accuracy->   9.83%\n","Current batch: Loss-> 1.7344, Train accuracy->   9.86%\n","Current batch: Loss-> 1.8778, Train accuracy->   9.90%\n","Current batch: Loss-> 1.8159, Train accuracy->   9.92%\n","Current batch: Loss-> 1.7454, Train accuracy->   9.96%\n","Current batch: Loss-> 1.8225, Train accuracy->   9.99%\n","Current batch: Loss-> 1.8064, Train accuracy->  10.03%\n","Current batch: Loss-> 1.7474, Train accuracy->  10.08%\n","Current batch: Loss-> 1.7965, Train accuracy->  10.11%\n","Current batch: Loss-> 1.7710, Train accuracy->  10.15%\n","Current batch: Loss-> 1.8321, Train accuracy->  10.19%\n","Current batch: Loss-> 1.6940, Train accuracy->  10.22%\n","Current batch: Loss-> 1.8224, Train accuracy->  10.26%\n","Current batch: Loss-> 1.8651, Train accuracy->  10.29%\n","Current batch: Loss-> 1.6900, Train accuracy->  10.32%\n","Current batch: Loss-> 1.7941, Train accuracy->  10.38%\n","Current batch: Loss-> 1.5364, Train accuracy->  10.42%\n","Current batch: Loss-> 1.8483, Train accuracy->  10.45%\n","Current batch: Loss-> 1.7667, Train accuracy->  10.47%\n","Current batch: Loss-> 1.7403, Train accuracy->  10.50%\n","Current batch: Loss-> 1.8599, Train accuracy->  10.53%\n","Current batch: Loss-> 1.7356, Train accuracy->  10.57%\n","Current batch: Loss-> 1.8220, Train accuracy->  10.61%\n","Current batch: Loss-> 1.6500, Train accuracy->  10.65%\n","Current batch: Loss-> 1.7685, Train accuracy->  10.69%\n","Current batch: Loss-> 1.6632, Train accuracy->  10.74%\n","Current batch: Loss-> 1.6806, Train accuracy->  10.77%\n","Current batch: Loss-> 1.7679, Train accuracy->  10.82%\n","Current batch: Loss-> 1.7696, Train accuracy->  10.86%\n","Current batch: Loss-> 1.6535, Train accuracy->  10.90%\n","Current batch: Loss-> 1.8987, Train accuracy->  10.93%\n","Current batch: Loss-> 1.8651, Train accuracy->  10.97%\n","Current batch: Loss-> 1.7000, Train accuracy->  11.01%\n","Current batch: Loss-> 1.8321, Train accuracy->  11.04%\n","Current batch: Loss-> 1.6708, Train accuracy->  11.09%\n","Current batch: Loss-> 1.6983, Train accuracy->  11.13%\n","Current batch: Loss-> 1.7692, Train accuracy->  11.16%\n","Current batch: Loss-> 1.6882, Train accuracy->  11.20%\n","Current batch: Loss-> 1.6407, Train accuracy->  11.23%\n","Current batch: Loss-> 1.8910, Train accuracy->  11.27%\n","Current batch: Loss-> 1.8359, Train accuracy->  11.29%\n","Current batch: Loss-> 1.8114, Train accuracy->  11.32%\n","Current batch: Loss-> 1.8014, Train accuracy->  11.36%\n","Current batch: Loss-> 1.8349, Train accuracy->  11.38%\n","Current batch: Loss-> 1.8047, Train accuracy->  11.41%\n","Current batch: Loss-> 1.8257, Train accuracy->  11.45%\n","Current batch: Loss-> 1.7169, Train accuracy->  11.48%\n","Current batch: Loss-> 1.6350, Train accuracy->  11.53%\n","Current batch: Loss-> 1.9254, Train accuracy->  11.57%\n","Current batch: Loss-> 1.6391, Train accuracy->  11.61%\n","Current batch: Loss-> 1.8828, Train accuracy->  11.64%\n","Current batch: Loss-> 1.8955, Train accuracy->  11.68%\n","Current batch: Loss-> 1.7831, Train accuracy->  11.70%\n","Current batch: Loss-> 1.5981, Train accuracy->  11.75%\n","Current batch: Loss-> 1.8164, Train accuracy->  11.77%\n","Current batch: Loss-> 1.9926, Train accuracy->  11.81%\n","Current batch: Loss-> 1.6411, Train accuracy->  11.85%\n","Current batch: Loss-> 1.7327, Train accuracy->  11.88%\n","Current batch: Loss-> 1.8464, Train accuracy->  11.91%\n","Current batch: Loss-> 1.8692, Train accuracy->  11.95%\n","Current batch: Loss-> 1.7416, Train accuracy->  11.98%\n","Current batch: Loss-> 1.7305, Train accuracy->  12.01%\n","Current batch: Loss-> 1.6246, Train accuracy->  12.06%\n","Current batch: Loss-> 1.8558, Train accuracy->  12.09%\n","Current batch: Loss-> 1.7767, Train accuracy->  12.12%\n","Current batch: Loss-> 1.7137, Train accuracy->  12.16%\n","Current batch: Loss-> 1.7861, Train accuracy->  12.19%\n","Current batch: Loss-> 1.6503, Train accuracy->  12.23%\n","Current batch: Loss-> 1.7578, Train accuracy->  12.25%\n","Current batch: Loss-> 1.6424, Train accuracy->  12.30%\n","Current batch: Loss-> 1.7419, Train accuracy->  12.34%\n","Current batch: Loss-> 1.7005, Train accuracy->  12.38%\n","Current batch: Loss-> 1.6777, Train accuracy->  12.42%\n","Current batch: Loss-> 1.6154, Train accuracy->  12.46%\n","Current batch: Loss-> 1.6162, Train accuracy->  12.49%\n","Current batch: Loss-> 1.9479, Train accuracy->  12.52%\n","Current batch: Loss-> 1.6520, Train accuracy->  12.57%\n","Current batch: Loss-> 1.7006, Train accuracy->  12.61%\n","Current batch: Loss-> 1.7076, Train accuracy->  12.64%\n","Current batch: Loss-> 1.5616, Train accuracy->  12.69%\n","Current batch: Loss-> 1.6770, Train accuracy->  12.73%\n","Current batch: Loss-> 1.6401, Train accuracy->  12.77%\n","Current batch: Loss-> 1.8730, Train accuracy->  12.81%\n","Current batch: Loss-> 1.6814, Train accuracy->  12.84%\n","Current batch: Loss-> 1.7814, Train accuracy->  12.87%\n","Current batch: Loss-> 1.8755, Train accuracy->  12.89%\n","Current batch: Loss-> 1.6932, Train accuracy->  12.93%\n","Current batch: Loss-> 1.8475, Train accuracy->  12.96%\n","Current batch: Loss-> 1.8034, Train accuracy->  12.99%\n","Current batch: Loss-> 1.8487, Train accuracy->  13.02%\n","Current batch: Loss-> 1.8054, Train accuracy->  13.06%\n","Current batch: Loss-> 1.8122, Train accuracy->  13.09%\n","Current batch: Loss-> 1.7779, Train accuracy->  13.11%\n","Current batch: Loss-> 1.8812, Train accuracy->  13.14%\n","Current batch: Loss-> 1.9100, Train accuracy->  13.17%\n","Current batch: Loss-> 1.7280, Train accuracy->  13.21%\n","Current batch: Loss-> 1.7041, Train accuracy->  13.25%\n","Current batch: Loss-> 1.6447, Train accuracy->  13.29%\n","Current batch: Loss-> 1.7668, Train accuracy->  13.32%\n","Current batch: Loss-> 1.7423, Train accuracy->  13.35%\n","Current batch: Loss-> 1.7774, Train accuracy->  13.38%\n","Current batch: Loss-> 1.7306, Train accuracy->  13.41%\n","Current batch: Loss-> 1.7763, Train accuracy->  13.45%\n","Current batch: Loss-> 1.6919, Train accuracy->  13.49%\n","Current batch: Loss-> 1.8752, Train accuracy->  13.52%\n","Current batch: Loss-> 1.7902, Train accuracy->  13.55%\n","Current batch: Loss-> 1.6907, Train accuracy->  13.58%\n","Current batch: Loss-> 1.8551, Train accuracy->  13.63%\n","Current batch: Loss-> 1.8375, Train accuracy->  13.66%\n","Current batch: Loss-> 1.8747, Train accuracy->  13.70%\n","Current batch: Loss-> 1.8008, Train accuracy->  13.74%\n","Current batch: Loss-> 1.8461, Train accuracy->  13.77%\n","Current batch: Loss-> 1.7636, Train accuracy->  13.80%\n","Current batch: Loss-> 1.7102, Train accuracy->  13.82%\n","Current batch: Loss-> 1.7397, Train accuracy->  13.86%\n","Current batch: Loss-> 1.7629, Train accuracy->  13.91%\n","Current batch: Loss-> 1.7902, Train accuracy->  13.94%\n","Current batch: Loss-> 1.7300, Train accuracy->  13.98%\n","Current batch: Loss-> 2.0581, Train accuracy->  14.02%\n","Current batch: Loss-> 1.8120, Train accuracy->  14.05%\n","Current batch: Loss-> 1.7368, Train accuracy->  14.09%\n","Current batch: Loss-> 1.8645, Train accuracy->  14.13%\n","Current batch: Loss-> 1.6987, Train accuracy->  14.16%\n","Current batch: Loss-> 1.7151, Train accuracy->  14.20%\n","Current batch: Loss-> 1.8263, Train accuracy->  14.24%\n","Current batch: Loss-> 1.7966, Train accuracy->  14.27%\n","Current batch: Loss-> 1.7524, Train accuracy->  14.31%\n","Current batch: Loss-> 1.8268, Train accuracy->  14.34%\n","Current batch: Loss-> 2.0152, Train accuracy->  14.37%\n","Current batch: Loss-> 1.8421, Train accuracy->  14.41%\n","Current batch: Loss-> 1.6738, Train accuracy->  14.45%\n","Current batch: Loss-> 1.6888, Train accuracy->  14.49%\n","Current batch: Loss-> 1.9017, Train accuracy->  14.51%\n","Current batch: Loss-> 1.8268, Train accuracy->  14.54%\n","Current batch: Loss-> 1.7196, Train accuracy->  14.57%\n","Current batch: Loss-> 1.7041, Train accuracy->  14.61%\n","Current batch: Loss-> 1.8424, Train accuracy->  14.65%\n","Current batch: Loss-> 1.7578, Train accuracy->  14.68%\n","Current batch: Loss-> 1.6936, Train accuracy->  14.71%\n","Current batch: Loss-> 1.8906, Train accuracy->  14.75%\n","Current batch: Loss-> 1.7938, Train accuracy->  14.78%\n","Current batch: Loss-> 1.6273, Train accuracy->  14.82%\n","Current batch: Loss-> 1.7880, Train accuracy->  14.85%\n","Current batch: Loss-> 1.8589, Train accuracy->  14.89%\n","Current batch: Loss-> 1.6560, Train accuracy->  14.94%\n","Current batch: Loss-> 1.5613, Train accuracy->  14.98%\n","Current batch: Loss-> 1.5942, Train accuracy->  15.02%\n","Current batch: Loss-> 1.7912, Train accuracy->  15.06%\n","Current batch: Loss-> 1.6298, Train accuracy->  15.10%\n","Current batch: Loss-> 1.7576, Train accuracy->  15.14%\n","Current batch: Loss-> 1.7543, Train accuracy->  15.17%\n","Current batch: Loss-> 1.7957, Train accuracy->  15.20%\n","Current batch: Loss-> 1.6382, Train accuracy->  15.25%\n","Current batch: Loss-> 1.6794, Train accuracy->  15.30%\n","Current batch: Loss-> 1.5680, Train accuracy->  15.36%\n","Current batch: Loss-> 1.6107, Train accuracy->  15.40%\n","Current batch: Loss-> 1.5912, Train accuracy->  15.45%\n","Current batch: Loss-> 1.7572, Train accuracy->  15.49%\n","Current batch: Loss-> 1.7193, Train accuracy->  15.51%\n","Current batch: Loss-> 1.7021, Train accuracy->  15.54%\n","Current batch: Loss-> 1.7797, Train accuracy->  15.59%\n","Current batch: Loss-> 1.8418, Train accuracy->  15.63%\n","Current batch: Loss-> 1.8012, Train accuracy->  15.67%\n","Current batch: Loss-> 1.6670, Train accuracy->  15.71%\n","Current batch: Loss-> 1.6784, Train accuracy->  15.75%\n","Current batch: Loss-> 1.8230, Train accuracy->  15.78%\n","Current batch: Loss-> 1.7212, Train accuracy->  15.81%\n","Current batch: Loss-> 1.7160, Train accuracy->  15.85%\n","Current batch: Loss-> 1.5956, Train accuracy->  15.89%\n","Current batch: Loss-> 1.6128, Train accuracy->  15.95%\n","Current batch: Loss-> 1.8091, Train accuracy->  15.97%\n","Current batch: Loss-> 1.7824, Train accuracy->  16.00%\n","Current batch: Loss-> 1.7941, Train accuracy->  16.03%\n","Current batch: Loss-> 1.8321, Train accuracy->  16.06%\n","Current batch: Loss-> 1.8187, Train accuracy->  16.08%\n","Current batch: Loss-> 1.8261, Train accuracy->  16.10%\n","Current batch: Loss-> 1.8092, Train accuracy->  16.13%\n","Current batch: Loss-> 1.7472, Train accuracy->  16.17%\n","Current batch: Loss-> 1.5771, Train accuracy->  16.20%\n","Current batch: Loss-> 1.6826, Train accuracy->  16.24%\n","Current batch: Loss-> 1.7296, Train accuracy->  16.28%\n","Current batch: Loss-> 1.6023, Train accuracy->  16.33%\n","Current batch: Loss-> 1.7192, Train accuracy->  16.37%\n","Current batch: Loss-> 1.7057, Train accuracy->  16.41%\n","Current batch: Loss-> 1.6341, Train accuracy->  16.44%\n","Current batch: Loss-> 1.8033, Train accuracy->  16.48%\n","Current batch: Loss-> 1.7123, Train accuracy->  16.51%\n","Current batch: Loss-> 1.9092, Train accuracy->  16.54%\n","Current batch: Loss-> 1.9392, Train accuracy->  16.56%\n","Current batch: Loss-> 1.7135, Train accuracy->  16.60%\n","Current batch: Loss-> 1.7110, Train accuracy->  16.64%\n","Current batch: Loss-> 1.6141, Train accuracy->  16.70%\n","Current batch: Loss-> 1.8388, Train accuracy->  16.73%\n","Current batch: Loss-> 1.6483, Train accuracy->  16.76%\n","Current batch: Loss-> 1.5404, Train accuracy->  16.81%\n","Current batch: Loss-> 1.5524, Train accuracy->  16.86%\n","Current batch: Loss-> 1.6427, Train accuracy->  16.90%\n","Current batch: Loss-> 1.7631, Train accuracy->  16.93%\n","Current batch: Loss-> 1.8767, Train accuracy->  16.96%\n","Current batch: Loss-> 1.4926, Train accuracy->  17.02%\n","Current batch: Loss-> 1.5867, Train accuracy->  17.05%\n","Current batch: Loss-> 1.7917, Train accuracy->  17.09%\n","Current batch: Loss-> 1.7041, Train accuracy->  17.12%\n","Current batch: Loss-> 1.6031, Train accuracy->  17.17%\n","Current batch: Loss-> 1.6701, Train accuracy->  17.20%\n","Current batch: Loss-> 1.7725, Train accuracy->  17.24%\n","Current batch: Loss-> 1.7343, Train accuracy->  17.28%\n","Current batch: Loss-> 1.7955, Train accuracy->  17.31%\n","Current batch: Loss-> 1.5140, Train accuracy->  17.36%\n","Current batch: Loss-> 1.8689, Train accuracy->  17.39%\n","Current batch: Loss-> 1.6762, Train accuracy->  17.43%\n","Current batch: Loss-> 1.8439, Train accuracy->  17.46%\n","Current batch: Loss-> 2.0018, Train accuracy->  17.48%\n","Current batch: Loss-> 1.7275, Train accuracy->  17.52%\n","Current batch: Loss-> 1.6954, Train accuracy->  17.56%\n","Current batch: Loss-> 1.7548, Train accuracy->  17.60%\n","Current batch: Loss-> 1.5852, Train accuracy->  17.65%\n","Current batch: Loss-> 1.6774, Train accuracy->  17.68%\n","Current batch: Loss-> 1.9170, Train accuracy->  17.72%\n","Current batch: Loss-> 1.7610, Train accuracy->  17.74%\n","Current batch: Loss-> 1.9018, Train accuracy->  17.77%\n","Current batch: Loss-> 1.5830, Train accuracy->  17.81%\n","Current batch: Loss-> 1.8522, Train accuracy->  17.84%\n","Current batch: Loss-> 1.7517, Train accuracy->  17.87%\n","Current batch: Loss-> 1.6472, Train accuracy->  17.91%\n","Current batch: Loss-> 1.6932, Train accuracy->  17.94%\n","Current batch: Loss-> 1.7279, Train accuracy->  17.99%\n","Current batch: Loss-> 1.7663, Train accuracy->  18.02%\n","Current batch: Loss-> 1.7479, Train accuracy->  18.07%\n","Current batch: Loss-> 1.6262, Train accuracy->  18.11%\n","Current batch: Loss-> 1.6674, Train accuracy->  18.15%\n","Current batch: Loss-> 1.7577, Train accuracy->  18.19%\n","Current batch: Loss-> 1.8281, Train accuracy->  18.23%\n","Current batch: Loss-> 1.8203, Train accuracy->  18.26%\n","Current batch: Loss-> 1.8206, Train accuracy->  18.29%\n","Current batch: Loss-> 1.8950, Train accuracy->  18.32%\n","Current batch: Loss-> 1.7465, Train accuracy->  18.35%\n","Current batch: Loss-> 1.7413, Train accuracy->  18.40%\n","Current batch: Loss-> 1.6390, Train accuracy->  18.44%\n","Current batch: Loss-> 1.7779, Train accuracy->  18.46%\n","Current batch: Loss-> 1.7234, Train accuracy->  18.49%\n","Current batch: Loss-> 1.8538, Train accuracy->  18.52%\n","Current batch: Loss-> 1.9413, Train accuracy->  18.55%\n","Current batch: Loss-> 1.7250, Train accuracy->  18.60%\n","Current batch: Loss-> 1.8468, Train accuracy->  18.63%\n","Current batch: Loss-> 1.8173, Train accuracy->  18.67%\n","Current batch: Loss-> 1.7582, Train accuracy->  18.71%\n","Current batch: Loss-> 1.6671, Train accuracy->  18.75%\n","Current batch: Loss-> 1.6881, Train accuracy->  18.79%\n","Current batch: Loss-> 1.6932, Train accuracy->  18.82%\n","Current batch: Loss-> 1.8309, Train accuracy->  18.85%\n","Current batch: Loss-> 1.5932, Train accuracy->  18.89%\n","Current batch: Loss-> 1.6505, Train accuracy->  18.94%\n","Current batch: Loss-> 1.6898, Train accuracy->  18.98%\n","Current batch: Loss-> 1.6844, Train accuracy->  19.04%\n","Current batch: Loss-> 1.8334, Train accuracy->  19.08%\n","Current batch: Loss-> 1.6678, Train accuracy->  19.11%\n","Current batch: Loss-> 1.8797, Train accuracy->  19.14%\n","Current batch: Loss-> 1.6801, Train accuracy->  19.18%\n","Current batch: Loss-> 1.6910, Train accuracy->  19.21%\n","Current batch: Loss-> 1.5713, Train accuracy->  19.25%\n","Current batch: Loss-> 1.5770, Train accuracy->  19.28%\n","Current batch: Loss-> 1.7129, Train accuracy->  19.32%\n","Current batch: Loss-> 1.6672, Train accuracy->  19.36%\n","Current batch: Loss-> 1.8298, Train accuracy->  19.41%\n","Current batch: Loss-> 1.7915, Train accuracy->  19.45%\n","Current batch: Loss-> 1.6542, Train accuracy->  19.49%\n","Current batch: Loss-> 1.6695, Train accuracy->  19.53%\n","Current batch: Loss-> 1.7542, Train accuracy->  19.56%\n","Current batch: Loss-> 1.8725, Train accuracy->  19.60%\n","Current batch: Loss-> 1.6567, Train accuracy->  19.64%\n","Current batch: Loss-> 1.7772, Train accuracy->  19.67%\n","Current batch: Loss-> 1.7782, Train accuracy->  19.71%\n","Current batch: Loss-> 1.7022, Train accuracy->  19.74%\n","Current batch: Loss-> 1.5750, Train accuracy->  19.80%\n","Current batch: Loss-> 1.7469, Train accuracy->  19.84%\n","Current batch: Loss-> 1.7843, Train accuracy->  19.88%\n","Current batch: Loss-> 1.6038, Train accuracy->  19.93%\n","Current batch: Loss-> 1.7327, Train accuracy->  19.96%\n","Current batch: Loss-> 1.6309, Train accuracy->  20.00%\n","Current batch: Loss-> 1.7498, Train accuracy->  20.04%\n","Current batch: Loss-> 1.6685, Train accuracy->  20.06%\n","Current batch: Loss-> 1.7781, Train accuracy->  20.10%\n","Current batch: Loss-> 1.6997, Train accuracy->  20.14%\n","Current batch: Loss-> 1.6357, Train accuracy->  20.17%\n","Current batch: Loss-> 1.9890, Train accuracy->  20.20%\n","Current batch: Loss-> 1.7604, Train accuracy->  20.24%\n","Current batch: Loss-> 1.6885, Train accuracy->  20.28%\n","Current batch: Loss-> 1.5733, Train accuracy->  20.33%\n","Current batch: Loss-> 1.8383, Train accuracy->  20.37%\n","Current batch: Loss-> 1.8116, Train accuracy->  20.41%\n","Current batch: Loss-> 1.8835, Train accuracy->  20.44%\n","Current batch: Loss-> 1.7410, Train accuracy->  20.47%\n","Current batch: Loss-> 1.7009, Train accuracy->  20.50%\n","Current batch: Loss-> 1.8406, Train accuracy->  20.54%\n","Current batch: Loss-> 1.7441, Train accuracy->  20.57%\n","Current batch: Loss-> 1.6924, Train accuracy->  20.60%\n","Current batch: Loss-> 1.6524, Train accuracy->  20.63%\n","Current batch: Loss-> 1.6557, Train accuracy->  20.68%\n","Current batch: Loss-> 1.7018, Train accuracy->  20.73%\n","Current batch: Loss-> 1.6702, Train accuracy->  20.76%\n","Current batch: Loss-> 1.6769, Train accuracy->  20.79%\n","Current batch: Loss-> 1.6330, Train accuracy->  20.82%\n","Current batch: Loss-> 1.6525, Train accuracy->  20.85%\n","Current batch: Loss-> 1.6611, Train accuracy->  20.88%\n","Current batch: Loss-> 1.8417, Train accuracy->  20.91%\n","Current batch: Loss-> 1.7431, Train accuracy->  20.94%\n","Current batch: Loss-> 1.7396, Train accuracy->  20.99%\n","Current batch: Loss-> 1.7131, Train accuracy->  21.01%\n","Current batch: Loss-> 1.6346, Train accuracy->  21.05%\n","Current batch: Loss-> 1.7876, Train accuracy->  21.09%\n","Current batch: Loss-> 1.6044, Train accuracy->  21.12%\n","Current batch: Loss-> 1.6630, Train accuracy->  21.16%\n","Current batch: Loss-> 1.5753, Train accuracy->  21.20%\n","Current batch: Loss-> 1.9152, Train accuracy->  21.23%\n","Current batch: Loss-> 1.5949, Train accuracy->  21.27%\n","Current batch: Loss-> 1.4928, Train accuracy->  21.32%\n","Current batch: Loss-> 1.5932, Train accuracy->  21.36%\n","Current batch: Loss-> 1.6011, Train accuracy->  21.40%\n","Current batch: Loss-> 1.5925, Train accuracy->  21.45%\n","Current batch: Loss-> 1.7311, Train accuracy->  21.48%\n","Current batch: Loss-> 1.7836, Train accuracy->  21.51%\n","Current batch: Loss-> 1.6418, Train accuracy->  21.55%\n","Current batch: Loss-> 1.8095, Train accuracy->  21.58%\n","Current batch: Loss-> 1.6469, Train accuracy->  21.62%\n","Current batch: Loss-> 1.6583, Train accuracy->  21.67%\n","Current batch: Loss-> 1.7148, Train accuracy->  21.72%\n","Current batch: Loss-> 1.9311, Train accuracy->  21.75%\n","Current batch: Loss-> 1.6719, Train accuracy->  21.79%\n","Current batch: Loss-> 1.5987, Train accuracy->  21.84%\n","Current batch: Loss-> 1.5508, Train accuracy->  21.88%\n","Current batch: Loss-> 1.8193, Train accuracy->  21.92%\n","Current batch: Loss-> 1.8032, Train accuracy->  21.96%\n","Current batch: Loss-> 1.6096, Train accuracy->  22.00%\n","Current batch: Loss-> 1.6400, Train accuracy->  22.05%\n","Current batch: Loss-> 1.7608, Train accuracy->  22.08%\n","Current batch: Loss-> 1.6123, Train accuracy->  22.12%\n","Current batch: Loss-> 1.5717, Train accuracy->  22.16%\n","Current batch: Loss-> 1.6788, Train accuracy->  22.20%\n","Current batch: Loss-> 1.7095, Train accuracy->  22.24%\n","Current batch: Loss-> 1.5666, Train accuracy->  22.28%\n","Current batch: Loss-> 1.6783, Train accuracy->  22.31%\n","Current batch: Loss-> 1.6257, Train accuracy->  22.36%\n","Current batch: Loss-> 1.6997, Train accuracy->  22.39%\n","Current batch: Loss-> 1.7218, Train accuracy->  22.43%\n","Current batch: Loss-> 1.5227, Train accuracy->  22.49%\n","Current batch: Loss-> 1.6852, Train accuracy->  22.52%\n","Current batch: Loss-> 1.6365, Train accuracy->  22.54%\n","Current batch: Loss-> 1.5649, Train accuracy->  22.59%\n","Current batch: Loss-> 1.6557, Train accuracy->  22.62%\n","Current batch: Loss-> 1.6541, Train accuracy->  22.65%\n","Current batch: Loss-> 1.7567, Train accuracy->  22.69%\n","Current batch: Loss-> 1.8126, Train accuracy->  22.72%\n","Current batch: Loss-> 1.6161, Train accuracy->  22.77%\n","Current batch: Loss-> 1.7557, Train accuracy->  22.80%\n","Current batch: Loss-> 1.7453, Train accuracy->  22.83%\n","Current batch: Loss-> 1.6696, Train accuracy->  22.86%\n","Current batch: Loss-> 1.4918, Train accuracy->  22.91%\n","Current batch: Loss-> 1.6354, Train accuracy->  22.96%\n","Current batch: Loss-> 1.5900, Train accuracy->  23.00%\n","Current batch: Loss-> 1.6429, Train accuracy->  23.05%\n","Current batch: Loss-> 1.6674, Train accuracy->  23.07%\n","Current batch: Loss-> 1.8106, Train accuracy->  23.12%\n","Current batch: Loss-> 1.5489, Train accuracy->  23.15%\n","Current batch: Loss-> 1.6284, Train accuracy->  23.21%\n","Current batch: Loss-> 1.7098, Train accuracy->  23.24%\n","Current batch: Loss-> 1.5150, Train accuracy->  23.29%\n","Current batch: Loss-> 1.5630, Train accuracy->  23.33%\n","Current batch: Loss-> 1.8708, Train accuracy->  23.36%\n","Current batch: Loss-> 1.6547, Train accuracy->  23.40%\n","Current batch: Loss-> 1.6546, Train accuracy->  23.45%\n","Current batch: Loss-> 1.8405, Train accuracy->  23.48%\n","Current batch: Loss-> 1.7606, Train accuracy->  23.52%\n","Current batch: Loss-> 1.6452, Train accuracy->  23.57%\n","Current batch: Loss-> 1.8030, Train accuracy->  23.60%\n","Current batch: Loss-> 1.8554, Train accuracy->  23.62%\n","Current batch: Loss-> 1.7775, Train accuracy->  23.68%\n","Current batch: Loss-> 1.7656, Train accuracy->  23.72%\n","Current batch: Loss-> 1.7559, Train accuracy->  23.74%\n","Current batch: Loss-> 1.7564, Train accuracy->  23.78%\n","Current batch: Loss-> 1.6736, Train accuracy->  23.81%\n","Current batch: Loss-> 1.5729, Train accuracy->  23.86%\n","Current batch: Loss-> 1.5887, Train accuracy->  23.90%\n","Current batch: Loss-> 1.7858, Train accuracy->  23.93%\n","Current batch: Loss-> 1.5779, Train accuracy->  23.99%\n","Current batch: Loss-> 1.7916, Train accuracy->  24.03%\n","Current batch: Loss-> 1.7581, Train accuracy->  24.07%\n","Current batch: Loss-> 1.8977, Train accuracy->  24.10%\n","Current batch: Loss-> 1.6220, Train accuracy->  24.14%\n","Current batch: Loss-> 1.7275, Train accuracy->  24.18%\n","Current batch: Loss-> 1.6802, Train accuracy->  24.21%\n","Current batch: Loss-> 1.8125, Train accuracy->  24.24%\n","Current batch: Loss-> 1.5825, Train accuracy->  24.28%\n","Current batch: Loss-> 1.7064, Train accuracy->  24.32%\n","Current batch: Loss-> 1.7229, Train accuracy->  24.36%\n","Current batch: Loss-> 1.8173, Train accuracy->  24.39%\n","Current batch: Loss-> 1.5784, Train accuracy->  24.43%\n","Current batch: Loss-> 1.7504, Train accuracy->  24.47%\n","Current batch: Loss-> 1.7296, Train accuracy->  24.50%\n","Current batch: Loss-> 1.5436, Train accuracy->  24.54%\n","Current batch: Loss-> 1.6854, Train accuracy->  24.59%\n","Current batch: Loss-> 1.6540, Train accuracy->  24.62%\n","Current batch: Loss-> 1.5967, Train accuracy->  24.66%\n","Current batch: Loss-> 1.7010, Train accuracy->  24.69%\n","Current batch: Loss-> 1.8014, Train accuracy->  24.73%\n","Current batch: Loss-> 1.6660, Train accuracy->  24.77%\n","Current batch: Loss-> 1.6718, Train accuracy->  24.82%\n","Current batch: Loss-> 1.6637, Train accuracy->  24.86%\n","Current batch: Loss-> 1.7469, Train accuracy->  24.89%\n","Current batch: Loss-> 1.7182, Train accuracy->  24.92%\n","Current batch: Loss-> 1.6370, Train accuracy->  24.96%\n","Current batch: Loss-> 1.6951, Train accuracy->  25.00%\n","Current batch: Loss-> 1.6023, Train accuracy->  25.04%\n","Current batch: Loss-> 1.4953, Train accuracy->  25.09%\n","Current batch: Loss-> 1.8039, Train accuracy->  25.11%\n","Current batch: Loss-> 1.5978, Train accuracy->  25.14%\n","Current batch: Loss-> 1.6050, Train accuracy->  25.17%\n","Current batch: Loss-> 1.6537, Train accuracy->  25.21%\n","Current batch: Loss-> 1.6773, Train accuracy->  25.24%\n","Current batch: Loss-> 1.5470, Train accuracy->  25.29%\n","Current batch: Loss-> 1.6039, Train accuracy->  25.33%\n","Current batch: Loss-> 1.5948, Train accuracy->  25.38%\n","Current batch: Loss-> 1.7200, Train accuracy->  25.41%\n","Current batch: Loss-> 1.5398, Train accuracy->  25.45%\n","Current batch: Loss-> 1.6423, Train accuracy->  25.50%\n","Current batch: Loss-> 1.7917, Train accuracy->  25.54%\n","Current batch: Loss-> 1.6172, Train accuracy->  25.59%\n","Current batch: Loss-> 1.6739, Train accuracy->  25.63%\n","Current batch: Loss-> 1.7559, Train accuracy->  25.65%\n","Current batch: Loss-> 1.5460, Train accuracy->  25.69%\n","Current batch: Loss-> 1.5752, Train accuracy->  25.73%\n","Current batch: Loss-> 1.6456, Train accuracy->  25.77%\n","Current batch: Loss-> 1.5285, Train accuracy->  25.82%\n","Current batch: Loss-> 1.7329, Train accuracy->  25.86%\n","Current batch: Loss-> 1.6436, Train accuracy->  25.92%\n","Current batch: Loss-> 1.7476, Train accuracy->  25.95%\n","Current batch: Loss-> 1.6878, Train accuracy->  25.99%\n","Current batch: Loss-> 1.5067, Train accuracy->  26.04%\n","Current batch: Loss-> 1.7817, Train accuracy->  26.08%\n","Current batch: Loss-> 1.5552, Train accuracy->  26.14%\n","Current batch: Loss-> 1.7376, Train accuracy->  26.17%\n","Current batch: Loss-> 1.6113, Train accuracy->  26.22%\n","Current batch: Loss-> 1.8389, Train accuracy->  26.25%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 45.90it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.5462, Train accuracy->  26.29%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.02it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.4935, Accuracy: 3646/12000 (30%)\n","\n","Current batch: Loss-> 1.5716, Train accuracy->   0.04%\n","Current batch: Loss-> 1.6532, Train accuracy->   0.08%\n","Current batch: Loss-> 1.7477, Train accuracy->   0.12%\n","Current batch: Loss-> 1.6478, Train accuracy->   0.15%\n","Current batch: Loss-> 1.6099, Train accuracy->   0.21%\n","Current batch: Loss-> 1.6050, Train accuracy->   0.25%\n","Current batch: Loss-> 1.6108, Train accuracy->   0.30%\n","Current batch: Loss-> 1.5544, Train accuracy->   0.35%\n","Current batch: Loss-> 1.6615, Train accuracy->   0.39%\n","Current batch: Loss-> 1.6390, Train accuracy->   0.42%\n","Current batch: Loss-> 1.7882, Train accuracy->   0.45%\n","Current batch: Loss-> 1.6429, Train accuracy->   0.49%\n","Current batch: Loss-> 1.6775, Train accuracy->   0.52%\n","Current batch: Loss-> 1.7389, Train accuracy->   0.56%\n","Current batch: Loss-> 1.6639, Train accuracy->   0.61%\n","Current batch: Loss-> 1.7360, Train accuracy->   0.64%\n","Current batch: Loss-> 1.6230, Train accuracy->   0.68%\n","Current batch: Loss-> 1.5842, Train accuracy->   0.71%\n","Current batch: Loss-> 1.6390, Train accuracy->   0.75%\n","Current batch: Loss-> 1.6072, Train accuracy->   0.79%\n","Current batch: Loss-> 1.5951, Train accuracy->   0.84%\n","Current batch: Loss-> 1.5233, Train accuracy->   0.89%\n","Current batch: Loss-> 1.6233, Train accuracy->   0.93%\n","Current batch: Loss-> 1.6651, Train accuracy->   0.96%\n","Current batch: Loss-> 1.5470, Train accuracy->   1.01%\n","Current batch: Loss-> 1.7416, Train accuracy->   1.06%\n","Current batch: Loss-> 1.6803, Train accuracy->   1.09%\n","Current batch: Loss-> 1.6124, Train accuracy->   1.14%\n","Current batch: Loss-> 1.6126, Train accuracy->   1.18%\n","Current batch: Loss-> 1.8438, Train accuracy->   1.21%\n","Current batch: Loss-> 1.6603, Train accuracy->   1.25%\n","Current batch: Loss-> 1.8743, Train accuracy->   1.28%\n","Current batch: Loss-> 1.6596, Train accuracy->   1.32%\n","Current batch: Loss-> 1.7366, Train accuracy->   1.36%\n","Current batch: Loss-> 1.4831, Train accuracy->   1.41%\n","Current batch: Loss-> 1.5766, Train accuracy->   1.45%\n","Current batch: Loss-> 1.7182, Train accuracy->   1.48%\n","Current batch: Loss-> 1.6363, Train accuracy->   1.52%\n","Current batch: Loss-> 1.6719, Train accuracy->   1.56%\n","Current batch: Loss-> 1.8433, Train accuracy->   1.59%\n","Current batch: Loss-> 1.6941, Train accuracy->   1.63%\n","Current batch: Loss-> 1.4879, Train accuracy->   1.68%\n","Current batch: Loss-> 1.7237, Train accuracy->   1.71%\n","Current batch: Loss-> 1.6831, Train accuracy->   1.74%\n","Current batch: Loss-> 1.6367, Train accuracy->   1.78%\n","Current batch: Loss-> 1.5896, Train accuracy->   1.82%\n","Current batch: Loss-> 1.8460, Train accuracy->   1.85%\n","Current batch: Loss-> 1.6793, Train accuracy->   1.89%\n","Current batch: Loss-> 1.6373, Train accuracy->   1.94%\n","Current batch: Loss-> 1.6033, Train accuracy->   1.98%\n","Current batch: Loss-> 1.7275, Train accuracy->   2.01%\n","Current batch: Loss-> 1.4741, Train accuracy->   2.05%\n","Current batch: Loss-> 1.8814, Train accuracy->   2.08%\n","Current batch: Loss-> 1.6079, Train accuracy->   2.13%\n","Current batch: Loss-> 1.5944, Train accuracy->   2.17%\n","Current batch: Loss-> 1.5474, Train accuracy->   2.21%\n","Current batch: Loss-> 1.6803, Train accuracy->   2.25%\n","Current batch: Loss-> 1.7977, Train accuracy->   2.28%\n","Current batch: Loss-> 1.7335, Train accuracy->   2.31%\n","Current batch: Loss-> 1.6128, Train accuracy->   2.35%\n","Current batch: Loss-> 1.7059, Train accuracy->   2.39%\n","Current batch: Loss-> 1.5448, Train accuracy->   2.45%\n","Current batch: Loss-> 1.6602, Train accuracy->   2.49%\n","Current batch: Loss-> 1.7843, Train accuracy->   2.52%\n","Current batch: Loss-> 1.7631, Train accuracy->   2.56%\n","Current batch: Loss-> 1.6193, Train accuracy->   2.60%\n","Current batch: Loss-> 1.7003, Train accuracy->   2.63%\n","Current batch: Loss-> 1.5297, Train accuracy->   2.67%\n","Current batch: Loss-> 1.4895, Train accuracy->   2.72%\n","Current batch: Loss-> 1.6519, Train accuracy->   2.76%\n","Current batch: Loss-> 1.6285, Train accuracy->   2.81%\n","Current batch: Loss-> 1.5775, Train accuracy->   2.85%\n","Current batch: Loss-> 1.5231, Train accuracy->   2.89%\n","Current batch: Loss-> 1.5953, Train accuracy->   2.94%\n","Current batch: Loss-> 1.6087, Train accuracy->   2.99%\n","Current batch: Loss-> 1.7484, Train accuracy->   3.01%\n","Current batch: Loss-> 1.6241, Train accuracy->   3.06%\n","Current batch: Loss-> 1.5903, Train accuracy->   3.10%\n","Current batch: Loss-> 1.5620, Train accuracy->   3.14%\n","Current batch: Loss-> 1.7152, Train accuracy->   3.19%\n","Current batch: Loss-> 1.7061, Train accuracy->   3.23%\n","Current batch: Loss-> 1.6010, Train accuracy->   3.29%\n","Current batch: Loss-> 1.7670, Train accuracy->   3.33%\n","Current batch: Loss-> 1.5757, Train accuracy->   3.36%\n","Current batch: Loss-> 1.6425, Train accuracy->   3.40%\n","Current batch: Loss-> 1.4910, Train accuracy->   3.45%\n","Current batch: Loss-> 1.6097, Train accuracy->   3.49%\n","Current batch: Loss-> 1.7682, Train accuracy->   3.53%\n","Current batch: Loss-> 1.6064, Train accuracy->   3.58%\n","Current batch: Loss-> 1.5727, Train accuracy->   3.61%\n","Current batch: Loss-> 1.5951, Train accuracy->   3.66%\n","Current batch: Loss-> 1.7197, Train accuracy->   3.68%\n","Current batch: Loss-> 1.5055, Train accuracy->   3.74%\n","Current batch: Loss-> 1.6420, Train accuracy->   3.79%\n","Current batch: Loss-> 1.6872, Train accuracy->   3.81%\n","Current batch: Loss-> 1.8519, Train accuracy->   3.85%\n","Current batch: Loss-> 1.5828, Train accuracy->   3.89%\n","Current batch: Loss-> 1.5253, Train accuracy->   3.95%\n","Current batch: Loss-> 1.7741, Train accuracy->   3.99%\n","Current batch: Loss-> 1.6689, Train accuracy->   4.02%\n","Current batch: Loss-> 1.8238, Train accuracy->   4.06%\n","Current batch: Loss-> 1.4921, Train accuracy->   4.11%\n","Current batch: Loss-> 1.5844, Train accuracy->   4.15%\n","Current batch: Loss-> 1.6268, Train accuracy->   4.20%\n","Current batch: Loss-> 1.7262, Train accuracy->   4.23%\n","Current batch: Loss-> 1.5899, Train accuracy->   4.27%\n","Current batch: Loss-> 1.7538, Train accuracy->   4.32%\n","Current batch: Loss-> 1.6104, Train accuracy->   4.34%\n","Current batch: Loss-> 1.5873, Train accuracy->   4.39%\n","Current batch: Loss-> 1.8911, Train accuracy->   4.41%\n","Current batch: Loss-> 1.5772, Train accuracy->   4.45%\n","Current batch: Loss-> 1.7120, Train accuracy->   4.48%\n","Current batch: Loss-> 1.5281, Train accuracy->   4.53%\n","Current batch: Loss-> 1.5243, Train accuracy->   4.59%\n","Current batch: Loss-> 1.7447, Train accuracy->   4.63%\n","Current batch: Loss-> 1.4850, Train accuracy->   4.68%\n","Current batch: Loss-> 1.5184, Train accuracy->   4.73%\n","Current batch: Loss-> 1.6665, Train accuracy->   4.78%\n","Current batch: Loss-> 1.6462, Train accuracy->   4.81%\n","Current batch: Loss-> 1.7265, Train accuracy->   4.85%\n","Current batch: Loss-> 1.7974, Train accuracy->   4.88%\n","Current batch: Loss-> 1.7442, Train accuracy->   4.90%\n","Current batch: Loss-> 1.5693, Train accuracy->   4.96%\n","Current batch: Loss-> 1.5955, Train accuracy->   5.00%\n","Current batch: Loss-> 1.6593, Train accuracy->   5.04%\n","Current batch: Loss-> 1.6804, Train accuracy->   5.08%\n","Current batch: Loss-> 1.6085, Train accuracy->   5.12%\n","Current batch: Loss-> 1.9328, Train accuracy->   5.15%\n","Current batch: Loss-> 1.6427, Train accuracy->   5.20%\n","Current batch: Loss-> 1.5392, Train accuracy->   5.25%\n","Current batch: Loss-> 1.5536, Train accuracy->   5.29%\n","Current batch: Loss-> 1.6822, Train accuracy->   5.33%\n","Current batch: Loss-> 1.6280, Train accuracy->   5.38%\n","Current batch: Loss-> 1.6169, Train accuracy->   5.43%\n","Current batch: Loss-> 1.5942, Train accuracy->   5.47%\n","Current batch: Loss-> 1.8390, Train accuracy->   5.51%\n","Current batch: Loss-> 1.6182, Train accuracy->   5.56%\n","Current batch: Loss-> 1.6465, Train accuracy->   5.60%\n","Current batch: Loss-> 1.5260, Train accuracy->   5.65%\n","Current batch: Loss-> 1.5595, Train accuracy->   5.70%\n","Current batch: Loss-> 1.6699, Train accuracy->   5.74%\n","Current batch: Loss-> 1.6149, Train accuracy->   5.79%\n","Current batch: Loss-> 1.5964, Train accuracy->   5.83%\n","Current batch: Loss-> 1.7003, Train accuracy->   5.86%\n","Current batch: Loss-> 1.6915, Train accuracy->   5.90%\n","Current batch: Loss-> 1.4418, Train accuracy->   5.95%\n","Current batch: Loss-> 1.4777, Train accuracy->   6.00%\n","Current batch: Loss-> 1.6184, Train accuracy->   6.04%\n","Current batch: Loss-> 1.6348, Train accuracy->   6.07%\n","Current batch: Loss-> 1.6258, Train accuracy->   6.09%\n","Current batch: Loss-> 1.7638, Train accuracy->   6.13%\n","Current batch: Loss-> 1.7398, Train accuracy->   6.16%\n","Current batch: Loss-> 1.6365, Train accuracy->   6.19%\n","Current batch: Loss-> 1.4872, Train accuracy->   6.24%\n","Current batch: Loss-> 1.6645, Train accuracy->   6.28%\n","Current batch: Loss-> 1.5922, Train accuracy->   6.33%\n","Current batch: Loss-> 1.7600, Train accuracy->   6.36%\n","Current batch: Loss-> 1.6176, Train accuracy->   6.40%\n","Current batch: Loss-> 1.6209, Train accuracy->   6.44%\n","Current batch: Loss-> 1.7813, Train accuracy->   6.48%\n","Current batch: Loss-> 1.4475, Train accuracy->   6.53%\n","Current batch: Loss-> 1.6909, Train accuracy->   6.57%\n","Current batch: Loss-> 1.5566, Train accuracy->   6.60%\n","Current batch: Loss-> 1.8503, Train accuracy->   6.64%\n","Current batch: Loss-> 1.6522, Train accuracy->   6.67%\n","Current batch: Loss-> 1.5037, Train accuracy->   6.72%\n","Current batch: Loss-> 1.4901, Train accuracy->   6.78%\n","Current batch: Loss-> 1.7488, Train accuracy->   6.81%\n","Current batch: Loss-> 1.6971, Train accuracy->   6.85%\n","Current batch: Loss-> 1.6728, Train accuracy->   6.90%\n","Current batch: Loss-> 1.7417, Train accuracy->   6.94%\n","Current batch: Loss-> 1.6463, Train accuracy->   6.99%\n","Current batch: Loss-> 1.6829, Train accuracy->   7.03%\n","Current batch: Loss-> 1.7299, Train accuracy->   7.07%\n","Current batch: Loss-> 1.7025, Train accuracy->   7.10%\n","Current batch: Loss-> 1.6472, Train accuracy->   7.14%\n","Current batch: Loss-> 1.5725, Train accuracy->   7.19%\n","Current batch: Loss-> 1.7874, Train accuracy->   7.24%\n","Current batch: Loss-> 1.7513, Train accuracy->   7.28%\n","Current batch: Loss-> 1.6541, Train accuracy->   7.33%\n","Current batch: Loss-> 1.6246, Train accuracy->   7.37%\n","Current batch: Loss-> 1.5168, Train accuracy->   7.41%\n","Current batch: Loss-> 1.4896, Train accuracy->   7.47%\n","Current batch: Loss-> 1.6494, Train accuracy->   7.50%\n","Current batch: Loss-> 1.5008, Train accuracy->   7.56%\n","Current batch: Loss-> 1.4811, Train accuracy->   7.62%\n","Current batch: Loss-> 1.4513, Train accuracy->   7.66%\n","Current batch: Loss-> 1.7812, Train accuracy->   7.71%\n","Current batch: Loss-> 1.5713, Train accuracy->   7.75%\n","Current batch: Loss-> 1.5410, Train accuracy->   7.80%\n","Current batch: Loss-> 1.7415, Train accuracy->   7.84%\n","Current batch: Loss-> 1.6306, Train accuracy->   7.89%\n","Current batch: Loss-> 1.8793, Train accuracy->   7.92%\n","Current batch: Loss-> 1.5207, Train accuracy->   7.96%\n","Current batch: Loss-> 1.8080, Train accuracy->   8.00%\n","Current batch: Loss-> 1.5306, Train accuracy->   8.05%\n","Current batch: Loss-> 1.6753, Train accuracy->   8.09%\n","Current batch: Loss-> 1.5688, Train accuracy->   8.13%\n","Current batch: Loss-> 1.6448, Train accuracy->   8.17%\n","Current batch: Loss-> 1.5542, Train accuracy->   8.23%\n","Current batch: Loss-> 1.6939, Train accuracy->   8.27%\n","Current batch: Loss-> 1.7518, Train accuracy->   8.31%\n","Current batch: Loss-> 1.6371, Train accuracy->   8.35%\n","Current batch: Loss-> 1.4771, Train accuracy->   8.40%\n","Current batch: Loss-> 1.7387, Train accuracy->   8.44%\n","Current batch: Loss-> 1.7148, Train accuracy->   8.48%\n","Current batch: Loss-> 1.5730, Train accuracy->   8.52%\n","Current batch: Loss-> 1.6439, Train accuracy->   8.58%\n","Current batch: Loss-> 1.7237, Train accuracy->   8.62%\n","Current batch: Loss-> 1.5196, Train accuracy->   8.67%\n","Current batch: Loss-> 1.6446, Train accuracy->   8.71%\n","Current batch: Loss-> 1.5461, Train accuracy->   8.75%\n","Current batch: Loss-> 1.5358, Train accuracy->   8.79%\n","Current batch: Loss-> 1.6490, Train accuracy->   8.83%\n","Current batch: Loss-> 1.7304, Train accuracy->   8.86%\n","Current batch: Loss-> 1.5108, Train accuracy->   8.90%\n","Current batch: Loss-> 1.7190, Train accuracy->   8.94%\n","Current batch: Loss-> 1.6517, Train accuracy->   8.98%\n","Current batch: Loss-> 1.6173, Train accuracy->   9.02%\n","Current batch: Loss-> 1.4751, Train accuracy->   9.08%\n","Current batch: Loss-> 1.7593, Train accuracy->   9.11%\n","Current batch: Loss-> 1.7091, Train accuracy->   9.15%\n","Current batch: Loss-> 1.8561, Train accuracy->   9.18%\n","Current batch: Loss-> 1.5063, Train accuracy->   9.22%\n","Current batch: Loss-> 1.6033, Train accuracy->   9.26%\n","Current batch: Loss-> 1.5015, Train accuracy->   9.31%\n","Current batch: Loss-> 1.4859, Train accuracy->   9.37%\n","Current batch: Loss-> 1.6878, Train accuracy->   9.42%\n","Current batch: Loss-> 1.4483, Train accuracy->   9.48%\n","Current batch: Loss-> 1.6298, Train accuracy->   9.52%\n","Current batch: Loss-> 1.6113, Train accuracy->   9.57%\n","Current batch: Loss-> 1.6244, Train accuracy->   9.61%\n","Current batch: Loss-> 1.5768, Train accuracy->   9.66%\n","Current batch: Loss-> 1.5159, Train accuracy->   9.70%\n","Current batch: Loss-> 1.4445, Train accuracy->   9.76%\n","Current batch: Loss-> 1.5663, Train accuracy->   9.80%\n","Current batch: Loss-> 1.5788, Train accuracy->   9.84%\n","Current batch: Loss-> 1.6635, Train accuracy->   9.88%\n","Current batch: Loss-> 1.5497, Train accuracy->   9.92%\n","Current batch: Loss-> 1.5871, Train accuracy->   9.95%\n","Current batch: Loss-> 1.6136, Train accuracy->   9.99%\n","Current batch: Loss-> 1.5845, Train accuracy->  10.04%\n","Current batch: Loss-> 1.5378, Train accuracy->  10.09%\n","Current batch: Loss-> 1.7156, Train accuracy->  10.12%\n","Current batch: Loss-> 1.7526, Train accuracy->  10.15%\n","Current batch: Loss-> 1.5138, Train accuracy->  10.19%\n","Current batch: Loss-> 1.7299, Train accuracy->  10.24%\n","Current batch: Loss-> 1.4962, Train accuracy->  10.30%\n","Current batch: Loss-> 1.4451, Train accuracy->  10.35%\n","Current batch: Loss-> 1.5866, Train accuracy->  10.40%\n","Current batch: Loss-> 1.5966, Train accuracy->  10.44%\n","Current batch: Loss-> 1.6936, Train accuracy->  10.49%\n","Current batch: Loss-> 1.5087, Train accuracy->  10.55%\n","Current batch: Loss-> 1.6867, Train accuracy->  10.60%\n","Current batch: Loss-> 1.6071, Train accuracy->  10.65%\n","Current batch: Loss-> 1.7050, Train accuracy->  10.69%\n","Current batch: Loss-> 1.6616, Train accuracy->  10.72%\n","Current batch: Loss-> 1.5544, Train accuracy->  10.77%\n","Current batch: Loss-> 1.5162, Train accuracy->  10.82%\n","Current batch: Loss-> 1.4096, Train accuracy->  10.88%\n","Current batch: Loss-> 1.8670, Train accuracy->  10.92%\n","Current batch: Loss-> 1.7070, Train accuracy->  10.96%\n","Current batch: Loss-> 1.6778, Train accuracy->  10.99%\n","Current batch: Loss-> 1.6793, Train accuracy->  11.03%\n","Current batch: Loss-> 1.8418, Train accuracy->  11.07%\n","Current batch: Loss-> 1.7694, Train accuracy->  11.09%\n","Current batch: Loss-> 1.7789, Train accuracy->  11.14%\n","Current batch: Loss-> 1.6050, Train accuracy->  11.18%\n","Current batch: Loss-> 1.5276, Train accuracy->  11.23%\n","Current batch: Loss-> 1.8015, Train accuracy->  11.27%\n","Current batch: Loss-> 1.6949, Train accuracy->  11.32%\n","Current batch: Loss-> 1.8393, Train accuracy->  11.36%\n","Current batch: Loss-> 1.7531, Train accuracy->  11.39%\n","Current batch: Loss-> 1.7089, Train accuracy->  11.44%\n","Current batch: Loss-> 1.6425, Train accuracy->  11.47%\n","Current batch: Loss-> 1.7213, Train accuracy->  11.51%\n","Current batch: Loss-> 1.7668, Train accuracy->  11.55%\n","Current batch: Loss-> 1.6561, Train accuracy->  11.59%\n","Current batch: Loss-> 1.6945, Train accuracy->  11.63%\n","Current batch: Loss-> 1.7080, Train accuracy->  11.67%\n","Current batch: Loss-> 1.7909, Train accuracy->  11.71%\n","Current batch: Loss-> 1.7103, Train accuracy->  11.74%\n","Current batch: Loss-> 1.7720, Train accuracy->  11.78%\n","Current batch: Loss-> 1.5949, Train accuracy->  11.84%\n","Current batch: Loss-> 1.8358, Train accuracy->  11.88%\n","Current batch: Loss-> 1.6825, Train accuracy->  11.91%\n","Current batch: Loss-> 1.6465, Train accuracy->  11.95%\n","Current batch: Loss-> 1.6656, Train accuracy->  11.99%\n","Current batch: Loss-> 1.6572, Train accuracy->  12.03%\n","Current batch: Loss-> 1.6600, Train accuracy->  12.07%\n","Current batch: Loss-> 1.7009, Train accuracy->  12.13%\n","Current batch: Loss-> 1.5886, Train accuracy->  12.18%\n","Current batch: Loss-> 1.6850, Train accuracy->  12.22%\n","Current batch: Loss-> 1.7483, Train accuracy->  12.25%\n","Current batch: Loss-> 1.5251, Train accuracy->  12.30%\n","Current batch: Loss-> 1.7589, Train accuracy->  12.33%\n","Current batch: Loss-> 1.6341, Train accuracy->  12.36%\n","Current batch: Loss-> 1.4911, Train accuracy->  12.42%\n","Current batch: Loss-> 1.4291, Train accuracy->  12.47%\n","Current batch: Loss-> 1.7120, Train accuracy->  12.51%\n","Current batch: Loss-> 1.7667, Train accuracy->  12.54%\n","Current batch: Loss-> 1.5399, Train accuracy->  12.59%\n","Current batch: Loss-> 1.6056, Train accuracy->  12.63%\n","Current batch: Loss-> 1.6421, Train accuracy->  12.68%\n","Current batch: Loss-> 1.5727, Train accuracy->  12.71%\n","Current batch: Loss-> 1.5206, Train accuracy->  12.77%\n","Current batch: Loss-> 1.6335, Train accuracy->  12.80%\n","Current batch: Loss-> 1.5594, Train accuracy->  12.83%\n","Current batch: Loss-> 1.7604, Train accuracy->  12.87%\n","Current batch: Loss-> 1.7420, Train accuracy->  12.91%\n","Current batch: Loss-> 1.5405, Train accuracy->  12.94%\n","Current batch: Loss-> 1.5477, Train accuracy->  12.99%\n","Current batch: Loss-> 1.8129, Train accuracy->  13.04%\n","Current batch: Loss-> 1.4361, Train accuracy->  13.09%\n","Current batch: Loss-> 1.5701, Train accuracy->  13.13%\n","Current batch: Loss-> 1.6198, Train accuracy->  13.17%\n","Current batch: Loss-> 1.6165, Train accuracy->  13.22%\n","Current batch: Loss-> 1.5793, Train accuracy->  13.27%\n","Current batch: Loss-> 1.5014, Train accuracy->  13.31%\n","Current batch: Loss-> 1.6903, Train accuracy->  13.34%\n","Current batch: Loss-> 1.5289, Train accuracy->  13.39%\n","Current batch: Loss-> 1.7106, Train accuracy->  13.43%\n","Current batch: Loss-> 1.6481, Train accuracy->  13.48%\n","Current batch: Loss-> 1.6104, Train accuracy->  13.52%\n","Current batch: Loss-> 1.7278, Train accuracy->  13.56%\n","Current batch: Loss-> 1.5393, Train accuracy->  13.61%\n","Current batch: Loss-> 1.6580, Train accuracy->  13.65%\n","Current batch: Loss-> 1.5116, Train accuracy->  13.70%\n","Current batch: Loss-> 1.7465, Train accuracy->  13.74%\n","Current batch: Loss-> 1.4989, Train accuracy->  13.78%\n","Current batch: Loss-> 1.6784, Train accuracy->  13.81%\n","Current batch: Loss-> 1.7082, Train accuracy->  13.84%\n","Current batch: Loss-> 1.5944, Train accuracy->  13.89%\n","Current batch: Loss-> 1.5966, Train accuracy->  13.94%\n","Current batch: Loss-> 1.5700, Train accuracy->  13.98%\n","Current batch: Loss-> 1.7369, Train accuracy->  14.01%\n","Current batch: Loss-> 1.5384, Train accuracy->  14.07%\n","Current batch: Loss-> 1.5507, Train accuracy->  14.11%\n","Current batch: Loss-> 1.6560, Train accuracy->  14.16%\n","Current batch: Loss-> 1.5329, Train accuracy->  14.20%\n","Current batch: Loss-> 1.6991, Train accuracy->  14.24%\n","Current batch: Loss-> 1.7860, Train accuracy->  14.27%\n","Current batch: Loss-> 1.7448, Train accuracy->  14.32%\n","Current batch: Loss-> 1.5151, Train accuracy->  14.37%\n","Current batch: Loss-> 1.5173, Train accuracy->  14.42%\n","Current batch: Loss-> 1.7209, Train accuracy->  14.46%\n","Current batch: Loss-> 1.7135, Train accuracy->  14.50%\n","Current batch: Loss-> 1.4999, Train accuracy->  14.55%\n","Current batch: Loss-> 1.7296, Train accuracy->  14.60%\n","Current batch: Loss-> 1.7048, Train accuracy->  14.63%\n","Current batch: Loss-> 1.6475, Train accuracy->  14.67%\n","Current batch: Loss-> 1.6937, Train accuracy->  14.72%\n","Current batch: Loss-> 1.4639, Train accuracy->  14.77%\n","Current batch: Loss-> 1.5740, Train accuracy->  14.82%\n","Current batch: Loss-> 1.7204, Train accuracy->  14.85%\n","Current batch: Loss-> 1.6600, Train accuracy->  14.88%\n","Current batch: Loss-> 1.5766, Train accuracy->  14.92%\n","Current batch: Loss-> 1.5634, Train accuracy->  14.96%\n","Current batch: Loss-> 1.8205, Train accuracy->  15.00%\n","Current batch: Loss-> 1.4921, Train accuracy->  15.05%\n","Current batch: Loss-> 1.6535, Train accuracy->  15.10%\n","Current batch: Loss-> 1.5150, Train accuracy->  15.16%\n","Current batch: Loss-> 1.6692, Train accuracy->  15.19%\n","Current batch: Loss-> 1.7519, Train accuracy->  15.22%\n","Current batch: Loss-> 1.6905, Train accuracy->  15.25%\n","Current batch: Loss-> 1.6337, Train accuracy->  15.29%\n","Current batch: Loss-> 1.6448, Train accuracy->  15.33%\n","Current batch: Loss-> 1.5882, Train accuracy->  15.37%\n","Current batch: Loss-> 1.7309, Train accuracy->  15.40%\n","Current batch: Loss-> 1.7073, Train accuracy->  15.43%\n","Current batch: Loss-> 1.5880, Train accuracy->  15.48%\n","Current batch: Loss-> 1.7146, Train accuracy->  15.51%\n","Current batch: Loss-> 1.5135, Train accuracy->  15.55%\n","Current batch: Loss-> 1.6760, Train accuracy->  15.60%\n","Current batch: Loss-> 1.7011, Train accuracy->  15.62%\n","Current batch: Loss-> 1.6383, Train accuracy->  15.68%\n","Current batch: Loss-> 1.4974, Train accuracy->  15.73%\n","Current batch: Loss-> 1.5426, Train accuracy->  15.78%\n","Current batch: Loss-> 1.5944, Train accuracy->  15.82%\n","Current batch: Loss-> 1.5590, Train accuracy->  15.87%\n","Current batch: Loss-> 1.6933, Train accuracy->  15.90%\n","Current batch: Loss-> 1.5828, Train accuracy->  15.95%\n","Current batch: Loss-> 1.5628, Train accuracy->  15.99%\n","Current batch: Loss-> 1.5077, Train accuracy->  16.04%\n","Current batch: Loss-> 1.6894, Train accuracy->  16.10%\n","Current batch: Loss-> 1.5693, Train accuracy->  16.14%\n","Current batch: Loss-> 1.6849, Train accuracy->  16.19%\n","Current batch: Loss-> 1.6314, Train accuracy->  16.23%\n","Current batch: Loss-> 1.4684, Train accuracy->  16.28%\n","Current batch: Loss-> 1.5775, Train accuracy->  16.33%\n","Current batch: Loss-> 1.6548, Train accuracy->  16.37%\n","Current batch: Loss-> 1.6183, Train accuracy->  16.40%\n","Current batch: Loss-> 1.6300, Train accuracy->  16.44%\n","Current batch: Loss-> 1.5558, Train accuracy->  16.50%\n","Current batch: Loss-> 1.4421, Train accuracy->  16.55%\n","Current batch: Loss-> 1.4558, Train accuracy->  16.60%\n","Current batch: Loss-> 1.6125, Train accuracy->  16.64%\n","Current batch: Loss-> 1.3458, Train accuracy->  16.69%\n","Current batch: Loss-> 1.6715, Train accuracy->  16.74%\n","Current batch: Loss-> 1.4589, Train accuracy->  16.80%\n","Current batch: Loss-> 1.5853, Train accuracy->  16.84%\n","Current batch: Loss-> 1.5200, Train accuracy->  16.90%\n","Current batch: Loss-> 1.5791, Train accuracy->  16.94%\n","Current batch: Loss-> 1.5011, Train accuracy->  16.99%\n","Current batch: Loss-> 1.4809, Train accuracy->  17.05%\n","Current batch: Loss-> 1.3982, Train accuracy->  17.11%\n","Current batch: Loss-> 1.6874, Train accuracy->  17.15%\n","Current batch: Loss-> 1.5240, Train accuracy->  17.20%\n","Current batch: Loss-> 1.4603, Train accuracy->  17.26%\n","Current batch: Loss-> 1.5751, Train accuracy->  17.31%\n","Current batch: Loss-> 1.6453, Train accuracy->  17.36%\n","Current batch: Loss-> 1.6436, Train accuracy->  17.40%\n","Current batch: Loss-> 1.6405, Train accuracy->  17.44%\n","Current batch: Loss-> 1.5882, Train accuracy->  17.48%\n","Current batch: Loss-> 1.5443, Train accuracy->  17.53%\n","Current batch: Loss-> 1.5142, Train accuracy->  17.57%\n","Current batch: Loss-> 1.6323, Train accuracy->  17.61%\n","Current batch: Loss-> 1.3986, Train accuracy->  17.66%\n","Current batch: Loss-> 1.4237, Train accuracy->  17.71%\n","Current batch: Loss-> 1.4241, Train accuracy->  17.75%\n","Current batch: Loss-> 1.7400, Train accuracy->  17.79%\n","Current batch: Loss-> 1.4909, Train accuracy->  17.84%\n","Current batch: Loss-> 1.5275, Train accuracy->  17.89%\n","Current batch: Loss-> 1.6293, Train accuracy->  17.94%\n","Current batch: Loss-> 1.7286, Train accuracy->  17.98%\n","Current batch: Loss-> 1.5374, Train accuracy->  18.02%\n","Current batch: Loss-> 1.4464, Train accuracy->  18.09%\n","Current batch: Loss-> 1.6549, Train accuracy->  18.13%\n","Current batch: Loss-> 1.5091, Train accuracy->  18.18%\n","Current batch: Loss-> 1.8733, Train accuracy->  18.21%\n","Current batch: Loss-> 1.6443, Train accuracy->  18.24%\n","Current batch: Loss-> 1.4776, Train accuracy->  18.28%\n","Current batch: Loss-> 1.5583, Train accuracy->  18.32%\n","Current batch: Loss-> 1.6535, Train accuracy->  18.36%\n","Current batch: Loss-> 1.6924, Train accuracy->  18.41%\n","Current batch: Loss-> 1.5188, Train accuracy->  18.44%\n","Current batch: Loss-> 1.6745, Train accuracy->  18.50%\n","Current batch: Loss-> 1.5262, Train accuracy->  18.55%\n","Current batch: Loss-> 1.5201, Train accuracy->  18.60%\n","Current batch: Loss-> 1.5217, Train accuracy->  18.64%\n","Current batch: Loss-> 1.4999, Train accuracy->  18.69%\n","Current batch: Loss-> 1.6016, Train accuracy->  18.72%\n","Current batch: Loss-> 1.7815, Train accuracy->  18.75%\n","Current batch: Loss-> 1.6953, Train accuracy->  18.80%\n","Current batch: Loss-> 1.5119, Train accuracy->  18.85%\n","Current batch: Loss-> 1.7111, Train accuracy->  18.89%\n","Current batch: Loss-> 1.5238, Train accuracy->  18.94%\n","Current batch: Loss-> 1.5989, Train accuracy->  18.99%\n","Current batch: Loss-> 1.6359, Train accuracy->  19.02%\n","Current batch: Loss-> 1.5675, Train accuracy->  19.07%\n","Current batch: Loss-> 1.5677, Train accuracy->  19.11%\n","Current batch: Loss-> 1.5664, Train accuracy->  19.14%\n","Current batch: Loss-> 1.6024, Train accuracy->  19.19%\n","Current batch: Loss-> 1.5413, Train accuracy->  19.25%\n","Current batch: Loss-> 1.6285, Train accuracy->  19.29%\n","Current batch: Loss-> 1.5916, Train accuracy->  19.35%\n","Current batch: Loss-> 1.6223, Train accuracy->  19.40%\n","Current batch: Loss-> 1.7278, Train accuracy->  19.44%\n","Current batch: Loss-> 1.7001, Train accuracy->  19.48%\n","Current batch: Loss-> 1.8107, Train accuracy->  19.52%\n","Current batch: Loss-> 1.4003, Train accuracy->  19.57%\n","Current batch: Loss-> 1.5905, Train accuracy->  19.61%\n","Current batch: Loss-> 1.7702, Train accuracy->  19.66%\n","Current batch: Loss-> 1.7913, Train accuracy->  19.70%\n","Current batch: Loss-> 1.6995, Train accuracy->  19.74%\n","Current batch: Loss-> 1.6283, Train accuracy->  19.77%\n","Current batch: Loss-> 1.6416, Train accuracy->  19.82%\n","Current batch: Loss-> 1.6530, Train accuracy->  19.86%\n","Current batch: Loss-> 1.6793, Train accuracy->  19.91%\n","Current batch: Loss-> 1.6142, Train accuracy->  19.95%\n","Current batch: Loss-> 1.6712, Train accuracy->  19.99%\n","Current batch: Loss-> 1.5813, Train accuracy->  20.03%\n","Current batch: Loss-> 1.5506, Train accuracy->  20.08%\n","Current batch: Loss-> 1.6025, Train accuracy->  20.12%\n","Current batch: Loss-> 1.6300, Train accuracy->  20.17%\n","Current batch: Loss-> 1.6924, Train accuracy->  20.21%\n","Current batch: Loss-> 1.6399, Train accuracy->  20.25%\n","Current batch: Loss-> 1.6695, Train accuracy->  20.30%\n","Current batch: Loss-> 1.5335, Train accuracy->  20.34%\n","Current batch: Loss-> 1.4835, Train accuracy->  20.38%\n","Current batch: Loss-> 1.8208, Train accuracy->  20.41%\n","Current batch: Loss-> 1.5440, Train accuracy->  20.45%\n","Current batch: Loss-> 1.4285, Train accuracy->  20.50%\n","Current batch: Loss-> 1.5366, Train accuracy->  20.54%\n","Current batch: Loss-> 1.4239, Train accuracy->  20.58%\n","Current batch: Loss-> 1.4911, Train accuracy->  20.62%\n","Current batch: Loss-> 1.4962, Train accuracy->  20.68%\n","Current batch: Loss-> 1.4250, Train accuracy->  20.73%\n","Current batch: Loss-> 1.5820, Train accuracy->  20.78%\n","Current batch: Loss-> 1.6109, Train accuracy->  20.83%\n","Current batch: Loss-> 1.7415, Train accuracy->  20.88%\n","Current batch: Loss-> 1.4766, Train accuracy->  20.93%\n","Current batch: Loss-> 1.4554, Train accuracy->  20.98%\n","Current batch: Loss-> 1.5493, Train accuracy->  21.03%\n","Current batch: Loss-> 1.5999, Train accuracy->  21.09%\n","Current batch: Loss-> 1.7449, Train accuracy->  21.12%\n","Current batch: Loss-> 1.7536, Train accuracy->  21.17%\n","Current batch: Loss-> 1.6207, Train accuracy->  21.21%\n","Current batch: Loss-> 1.4818, Train accuracy->  21.26%\n","Current batch: Loss-> 1.4797, Train accuracy->  21.31%\n","Current batch: Loss-> 1.5193, Train accuracy->  21.35%\n","Current batch: Loss-> 1.4875, Train accuracy->  21.39%\n","Current batch: Loss-> 1.5461, Train accuracy->  21.43%\n","Current batch: Loss-> 1.6532, Train accuracy->  21.46%\n","Current batch: Loss-> 1.6017, Train accuracy->  21.50%\n","Current batch: Loss-> 1.6347, Train accuracy->  21.54%\n","Current batch: Loss-> 1.5709, Train accuracy->  21.58%\n","Current batch: Loss-> 1.6528, Train accuracy->  21.62%\n","Current batch: Loss-> 1.6008, Train accuracy->  21.67%\n","Current batch: Loss-> 1.7253, Train accuracy->  21.71%\n","Current batch: Loss-> 1.6144, Train accuracy->  21.75%\n","Current batch: Loss-> 1.6770, Train accuracy->  21.78%\n","Current batch: Loss-> 1.6010, Train accuracy->  21.84%\n","Current batch: Loss-> 1.5397, Train accuracy->  21.89%\n","Current batch: Loss-> 1.4730, Train accuracy->  21.94%\n","Current batch: Loss-> 1.7059, Train accuracy->  21.98%\n","Current batch: Loss-> 1.5068, Train accuracy->  22.03%\n","Current batch: Loss-> 1.6800, Train accuracy->  22.08%\n","Current batch: Loss-> 1.4886, Train accuracy->  22.12%\n","Current batch: Loss-> 1.6086, Train accuracy->  22.16%\n","Current batch: Loss-> 1.5997, Train accuracy->  22.21%\n","Current batch: Loss-> 1.5831, Train accuracy->  22.26%\n","Current batch: Loss-> 1.6325, Train accuracy->  22.31%\n","Current batch: Loss-> 1.5551, Train accuracy->  22.36%\n","Current batch: Loss-> 1.5390, Train accuracy->  22.40%\n","Current batch: Loss-> 1.4516, Train accuracy->  22.45%\n","Current batch: Loss-> 1.5342, Train accuracy->  22.49%\n","Current batch: Loss-> 1.4228, Train accuracy->  22.54%\n","Current batch: Loss-> 1.6696, Train accuracy->  22.57%\n","Current batch: Loss-> 1.6902, Train accuracy->  22.61%\n","Current batch: Loss-> 1.6894, Train accuracy->  22.66%\n","Current batch: Loss-> 1.5479, Train accuracy->  22.71%\n","Current batch: Loss-> 1.4858, Train accuracy->  22.76%\n","Current batch: Loss-> 1.4893, Train accuracy->  22.80%\n","Current batch: Loss-> 1.4780, Train accuracy->  22.86%\n","Current batch: Loss-> 1.5716, Train accuracy->  22.89%\n","Current batch: Loss-> 1.6261, Train accuracy->  22.95%\n","Current batch: Loss-> 1.5176, Train accuracy->  23.00%\n","Current batch: Loss-> 1.5730, Train accuracy->  23.05%\n","Current batch: Loss-> 1.6004, Train accuracy->  23.10%\n","Current batch: Loss-> 1.5190, Train accuracy->  23.15%\n","Current batch: Loss-> 1.5447, Train accuracy->  23.20%\n","Current batch: Loss-> 1.5880, Train accuracy->  23.24%\n","Current batch: Loss-> 1.5271, Train accuracy->  23.29%\n","Current batch: Loss-> 1.5279, Train accuracy->  23.33%\n","Current batch: Loss-> 1.5486, Train accuracy->  23.38%\n","Current batch: Loss-> 1.5381, Train accuracy->  23.43%\n","Current batch: Loss-> 1.6012, Train accuracy->  23.49%\n","Current batch: Loss-> 1.4585, Train accuracy->  23.54%\n","Current batch: Loss-> 1.4406, Train accuracy->  23.61%\n","Current batch: Loss-> 1.5540, Train accuracy->  23.65%\n","Current batch: Loss-> 1.5673, Train accuracy->  23.69%\n","Current batch: Loss-> 1.6432, Train accuracy->  23.74%\n","Current batch: Loss-> 1.5261, Train accuracy->  23.79%\n","Current batch: Loss-> 1.5402, Train accuracy->  23.84%\n","Current batch: Loss-> 1.4464, Train accuracy->  23.89%\n","Current batch: Loss-> 1.6970, Train accuracy->  23.93%\n","Current batch: Loss-> 1.5525, Train accuracy->  23.97%\n","Current batch: Loss-> 1.7236, Train accuracy->  24.02%\n","Current batch: Loss-> 1.5285, Train accuracy->  24.06%\n","Current batch: Loss-> 1.5622, Train accuracy->  24.11%\n","Current batch: Loss-> 1.7567, Train accuracy->  24.16%\n","Current batch: Loss-> 1.4726, Train accuracy->  24.21%\n","Current batch: Loss-> 1.5077, Train accuracy->  24.27%\n","Current batch: Loss-> 1.6648, Train accuracy->  24.31%\n","Current batch: Loss-> 1.5197, Train accuracy->  24.36%\n","Current batch: Loss-> 1.4165, Train accuracy->  24.42%\n","Current batch: Loss-> 1.3747, Train accuracy->  24.49%\n","Current batch: Loss-> 1.7713, Train accuracy->  24.52%\n","Current batch: Loss-> 1.5089, Train accuracy->  24.57%\n","Current batch: Loss-> 1.4752, Train accuracy->  24.63%\n","Current batch: Loss-> 1.6090, Train accuracy->  24.68%\n","Current batch: Loss-> 1.4479, Train accuracy->  24.73%\n","Current batch: Loss-> 1.6220, Train accuracy->  24.78%\n","Current batch: Loss-> 1.6815, Train accuracy->  24.81%\n","Current batch: Loss-> 1.6571, Train accuracy->  24.87%\n","Current batch: Loss-> 1.5956, Train accuracy->  24.90%\n","Current batch: Loss-> 1.5134, Train accuracy->  24.95%\n","Current batch: Loss-> 1.5280, Train accuracy->  24.98%\n","Current batch: Loss-> 1.4776, Train accuracy->  25.03%\n","Current batch: Loss-> 1.4198, Train accuracy->  25.09%\n","Current batch: Loss-> 1.6914, Train accuracy->  25.13%\n","Current batch: Loss-> 1.5250, Train accuracy->  25.17%\n","Current batch: Loss-> 1.5241, Train accuracy->  25.22%\n","Current batch: Loss-> 1.4713, Train accuracy->  25.26%\n","Current batch: Loss-> 1.4972, Train accuracy->  25.32%\n","Current batch: Loss-> 1.7356, Train accuracy->  25.35%\n","Current batch: Loss-> 1.4944, Train accuracy->  25.40%\n","Current batch: Loss-> 1.5089, Train accuracy->  25.45%\n","Current batch: Loss-> 1.7013, Train accuracy->  25.49%\n","Current batch: Loss-> 1.3897, Train accuracy->  25.55%\n","Current batch: Loss-> 1.4466, Train accuracy->  25.59%\n","Current batch: Loss-> 1.5949, Train accuracy->  25.64%\n","Current batch: Loss-> 1.6236, Train accuracy->  25.68%\n","Current batch: Loss-> 1.6858, Train accuracy->  25.73%\n","Current batch: Loss-> 1.5262, Train accuracy->  25.78%\n","Current batch: Loss-> 1.5447, Train accuracy->  25.84%\n","Current batch: Loss-> 1.4276, Train accuracy->  25.89%\n","Current batch: Loss-> 1.7004, Train accuracy->  25.94%\n","Current batch: Loss-> 1.4820, Train accuracy->  25.98%\n","Current batch: Loss-> 1.6190, Train accuracy->  26.03%\n","Current batch: Loss-> 1.5798, Train accuracy->  26.09%\n","Current batch: Loss-> 1.4367, Train accuracy->  26.13%\n","Current batch: Loss-> 1.6036, Train accuracy->  26.17%\n","Current batch: Loss-> 1.5302, Train accuracy->  26.22%\n","Current batch: Loss-> 1.4861, Train accuracy->  26.26%\n","Current batch: Loss-> 1.4783, Train accuracy->  26.31%\n","Current batch: Loss-> 1.5308, Train accuracy->  26.35%\n","Current batch: Loss-> 1.5795, Train accuracy->  26.41%\n","Current batch: Loss-> 1.6400, Train accuracy->  26.45%\n","Current batch: Loss-> 1.8773, Train accuracy->  26.48%\n","Current batch: Loss-> 1.5495, Train accuracy->  26.52%\n","Current batch: Loss-> 1.7319, Train accuracy->  26.56%\n","Current batch: Loss-> 1.5642, Train accuracy->  26.61%\n","Current batch: Loss-> 1.6515, Train accuracy->  26.65%\n","Current batch: Loss-> 1.8295, Train accuracy->  26.69%\n","Current batch: Loss-> 1.5859, Train accuracy->  26.74%\n","Current batch: Loss-> 1.6993, Train accuracy->  26.78%\n","Current batch: Loss-> 1.4556, Train accuracy->  26.83%\n","Current batch: Loss-> 1.6189, Train accuracy->  26.88%\n","Current batch: Loss-> 1.7426, Train accuracy->  26.92%\n","Current batch: Loss-> 1.3572, Train accuracy->  26.97%\n","Current batch: Loss-> 1.5133, Train accuracy->  27.01%\n","Current batch: Loss-> 1.6331, Train accuracy->  27.06%\n","Current batch: Loss-> 1.6352, Train accuracy->  27.11%\n","Current batch: Loss-> 1.7148, Train accuracy->  27.15%\n","Current batch: Loss-> 1.4348, Train accuracy->  27.20%\n","Current batch: Loss-> 1.5036, Train accuracy->  27.24%\n","Current batch: Loss-> 1.7095, Train accuracy->  27.29%\n","Current batch: Loss-> 1.5218, Train accuracy->  27.34%\n","Current batch: Loss-> 1.6838, Train accuracy->  27.37%\n","Current batch: Loss-> 1.5242, Train accuracy->  27.42%\n","Current batch: Loss-> 1.6585, Train accuracy->  27.46%\n","Current batch: Loss-> 1.6958, Train accuracy->  27.51%\n","Current batch: Loss-> 1.5244, Train accuracy->  27.55%\n","Current batch: Loss-> 1.5750, Train accuracy->  27.60%\n","Current batch: Loss-> 1.5066, Train accuracy->  27.65%\n","Current batch: Loss-> 1.8262, Train accuracy->  27.70%\n","Current batch: Loss-> 1.6403, Train accuracy->  27.75%\n","Current batch: Loss-> 1.5685, Train accuracy->  27.81%\n","Current batch: Loss-> 1.3765, Train accuracy->  27.87%\n","Current batch: Loss-> 1.3663, Train accuracy->  27.94%\n","Current batch: Loss-> 1.4855, Train accuracy->  28.00%\n","Current batch: Loss-> 1.6182, Train accuracy->  28.04%\n","Current batch: Loss-> 1.5010, Train accuracy->  28.08%\n","Current batch: Loss-> 1.8033, Train accuracy->  28.12%\n","Current batch: Loss-> 1.6741, Train accuracy->  28.17%\n","Current batch: Loss-> 1.4611, Train accuracy->  28.22%\n","Current batch: Loss-> 1.4312, Train accuracy->  28.27%\n","Current batch: Loss-> 1.6593, Train accuracy->  28.32%\n","Current batch: Loss-> 1.4323, Train accuracy->  28.39%\n","Current batch: Loss-> 1.6608, Train accuracy->  28.43%\n","Current batch: Loss-> 1.4534, Train accuracy->  28.48%\n","Current batch: Loss-> 1.6902, Train accuracy->  28.52%\n","Current batch: Loss-> 1.5665, Train accuracy->  28.58%\n","Current batch: Loss-> 1.5749, Train accuracy->  28.62%\n","Current batch: Loss-> 1.5945, Train accuracy->  28.67%\n","Current batch: Loss-> 1.6542, Train accuracy->  28.72%\n","Current batch: Loss-> 1.4845, Train accuracy->  28.77%\n","Current batch: Loss-> 1.6640, Train accuracy->  28.81%\n","Current batch: Loss-> 1.4789, Train accuracy->  28.88%\n","Current batch: Loss-> 1.4845, Train accuracy->  28.93%\n","Current batch: Loss-> 1.5677, Train accuracy->  28.98%\n","Current batch: Loss-> 1.7573, Train accuracy->  29.03%\n","Current batch: Loss-> 1.5646, Train accuracy->  29.07%\n","Current batch: Loss-> 1.5820, Train accuracy->  29.13%\n","Current batch: Loss-> 1.5373, Train accuracy->  29.18%\n","Current batch: Loss-> 1.4743, Train accuracy->  29.22%\n","Current batch: Loss-> 1.5298, Train accuracy->  29.27%\n","Current batch: Loss-> 1.5476, Train accuracy->  29.32%\n","Current batch: Loss-> 1.8095, Train accuracy->  29.34%\n","Current batch: Loss-> 1.4946, Train accuracy->  29.39%\n","Current batch: Loss-> 1.4725, Train accuracy->  29.44%\n","Current batch: Loss-> 1.5755, Train accuracy->  29.48%\n","Current batch: Loss-> 1.6070, Train accuracy->  29.53%\n","Current batch: Loss-> 1.4737, Train accuracy->  29.58%\n","Current batch: Loss-> 1.4390, Train accuracy->  29.64%\n","Current batch: Loss-> 1.6704, Train accuracy->  29.68%\n","Current batch: Loss-> 1.6214, Train accuracy->  29.73%\n","Current batch: Loss-> 1.6641, Train accuracy->  29.77%\n","Current batch: Loss-> 1.4446, Train accuracy->  29.82%\n","Current batch: Loss-> 1.6081, Train accuracy->  29.87%\n","Current batch: Loss-> 1.5696, Train accuracy->  29.92%\n","Current batch: Loss-> 1.7562, Train accuracy->  29.96%\n","Current batch: Loss-> 1.4442, Train accuracy->  30.01%\n","Current batch: Loss-> 1.5568, Train accuracy->  30.05%\n","Current batch: Loss-> 1.6096, Train accuracy->  30.10%\n","Current batch: Loss-> 1.4497, Train accuracy->  30.16%\n","Current batch: Loss-> 1.8930, Train accuracy->  30.20%\n","Current batch: Loss-> 1.4112, Train accuracy->  30.26%\n","Current batch: Loss-> 1.3603, Train accuracy->  30.32%\n","Current batch: Loss-> 1.5251, Train accuracy->  30.37%\n","Current batch: Loss-> 1.5479, Train accuracy->  30.41%\n","Current batch: Loss-> 1.5603, Train accuracy->  30.47%\n","Current batch: Loss-> 1.7189, Train accuracy->  30.51%\n","Current batch: Loss-> 1.4722, Train accuracy->  30.56%\n","Current batch: Loss-> 1.4846, Train accuracy->  30.61%\n","Current batch: Loss-> 1.5323, Train accuracy->  30.65%\n","Current batch: Loss-> 1.3817, Train accuracy->  30.71%\n","Current batch: Loss-> 1.4510, Train accuracy->  30.77%\n","Current batch: Loss-> 1.4261, Train accuracy->  30.82%\n","Current batch: Loss-> 1.5569, Train accuracy->  30.87%\n","Current batch: Loss-> 1.6711, Train accuracy->  30.92%\n","Current batch: Loss-> 1.4579, Train accuracy->  30.97%\n","Current batch: Loss-> 1.5798, Train accuracy->  31.02%\n","Current batch: Loss-> 1.4735, Train accuracy->  31.07%\n","Current batch: Loss-> 1.5278, Train accuracy->  31.12%\n","Current batch: Loss-> 1.4561, Train accuracy->  31.18%\n","Current batch: Loss-> 1.6643, Train accuracy->  31.22%\n","Current batch: Loss-> 1.4438, Train accuracy->  31.29%\n","Current batch: Loss-> 1.5054, Train accuracy->  31.33%\n","Current batch: Loss-> 1.5101, Train accuracy->  31.38%\n","Current batch: Loss-> 1.4920, Train accuracy->  31.44%\n","Current batch: Loss-> 1.5567, Train accuracy->  31.50%\n","Current batch: Loss-> 1.3937, Train accuracy->  31.56%\n","Current batch: Loss-> 1.5802, Train accuracy->  31.61%\n","Current batch: Loss-> 1.4786, Train accuracy->  31.65%\n","Current batch: Loss-> 1.5443, Train accuracy->  31.70%\n","Current batch: Loss-> 1.4893, Train accuracy->  31.75%\n","Current batch: Loss-> 1.3837, Train accuracy->  31.81%\n","Current batch: Loss-> 1.4206, Train accuracy->  31.87%\n","Current batch: Loss-> 1.6003, Train accuracy->  31.91%\n","Current batch: Loss-> 1.5848, Train accuracy->  31.95%\n","Current batch: Loss-> 1.3213, Train accuracy->  32.01%\n","Current batch: Loss-> 1.3957, Train accuracy->  32.07%\n","Current batch: Loss-> 1.5865, Train accuracy->  32.11%\n","Current batch: Loss-> 1.5456, Train accuracy->  32.16%\n","Current batch: Loss-> 1.6265, Train accuracy->  32.20%\n","Current batch: Loss-> 1.5536, Train accuracy->  32.26%\n","Current batch: Loss-> 1.4791, Train accuracy->  32.31%\n","Current batch: Loss-> 1.4627, Train accuracy->  32.36%\n","Current batch: Loss-> 1.5194, Train accuracy->  32.40%\n","Current batch: Loss-> 1.4432, Train accuracy->  32.45%\n","Current batch: Loss-> 1.3992, Train accuracy->  32.50%\n","Current batch: Loss-> 1.4936, Train accuracy->  32.55%\n","Current batch: Loss-> 1.4972, Train accuracy->  32.60%\n","Current batch: Loss-> 1.4927, Train accuracy->  32.66%\n","Current batch: Loss-> 1.7306, Train accuracy->  32.70%\n","Current batch: Loss-> 1.6718, Train accuracy->  32.73%\n","Current batch: Loss-> 1.4877, Train accuracy->  32.77%\n","Current batch: Loss-> 1.6095, Train accuracy->  32.81%\n","Current batch: Loss-> 1.5068, Train accuracy->  32.86%\n","Current batch: Loss-> 1.4804, Train accuracy->  32.91%\n","Current batch: Loss-> 2.0604, Train accuracy->  32.92%\n","Current batch: Loss-> 1.5940, Train accuracy->  32.97%\n","Current batch: Loss-> 1.4727, Train accuracy->  33.01%\n","Current batch: Loss-> 1.4948, Train accuracy->  33.05%\n","Current batch: Loss-> 1.4225, Train accuracy->  33.10%\n","Current batch: Loss-> 1.6896, Train accuracy->  33.14%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 47.46it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.3961, Train accuracy->  33.20%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.90it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.4181, Accuracy: 4424/12000 (37%)\n","\n","Current batch: Loss-> 1.5272, Train accuracy->   0.04%\n","Current batch: Loss-> 1.7527, Train accuracy->   0.08%\n","Current batch: Loss-> 1.3745, Train accuracy->   0.14%\n","Current batch: Loss-> 1.7128, Train accuracy->   0.18%\n","Current batch: Loss-> 1.4678, Train accuracy->   0.23%\n","Current batch: Loss-> 1.4335, Train accuracy->   0.29%\n","Current batch: Loss-> 1.4401, Train accuracy->   0.34%\n","Current batch: Loss-> 1.4144, Train accuracy->   0.39%\n","Current batch: Loss-> 1.4953, Train accuracy->   0.44%\n","Current batch: Loss-> 1.6638, Train accuracy->   0.49%\n","Current batch: Loss-> 1.5144, Train accuracy->   0.53%\n","Current batch: Loss-> 1.5719, Train accuracy->   0.57%\n","Current batch: Loss-> 1.5521, Train accuracy->   0.63%\n","Current batch: Loss-> 1.3942, Train accuracy->   0.69%\n","Current batch: Loss-> 1.4431, Train accuracy->   0.74%\n","Current batch: Loss-> 1.4684, Train accuracy->   0.79%\n","Current batch: Loss-> 1.4284, Train accuracy->   0.85%\n","Current batch: Loss-> 1.4275, Train accuracy->   0.91%\n","Current batch: Loss-> 1.5761, Train accuracy->   0.97%\n","Current batch: Loss-> 1.4604, Train accuracy->   1.02%\n","Current batch: Loss-> 1.3865, Train accuracy->   1.08%\n","Current batch: Loss-> 1.1817, Train accuracy->   1.16%\n","Current batch: Loss-> 1.5392, Train accuracy->   1.20%\n","Current batch: Loss-> 1.5001, Train accuracy->   1.24%\n","Current batch: Loss-> 1.6196, Train accuracy->   1.29%\n","Current batch: Loss-> 1.5206, Train accuracy->   1.33%\n","Current batch: Loss-> 1.4374, Train accuracy->   1.39%\n","Current batch: Loss-> 1.5857, Train accuracy->   1.45%\n","Current batch: Loss-> 1.4025, Train accuracy->   1.50%\n","Current batch: Loss-> 1.5428, Train accuracy->   1.56%\n","Current batch: Loss-> 1.3894, Train accuracy->   1.61%\n","Current batch: Loss-> 1.4758, Train accuracy->   1.66%\n","Current batch: Loss-> 1.3888, Train accuracy->   1.72%\n","Current batch: Loss-> 1.5561, Train accuracy->   1.76%\n","Current batch: Loss-> 1.7556, Train accuracy->   1.80%\n","Current batch: Loss-> 1.5323, Train accuracy->   1.84%\n","Current batch: Loss-> 1.8688, Train accuracy->   1.88%\n","Current batch: Loss-> 1.5399, Train accuracy->   1.93%\n","Current batch: Loss-> 1.6278, Train accuracy->   1.97%\n","Current batch: Loss-> 1.9796, Train accuracy->   2.00%\n","Current batch: Loss-> 1.6227, Train accuracy->   2.06%\n","Current batch: Loss-> 1.5763, Train accuracy->   2.10%\n","Current batch: Loss-> 1.6315, Train accuracy->   2.16%\n","Current batch: Loss-> 1.4631, Train accuracy->   2.22%\n","Current batch: Loss-> 1.4245, Train accuracy->   2.27%\n","Current batch: Loss-> 1.7569, Train accuracy->   2.31%\n","Current batch: Loss-> 1.9922, Train accuracy->   2.35%\n","Current batch: Loss-> 1.7248, Train accuracy->   2.39%\n","Current batch: Loss-> 1.5023, Train accuracy->   2.46%\n","Current batch: Loss-> 1.4253, Train accuracy->   2.50%\n","Current batch: Loss-> 1.5695, Train accuracy->   2.55%\n","Current batch: Loss-> 1.5418, Train accuracy->   2.60%\n","Current batch: Loss-> 1.4769, Train accuracy->   2.65%\n","Current batch: Loss-> 1.7131, Train accuracy->   2.69%\n","Current batch: Loss-> 1.6097, Train accuracy->   2.74%\n","Current batch: Loss-> 1.4730, Train accuracy->   2.78%\n","Current batch: Loss-> 1.5207, Train accuracy->   2.84%\n","Current batch: Loss-> 1.4953, Train accuracy->   2.88%\n","Current batch: Loss-> 1.6519, Train accuracy->   2.93%\n","Current batch: Loss-> 1.3701, Train accuracy->   2.99%\n","Current batch: Loss-> 1.6695, Train accuracy->   3.02%\n","Current batch: Loss-> 1.5094, Train accuracy->   3.07%\n","Current batch: Loss-> 1.6629, Train accuracy->   3.11%\n","Current batch: Loss-> 1.6527, Train accuracy->   3.15%\n","Current batch: Loss-> 1.6669, Train accuracy->   3.19%\n","Current batch: Loss-> 1.6361, Train accuracy->   3.24%\n","Current batch: Loss-> 1.6621, Train accuracy->   3.29%\n","Current batch: Loss-> 1.3882, Train accuracy->   3.35%\n","Current batch: Loss-> 1.3099, Train accuracy->   3.41%\n","Current batch: Loss-> 1.4242, Train accuracy->   3.47%\n","Current batch: Loss-> 1.6088, Train accuracy->   3.51%\n","Current batch: Loss-> 1.5950, Train accuracy->   3.58%\n","Current batch: Loss-> 1.4881, Train accuracy->   3.64%\n","Current batch: Loss-> 1.3845, Train accuracy->   3.70%\n","Current batch: Loss-> 1.4422, Train accuracy->   3.74%\n","Current batch: Loss-> 1.5439, Train accuracy->   3.79%\n","Current batch: Loss-> 1.5544, Train accuracy->   3.83%\n","Current batch: Loss-> 1.4278, Train accuracy->   3.89%\n","Current batch: Loss-> 1.4231, Train accuracy->   3.94%\n","Current batch: Loss-> 1.6122, Train accuracy->   3.98%\n","Current batch: Loss-> 1.6451, Train accuracy->   4.02%\n","Current batch: Loss-> 1.6136, Train accuracy->   4.06%\n","Current batch: Loss-> 1.5488, Train accuracy->   4.10%\n","Current batch: Loss-> 1.4190, Train accuracy->   4.15%\n","Current batch: Loss-> 1.4127, Train accuracy->   4.21%\n","Current batch: Loss-> 1.4249, Train accuracy->   4.27%\n","Current batch: Loss-> 1.4575, Train accuracy->   4.32%\n","Current batch: Loss-> 1.5007, Train accuracy->   4.37%\n","Current batch: Loss-> 1.5210, Train accuracy->   4.41%\n","Current batch: Loss-> 1.6356, Train accuracy->   4.45%\n","Current batch: Loss-> 1.4542, Train accuracy->   4.51%\n","Current batch: Loss-> 1.7362, Train accuracy->   4.55%\n","Current batch: Loss-> 1.3373, Train accuracy->   4.61%\n","Current batch: Loss-> 1.4144, Train accuracy->   4.66%\n","Current batch: Loss-> 1.4384, Train accuracy->   4.72%\n","Current batch: Loss-> 1.4843, Train accuracy->   4.78%\n","Current batch: Loss-> 1.4182, Train accuracy->   4.84%\n","Current batch: Loss-> 1.5031, Train accuracy->   4.89%\n","Current batch: Loss-> 1.3575, Train accuracy->   4.95%\n","Current batch: Loss-> 1.5021, Train accuracy->   4.99%\n","Current batch: Loss-> 1.5248, Train accuracy->   5.04%\n","Current batch: Loss-> 1.4799, Train accuracy->   5.09%\n","Current batch: Loss-> 1.4934, Train accuracy->   5.15%\n","Current batch: Loss-> 1.4517, Train accuracy->   5.21%\n","Current batch: Loss-> 1.6986, Train accuracy->   5.26%\n","Current batch: Loss-> 1.4825, Train accuracy->   5.32%\n","Current batch: Loss-> 1.5500, Train accuracy->   5.37%\n","Current batch: Loss-> 1.6947, Train accuracy->   5.41%\n","Current batch: Loss-> 1.9187, Train accuracy->   5.45%\n","Current batch: Loss-> 1.5561, Train accuracy->   5.50%\n","Current batch: Loss-> 1.6491, Train accuracy->   5.55%\n","Current batch: Loss-> 1.3247, Train accuracy->   5.61%\n","Current batch: Loss-> 1.3860, Train accuracy->   5.66%\n","Current batch: Loss-> 1.4812, Train accuracy->   5.72%\n","Current batch: Loss-> 1.6197, Train accuracy->   5.76%\n","Current batch: Loss-> 1.5672, Train accuracy->   5.80%\n","Current batch: Loss-> 1.5227, Train accuracy->   5.85%\n","Current batch: Loss-> 1.5965, Train accuracy->   5.89%\n","Current batch: Loss-> 1.4728, Train accuracy->   5.94%\n","Current batch: Loss-> 1.5185, Train accuracy->   5.98%\n","Current batch: Loss-> 1.6477, Train accuracy->   6.03%\n","Current batch: Loss-> 1.3793, Train accuracy->   6.09%\n","Current batch: Loss-> 1.5913, Train accuracy->   6.13%\n","Current batch: Loss-> 1.6697, Train accuracy->   6.17%\n","Current batch: Loss-> 1.4243, Train accuracy->   6.22%\n","Current batch: Loss-> 1.5631, Train accuracy->   6.27%\n","Current batch: Loss-> 1.3882, Train accuracy->   6.32%\n","Current batch: Loss-> 1.3974, Train accuracy->   6.36%\n","Current batch: Loss-> 1.5484, Train accuracy->   6.41%\n","Current batch: Loss-> 1.5199, Train accuracy->   6.45%\n","Current batch: Loss-> 1.5154, Train accuracy->   6.51%\n","Current batch: Loss-> 1.3131, Train accuracy->   6.58%\n","Current batch: Loss-> 1.3381, Train accuracy->   6.63%\n","Current batch: Loss-> 1.4879, Train accuracy->   6.69%\n","Current batch: Loss-> 1.5769, Train accuracy->   6.74%\n","Current batch: Loss-> 1.5139, Train accuracy->   6.80%\n","Current batch: Loss-> 1.4202, Train accuracy->   6.85%\n","Current batch: Loss-> 1.4368, Train accuracy->   6.90%\n","Current batch: Loss-> 1.3827, Train accuracy->   6.95%\n","Current batch: Loss-> 1.5559, Train accuracy->   6.99%\n","Current batch: Loss-> 1.5709, Train accuracy->   7.03%\n","Current batch: Loss-> 1.5417, Train accuracy->   7.08%\n","Current batch: Loss-> 1.5640, Train accuracy->   7.13%\n","Current batch: Loss-> 1.3812, Train accuracy->   7.18%\n","Current batch: Loss-> 1.6382, Train accuracy->   7.23%\n","Current batch: Loss-> 1.4895, Train accuracy->   7.29%\n","Current batch: Loss-> 1.4569, Train accuracy->   7.33%\n","Current batch: Loss-> 1.5409, Train accuracy->   7.36%\n","Current batch: Loss-> 1.3840, Train accuracy->   7.42%\n","Current batch: Loss-> 1.5307, Train accuracy->   7.47%\n","Current batch: Loss-> 1.4808, Train accuracy->   7.51%\n","Current batch: Loss-> 1.6258, Train accuracy->   7.56%\n","Current batch: Loss-> 1.6156, Train accuracy->   7.60%\n","Current batch: Loss-> 1.6381, Train accuracy->   7.63%\n","Current batch: Loss-> 1.5238, Train accuracy->   7.69%\n","Current batch: Loss-> 1.4720, Train accuracy->   7.74%\n","Current batch: Loss-> 1.7041, Train accuracy->   7.78%\n","Current batch: Loss-> 1.7484, Train accuracy->   7.81%\n","Current batch: Loss-> 1.8396, Train accuracy->   7.84%\n","Current batch: Loss-> 1.6649, Train accuracy->   7.89%\n","Current batch: Loss-> 1.5610, Train accuracy->   7.96%\n","Current batch: Loss-> 1.7054, Train accuracy->   8.00%\n","Current batch: Loss-> 1.6039, Train accuracy->   8.05%\n","Current batch: Loss-> 1.5549, Train accuracy->   8.10%\n","Current batch: Loss-> 1.4908, Train accuracy->   8.15%\n","Current batch: Loss-> 1.9494, Train accuracy->   8.17%\n","Current batch: Loss-> 1.5448, Train accuracy->   8.22%\n","Current batch: Loss-> 1.6939, Train accuracy->   8.27%\n","Current batch: Loss-> 1.5270, Train accuracy->   8.32%\n","Current batch: Loss-> 1.5006, Train accuracy->   8.35%\n","Current batch: Loss-> 1.5927, Train accuracy->   8.39%\n","Current batch: Loss-> 1.5572, Train accuracy->   8.43%\n","Current batch: Loss-> 1.6765, Train accuracy->   8.47%\n","Current batch: Loss-> 1.6772, Train accuracy->   8.52%\n","Current batch: Loss-> 1.4193, Train accuracy->   8.58%\n","Current batch: Loss-> 1.4451, Train accuracy->   8.63%\n","Current batch: Loss-> 1.6012, Train accuracy->   8.68%\n","Current batch: Loss-> 1.5711, Train accuracy->   8.73%\n","Current batch: Loss-> 1.4764, Train accuracy->   8.77%\n","Current batch: Loss-> 1.6737, Train accuracy->   8.81%\n","Current batch: Loss-> 1.4796, Train accuracy->   8.87%\n","Current batch: Loss-> 1.5825, Train accuracy->   8.92%\n","Current batch: Loss-> 1.5054, Train accuracy->   8.98%\n","Current batch: Loss-> 1.6493, Train accuracy->   9.01%\n","Current batch: Loss-> 1.4558, Train accuracy->   9.07%\n","Current batch: Loss-> 1.3223, Train accuracy->   9.13%\n","Current batch: Loss-> 1.5052, Train accuracy->   9.18%\n","Current batch: Loss-> 1.5188, Train accuracy->   9.23%\n","Current batch: Loss-> 1.5053, Train accuracy->   9.28%\n","Current batch: Loss-> 1.3915, Train accuracy->   9.35%\n","Current batch: Loss-> 1.5689, Train accuracy->   9.39%\n","Current batch: Loss-> 1.6398, Train accuracy->   9.44%\n","Current batch: Loss-> 1.3871, Train accuracy->   9.50%\n","Current batch: Loss-> 1.5643, Train accuracy->   9.56%\n","Current batch: Loss-> 1.4615, Train accuracy->   9.60%\n","Current batch: Loss-> 1.4013, Train accuracy->   9.65%\n","Current batch: Loss-> 1.3883, Train accuracy->   9.71%\n","Current batch: Loss-> 1.4195, Train accuracy->   9.78%\n","Current batch: Loss-> 1.3197, Train accuracy->   9.85%\n","Current batch: Loss-> 1.3257, Train accuracy->   9.91%\n","Current batch: Loss-> 1.5165, Train accuracy->   9.96%\n","Current batch: Loss-> 1.4572, Train accuracy->  10.01%\n","Current batch: Loss-> 1.5965, Train accuracy->  10.06%\n","Current batch: Loss-> 1.4679, Train accuracy->  10.11%\n","Current batch: Loss-> 1.6620, Train accuracy->  10.15%\n","Current batch: Loss-> 1.8266, Train accuracy->  10.18%\n","Current batch: Loss-> 1.4239, Train accuracy->  10.24%\n","Current batch: Loss-> 1.5087, Train accuracy->  10.29%\n","Current batch: Loss-> 1.4890, Train accuracy->  10.34%\n","Current batch: Loss-> 1.3819, Train accuracy->  10.39%\n","Current batch: Loss-> 1.4829, Train accuracy->  10.44%\n","Current batch: Loss-> 1.3157, Train accuracy->  10.50%\n","Current batch: Loss-> 1.4939, Train accuracy->  10.54%\n","Current batch: Loss-> 1.2951, Train accuracy->  10.61%\n","Current batch: Loss-> 1.3845, Train accuracy->  10.66%\n","Current batch: Loss-> 1.3257, Train accuracy->  10.73%\n","Current batch: Loss-> 1.3936, Train accuracy->  10.78%\n","Current batch: Loss-> 1.4472, Train accuracy->  10.82%\n","Current batch: Loss-> 1.4287, Train accuracy->  10.89%\n","Current batch: Loss-> 1.6460, Train accuracy->  10.94%\n","Current batch: Loss-> 1.4091, Train accuracy->  11.00%\n","Current batch: Loss-> 1.2960, Train accuracy->  11.06%\n","Current batch: Loss-> 1.3575, Train accuracy->  11.11%\n","Current batch: Loss-> 1.4735, Train accuracy->  11.17%\n","Current batch: Loss-> 1.3268, Train accuracy->  11.23%\n","Current batch: Loss-> 1.5373, Train accuracy->  11.28%\n","Current batch: Loss-> 1.4822, Train accuracy->  11.34%\n","Current batch: Loss-> 1.5228, Train accuracy->  11.39%\n","Current batch: Loss-> 1.5386, Train accuracy->  11.44%\n","Current batch: Loss-> 1.4807, Train accuracy->  11.49%\n","Current batch: Loss-> 1.6008, Train accuracy->  11.54%\n","Current batch: Loss-> 1.6133, Train accuracy->  11.58%\n","Current batch: Loss-> 1.5347, Train accuracy->  11.64%\n","Current batch: Loss-> 1.6932, Train accuracy->  11.69%\n","Current batch: Loss-> 1.6173, Train accuracy->  11.72%\n","Current batch: Loss-> 1.5601, Train accuracy->  11.77%\n","Current batch: Loss-> 1.4280, Train accuracy->  11.83%\n","Current batch: Loss-> 1.5271, Train accuracy->  11.88%\n","Current batch: Loss-> 1.5878, Train accuracy->  11.92%\n","Current batch: Loss-> 1.4881, Train accuracy->  11.95%\n","Current batch: Loss-> 1.5225, Train accuracy->  12.00%\n","Current batch: Loss-> 1.4667, Train accuracy->  12.05%\n","Current batch: Loss-> 1.5111, Train accuracy->  12.09%\n","Current batch: Loss-> 1.5492, Train accuracy->  12.14%\n","Current batch: Loss-> 1.4584, Train accuracy->  12.19%\n","Current batch: Loss-> 1.4140, Train accuracy->  12.25%\n","Current batch: Loss-> 1.4423, Train accuracy->  12.31%\n","Current batch: Loss-> 1.5817, Train accuracy->  12.34%\n","Current batch: Loss-> 1.4866, Train accuracy->  12.38%\n","Current batch: Loss-> 1.4315, Train accuracy->  12.43%\n","Current batch: Loss-> 1.4663, Train accuracy->  12.48%\n","Current batch: Loss-> 1.6899, Train accuracy->  12.52%\n","Current batch: Loss-> 1.4746, Train accuracy->  12.57%\n","Current batch: Loss-> 1.4201, Train accuracy->  12.62%\n","Current batch: Loss-> 1.4454, Train accuracy->  12.67%\n","Current batch: Loss-> 1.3946, Train accuracy->  12.73%\n","Current batch: Loss-> 1.4816, Train accuracy->  12.78%\n","Current batch: Loss-> 1.4818, Train accuracy->  12.82%\n","Current batch: Loss-> 1.5394, Train accuracy->  12.88%\n","Current batch: Loss-> 1.6574, Train accuracy->  12.93%\n","Current batch: Loss-> 1.5848, Train accuracy->  12.97%\n","Current batch: Loss-> 1.5749, Train accuracy->  13.02%\n","Current batch: Loss-> 1.4701, Train accuracy->  13.07%\n","Current batch: Loss-> 1.4517, Train accuracy->  13.13%\n","Current batch: Loss-> 1.3988, Train accuracy->  13.19%\n","Current batch: Loss-> 1.5419, Train accuracy->  13.24%\n","Current batch: Loss-> 1.4459, Train accuracy->  13.29%\n","Current batch: Loss-> 1.5350, Train accuracy->  13.33%\n","Current batch: Loss-> 1.4062, Train accuracy->  13.38%\n","Current batch: Loss-> 1.4760, Train accuracy->  13.42%\n","Current batch: Loss-> 1.7514, Train accuracy->  13.46%\n","Current batch: Loss-> 1.3625, Train accuracy->  13.52%\n","Current batch: Loss-> 1.5249, Train accuracy->  13.56%\n","Current batch: Loss-> 1.3663, Train accuracy->  13.63%\n","Current batch: Loss-> 1.5167, Train accuracy->  13.68%\n","Current batch: Loss-> 1.3228, Train accuracy->  13.74%\n","Current batch: Loss-> 1.4612, Train accuracy->  13.78%\n","Current batch: Loss-> 1.5038, Train accuracy->  13.84%\n","Current batch: Loss-> 1.4108, Train accuracy->  13.90%\n","Current batch: Loss-> 1.8001, Train accuracy->  13.95%\n","Current batch: Loss-> 1.6281, Train accuracy->  13.99%\n","Current batch: Loss-> 1.6361, Train accuracy->  14.03%\n","Current batch: Loss-> 1.8823, Train accuracy->  14.08%\n","Current batch: Loss-> 1.7227, Train accuracy->  14.10%\n","Current batch: Loss-> 1.3958, Train accuracy->  14.14%\n","Current batch: Loss-> 1.4475, Train accuracy->  14.20%\n","Current batch: Loss-> 1.4863, Train accuracy->  14.25%\n","Current batch: Loss-> 1.4465, Train accuracy->  14.30%\n","Current batch: Loss-> 1.6612, Train accuracy->  14.35%\n","Current batch: Loss-> 1.7308, Train accuracy->  14.40%\n","Current batch: Loss-> 1.7294, Train accuracy->  14.44%\n","Current batch: Loss-> 1.4915, Train accuracy->  14.50%\n","Current batch: Loss-> 1.4551, Train accuracy->  14.56%\n","Current batch: Loss-> 1.5366, Train accuracy->  14.61%\n","Current batch: Loss-> 1.7377, Train accuracy->  14.66%\n","Current batch: Loss-> 1.3924, Train accuracy->  14.71%\n","Current batch: Loss-> 1.5618, Train accuracy->  14.77%\n","Current batch: Loss-> 1.6411, Train accuracy->  14.81%\n","Current batch: Loss-> 1.5691, Train accuracy->  14.85%\n","Current batch: Loss-> 1.5978, Train accuracy->  14.91%\n","Current batch: Loss-> 1.5040, Train accuracy->  14.95%\n","Current batch: Loss-> 1.5766, Train accuracy->  14.99%\n","Current batch: Loss-> 1.7220, Train accuracy->  15.02%\n","Current batch: Loss-> 1.5270, Train accuracy->  15.07%\n","Current batch: Loss-> 1.3731, Train accuracy->  15.13%\n","Current batch: Loss-> 1.5950, Train accuracy->  15.18%\n","Current batch: Loss-> 1.5427, Train accuracy->  15.25%\n","Current batch: Loss-> 1.3482, Train accuracy->  15.31%\n","Current batch: Loss-> 1.4195, Train accuracy->  15.36%\n","Current batch: Loss-> 1.5710, Train accuracy->  15.41%\n","Current batch: Loss-> 1.7613, Train accuracy->  15.46%\n","Current batch: Loss-> 1.4650, Train accuracy->  15.51%\n","Current batch: Loss-> 1.3996, Train accuracy->  15.56%\n","Current batch: Loss-> 1.5132, Train accuracy->  15.61%\n","Current batch: Loss-> 1.5788, Train accuracy->  15.66%\n","Current batch: Loss-> 1.4310, Train accuracy->  15.72%\n","Current batch: Loss-> 1.3894, Train accuracy->  15.77%\n","Current batch: Loss-> 1.3675, Train accuracy->  15.82%\n","Current batch: Loss-> 1.4481, Train accuracy->  15.89%\n","Current batch: Loss-> 1.4942, Train accuracy->  15.94%\n","Current batch: Loss-> 1.4236, Train accuracy->  15.98%\n","Current batch: Loss-> 1.7542, Train accuracy->  16.02%\n","Current batch: Loss-> 1.4387, Train accuracy->  16.08%\n","Current batch: Loss-> 1.3537, Train accuracy->  16.13%\n","Current batch: Loss-> 1.4361, Train accuracy->  16.19%\n","Current batch: Loss-> 1.5597, Train accuracy->  16.24%\n","Current batch: Loss-> 1.4636, Train accuracy->  16.30%\n","Current batch: Loss-> 1.5843, Train accuracy->  16.36%\n","Current batch: Loss-> 1.4246, Train accuracy->  16.40%\n","Current batch: Loss-> 1.4560, Train accuracy->  16.45%\n","Current batch: Loss-> 1.5116, Train accuracy->  16.50%\n","Current batch: Loss-> 1.4064, Train accuracy->  16.55%\n","Current batch: Loss-> 1.3527, Train accuracy->  16.61%\n","Current batch: Loss-> 1.5217, Train accuracy->  16.67%\n","Current batch: Loss-> 1.3531, Train accuracy->  16.73%\n","Current batch: Loss-> 1.2879, Train accuracy->  16.79%\n","Current batch: Loss-> 1.4432, Train accuracy->  16.85%\n","Current batch: Loss-> 1.5707, Train accuracy->  16.90%\n","Current batch: Loss-> 1.7270, Train accuracy->  16.94%\n","Current batch: Loss-> 1.4072, Train accuracy->  16.99%\n","Current batch: Loss-> 1.4073, Train accuracy->  17.05%\n","Current batch: Loss-> 1.5266, Train accuracy->  17.10%\n","Current batch: Loss-> 1.5194, Train accuracy->  17.15%\n","Current batch: Loss-> 1.4425, Train accuracy->  17.21%\n","Current batch: Loss-> 1.5346, Train accuracy->  17.26%\n","Current batch: Loss-> 1.4042, Train accuracy->  17.31%\n","Current batch: Loss-> 1.3885, Train accuracy->  17.39%\n","Current batch: Loss-> 1.6480, Train accuracy->  17.44%\n","Current batch: Loss-> 1.3195, Train accuracy->  17.50%\n","Current batch: Loss-> 1.3700, Train accuracy->  17.56%\n","Current batch: Loss-> 1.7237, Train accuracy->  17.61%\n","Current batch: Loss-> 1.5333, Train accuracy->  17.64%\n","Current batch: Loss-> 1.5893, Train accuracy->  17.69%\n","Current batch: Loss-> 1.2464, Train accuracy->  17.75%\n","Current batch: Loss-> 1.4469, Train accuracy->  17.80%\n","Current batch: Loss-> 1.4346, Train accuracy->  17.86%\n","Current batch: Loss-> 1.5366, Train accuracy->  17.89%\n","Current batch: Loss-> 1.4460, Train accuracy->  17.95%\n","Current batch: Loss-> 1.3326, Train accuracy->  18.02%\n","Current batch: Loss-> 1.5093, Train accuracy->  18.06%\n","Current batch: Loss-> 1.4722, Train accuracy->  18.12%\n","Current batch: Loss-> 1.4321, Train accuracy->  18.19%\n","Current batch: Loss-> 1.3818, Train accuracy->  18.24%\n","Current batch: Loss-> 1.4564, Train accuracy->  18.29%\n","Current batch: Loss-> 1.5656, Train accuracy->  18.33%\n","Current batch: Loss-> 1.3978, Train accuracy->  18.38%\n","Current batch: Loss-> 1.5461, Train accuracy->  18.44%\n","Current batch: Loss-> 1.5519, Train accuracy->  18.48%\n","Current batch: Loss-> 1.4038, Train accuracy->  18.53%\n","Current batch: Loss-> 1.4737, Train accuracy->  18.58%\n","Current batch: Loss-> 1.4365, Train accuracy->  18.63%\n","Current batch: Loss-> 1.6106, Train accuracy->  18.67%\n","Current batch: Loss-> 1.4871, Train accuracy->  18.72%\n","Current batch: Loss-> 1.3215, Train accuracy->  18.78%\n","Current batch: Loss-> 1.3394, Train accuracy->  18.84%\n","Current batch: Loss-> 1.5418, Train accuracy->  18.89%\n","Current batch: Loss-> 1.4369, Train accuracy->  18.94%\n","Current batch: Loss-> 1.6862, Train accuracy->  19.00%\n","Current batch: Loss-> 1.5378, Train accuracy->  19.05%\n","Current batch: Loss-> 1.4829, Train accuracy->  19.11%\n","Current batch: Loss-> 1.3825, Train accuracy->  19.16%\n","Current batch: Loss-> 1.3700, Train accuracy->  19.23%\n","Current batch: Loss-> 1.4735, Train accuracy->  19.29%\n","Current batch: Loss-> 1.5513, Train accuracy->  19.34%\n","Current batch: Loss-> 1.4153, Train accuracy->  19.38%\n","Current batch: Loss-> 1.4001, Train accuracy->  19.43%\n","Current batch: Loss-> 1.4557, Train accuracy->  19.48%\n","Current batch: Loss-> 1.7462, Train accuracy->  19.53%\n","Current batch: Loss-> 1.3491, Train accuracy->  19.59%\n","Current batch: Loss-> 1.4019, Train accuracy->  19.65%\n","Current batch: Loss-> 1.4985, Train accuracy->  19.70%\n","Current batch: Loss-> 1.5555, Train accuracy->  19.75%\n","Current batch: Loss-> 1.7339, Train accuracy->  19.79%\n","Current batch: Loss-> 1.3737, Train accuracy->  19.86%\n","Current batch: Loss-> 1.4777, Train accuracy->  19.90%\n","Current batch: Loss-> 1.5407, Train accuracy->  19.94%\n","Current batch: Loss-> 1.4549, Train accuracy->  19.99%\n","Current batch: Loss-> 1.5247, Train accuracy->  20.04%\n","Current batch: Loss-> 1.3608, Train accuracy->  20.09%\n","Current batch: Loss-> 1.6385, Train accuracy->  20.13%\n","Current batch: Loss-> 1.3879, Train accuracy->  20.20%\n","Current batch: Loss-> 1.3975, Train accuracy->  20.25%\n","Current batch: Loss-> 1.4236, Train accuracy->  20.30%\n","Current batch: Loss-> 1.4866, Train accuracy->  20.35%\n","Current batch: Loss-> 1.2686, Train accuracy->  20.42%\n","Current batch: Loss-> 1.4793, Train accuracy->  20.46%\n","Current batch: Loss-> 1.5967, Train accuracy->  20.50%\n","Current batch: Loss-> 1.6571, Train accuracy->  20.56%\n","Current batch: Loss-> 1.4515, Train accuracy->  20.61%\n","Current batch: Loss-> 1.4368, Train accuracy->  20.68%\n","Current batch: Loss-> 1.4273, Train accuracy->  20.73%\n","Current batch: Loss-> 1.5162, Train accuracy->  20.78%\n","Current batch: Loss-> 1.3753, Train accuracy->  20.83%\n","Current batch: Loss-> 1.3754, Train accuracy->  20.88%\n","Current batch: Loss-> 1.4377, Train accuracy->  20.92%\n","Current batch: Loss-> 1.3642, Train accuracy->  20.99%\n","Current batch: Loss-> 1.3368, Train accuracy->  21.05%\n","Current batch: Loss-> 1.3152, Train accuracy->  21.11%\n","Current batch: Loss-> 1.6626, Train accuracy->  21.16%\n","Current batch: Loss-> 1.3806, Train accuracy->  21.21%\n","Current batch: Loss-> 1.4707, Train accuracy->  21.27%\n","Current batch: Loss-> 1.4851, Train accuracy->  21.34%\n","Current batch: Loss-> 1.3006, Train accuracy->  21.38%\n","Current batch: Loss-> 1.5312, Train accuracy->  21.43%\n","Current batch: Loss-> 1.4085, Train accuracy->  21.49%\n","Current batch: Loss-> 1.3110, Train accuracy->  21.54%\n","Current batch: Loss-> 1.5861, Train accuracy->  21.59%\n","Current batch: Loss-> 1.3836, Train accuracy->  21.65%\n","Current batch: Loss-> 1.3670, Train accuracy->  21.71%\n","Current batch: Loss-> 1.3595, Train accuracy->  21.78%\n","Current batch: Loss-> 1.4213, Train accuracy->  21.84%\n","Current batch: Loss-> 1.4129, Train accuracy->  21.90%\n","Current batch: Loss-> 1.3123, Train accuracy->  21.96%\n","Current batch: Loss-> 1.5932, Train accuracy->  22.01%\n","Current batch: Loss-> 1.3004, Train accuracy->  22.08%\n","Current batch: Loss-> 1.4045, Train accuracy->  22.12%\n","Current batch: Loss-> 1.3496, Train accuracy->  22.17%\n","Current batch: Loss-> 1.7556, Train accuracy->  22.22%\n","Current batch: Loss-> 1.4268, Train accuracy->  22.28%\n","Current batch: Loss-> 1.4156, Train accuracy->  22.34%\n","Current batch: Loss-> 1.4291, Train accuracy->  22.40%\n","Current batch: Loss-> 1.5399, Train accuracy->  22.45%\n","Current batch: Loss-> 1.2568, Train accuracy->  22.51%\n","Current batch: Loss-> 1.4844, Train accuracy->  22.57%\n","Current batch: Loss-> 1.5136, Train accuracy->  22.61%\n","Current batch: Loss-> 1.4586, Train accuracy->  22.66%\n","Current batch: Loss-> 1.4099, Train accuracy->  22.72%\n","Current batch: Loss-> 1.6893, Train accuracy->  22.76%\n","Current batch: Loss-> 1.5048, Train accuracy->  22.82%\n","Current batch: Loss-> 1.4346, Train accuracy->  22.87%\n","Current batch: Loss-> 1.3870, Train accuracy->  22.92%\n","Current batch: Loss-> 1.8262, Train accuracy->  22.96%\n","Current batch: Loss-> 1.4836, Train accuracy->  23.01%\n","Current batch: Loss-> 1.4948, Train accuracy->  23.06%\n","Current batch: Loss-> 1.3755, Train accuracy->  23.11%\n","Current batch: Loss-> 1.6521, Train accuracy->  23.14%\n","Current batch: Loss-> 1.5652, Train accuracy->  23.19%\n","Current batch: Loss-> 1.4606, Train accuracy->  23.24%\n","Current batch: Loss-> 1.4729, Train accuracy->  23.29%\n","Current batch: Loss-> 1.4633, Train accuracy->  23.34%\n","Current batch: Loss-> 1.3871, Train accuracy->  23.39%\n","Current batch: Loss-> 1.5025, Train accuracy->  23.44%\n","Current batch: Loss-> 1.3372, Train accuracy->  23.51%\n","Current batch: Loss-> 1.2634, Train accuracy->  23.57%\n","Current batch: Loss-> 1.4638, Train accuracy->  23.62%\n","Current batch: Loss-> 1.3131, Train accuracy->  23.68%\n","Current batch: Loss-> 1.5212, Train accuracy->  23.74%\n","Current batch: Loss-> 1.4627, Train accuracy->  23.79%\n","Current batch: Loss-> 1.5450, Train accuracy->  23.85%\n","Current batch: Loss-> 1.5304, Train accuracy->  23.90%\n","Current batch: Loss-> 1.5871, Train accuracy->  23.95%\n","Current batch: Loss-> 1.4122, Train accuracy->  24.01%\n","Current batch: Loss-> 1.4006, Train accuracy->  24.06%\n","Current batch: Loss-> 1.4362, Train accuracy->  24.12%\n","Current batch: Loss-> 1.3900, Train accuracy->  24.18%\n","Current batch: Loss-> 1.4210, Train accuracy->  24.23%\n","Current batch: Loss-> 1.2713, Train accuracy->  24.29%\n","Current batch: Loss-> 1.4512, Train accuracy->  24.35%\n","Current batch: Loss-> 1.4434, Train accuracy->  24.41%\n","Current batch: Loss-> 1.5364, Train accuracy->  24.46%\n","Current batch: Loss-> 1.2311, Train accuracy->  24.52%\n","Current batch: Loss-> 1.4054, Train accuracy->  24.55%\n","Current batch: Loss-> 1.3617, Train accuracy->  24.60%\n","Current batch: Loss-> 1.5945, Train accuracy->  24.64%\n","Current batch: Loss-> 1.6621, Train accuracy->  24.68%\n","Current batch: Loss-> 1.5151, Train accuracy->  24.73%\n","Current batch: Loss-> 1.4195, Train accuracy->  24.78%\n","Current batch: Loss-> 1.5869, Train accuracy->  24.84%\n","Current batch: Loss-> 1.4019, Train accuracy->  24.88%\n","Current batch: Loss-> 1.4370, Train accuracy->  24.94%\n","Current batch: Loss-> 1.6285, Train accuracy->  24.99%\n","Current batch: Loss-> 1.5058, Train accuracy->  25.04%\n","Current batch: Loss-> 1.4532, Train accuracy->  25.11%\n","Current batch: Loss-> 1.6187, Train accuracy->  25.16%\n","Current batch: Loss-> 1.3080, Train accuracy->  25.22%\n","Current batch: Loss-> 1.4160, Train accuracy->  25.29%\n","Current batch: Loss-> 1.2640, Train accuracy->  25.35%\n","Current batch: Loss-> 1.5091, Train accuracy->  25.40%\n","Current batch: Loss-> 1.6708, Train accuracy->  25.44%\n","Current batch: Loss-> 1.3212, Train accuracy->  25.50%\n","Current batch: Loss-> 1.3303, Train accuracy->  25.56%\n","Current batch: Loss-> 1.4492, Train accuracy->  25.63%\n","Current batch: Loss-> 1.4200, Train accuracy->  25.68%\n","Current batch: Loss-> 1.3540, Train accuracy->  25.74%\n","Current batch: Loss-> 1.5613, Train accuracy->  25.80%\n","Current batch: Loss-> 1.3370, Train accuracy->  25.85%\n","Current batch: Loss-> 1.5340, Train accuracy->  25.91%\n","Current batch: Loss-> 1.3839, Train accuracy->  25.98%\n","Current batch: Loss-> 1.4810, Train accuracy->  26.04%\n","Current batch: Loss-> 1.5069, Train accuracy->  26.09%\n","Current batch: Loss-> 1.3760, Train accuracy->  26.16%\n","Current batch: Loss-> 1.3574, Train accuracy->  26.21%\n","Current batch: Loss-> 1.5606, Train accuracy->  26.26%\n","Current batch: Loss-> 1.4574, Train accuracy->  26.33%\n","Current batch: Loss-> 1.3709, Train accuracy->  26.38%\n","Current batch: Loss-> 1.4651, Train accuracy->  26.44%\n","Current batch: Loss-> 1.5587, Train accuracy->  26.49%\n","Current batch: Loss-> 1.5289, Train accuracy->  26.55%\n","Current batch: Loss-> 1.5515, Train accuracy->  26.60%\n","Current batch: Loss-> 1.5389, Train accuracy->  26.65%\n","Current batch: Loss-> 1.4514, Train accuracy->  26.72%\n","Current batch: Loss-> 1.3277, Train accuracy->  26.77%\n","Current batch: Loss-> 1.4650, Train accuracy->  26.81%\n","Current batch: Loss-> 1.3852, Train accuracy->  26.86%\n","Current batch: Loss-> 1.4255, Train accuracy->  26.92%\n","Current batch: Loss-> 1.6110, Train accuracy->  26.96%\n","Current batch: Loss-> 1.4707, Train accuracy->  27.01%\n","Current batch: Loss-> 1.3704, Train accuracy->  27.07%\n","Current batch: Loss-> 1.5666, Train accuracy->  27.11%\n","Current batch: Loss-> 1.3192, Train accuracy->  27.17%\n","Current batch: Loss-> 1.5984, Train accuracy->  27.21%\n","Current batch: Loss-> 1.6173, Train accuracy->  27.26%\n","Current batch: Loss-> 1.4189, Train accuracy->  27.31%\n","Current batch: Loss-> 1.2616, Train accuracy->  27.38%\n","Current batch: Loss-> 1.4328, Train accuracy->  27.43%\n","Current batch: Loss-> 1.4150, Train accuracy->  27.48%\n","Current batch: Loss-> 1.6165, Train accuracy->  27.53%\n","Current batch: Loss-> 1.5032, Train accuracy->  27.57%\n","Current batch: Loss-> 1.6752, Train accuracy->  27.61%\n","Current batch: Loss-> 1.3474, Train accuracy->  27.66%\n","Current batch: Loss-> 1.3404, Train accuracy->  27.73%\n","Current batch: Loss-> 1.4235, Train accuracy->  27.79%\n","Current batch: Loss-> 1.3265, Train accuracy->  27.84%\n","Current batch: Loss-> 1.3494, Train accuracy->  27.89%\n","Current batch: Loss-> 1.2182, Train accuracy->  27.96%\n","Current batch: Loss-> 1.4126, Train accuracy->  28.00%\n","Current batch: Loss-> 1.4679, Train accuracy->  28.06%\n","Current batch: Loss-> 1.5947, Train accuracy->  28.11%\n","Current batch: Loss-> 1.3791, Train accuracy->  28.15%\n","Current batch: Loss-> 1.3520, Train accuracy->  28.21%\n","Current batch: Loss-> 1.3515, Train accuracy->  28.26%\n","Current batch: Loss-> 1.5943, Train accuracy->  28.31%\n","Current batch: Loss-> 1.4925, Train accuracy->  28.36%\n","Current batch: Loss-> 1.3842, Train accuracy->  28.42%\n","Current batch: Loss-> 1.3949, Train accuracy->  28.47%\n","Current batch: Loss-> 1.3112, Train accuracy->  28.54%\n","Current batch: Loss-> 1.2191, Train accuracy->  28.60%\n","Current batch: Loss-> 1.3565, Train accuracy->  28.66%\n","Current batch: Loss-> 1.2969, Train accuracy->  28.73%\n","Current batch: Loss-> 1.4626, Train accuracy->  28.79%\n","Current batch: Loss-> 1.5277, Train accuracy->  28.83%\n","Current batch: Loss-> 1.3801, Train accuracy->  28.88%\n","Current batch: Loss-> 1.5657, Train accuracy->  28.91%\n","Current batch: Loss-> 1.2300, Train accuracy->  28.99%\n","Current batch: Loss-> 1.3132, Train accuracy->  29.05%\n","Current batch: Loss-> 1.2003, Train accuracy->  29.11%\n","Current batch: Loss-> 1.3469, Train accuracy->  29.19%\n","Current batch: Loss-> 1.3525, Train accuracy->  29.25%\n","Current batch: Loss-> 1.6007, Train accuracy->  29.30%\n","Current batch: Loss-> 1.4640, Train accuracy->  29.34%\n","Current batch: Loss-> 1.3443, Train accuracy->  29.41%\n","Current batch: Loss-> 1.5097, Train accuracy->  29.46%\n","Current batch: Loss-> 1.3073, Train accuracy->  29.51%\n","Current batch: Loss-> 1.1912, Train accuracy->  29.57%\n","Current batch: Loss-> 1.3115, Train accuracy->  29.63%\n","Current batch: Loss-> 1.5930, Train accuracy->  29.67%\n","Current batch: Loss-> 1.4309, Train accuracy->  29.73%\n","Current batch: Loss-> 1.5388, Train accuracy->  29.79%\n","Current batch: Loss-> 1.4256, Train accuracy->  29.84%\n","Current batch: Loss-> 1.3051, Train accuracy->  29.90%\n","Current batch: Loss-> 1.5930, Train accuracy->  29.95%\n","Current batch: Loss-> 1.5073, Train accuracy->  29.99%\n","Current batch: Loss-> 1.3170, Train accuracy->  30.04%\n","Current batch: Loss-> 1.5491, Train accuracy->  30.08%\n","Current batch: Loss-> 1.3486, Train accuracy->  30.14%\n","Current batch: Loss-> 1.5393, Train accuracy->  30.18%\n","Current batch: Loss-> 1.5319, Train accuracy->  30.24%\n","Current batch: Loss-> 1.3339, Train accuracy->  30.31%\n","Current batch: Loss-> 1.4056, Train accuracy->  30.37%\n","Current batch: Loss-> 1.3389, Train accuracy->  30.40%\n","Current batch: Loss-> 1.3485, Train accuracy->  30.48%\n","Current batch: Loss-> 1.4490, Train accuracy->  30.52%\n","Current batch: Loss-> 1.4664, Train accuracy->  30.56%\n","Current batch: Loss-> 1.6420, Train accuracy->  30.60%\n","Current batch: Loss-> 1.6868, Train accuracy->  30.64%\n","Current batch: Loss-> 1.5070, Train accuracy->  30.70%\n","Current batch: Loss-> 1.3663, Train accuracy->  30.77%\n","Current batch: Loss-> 1.4875, Train accuracy->  30.82%\n","Current batch: Loss-> 1.4811, Train accuracy->  30.86%\n","Current batch: Loss-> 1.3380, Train accuracy->  30.94%\n","Current batch: Loss-> 1.5986, Train accuracy->  30.97%\n","Current batch: Loss-> 1.2779, Train accuracy->  31.04%\n","Current batch: Loss-> 1.0733, Train accuracy->  31.11%\n","Current batch: Loss-> 1.2944, Train accuracy->  31.17%\n","Current batch: Loss-> 1.5368, Train accuracy->  31.22%\n","Current batch: Loss-> 1.3316, Train accuracy->  31.29%\n","Current batch: Loss-> 1.3939, Train accuracy->  31.34%\n","Current batch: Loss-> 1.4068, Train accuracy->  31.39%\n","Current batch: Loss-> 1.5248, Train accuracy->  31.44%\n","Current batch: Loss-> 1.3548, Train accuracy->  31.49%\n","Current batch: Loss-> 1.4482, Train accuracy->  31.54%\n","Current batch: Loss-> 1.2769, Train accuracy->  31.61%\n","Current batch: Loss-> 1.2855, Train accuracy->  31.67%\n","Current batch: Loss-> 1.3268, Train accuracy->  31.73%\n","Current batch: Loss-> 1.4918, Train accuracy->  31.79%\n","Current batch: Loss-> 1.4425, Train accuracy->  31.84%\n","Current batch: Loss-> 1.5958, Train accuracy->  31.89%\n","Current batch: Loss-> 1.4763, Train accuracy->  31.93%\n","Current batch: Loss-> 1.4427, Train accuracy->  32.00%\n","Current batch: Loss-> 1.2429, Train accuracy->  32.06%\n","Current batch: Loss-> 1.3865, Train accuracy->  32.11%\n","Current batch: Loss-> 1.4748, Train accuracy->  32.17%\n","Current batch: Loss-> 1.3739, Train accuracy->  32.23%\n","Current batch: Loss-> 1.3772, Train accuracy->  32.29%\n","Current batch: Loss-> 1.4772, Train accuracy->  32.34%\n","Current batch: Loss-> 1.3830, Train accuracy->  32.40%\n","Current batch: Loss-> 1.4580, Train accuracy->  32.45%\n","Current batch: Loss-> 1.2747, Train accuracy->  32.52%\n","Current batch: Loss-> 1.3471, Train accuracy->  32.58%\n","Current batch: Loss-> 1.4547, Train accuracy->  32.61%\n","Current batch: Loss-> 1.2724, Train accuracy->  32.68%\n","Current batch: Loss-> 1.4539, Train accuracy->  32.74%\n","Current batch: Loss-> 1.5530, Train accuracy->  32.79%\n","Current batch: Loss-> 1.2436, Train accuracy->  32.84%\n","Current batch: Loss-> 1.5054, Train accuracy->  32.89%\n","Current batch: Loss-> 1.1814, Train accuracy->  32.95%\n","Current batch: Loss-> 1.2776, Train accuracy->  33.01%\n","Current batch: Loss-> 1.3476, Train accuracy->  33.08%\n","Current batch: Loss-> 1.2984, Train accuracy->  33.14%\n","Current batch: Loss-> 1.4488, Train accuracy->  33.20%\n","Current batch: Loss-> 1.5275, Train accuracy->  33.24%\n","Current batch: Loss-> 1.4694, Train accuracy->  33.29%\n","Current batch: Loss-> 1.2688, Train accuracy->  33.36%\n","Current batch: Loss-> 1.1687, Train accuracy->  33.42%\n","Current batch: Loss-> 1.5426, Train accuracy->  33.47%\n","Current batch: Loss-> 1.3549, Train accuracy->  33.53%\n","Current batch: Loss-> 1.3780, Train accuracy->  33.57%\n","Current batch: Loss-> 1.5987, Train accuracy->  33.61%\n","Current batch: Loss-> 1.5662, Train accuracy->  33.65%\n","Current batch: Loss-> 1.4458, Train accuracy->  33.71%\n","Current batch: Loss-> 1.3604, Train accuracy->  33.77%\n","Current batch: Loss-> 1.2405, Train accuracy->  33.84%\n","Current batch: Loss-> 1.3536, Train accuracy->  33.90%\n","Current batch: Loss-> 1.6045, Train accuracy->  33.93%\n","Current batch: Loss-> 1.2936, Train accuracy->  33.98%\n","Current batch: Loss-> 1.4776, Train accuracy->  34.03%\n","Current batch: Loss-> 1.5373, Train accuracy->  34.08%\n","Current batch: Loss-> 1.6172, Train accuracy->  34.14%\n","Current batch: Loss-> 1.3423, Train accuracy->  34.21%\n","Current batch: Loss-> 1.4954, Train accuracy->  34.25%\n","Current batch: Loss-> 1.3392, Train accuracy->  34.31%\n","Current batch: Loss-> 1.5446, Train accuracy->  34.36%\n","Current batch: Loss-> 1.4284, Train accuracy->  34.42%\n","Current batch: Loss-> 1.3083, Train accuracy->  34.48%\n","Current batch: Loss-> 1.6137, Train accuracy->  34.53%\n","Current batch: Loss-> 1.1800, Train accuracy->  34.60%\n","Current batch: Loss-> 1.3601, Train accuracy->  34.65%\n","Current batch: Loss-> 1.3468, Train accuracy->  34.70%\n","Current batch: Loss-> 1.3845, Train accuracy->  34.76%\n","Current batch: Loss-> 1.4093, Train accuracy->  34.80%\n","Current batch: Loss-> 1.2825, Train accuracy->  34.86%\n","Current batch: Loss-> 1.3917, Train accuracy->  34.93%\n","Current batch: Loss-> 1.4054, Train accuracy->  34.98%\n","Current batch: Loss-> 1.3845, Train accuracy->  35.03%\n","Current batch: Loss-> 1.3819, Train accuracy->  35.09%\n","Current batch: Loss-> 1.5172, Train accuracy->  35.14%\n","Current batch: Loss-> 1.3352, Train accuracy->  35.18%\n","Current batch: Loss-> 1.3838, Train accuracy->  35.23%\n","Current batch: Loss-> 1.2573, Train accuracy->  35.29%\n","Current batch: Loss-> 1.3963, Train accuracy->  35.36%\n","Current batch: Loss-> 1.3100, Train accuracy->  35.41%\n","Current batch: Loss-> 1.4491, Train accuracy->  35.45%\n","Current batch: Loss-> 1.4853, Train accuracy->  35.51%\n","Current batch: Loss-> 1.2259, Train accuracy->  35.58%\n","Current batch: Loss-> 1.3854, Train accuracy->  35.65%\n","Current batch: Loss-> 1.5903, Train accuracy->  35.71%\n","Current batch: Loss-> 1.5088, Train accuracy->  35.77%\n","Current batch: Loss-> 1.3673, Train accuracy->  35.83%\n","Current batch: Loss-> 1.4153, Train accuracy->  35.89%\n","Current batch: Loss-> 1.5223, Train accuracy->  35.93%\n","Current batch: Loss-> 1.3465, Train accuracy->  35.99%\n","Current batch: Loss-> 1.4814, Train accuracy->  36.04%\n","Current batch: Loss-> 1.2492, Train accuracy->  36.12%\n","Current batch: Loss-> 1.3429, Train accuracy->  36.17%\n","Current batch: Loss-> 1.4059, Train accuracy->  36.24%\n","Current batch: Loss-> 1.3696, Train accuracy->  36.30%\n","Current batch: Loss-> 1.3845, Train accuracy->  36.36%\n","Current batch: Loss-> 1.3345, Train accuracy->  36.42%\n","Current batch: Loss-> 1.1651, Train accuracy->  36.48%\n","Current batch: Loss-> 1.4026, Train accuracy->  36.54%\n","Current batch: Loss-> 1.4365, Train accuracy->  36.59%\n","Current batch: Loss-> 1.3094, Train accuracy->  36.67%\n","Current batch: Loss-> 1.3427, Train accuracy->  36.74%\n","Current batch: Loss-> 1.5087, Train accuracy->  36.79%\n","Current batch: Loss-> 1.3400, Train accuracy->  36.85%\n","Current batch: Loss-> 1.3490, Train accuracy->  36.92%\n","Current batch: Loss-> 1.3553, Train accuracy->  36.98%\n","Current batch: Loss-> 1.3299, Train accuracy->  37.04%\n","Current batch: Loss-> 1.4818, Train accuracy->  37.11%\n","Current batch: Loss-> 1.5158, Train accuracy->  37.16%\n","Current batch: Loss-> 1.2484, Train accuracy->  37.23%\n","Current batch: Loss-> 1.2689, Train accuracy->  37.28%\n","Current batch: Loss-> 1.4297, Train accuracy->  37.33%\n","Current batch: Loss-> 1.3746, Train accuracy->  37.38%\n","Current batch: Loss-> 1.4312, Train accuracy->  37.43%\n","Current batch: Loss-> 1.3141, Train accuracy->  37.49%\n","Current batch: Loss-> 1.4552, Train accuracy->  37.55%\n","Current batch: Loss-> 1.3208, Train accuracy->  37.61%\n","Current batch: Loss-> 1.3059, Train accuracy->  37.67%\n","Current batch: Loss-> 1.3185, Train accuracy->  37.72%\n","Current batch: Loss-> 1.4340, Train accuracy->  37.78%\n","Current batch: Loss-> 1.4675, Train accuracy->  37.84%\n","Current batch: Loss-> 1.5625, Train accuracy->  37.89%\n","Current batch: Loss-> 1.5201, Train accuracy->  37.94%\n","Current batch: Loss-> 1.4962, Train accuracy->  37.99%\n","Current batch: Loss-> 1.6511, Train accuracy->  38.04%\n","Current batch: Loss-> 1.4276, Train accuracy->  38.09%\n","Current batch: Loss-> 1.3383, Train accuracy->  38.15%\n","Current batch: Loss-> 1.2651, Train accuracy->  38.21%\n","Current batch: Loss-> 1.2748, Train accuracy->  38.28%\n","Current batch: Loss-> 1.6682, Train accuracy->  38.32%\n","Current batch: Loss-> 1.3911, Train accuracy->  38.37%\n","Current batch: Loss-> 1.5550, Train accuracy->  38.42%\n","Current batch: Loss-> 1.3606, Train accuracy->  38.48%\n","Current batch: Loss-> 1.2963, Train accuracy->  38.55%\n","Current batch: Loss-> 1.5010, Train accuracy->  38.60%\n","Current batch: Loss-> 1.3477, Train accuracy->  38.67%\n","Current batch: Loss-> 1.2958, Train accuracy->  38.74%\n","Current batch: Loss-> 1.5127, Train accuracy->  38.78%\n","Current batch: Loss-> 1.3584, Train accuracy->  38.85%\n","Current batch: Loss-> 1.3147, Train accuracy->  38.91%\n","Current batch: Loss-> 1.1989, Train accuracy->  38.98%\n","Current batch: Loss-> 1.3768, Train accuracy->  39.03%\n","Current batch: Loss-> 1.7170, Train accuracy->  39.08%\n","Current batch: Loss-> 1.1978, Train accuracy->  39.14%\n","Current batch: Loss-> 1.4736, Train accuracy->  39.18%\n","Current batch: Loss-> 1.2315, Train accuracy->  39.26%\n","Current batch: Loss-> 1.2672, Train accuracy->  39.31%\n","Current batch: Loss-> 1.2464, Train accuracy->  39.37%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 47.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.3560, Train accuracy->  39.45%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.26it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.3579, Accuracy: 3653/12000 (30%)\n","\n","Current batch: Loss-> 1.6384, Train accuracy->   0.04%\n","Current batch: Loss-> 1.3185, Train accuracy->   0.10%\n","Current batch: Loss-> 1.5245, Train accuracy->   0.15%\n","Current batch: Loss-> 1.5514, Train accuracy->   0.20%\n","Current batch: Loss-> 1.4198, Train accuracy->   0.26%\n","Current batch: Loss-> 1.2143, Train accuracy->   0.34%\n","Current batch: Loss-> 1.4119, Train accuracy->   0.38%\n","Current batch: Loss-> 1.2607, Train accuracy->   0.44%\n","Current batch: Loss-> 1.2658, Train accuracy->   0.51%\n","Current batch: Loss-> 1.2989, Train accuracy->   0.57%\n","Current batch: Loss-> 1.3188, Train accuracy->   0.63%\n","Current batch: Loss-> 1.3589, Train accuracy->   0.69%\n","Current batch: Loss-> 1.4231, Train accuracy->   0.74%\n","Current batch: Loss-> 1.3546, Train accuracy->   0.80%\n","Current batch: Loss-> 1.4221, Train accuracy->   0.87%\n","Current batch: Loss-> 1.2669, Train accuracy->   0.93%\n","Current batch: Loss-> 1.2599, Train accuracy->   0.98%\n","Current batch: Loss-> 1.3838, Train accuracy->   1.03%\n","Current batch: Loss-> 1.5660, Train accuracy->   1.09%\n","Current batch: Loss-> 1.2308, Train accuracy->   1.15%\n","Current batch: Loss-> 1.2432, Train accuracy->   1.21%\n","Current batch: Loss-> 1.5385, Train accuracy->   1.26%\n","Current batch: Loss-> 1.5405, Train accuracy->   1.30%\n","Current batch: Loss-> 1.2211, Train accuracy->   1.38%\n","Current batch: Loss-> 1.6855, Train accuracy->   1.42%\n","Current batch: Loss-> 1.4430, Train accuracy->   1.48%\n","Current batch: Loss-> 1.5311, Train accuracy->   1.52%\n","Current batch: Loss-> 1.2762, Train accuracy->   1.58%\n","Current batch: Loss-> 1.2502, Train accuracy->   1.64%\n","Current batch: Loss-> 1.2947, Train accuracy->   1.69%\n","Current batch: Loss-> 1.3164, Train accuracy->   1.75%\n","Current batch: Loss-> 1.1410, Train accuracy->   1.83%\n","Current batch: Loss-> 1.3033, Train accuracy->   1.89%\n","Current batch: Loss-> 1.4526, Train accuracy->   1.93%\n","Current batch: Loss-> 1.3801, Train accuracy->   1.99%\n","Current batch: Loss-> 1.3128, Train accuracy->   2.06%\n","Current batch: Loss-> 1.3372, Train accuracy->   2.12%\n","Current batch: Loss-> 1.2938, Train accuracy->   2.19%\n","Current batch: Loss-> 1.3360, Train accuracy->   2.24%\n","Current batch: Loss-> 1.4451, Train accuracy->   2.30%\n","Current batch: Loss-> 1.2845, Train accuracy->   2.37%\n","Current batch: Loss-> 1.4935, Train accuracy->   2.41%\n","Current batch: Loss-> 1.6335, Train accuracy->   2.46%\n","Current batch: Loss-> 1.2518, Train accuracy->   2.53%\n","Current batch: Loss-> 1.5312, Train accuracy->   2.58%\n","Current batch: Loss-> 1.2503, Train accuracy->   2.66%\n","Current batch: Loss-> 1.2273, Train accuracy->   2.73%\n","Current batch: Loss-> 1.3575, Train accuracy->   2.79%\n","Current batch: Loss-> 1.3886, Train accuracy->   2.85%\n","Current batch: Loss-> 1.2764, Train accuracy->   2.90%\n","Current batch: Loss-> 1.2395, Train accuracy->   2.97%\n","Current batch: Loss-> 1.2396, Train accuracy->   3.03%\n","Current batch: Loss-> 1.4630, Train accuracy->   3.10%\n","Current batch: Loss-> 1.2575, Train accuracy->   3.16%\n","Current batch: Loss-> 1.3878, Train accuracy->   3.21%\n","Current batch: Loss-> 1.5478, Train accuracy->   3.26%\n","Current batch: Loss-> 1.0736, Train accuracy->   3.34%\n","Current batch: Loss-> 1.2547, Train accuracy->   3.41%\n","Current batch: Loss-> 1.1853, Train accuracy->   3.47%\n","Current batch: Loss-> 1.4523, Train accuracy->   3.52%\n","Current batch: Loss-> 1.2814, Train accuracy->   3.58%\n","Current batch: Loss-> 1.3023, Train accuracy->   3.65%\n","Current batch: Loss-> 1.2020, Train accuracy->   3.72%\n","Current batch: Loss-> 1.5175, Train accuracy->   3.78%\n","Current batch: Loss-> 1.4483, Train accuracy->   3.83%\n","Current batch: Loss-> 1.4892, Train accuracy->   3.88%\n","Current batch: Loss-> 1.7547, Train accuracy->   3.93%\n","Current batch: Loss-> 1.4329, Train accuracy->   3.99%\n","Current batch: Loss-> 1.4159, Train accuracy->   4.05%\n","Current batch: Loss-> 1.3695, Train accuracy->   4.12%\n","Current batch: Loss-> 1.2684, Train accuracy->   4.19%\n","Current batch: Loss-> 1.5314, Train accuracy->   4.25%\n","Current batch: Loss-> 1.2983, Train accuracy->   4.32%\n","Current batch: Loss-> 1.4233, Train accuracy->   4.37%\n","Current batch: Loss-> 1.3807, Train accuracy->   4.42%\n","Current batch: Loss-> 1.2937, Train accuracy->   4.49%\n","Current batch: Loss-> 1.4396, Train accuracy->   4.56%\n","Current batch: Loss-> 1.3561, Train accuracy->   4.62%\n","Current batch: Loss-> 1.3777, Train accuracy->   4.68%\n","Current batch: Loss-> 1.2988, Train accuracy->   4.74%\n","Current batch: Loss-> 1.1705, Train accuracy->   4.81%\n","Current batch: Loss-> 1.2394, Train accuracy->   4.88%\n","Current batch: Loss-> 1.6024, Train accuracy->   4.93%\n","Current batch: Loss-> 1.3252, Train accuracy->   4.98%\n","Current batch: Loss-> 1.3478, Train accuracy->   5.03%\n","Current batch: Loss-> 1.4521, Train accuracy->   5.09%\n","Current batch: Loss-> 1.1312, Train accuracy->   5.17%\n","Current batch: Loss-> 1.3177, Train accuracy->   5.22%\n","Current batch: Loss-> 1.3832, Train accuracy->   5.28%\n","Current batch: Loss-> 1.4943, Train accuracy->   5.33%\n","Current batch: Loss-> 1.3829, Train accuracy->   5.39%\n","Current batch: Loss-> 1.5690, Train accuracy->   5.44%\n","Current batch: Loss-> 1.2792, Train accuracy->   5.51%\n","Current batch: Loss-> 1.5249, Train accuracy->   5.57%\n","Current batch: Loss-> 1.2476, Train accuracy->   5.63%\n","Current batch: Loss-> 1.1089, Train accuracy->   5.71%\n","Current batch: Loss-> 1.4766, Train accuracy->   5.77%\n","Current batch: Loss-> 1.4002, Train accuracy->   5.84%\n","Current batch: Loss-> 1.3958, Train accuracy->   5.90%\n","Current batch: Loss-> 1.2668, Train accuracy->   5.97%\n","Current batch: Loss-> 1.5302, Train accuracy->   6.01%\n","Current batch: Loss-> 1.3590, Train accuracy->   6.06%\n","Current batch: Loss-> 1.4506, Train accuracy->   6.12%\n","Current batch: Loss-> 1.2914, Train accuracy->   6.19%\n","Current batch: Loss-> 1.2594, Train accuracy->   6.25%\n","Current batch: Loss-> 1.3478, Train accuracy->   6.31%\n","Current batch: Loss-> 1.3003, Train accuracy->   6.38%\n","Current batch: Loss-> 1.4459, Train accuracy->   6.42%\n","Current batch: Loss-> 1.7183, Train accuracy->   6.46%\n","Current batch: Loss-> 1.4551, Train accuracy->   6.51%\n","Current batch: Loss-> 1.4573, Train accuracy->   6.56%\n","Current batch: Loss-> 1.3546, Train accuracy->   6.62%\n","Current batch: Loss-> 1.1961, Train accuracy->   6.69%\n","Current batch: Loss-> 1.3157, Train accuracy->   6.74%\n","Current batch: Loss-> 1.2290, Train accuracy->   6.81%\n","Current batch: Loss-> 1.3172, Train accuracy->   6.86%\n","Current batch: Loss-> 1.3379, Train accuracy->   6.91%\n","Current batch: Loss-> 1.4137, Train accuracy->   6.96%\n","Current batch: Loss-> 1.5871, Train accuracy->   7.01%\n","Current batch: Loss-> 1.1664, Train accuracy->   7.07%\n","Current batch: Loss-> 1.6311, Train accuracy->   7.13%\n","Current batch: Loss-> 1.3741, Train accuracy->   7.20%\n","Current batch: Loss-> 1.4378, Train accuracy->   7.26%\n","Current batch: Loss-> 1.3780, Train accuracy->   7.33%\n","Current batch: Loss-> 1.2802, Train accuracy->   7.40%\n","Current batch: Loss-> 1.5063, Train accuracy->   7.45%\n","Current batch: Loss-> 1.2830, Train accuracy->   7.51%\n","Current batch: Loss-> 1.1913, Train accuracy->   7.58%\n","Current batch: Loss-> 1.3672, Train accuracy->   7.64%\n","Current batch: Loss-> 1.1891, Train accuracy->   7.72%\n","Current batch: Loss-> 1.4719, Train accuracy->   7.78%\n","Current batch: Loss-> 1.2430, Train accuracy->   7.84%\n","Current batch: Loss-> 1.6815, Train accuracy->   7.89%\n","Current batch: Loss-> 1.2716, Train accuracy->   7.96%\n","Current batch: Loss-> 1.4208, Train accuracy->   8.02%\n","Current batch: Loss-> 1.5962, Train accuracy->   8.07%\n","Current batch: Loss-> 1.2396, Train accuracy->   8.13%\n","Current batch: Loss-> 1.3853, Train accuracy->   8.19%\n","Current batch: Loss-> 1.2843, Train accuracy->   8.25%\n","Current batch: Loss-> 1.2521, Train accuracy->   8.31%\n","Current batch: Loss-> 1.2081, Train accuracy->   8.38%\n","Current batch: Loss-> 1.3351, Train accuracy->   8.44%\n","Current batch: Loss-> 1.4361, Train accuracy->   8.50%\n","Current batch: Loss-> 1.2299, Train accuracy->   8.57%\n","Current batch: Loss-> 1.4189, Train accuracy->   8.62%\n","Current batch: Loss-> 1.4307, Train accuracy->   8.66%\n","Current batch: Loss-> 1.4323, Train accuracy->   8.72%\n","Current batch: Loss-> 1.3773, Train accuracy->   8.78%\n","Current batch: Loss-> 1.3595, Train accuracy->   8.83%\n","Current batch: Loss-> 1.2339, Train accuracy->   8.88%\n","Current batch: Loss-> 1.4348, Train accuracy->   8.93%\n","Current batch: Loss-> 1.2245, Train accuracy->   8.99%\n","Current batch: Loss-> 1.3168, Train accuracy->   9.04%\n","Current batch: Loss-> 1.6051, Train accuracy->   9.09%\n","Current batch: Loss-> 1.4326, Train accuracy->   9.16%\n","Current batch: Loss-> 1.2327, Train accuracy->   9.23%\n","Current batch: Loss-> 1.3171, Train accuracy->   9.28%\n","Current batch: Loss-> 1.3914, Train accuracy->   9.34%\n","Current batch: Loss-> 1.4741, Train accuracy->   9.39%\n","Current batch: Loss-> 1.4954, Train accuracy->   9.44%\n","Current batch: Loss-> 1.3176, Train accuracy->   9.50%\n","Current batch: Loss-> 1.4789, Train accuracy->   9.56%\n","Current batch: Loss-> 1.4201, Train accuracy->   9.61%\n","Current batch: Loss-> 1.5575, Train accuracy->   9.65%\n","Current batch: Loss-> 1.2559, Train accuracy->   9.71%\n","Current batch: Loss-> 1.2790, Train accuracy->   9.77%\n","Current batch: Loss-> 1.4393, Train accuracy->   9.84%\n","Current batch: Loss-> 1.2946, Train accuracy->   9.90%\n","Current batch: Loss-> 1.2220, Train accuracy->   9.96%\n","Current batch: Loss-> 1.4047, Train accuracy->  10.02%\n","Current batch: Loss-> 1.2973, Train accuracy->  10.08%\n","Current batch: Loss-> 1.3308, Train accuracy->  10.14%\n","Current batch: Loss-> 1.4417, Train accuracy->  10.21%\n","Current batch: Loss-> 1.1270, Train accuracy->  10.29%\n","Current batch: Loss-> 1.3174, Train accuracy->  10.35%\n","Current batch: Loss-> 1.1833, Train accuracy->  10.43%\n","Current batch: Loss-> 1.2997, Train accuracy->  10.50%\n","Current batch: Loss-> 1.4862, Train accuracy->  10.56%\n","Current batch: Loss-> 1.4519, Train accuracy->  10.60%\n","Current batch: Loss-> 1.3481, Train accuracy->  10.65%\n","Current batch: Loss-> 1.3304, Train accuracy->  10.70%\n","Current batch: Loss-> 1.3022, Train accuracy->  10.76%\n","Current batch: Loss-> 1.3716, Train accuracy->  10.82%\n","Current batch: Loss-> 1.3709, Train accuracy->  10.86%\n","Current batch: Loss-> 1.2677, Train accuracy->  10.93%\n","Current batch: Loss-> 1.4245, Train accuracy->  10.97%\n","Current batch: Loss-> 1.3313, Train accuracy->  11.04%\n","Current batch: Loss-> 1.2736, Train accuracy->  11.10%\n","Current batch: Loss-> 1.3714, Train accuracy->  11.16%\n","Current batch: Loss-> 1.3880, Train accuracy->  11.22%\n","Current batch: Loss-> 1.2492, Train accuracy->  11.29%\n","Current batch: Loss-> 1.4500, Train accuracy->  11.35%\n","Current batch: Loss-> 1.2147, Train accuracy->  11.43%\n","Current batch: Loss-> 1.4973, Train accuracy->  11.48%\n","Current batch: Loss-> 1.3440, Train accuracy->  11.54%\n","Current batch: Loss-> 1.1722, Train accuracy->  11.59%\n","Current batch: Loss-> 1.3182, Train accuracy->  11.66%\n","Current batch: Loss-> 1.5492, Train accuracy->  11.71%\n","Current batch: Loss-> 1.4366, Train accuracy->  11.77%\n","Current batch: Loss-> 1.3668, Train accuracy->  11.84%\n","Current batch: Loss-> 1.6992, Train accuracy->  11.89%\n","Current batch: Loss-> 1.3000, Train accuracy->  11.95%\n","Current batch: Loss-> 1.3984, Train accuracy->  12.01%\n","Current batch: Loss-> 1.4339, Train accuracy->  12.07%\n","Current batch: Loss-> 1.3768, Train accuracy->  12.14%\n","Current batch: Loss-> 1.3054, Train accuracy->  12.20%\n","Current batch: Loss-> 1.3568, Train accuracy->  12.26%\n","Current batch: Loss-> 1.3176, Train accuracy->  12.31%\n","Current batch: Loss-> 1.3283, Train accuracy->  12.37%\n","Current batch: Loss-> 1.1552, Train accuracy->  12.44%\n","Current batch: Loss-> 1.3636, Train accuracy->  12.50%\n","Current batch: Loss-> 1.4409, Train accuracy->  12.56%\n","Current batch: Loss-> 1.3893, Train accuracy->  12.62%\n","Current batch: Loss-> 1.4823, Train accuracy->  12.68%\n","Current batch: Loss-> 1.4128, Train accuracy->  12.74%\n","Current batch: Loss-> 1.5780, Train accuracy->  12.78%\n","Current batch: Loss-> 1.2653, Train accuracy->  12.84%\n","Current batch: Loss-> 1.4665, Train accuracy->  12.89%\n","Current batch: Loss-> 1.3254, Train accuracy->  12.94%\n","Current batch: Loss-> 1.3260, Train accuracy->  13.00%\n","Current batch: Loss-> 1.3216, Train accuracy->  13.07%\n","Current batch: Loss-> 1.3851, Train accuracy->  13.12%\n","Current batch: Loss-> 1.3101, Train accuracy->  13.18%\n","Current batch: Loss-> 1.5649, Train accuracy->  13.21%\n","Current batch: Loss-> 1.2987, Train accuracy->  13.27%\n","Current batch: Loss-> 1.3715, Train accuracy->  13.33%\n","Current batch: Loss-> 1.5208, Train accuracy->  13.38%\n","Current batch: Loss-> 1.5873, Train accuracy->  13.44%\n","Current batch: Loss-> 1.5019, Train accuracy->  13.50%\n","Current batch: Loss-> 1.3271, Train accuracy->  13.57%\n","Current batch: Loss-> 1.3557, Train accuracy->  13.62%\n","Current batch: Loss-> 1.4771, Train accuracy->  13.67%\n","Current batch: Loss-> 1.3774, Train accuracy->  13.73%\n","Current batch: Loss-> 1.2805, Train accuracy->  13.79%\n","Current batch: Loss-> 1.5336, Train accuracy->  13.85%\n","Current batch: Loss-> 1.3415, Train accuracy->  13.91%\n","Current batch: Loss-> 1.7208, Train accuracy->  13.96%\n","Current batch: Loss-> 1.4518, Train accuracy->  14.01%\n","Current batch: Loss-> 1.3025, Train accuracy->  14.08%\n","Current batch: Loss-> 1.4833, Train accuracy->  14.13%\n","Current batch: Loss-> 1.3648, Train accuracy->  14.18%\n","Current batch: Loss-> 1.4482, Train accuracy->  14.24%\n","Current batch: Loss-> 1.4094, Train accuracy->  14.29%\n","Current batch: Loss-> 1.2036, Train accuracy->  14.36%\n","Current batch: Loss-> 1.3477, Train accuracy->  14.42%\n","Current batch: Loss-> 1.4626, Train accuracy->  14.48%\n","Current batch: Loss-> 1.3474, Train accuracy->  14.53%\n","Current batch: Loss-> 1.4081, Train accuracy->  14.60%\n","Current batch: Loss-> 1.5357, Train accuracy->  14.65%\n","Current batch: Loss-> 1.5983, Train accuracy->  14.71%\n","Current batch: Loss-> 1.5647, Train accuracy->  14.76%\n","Current batch: Loss-> 1.3195, Train accuracy->  14.82%\n","Current batch: Loss-> 1.1801, Train accuracy->  14.91%\n","Current batch: Loss-> 1.4133, Train accuracy->  14.96%\n","Current batch: Loss-> 1.2809, Train accuracy->  15.02%\n","Current batch: Loss-> 1.2790, Train accuracy->  15.09%\n","Current batch: Loss-> 1.3137, Train accuracy->  15.16%\n","Current batch: Loss-> 1.4991, Train accuracy->  15.21%\n","Current batch: Loss-> 1.3070, Train accuracy->  15.27%\n","Current batch: Loss-> 1.5235, Train accuracy->  15.32%\n","Current batch: Loss-> 1.3408, Train accuracy->  15.37%\n","Current batch: Loss-> 1.2482, Train accuracy->  15.43%\n","Current batch: Loss-> 1.2619, Train accuracy->  15.49%\n","Current batch: Loss-> 1.4400, Train accuracy->  15.55%\n","Current batch: Loss-> 1.2634, Train accuracy->  15.62%\n","Current batch: Loss-> 1.4570, Train accuracy->  15.67%\n","Current batch: Loss-> 1.4739, Train accuracy->  15.73%\n","Current batch: Loss-> 1.3467, Train accuracy->  15.79%\n","Current batch: Loss-> 1.4073, Train accuracy->  15.84%\n","Current batch: Loss-> 1.3589, Train accuracy->  15.91%\n","Current batch: Loss-> 1.2353, Train accuracy->  15.97%\n","Current batch: Loss-> 1.2553, Train accuracy->  16.04%\n","Current batch: Loss-> 1.2106, Train accuracy->  16.12%\n","Current batch: Loss-> 1.3448, Train accuracy->  16.18%\n","Current batch: Loss-> 1.2815, Train accuracy->  16.24%\n","Current batch: Loss-> 1.1856, Train accuracy->  16.32%\n","Current batch: Loss-> 1.3041, Train accuracy->  16.38%\n","Current batch: Loss-> 1.3040, Train accuracy->  16.45%\n","Current batch: Loss-> 1.5323, Train accuracy->  16.51%\n","Current batch: Loss-> 1.1936, Train accuracy->  16.59%\n","Current batch: Loss-> 1.3249, Train accuracy->  16.64%\n","Current batch: Loss-> 1.3832, Train accuracy->  16.69%\n","Current batch: Loss-> 1.3048, Train accuracy->  16.75%\n","Current batch: Loss-> 1.4231, Train accuracy->  16.81%\n","Current batch: Loss-> 1.1065, Train accuracy->  16.88%\n","Current batch: Loss-> 1.4492, Train accuracy->  16.94%\n","Current batch: Loss-> 1.3585, Train accuracy->  17.00%\n","Current batch: Loss-> 1.4396, Train accuracy->  17.06%\n","Current batch: Loss-> 1.1977, Train accuracy->  17.12%\n","Current batch: Loss-> 1.3009, Train accuracy->  17.19%\n","Current batch: Loss-> 1.3315, Train accuracy->  17.25%\n","Current batch: Loss-> 1.2591, Train accuracy->  17.33%\n","Current batch: Loss-> 1.2397, Train accuracy->  17.40%\n","Current batch: Loss-> 1.4135, Train accuracy->  17.46%\n","Current batch: Loss-> 1.2972, Train accuracy->  17.53%\n","Current batch: Loss-> 1.3213, Train accuracy->  17.60%\n","Current batch: Loss-> 1.3263, Train accuracy->  17.66%\n","Current batch: Loss-> 1.1738, Train accuracy->  17.72%\n","Current batch: Loss-> 1.3927, Train accuracy->  17.78%\n","Current batch: Loss-> 1.4449, Train accuracy->  17.85%\n","Current batch: Loss-> 1.3792, Train accuracy->  17.90%\n","Current batch: Loss-> 1.4130, Train accuracy->  17.96%\n","Current batch: Loss-> 1.4143, Train accuracy->  18.02%\n","Current batch: Loss-> 1.1878, Train accuracy->  18.09%\n","Current batch: Loss-> 1.3120, Train accuracy->  18.14%\n","Current batch: Loss-> 1.4088, Train accuracy->  18.20%\n","Current batch: Loss-> 1.2327, Train accuracy->  18.28%\n","Current batch: Loss-> 1.3569, Train accuracy->  18.34%\n","Current batch: Loss-> 1.3477, Train accuracy->  18.40%\n","Current batch: Loss-> 1.1811, Train accuracy->  18.46%\n","Current batch: Loss-> 1.5550, Train accuracy->  18.52%\n","Current batch: Loss-> 1.3120, Train accuracy->  18.57%\n","Current batch: Loss-> 1.4214, Train accuracy->  18.62%\n","Current batch: Loss-> 1.4756, Train accuracy->  18.67%\n","Current batch: Loss-> 1.1796, Train accuracy->  18.74%\n","Current batch: Loss-> 1.2165, Train accuracy->  18.80%\n","Current batch: Loss-> 1.3682, Train accuracy->  18.86%\n","Current batch: Loss-> 1.4829, Train accuracy->  18.92%\n","Current batch: Loss-> 1.1680, Train accuracy->  18.99%\n","Current batch: Loss-> 1.2265, Train accuracy->  19.06%\n","Current batch: Loss-> 1.0950, Train accuracy->  19.13%\n","Current batch: Loss-> 1.3975, Train accuracy->  19.19%\n","Current batch: Loss-> 1.1180, Train accuracy->  19.26%\n","Current batch: Loss-> 1.4419, Train accuracy->  19.31%\n","Current batch: Loss-> 1.3783, Train accuracy->  19.36%\n","Current batch: Loss-> 1.2697, Train accuracy->  19.42%\n","Current batch: Loss-> 1.2848, Train accuracy->  19.49%\n","Current batch: Loss-> 1.7565, Train accuracy->  19.52%\n","Current batch: Loss-> 1.2505, Train accuracy->  19.59%\n","Current batch: Loss-> 1.2651, Train accuracy->  19.65%\n","Current batch: Loss-> 1.4824, Train accuracy->  19.72%\n","Current batch: Loss-> 1.3676, Train accuracy->  19.77%\n","Current batch: Loss-> 1.3799, Train accuracy->  19.84%\n","Current batch: Loss-> 1.3571, Train accuracy->  19.90%\n","Current batch: Loss-> 1.5385, Train accuracy->  19.94%\n","Current batch: Loss-> 1.1994, Train accuracy->  20.02%\n","Current batch: Loss-> 1.3919, Train accuracy->  20.08%\n","Current batch: Loss-> 1.1931, Train accuracy->  20.15%\n","Current batch: Loss-> 1.1774, Train accuracy->  20.21%\n","Current batch: Loss-> 1.3836, Train accuracy->  20.27%\n","Current batch: Loss-> 1.1464, Train accuracy->  20.35%\n","Current batch: Loss-> 1.3545, Train accuracy->  20.41%\n","Current batch: Loss-> 1.1020, Train accuracy->  20.49%\n","Current batch: Loss-> 1.3255, Train accuracy->  20.56%\n","Current batch: Loss-> 1.2050, Train accuracy->  20.62%\n","Current batch: Loss-> 1.5996, Train accuracy->  20.66%\n","Current batch: Loss-> 1.1411, Train accuracy->  20.73%\n","Current batch: Loss-> 1.4710, Train accuracy->  20.77%\n","Current batch: Loss-> 1.3403, Train accuracy->  20.83%\n","Current batch: Loss-> 1.3316, Train accuracy->  20.89%\n","Current batch: Loss-> 1.3425, Train accuracy->  20.96%\n","Current batch: Loss-> 1.1681, Train accuracy->  21.03%\n","Current batch: Loss-> 1.3431, Train accuracy->  21.10%\n","Current batch: Loss-> 1.2696, Train accuracy->  21.15%\n","Current batch: Loss-> 1.5169, Train accuracy->  21.20%\n","Current batch: Loss-> 1.3713, Train accuracy->  21.26%\n","Current batch: Loss-> 1.1050, Train accuracy->  21.33%\n","Current batch: Loss-> 1.6752, Train accuracy->  21.36%\n","Current batch: Loss-> 1.4144, Train accuracy->  21.43%\n","Current batch: Loss-> 1.5010, Train accuracy->  21.48%\n","Current batch: Loss-> 1.5637, Train accuracy->  21.53%\n","Current batch: Loss-> 1.4634, Train accuracy->  21.59%\n","Current batch: Loss-> 1.2835, Train accuracy->  21.64%\n","Current batch: Loss-> 1.4025, Train accuracy->  21.69%\n","Current batch: Loss-> 1.6489, Train accuracy->  21.74%\n","Current batch: Loss-> 1.4291, Train accuracy->  21.80%\n","Current batch: Loss-> 1.3107, Train accuracy->  21.87%\n","Current batch: Loss-> 1.0967, Train accuracy->  21.94%\n","Current batch: Loss-> 1.4343, Train accuracy->  22.00%\n","Current batch: Loss-> 1.4850, Train accuracy->  22.04%\n","Current batch: Loss-> 1.1488, Train accuracy->  22.11%\n","Current batch: Loss-> 1.2616, Train accuracy->  22.18%\n","Current batch: Loss-> 1.1705, Train accuracy->  22.24%\n","Current batch: Loss-> 1.5577, Train accuracy->  22.30%\n","Current batch: Loss-> 1.3351, Train accuracy->  22.36%\n","Current batch: Loss-> 1.1583, Train accuracy->  22.43%\n","Current batch: Loss-> 1.4780, Train accuracy->  22.49%\n","Current batch: Loss-> 1.5107, Train accuracy->  22.55%\n","Current batch: Loss-> 1.4517, Train accuracy->  22.61%\n","Current batch: Loss-> 1.3214, Train accuracy->  22.67%\n","Current batch: Loss-> 1.4253, Train accuracy->  22.74%\n","Current batch: Loss-> 1.2742, Train accuracy->  22.81%\n","Current batch: Loss-> 1.4643, Train accuracy->  22.87%\n","Current batch: Loss-> 1.1842, Train accuracy->  22.94%\n","Current batch: Loss-> 1.3230, Train accuracy->  23.01%\n","Current batch: Loss-> 1.3284, Train accuracy->  23.07%\n","Current batch: Loss-> 1.2745, Train accuracy->  23.16%\n","Current batch: Loss-> 1.3562, Train accuracy->  23.21%\n","Current batch: Loss-> 1.4847, Train accuracy->  23.26%\n","Current batch: Loss-> 1.3415, Train accuracy->  23.31%\n","Current batch: Loss-> 1.1723, Train accuracy->  23.38%\n","Current batch: Loss-> 1.4927, Train accuracy->  23.42%\n","Current batch: Loss-> 1.4249, Train accuracy->  23.48%\n","Current batch: Loss-> 1.3013, Train accuracy->  23.53%\n","Current batch: Loss-> 1.3342, Train accuracy->  23.59%\n","Current batch: Loss-> 1.1647, Train accuracy->  23.67%\n","Current batch: Loss-> 1.3361, Train accuracy->  23.73%\n","Current batch: Loss-> 1.3861, Train accuracy->  23.80%\n","Current batch: Loss-> 1.0992, Train accuracy->  23.87%\n","Current batch: Loss-> 1.3033, Train accuracy->  23.93%\n","Current batch: Loss-> 1.1817, Train accuracy->  24.01%\n","Current batch: Loss-> 1.3884, Train accuracy->  24.06%\n","Current batch: Loss-> 1.3988, Train accuracy->  24.12%\n","Current batch: Loss-> 1.4228, Train accuracy->  24.18%\n","Current batch: Loss-> 1.2498, Train accuracy->  24.24%\n","Current batch: Loss-> 1.4076, Train accuracy->  24.29%\n","Current batch: Loss-> 1.3232, Train accuracy->  24.36%\n","Current batch: Loss-> 1.0850, Train accuracy->  24.45%\n","Current batch: Loss-> 1.2856, Train accuracy->  24.52%\n","Current batch: Loss-> 1.5687, Train accuracy->  24.57%\n","Current batch: Loss-> 1.4703, Train accuracy->  24.63%\n","Current batch: Loss-> 1.4920, Train accuracy->  24.69%\n","Current batch: Loss-> 1.3835, Train accuracy->  24.75%\n","Current batch: Loss-> 1.4081, Train accuracy->  24.80%\n","Current batch: Loss-> 1.2222, Train accuracy->  24.86%\n","Current batch: Loss-> 1.2886, Train accuracy->  24.91%\n","Current batch: Loss-> 1.4742, Train accuracy->  24.97%\n","Current batch: Loss-> 1.5569, Train accuracy->  25.04%\n","Current batch: Loss-> 1.2726, Train accuracy->  25.11%\n","Current batch: Loss-> 1.1971, Train accuracy->  25.17%\n","Current batch: Loss-> 1.3096, Train accuracy->  25.25%\n","Current batch: Loss-> 1.5410, Train accuracy->  25.30%\n","Current batch: Loss-> 1.3253, Train accuracy->  25.35%\n","Current batch: Loss-> 1.3331, Train accuracy->  25.41%\n","Current batch: Loss-> 1.3474, Train accuracy->  25.46%\n","Current batch: Loss-> 1.2181, Train accuracy->  25.52%\n","Current batch: Loss-> 1.3300, Train accuracy->  25.58%\n","Current batch: Loss-> 1.3361, Train accuracy->  25.64%\n","Current batch: Loss-> 1.2219, Train accuracy->  25.71%\n","Current batch: Loss-> 1.2745, Train accuracy->  25.76%\n","Current batch: Loss-> 1.4774, Train accuracy->  25.81%\n","Current batch: Loss-> 1.2543, Train accuracy->  25.89%\n","Current batch: Loss-> 1.4960, Train accuracy->  25.94%\n","Current batch: Loss-> 1.2578, Train accuracy->  26.00%\n","Current batch: Loss-> 1.2295, Train accuracy->  26.08%\n","Current batch: Loss-> 1.1726, Train accuracy->  26.15%\n","Current batch: Loss-> 1.1787, Train accuracy->  26.22%\n","Current batch: Loss-> 1.3667, Train accuracy->  26.27%\n","Current batch: Loss-> 1.4350, Train accuracy->  26.33%\n","Current batch: Loss-> 1.3178, Train accuracy->  26.39%\n","Current batch: Loss-> 1.3534, Train accuracy->  26.45%\n","Current batch: Loss-> 1.3756, Train accuracy->  26.51%\n","Current batch: Loss-> 1.2731, Train accuracy->  26.58%\n","Current batch: Loss-> 1.1893, Train accuracy->  26.63%\n","Current batch: Loss-> 1.2998, Train accuracy->  26.70%\n","Current batch: Loss-> 1.2940, Train accuracy->  26.74%\n","Current batch: Loss-> 1.4025, Train accuracy->  26.79%\n","Current batch: Loss-> 1.4075, Train accuracy->  26.84%\n","Current batch: Loss-> 1.2632, Train accuracy->  26.90%\n","Current batch: Loss-> 1.3876, Train accuracy->  26.96%\n","Current batch: Loss-> 1.2539, Train accuracy->  27.02%\n","Current batch: Loss-> 1.4116, Train accuracy->  27.09%\n","Current batch: Loss-> 1.3246, Train accuracy->  27.15%\n","Current batch: Loss-> 1.3384, Train accuracy->  27.20%\n","Current batch: Loss-> 1.1693, Train accuracy->  27.27%\n","Current batch: Loss-> 1.4314, Train accuracy->  27.32%\n","Current batch: Loss-> 1.3898, Train accuracy->  27.38%\n","Current batch: Loss-> 1.1674, Train accuracy->  27.45%\n","Current batch: Loss-> 1.3705, Train accuracy->  27.49%\n","Current batch: Loss-> 1.3210, Train accuracy->  27.55%\n","Current batch: Loss-> 1.2943, Train accuracy->  27.61%\n","Current batch: Loss-> 1.2286, Train accuracy->  27.66%\n","Current batch: Loss-> 1.1952, Train accuracy->  27.73%\n","Current batch: Loss-> 1.2440, Train accuracy->  27.80%\n","Current batch: Loss-> 1.2127, Train accuracy->  27.87%\n","Current batch: Loss-> 1.6120, Train accuracy->  27.93%\n","Current batch: Loss-> 1.3011, Train accuracy->  28.00%\n","Current batch: Loss-> 1.4186, Train accuracy->  28.05%\n","Current batch: Loss-> 1.4659, Train accuracy->  28.10%\n","Current batch: Loss-> 1.6180, Train accuracy->  28.17%\n","Current batch: Loss-> 1.5370, Train accuracy->  28.21%\n","Current batch: Loss-> 1.2955, Train accuracy->  28.28%\n","Current batch: Loss-> 1.3794, Train accuracy->  28.34%\n","Current batch: Loss-> 1.3568, Train accuracy->  28.40%\n","Current batch: Loss-> 1.3521, Train accuracy->  28.46%\n","Current batch: Loss-> 1.0615, Train accuracy->  28.53%\n","Current batch: Loss-> 1.2731, Train accuracy->  28.60%\n","Current batch: Loss-> 1.1368, Train accuracy->  28.66%\n","Current batch: Loss-> 1.4225, Train accuracy->  28.73%\n","Current batch: Loss-> 1.3262, Train accuracy->  28.78%\n","Current batch: Loss-> 1.1869, Train accuracy->  28.85%\n","Current batch: Loss-> 1.3640, Train accuracy->  28.92%\n","Current batch: Loss-> 1.3200, Train accuracy->  28.99%\n","Current batch: Loss-> 1.2700, Train accuracy->  29.06%\n","Current batch: Loss-> 1.3254, Train accuracy->  29.13%\n","Current batch: Loss-> 1.2511, Train accuracy->  29.19%\n","Current batch: Loss-> 1.2388, Train accuracy->  29.25%\n","Current batch: Loss-> 1.3302, Train accuracy->  29.31%\n","Current batch: Loss-> 1.5098, Train accuracy->  29.37%\n","Current batch: Loss-> 1.0961, Train accuracy->  29.45%\n","Current batch: Loss-> 1.2859, Train accuracy->  29.52%\n","Current batch: Loss-> 1.3167, Train accuracy->  29.57%\n","Current batch: Loss-> 1.0819, Train accuracy->  29.64%\n","Current batch: Loss-> 1.2633, Train accuracy->  29.71%\n","Current batch: Loss-> 1.1158, Train accuracy->  29.79%\n","Current batch: Loss-> 1.2465, Train accuracy->  29.86%\n","Current batch: Loss-> 1.2956, Train accuracy->  29.93%\n","Current batch: Loss-> 1.3503, Train accuracy->  29.99%\n","Current batch: Loss-> 1.2469, Train accuracy->  30.06%\n","Current batch: Loss-> 1.1360, Train accuracy->  30.12%\n","Current batch: Loss-> 1.3723, Train accuracy->  30.17%\n","Current batch: Loss-> 1.2772, Train accuracy->  30.23%\n","Current batch: Loss-> 1.2492, Train accuracy->  30.29%\n","Current batch: Loss-> 1.5438, Train accuracy->  30.33%\n","Current batch: Loss-> 1.3009, Train accuracy->  30.38%\n","Current batch: Loss-> 1.5492, Train accuracy->  30.44%\n","Current batch: Loss-> 1.3524, Train accuracy->  30.50%\n","Current batch: Loss-> 1.2865, Train accuracy->  30.56%\n","Current batch: Loss-> 1.2929, Train accuracy->  30.61%\n","Current batch: Loss-> 1.3424, Train accuracy->  30.67%\n","Current batch: Loss-> 1.3258, Train accuracy->  30.74%\n","Current batch: Loss-> 1.4977, Train accuracy->  30.77%\n","Current batch: Loss-> 1.2090, Train accuracy->  30.84%\n","Current batch: Loss-> 1.1973, Train accuracy->  30.89%\n","Current batch: Loss-> 1.2792, Train accuracy->  30.96%\n","Current batch: Loss-> 1.2259, Train accuracy->  31.02%\n","Current batch: Loss-> 1.2208, Train accuracy->  31.08%\n","Current batch: Loss-> 1.2477, Train accuracy->  31.14%\n","Current batch: Loss-> 1.2837, Train accuracy->  31.20%\n","Current batch: Loss-> 1.3778, Train accuracy->  31.26%\n","Current batch: Loss-> 1.2900, Train accuracy->  31.33%\n","Current batch: Loss-> 1.2574, Train accuracy->  31.39%\n","Current batch: Loss-> 1.1732, Train accuracy->  31.47%\n","Current batch: Loss-> 1.0524, Train accuracy->  31.54%\n","Current batch: Loss-> 1.4445, Train accuracy->  31.61%\n","Current batch: Loss-> 1.3946, Train accuracy->  31.66%\n","Current batch: Loss-> 1.3404, Train accuracy->  31.73%\n","Current batch: Loss-> 1.3662, Train accuracy->  31.79%\n","Current batch: Loss-> 1.2038, Train accuracy->  31.87%\n","Current batch: Loss-> 1.3439, Train accuracy->  31.94%\n","Current batch: Loss-> 1.4563, Train accuracy->  31.99%\n","Current batch: Loss-> 1.3584, Train accuracy->  32.05%\n","Current batch: Loss-> 1.2361, Train accuracy->  32.12%\n","Current batch: Loss-> 1.4752, Train accuracy->  32.17%\n","Current batch: Loss-> 1.2038, Train accuracy->  32.25%\n","Current batch: Loss-> 1.3427, Train accuracy->  32.30%\n","Current batch: Loss-> 1.1287, Train accuracy->  32.37%\n","Current batch: Loss-> 1.2971, Train accuracy->  32.44%\n","Current batch: Loss-> 1.3878, Train accuracy->  32.49%\n","Current batch: Loss-> 1.3064, Train accuracy->  32.56%\n","Current batch: Loss-> 1.1080, Train accuracy->  32.63%\n","Current batch: Loss-> 1.2287, Train accuracy->  32.71%\n","Current batch: Loss-> 1.2480, Train accuracy->  32.77%\n","Current batch: Loss-> 1.5486, Train accuracy->  32.82%\n","Current batch: Loss-> 1.3972, Train accuracy->  32.88%\n","Current batch: Loss-> 1.1253, Train accuracy->  32.95%\n","Current batch: Loss-> 1.0778, Train accuracy->  33.04%\n","Current batch: Loss-> 1.2359, Train accuracy->  33.09%\n","Current batch: Loss-> 1.0928, Train accuracy->  33.17%\n","Current batch: Loss-> 1.4006, Train accuracy->  33.22%\n","Current batch: Loss-> 1.5165, Train accuracy->  33.28%\n","Current batch: Loss-> 1.3791, Train accuracy->  33.33%\n","Current batch: Loss-> 1.2785, Train accuracy->  33.40%\n","Current batch: Loss-> 1.1902, Train accuracy->  33.46%\n","Current batch: Loss-> 1.4716, Train accuracy->  33.50%\n","Current batch: Loss-> 1.2457, Train accuracy->  33.56%\n","Current batch: Loss-> 1.2430, Train accuracy->  33.61%\n","Current batch: Loss-> 1.3166, Train accuracy->  33.66%\n","Current batch: Loss-> 1.3235, Train accuracy->  33.72%\n","Current batch: Loss-> 1.1873, Train accuracy->  33.79%\n","Current batch: Loss-> 1.2902, Train accuracy->  33.85%\n","Current batch: Loss-> 1.1025, Train accuracy->  33.93%\n","Current batch: Loss-> 1.2357, Train accuracy->  33.99%\n","Current batch: Loss-> 1.3046, Train accuracy->  34.05%\n","Current batch: Loss-> 1.3371, Train accuracy->  34.10%\n","Current batch: Loss-> 1.3063, Train accuracy->  34.17%\n","Current batch: Loss-> 1.4011, Train accuracy->  34.22%\n","Current batch: Loss-> 1.3008, Train accuracy->  34.29%\n","Current batch: Loss-> 1.2754, Train accuracy->  34.35%\n","Current batch: Loss-> 1.5263, Train accuracy->  34.40%\n","Current batch: Loss-> 1.1253, Train accuracy->  34.47%\n","Current batch: Loss-> 1.1416, Train accuracy->  34.54%\n","Current batch: Loss-> 1.3797, Train accuracy->  34.60%\n","Current batch: Loss-> 1.3903, Train accuracy->  34.66%\n","Current batch: Loss-> 1.3524, Train accuracy->  34.73%\n","Current batch: Loss-> 1.4825, Train accuracy->  34.79%\n","Current batch: Loss-> 1.2912, Train accuracy->  34.86%\n","Current batch: Loss-> 1.5044, Train accuracy->  34.91%\n","Current batch: Loss-> 1.6561, Train accuracy->  34.96%\n","Current batch: Loss-> 1.4116, Train accuracy->  35.03%\n","Current batch: Loss-> 1.4672, Train accuracy->  35.09%\n","Current batch: Loss-> 1.3823, Train accuracy->  35.15%\n","Current batch: Loss-> 1.4696, Train accuracy->  35.21%\n","Current batch: Loss-> 1.5571, Train accuracy->  35.26%\n","Current batch: Loss-> 1.1973, Train accuracy->  35.32%\n","Current batch: Loss-> 1.3547, Train accuracy->  35.37%\n","Current batch: Loss-> 1.2376, Train accuracy->  35.44%\n","Current batch: Loss-> 1.4640, Train accuracy->  35.50%\n","Current batch: Loss-> 1.3783, Train accuracy->  35.56%\n","Current batch: Loss-> 1.2096, Train accuracy->  35.64%\n","Current batch: Loss-> 1.3802, Train accuracy->  35.69%\n","Current batch: Loss-> 1.3668, Train accuracy->  35.75%\n","Current batch: Loss-> 1.4459, Train accuracy->  35.80%\n","Current batch: Loss-> 1.3550, Train accuracy->  35.87%\n","Current batch: Loss-> 1.2934, Train accuracy->  35.92%\n","Current batch: Loss-> 1.0101, Train accuracy->  36.02%\n","Current batch: Loss-> 1.2054, Train accuracy->  36.10%\n","Current batch: Loss-> 1.3922, Train accuracy->  36.15%\n","Current batch: Loss-> 1.3910, Train accuracy->  36.22%\n","Current batch: Loss-> 1.2527, Train accuracy->  36.27%\n","Current batch: Loss-> 1.1705, Train accuracy->  36.35%\n","Current batch: Loss-> 1.2086, Train accuracy->  36.42%\n","Current batch: Loss-> 1.1858, Train accuracy->  36.49%\n","Current batch: Loss-> 1.2750, Train accuracy->  36.56%\n","Current batch: Loss-> 1.2071, Train accuracy->  36.64%\n","Current batch: Loss-> 1.2946, Train accuracy->  36.71%\n","Current batch: Loss-> 1.0384, Train accuracy->  36.79%\n","Current batch: Loss-> 1.2164, Train accuracy->  36.85%\n","Current batch: Loss-> 1.2603, Train accuracy->  36.91%\n","Current batch: Loss-> 1.3818, Train accuracy->  36.96%\n","Current batch: Loss-> 1.1028, Train accuracy->  37.02%\n","Current batch: Loss-> 1.1698, Train accuracy->  37.11%\n","Current batch: Loss-> 1.2325, Train accuracy->  37.17%\n","Current batch: Loss-> 1.1120, Train accuracy->  37.24%\n","Current batch: Loss-> 1.2928, Train accuracy->  37.31%\n","Current batch: Loss-> 1.3525, Train accuracy->  37.38%\n","Current batch: Loss-> 1.2095, Train accuracy->  37.46%\n","Current batch: Loss-> 1.2417, Train accuracy->  37.52%\n","Current batch: Loss-> 1.3002, Train accuracy->  37.58%\n","Current batch: Loss-> 1.5754, Train accuracy->  37.64%\n","Current batch: Loss-> 1.2526, Train accuracy->  37.70%\n","Current batch: Loss-> 1.3392, Train accuracy->  37.76%\n","Current batch: Loss-> 1.1570, Train accuracy->  37.83%\n","Current batch: Loss-> 1.2164, Train accuracy->  37.90%\n","Current batch: Loss-> 1.2803, Train accuracy->  37.97%\n","Current batch: Loss-> 1.2505, Train accuracy->  38.03%\n","Current batch: Loss-> 1.3217, Train accuracy->  38.09%\n","Current batch: Loss-> 1.1529, Train accuracy->  38.17%\n","Current batch: Loss-> 1.3585, Train accuracy->  38.24%\n","Current batch: Loss-> 1.3111, Train accuracy->  38.31%\n","Current batch: Loss-> 1.2386, Train accuracy->  38.38%\n","Current batch: Loss-> 1.2000, Train accuracy->  38.44%\n","Current batch: Loss-> 1.3447, Train accuracy->  38.50%\n","Current batch: Loss-> 1.3097, Train accuracy->  38.56%\n","Current batch: Loss-> 1.2326, Train accuracy->  38.62%\n","Current batch: Loss-> 1.2468, Train accuracy->  38.69%\n","Current batch: Loss-> 1.2925, Train accuracy->  38.75%\n","Current batch: Loss-> 1.0353, Train accuracy->  38.84%\n","Current batch: Loss-> 1.2553, Train accuracy->  38.90%\n","Current batch: Loss-> 1.3844, Train accuracy->  38.96%\n","Current batch: Loss-> 1.4397, Train accuracy->  39.02%\n","Current batch: Loss-> 1.1778, Train accuracy->  39.09%\n","Current batch: Loss-> 1.5159, Train accuracy->  39.14%\n","Current batch: Loss-> 1.1822, Train accuracy->  39.20%\n","Current batch: Loss-> 1.2723, Train accuracy->  39.27%\n","Current batch: Loss-> 1.2834, Train accuracy->  39.34%\n","Current batch: Loss-> 1.3598, Train accuracy->  39.41%\n","Current batch: Loss-> 1.5793, Train accuracy->  39.46%\n","Current batch: Loss-> 1.2480, Train accuracy->  39.51%\n","Current batch: Loss-> 0.9875, Train accuracy->  39.59%\n","Current batch: Loss-> 1.4723, Train accuracy->  39.65%\n","Current batch: Loss-> 1.3166, Train accuracy->  39.71%\n","Current batch: Loss-> 1.2616, Train accuracy->  39.76%\n","Current batch: Loss-> 1.2121, Train accuracy->  39.84%\n","Current batch: Loss-> 1.2708, Train accuracy->  39.90%\n","Current batch: Loss-> 1.4396, Train accuracy->  39.95%\n","Current batch: Loss-> 1.2188, Train accuracy->  40.03%\n","Current batch: Loss-> 1.3735, Train accuracy->  40.09%\n","Current batch: Loss-> 1.3601, Train accuracy->  40.15%\n","Current batch: Loss-> 1.4008, Train accuracy->  40.20%\n","Current batch: Loss-> 1.2884, Train accuracy->  40.26%\n","Current batch: Loss-> 1.1360, Train accuracy->  40.34%\n","Current batch: Loss-> 1.0517, Train accuracy->  40.41%\n","Current batch: Loss-> 1.2471, Train accuracy->  40.49%\n","Current batch: Loss-> 1.0571, Train accuracy->  40.56%\n","Current batch: Loss-> 1.1498, Train accuracy->  40.62%\n","Current batch: Loss-> 1.1321, Train accuracy->  40.70%\n","Current batch: Loss-> 1.3531, Train accuracy->  40.77%\n","Current batch: Loss-> 1.2846, Train accuracy->  40.83%\n","Current batch: Loss-> 1.4322, Train accuracy->  40.90%\n","Current batch: Loss-> 1.3362, Train accuracy->  40.97%\n","Current batch: Loss-> 1.2159, Train accuracy->  41.04%\n","Current batch: Loss-> 1.1183, Train accuracy->  41.11%\n","Current batch: Loss-> 1.1335, Train accuracy->  41.17%\n","Current batch: Loss-> 1.5109, Train accuracy->  41.24%\n","Current batch: Loss-> 1.4044, Train accuracy->  41.31%\n","Current batch: Loss-> 1.2162, Train accuracy->  41.38%\n","Current batch: Loss-> 1.2576, Train accuracy->  41.44%\n","Current batch: Loss-> 1.3520, Train accuracy->  41.49%\n","Current batch: Loss-> 1.4402, Train accuracy->  41.55%\n","Current batch: Loss-> 1.1640, Train accuracy->  41.60%\n","Current batch: Loss-> 1.3226, Train accuracy->  41.67%\n","Current batch: Loss-> 1.2449, Train accuracy->  41.74%\n","Current batch: Loss-> 1.2491, Train accuracy->  41.82%\n","Current batch: Loss-> 1.1892, Train accuracy->  41.88%\n","Current batch: Loss-> 1.2556, Train accuracy->  41.94%\n","Current batch: Loss-> 1.4071, Train accuracy->  42.01%\n","Current batch: Loss-> 1.2370, Train accuracy->  42.08%\n","Current batch: Loss-> 1.3156, Train accuracy->  42.15%\n","Current batch: Loss-> 1.3045, Train accuracy->  42.20%\n","Current batch: Loss-> 1.2543, Train accuracy->  42.26%\n","Current batch: Loss-> 1.4707, Train accuracy->  42.33%\n","Current batch: Loss-> 1.3856, Train accuracy->  42.39%\n","Current batch: Loss-> 1.4144, Train accuracy->  42.45%\n","Current batch: Loss-> 1.2943, Train accuracy->  42.51%\n","Current batch: Loss-> 1.1942, Train accuracy->  42.58%\n","Current batch: Loss-> 1.1023, Train accuracy->  42.64%\n","Current batch: Loss-> 1.3655, Train accuracy->  42.71%\n","Current batch: Loss-> 1.5217, Train accuracy->  42.75%\n","Current batch: Loss-> 1.0418, Train accuracy->  42.83%\n","Current batch: Loss-> 1.3730, Train accuracy->  42.89%\n","Current batch: Loss-> 1.3390, Train accuracy->  42.94%\n","Current batch: Loss-> 1.4863, Train accuracy->  43.00%\n","Current batch: Loss-> 1.2254, Train accuracy->  43.06%\n","Current batch: Loss-> 1.1981, Train accuracy->  43.13%\n","Current batch: Loss-> 1.5458, Train accuracy->  43.19%\n","Current batch: Loss-> 1.3423, Train accuracy->  43.25%\n","Current batch: Loss-> 1.2254, Train accuracy->  43.32%\n","Current batch: Loss-> 1.2792, Train accuracy->  43.38%\n","Current batch: Loss-> 1.3378, Train accuracy->  43.44%\n","Current batch: Loss-> 1.1842, Train accuracy->  43.52%\n","Current batch: Loss-> 1.3579, Train accuracy->  43.59%\n","Current batch: Loss-> 1.3088, Train accuracy->  43.65%\n","Current batch: Loss-> 1.5312, Train accuracy->  43.72%\n","Current batch: Loss-> 1.2485, Train accuracy->  43.79%\n","Current batch: Loss-> 1.2023, Train accuracy->  43.86%\n","Current batch: Loss-> 1.0803, Train accuracy->  43.94%\n","Current batch: Loss-> 1.1577, Train accuracy->  44.01%\n","Current batch: Loss-> 1.4218, Train accuracy->  44.06%\n","Current batch: Loss-> 1.2262, Train accuracy->  44.12%\n","Current batch: Loss-> 1.4776, Train accuracy->  44.19%\n","Current batch: Loss-> 1.7927, Train accuracy->  44.24%\n","Current batch: Loss-> 1.4253, Train accuracy->  44.29%\n","Current batch: Loss-> 1.4271, Train accuracy->  44.36%\n","Current batch: Loss-> 1.3121, Train accuracy->  44.42%\n","Current batch: Loss-> 1.2474, Train accuracy->  44.48%\n","Current batch: Loss-> 1.4264, Train accuracy->  44.54%\n","Current batch: Loss-> 1.2939, Train accuracy->  44.61%\n","Current batch: Loss-> 1.5710, Train accuracy->  44.65%\n","Current batch: Loss-> 1.4464, Train accuracy->  44.70%\n","Current batch: Loss-> 1.3618, Train accuracy->  44.75%\n","Current batch: Loss-> 1.4097, Train accuracy->  44.81%\n","Current batch: Loss-> 1.2713, Train accuracy->  44.89%\n","Current batch: Loss-> 1.3992, Train accuracy->  44.95%\n","Current batch: Loss-> 1.3421, Train accuracy->  45.00%\n","Current batch: Loss-> 1.2502, Train accuracy->  45.07%\n","Current batch: Loss-> 1.3491, Train accuracy->  45.14%\n","Current batch: Loss-> 1.2667, Train accuracy->  45.21%\n","Current batch: Loss-> 1.7272, Train accuracy->  45.25%\n","Current batch: Loss-> 1.2879, Train accuracy->  45.32%\n","Current batch: Loss-> 1.0828, Train accuracy->  45.39%\n","Current batch: Loss-> 1.2577, Train accuracy->  45.46%\n","Current batch: Loss-> 1.2285, Train accuracy->  45.52%\n","Current batch: Loss-> 1.2077, Train accuracy->  45.59%\n","Current batch: Loss-> 1.2049, Train accuracy->  45.66%\n","Current batch: Loss-> 1.1930, Train accuracy->  45.74%\n","Current batch: Loss-> 1.1314, Train accuracy->  45.81%\n","Current batch: Loss-> 1.0844, Train accuracy->  45.88%\n","Current batch: Loss-> 1.3259, Train accuracy->  45.95%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:04, 44.98it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.5980, Train accuracy->  46.01%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.6954, Accuracy: 3814/12000 (32%)\n","\n","Current batch: Loss-> 1.3162, Train accuracy->   0.06%\n","Current batch: Loss-> 1.2475, Train accuracy->   0.13%\n","Current batch: Loss-> 1.6453, Train accuracy->   0.17%\n","Current batch: Loss-> 1.4876, Train accuracy->   0.24%\n","Current batch: Loss-> 1.3468, Train accuracy->   0.30%\n","Current batch: Loss-> 1.3100, Train accuracy->   0.35%\n","Current batch: Loss-> 1.5758, Train accuracy->   0.38%\n","Current batch: Loss-> 1.3955, Train accuracy->   0.43%\n","Current batch: Loss-> 1.5186, Train accuracy->   0.48%\n","Current batch: Loss-> 1.1557, Train accuracy->   0.56%\n","Current batch: Loss-> 1.2795, Train accuracy->   0.62%\n","Current batch: Loss-> 1.2350, Train accuracy->   0.70%\n","Current batch: Loss-> 1.3510, Train accuracy->   0.76%\n","Current batch: Loss-> 1.3851, Train accuracy->   0.81%\n","Current batch: Loss-> 1.2758, Train accuracy->   0.88%\n","Current batch: Loss-> 1.2605, Train accuracy->   0.94%\n","Current batch: Loss-> 1.3061, Train accuracy->   1.00%\n","Current batch: Loss-> 1.3451, Train accuracy->   1.06%\n","Current batch: Loss-> 1.2685, Train accuracy->   1.12%\n","Current batch: Loss-> 1.2479, Train accuracy->   1.18%\n","Current batch: Loss-> 1.2165, Train accuracy->   1.25%\n","Current batch: Loss-> 1.2130, Train accuracy->   1.34%\n","Current batch: Loss-> 1.1893, Train accuracy->   1.40%\n","Current batch: Loss-> 1.2021, Train accuracy->   1.46%\n","Current batch: Loss-> 1.3608, Train accuracy->   1.53%\n","Current batch: Loss-> 1.2005, Train accuracy->   1.59%\n","Current batch: Loss-> 1.1787, Train accuracy->   1.66%\n","Current batch: Loss-> 1.2940, Train accuracy->   1.72%\n","Current batch: Loss-> 1.4497, Train accuracy->   1.77%\n","Current batch: Loss-> 1.2966, Train accuracy->   1.84%\n","Current batch: Loss-> 1.2242, Train accuracy->   1.89%\n","Current batch: Loss-> 1.0880, Train accuracy->   1.97%\n","Current batch: Loss-> 1.2138, Train accuracy->   2.04%\n","Current batch: Loss-> 1.2163, Train accuracy->   2.13%\n","Current batch: Loss-> 1.2536, Train accuracy->   2.19%\n","Current batch: Loss-> 1.4178, Train accuracy->   2.24%\n","Current batch: Loss-> 1.2422, Train accuracy->   2.30%\n","Current batch: Loss-> 1.4373, Train accuracy->   2.36%\n","Current batch: Loss-> 1.2077, Train accuracy->   2.42%\n","Current batch: Loss-> 1.3904, Train accuracy->   2.49%\n","Current batch: Loss-> 1.4358, Train accuracy->   2.55%\n","Current batch: Loss-> 1.2127, Train accuracy->   2.60%\n","Current batch: Loss-> 1.2538, Train accuracy->   2.67%\n","Current batch: Loss-> 1.1914, Train accuracy->   2.74%\n","Current batch: Loss-> 1.4133, Train accuracy->   2.79%\n","Current batch: Loss-> 1.3983, Train accuracy->   2.84%\n","Current batch: Loss-> 1.4442, Train accuracy->   2.89%\n","Current batch: Loss-> 1.3199, Train accuracy->   2.96%\n","Current batch: Loss-> 1.3696, Train accuracy->   3.04%\n","Current batch: Loss-> 1.0246, Train accuracy->   3.13%\n","Current batch: Loss-> 1.2508, Train accuracy->   3.19%\n","Current batch: Loss-> 1.1747, Train accuracy->   3.27%\n","Current batch: Loss-> 1.2227, Train accuracy->   3.32%\n","Current batch: Loss-> 1.1500, Train accuracy->   3.40%\n","Current batch: Loss-> 1.3338, Train accuracy->   3.47%\n","Current batch: Loss-> 1.1864, Train accuracy->   3.54%\n","Current batch: Loss-> 1.2449, Train accuracy->   3.61%\n","Current batch: Loss-> 1.2265, Train accuracy->   3.67%\n","Current batch: Loss-> 1.1396, Train accuracy->   3.74%\n","Current batch: Loss-> 1.2133, Train accuracy->   3.81%\n","Current batch: Loss-> 1.1817, Train accuracy->   3.88%\n","Current batch: Loss-> 1.4352, Train accuracy->   3.95%\n","Current batch: Loss-> 1.3674, Train accuracy->   4.01%\n","Current batch: Loss-> 1.2257, Train accuracy->   4.07%\n","Current batch: Loss-> 1.3300, Train accuracy->   4.13%\n","Current batch: Loss-> 1.1982, Train accuracy->   4.20%\n","Current batch: Loss-> 1.5011, Train accuracy->   4.26%\n","Current batch: Loss-> 1.1089, Train accuracy->   4.33%\n","Current batch: Loss-> 1.2819, Train accuracy->   4.39%\n","Current batch: Loss-> 1.2104, Train accuracy->   4.47%\n","Current batch: Loss-> 1.4012, Train accuracy->   4.54%\n","Current batch: Loss-> 1.2555, Train accuracy->   4.61%\n","Current batch: Loss-> 1.1111, Train accuracy->   4.70%\n","Current batch: Loss-> 1.3015, Train accuracy->   4.76%\n","Current batch: Loss-> 1.2433, Train accuracy->   4.83%\n","Current batch: Loss-> 1.1857, Train accuracy->   4.90%\n","Current batch: Loss-> 1.2921, Train accuracy->   4.96%\n","Current batch: Loss-> 1.2499, Train accuracy->   5.04%\n","Current batch: Loss-> 1.0858, Train accuracy->   5.11%\n","Current batch: Loss-> 1.0308, Train accuracy->   5.19%\n","Current batch: Loss-> 1.1425, Train accuracy->   5.26%\n","Current batch: Loss-> 1.0050, Train accuracy->   5.35%\n","Current batch: Loss-> 1.2334, Train accuracy->   5.43%\n","Current batch: Loss-> 1.0825, Train accuracy->   5.50%\n","Current batch: Loss-> 1.3573, Train accuracy->   5.56%\n","Current batch: Loss-> 1.1639, Train accuracy->   5.62%\n","Current batch: Loss-> 1.3698, Train accuracy->   5.69%\n","Current batch: Loss-> 1.2830, Train accuracy->   5.76%\n","Current batch: Loss-> 1.5318, Train accuracy->   5.80%\n","Current batch: Loss-> 1.2498, Train accuracy->   5.86%\n","Current batch: Loss-> 1.4036, Train accuracy->   5.92%\n","Current batch: Loss-> 1.1243, Train accuracy->   6.00%\n","Current batch: Loss-> 1.5576, Train accuracy->   6.05%\n","Current batch: Loss-> 1.2166, Train accuracy->   6.11%\n","Current batch: Loss-> 1.4079, Train accuracy->   6.17%\n","Current batch: Loss-> 1.3860, Train accuracy->   6.23%\n","Current batch: Loss-> 1.4541, Train accuracy->   6.30%\n","Current batch: Loss-> 1.1774, Train accuracy->   6.38%\n","Current batch: Loss-> 1.2001, Train accuracy->   6.45%\n","Current batch: Loss-> 1.2787, Train accuracy->   6.51%\n","Current batch: Loss-> 1.2406, Train accuracy->   6.58%\n","Current batch: Loss-> 1.0368, Train accuracy->   6.66%\n","Current batch: Loss-> 1.3310, Train accuracy->   6.73%\n","Current batch: Loss-> 1.0725, Train accuracy->   6.81%\n","Current batch: Loss-> 1.5438, Train accuracy->   6.88%\n","Current batch: Loss-> 1.2690, Train accuracy->   6.95%\n","Current batch: Loss-> 1.1809, Train accuracy->   7.02%\n","Current batch: Loss-> 1.2440, Train accuracy->   7.09%\n","Current batch: Loss-> 1.2174, Train accuracy->   7.15%\n","Current batch: Loss-> 1.2955, Train accuracy->   7.22%\n","Current batch: Loss-> 1.4018, Train accuracy->   7.27%\n","Current batch: Loss-> 1.2322, Train accuracy->   7.34%\n","Current batch: Loss-> 1.1756, Train accuracy->   7.41%\n","Current batch: Loss-> 1.2438, Train accuracy->   7.48%\n","Current batch: Loss-> 1.3265, Train accuracy->   7.55%\n","Current batch: Loss-> 1.0567, Train accuracy->   7.63%\n","Current batch: Loss-> 1.2997, Train accuracy->   7.70%\n","Current batch: Loss-> 1.3024, Train accuracy->   7.77%\n","Current batch: Loss-> 1.0997, Train accuracy->   7.85%\n","Current batch: Loss-> 1.3200, Train accuracy->   7.91%\n","Current batch: Loss-> 1.2177, Train accuracy->   7.98%\n","Current batch: Loss-> 1.2300, Train accuracy->   8.05%\n","Current batch: Loss-> 1.3926, Train accuracy->   8.11%\n","Current batch: Loss-> 1.4460, Train accuracy->   8.18%\n","Current batch: Loss-> 1.3073, Train accuracy->   8.25%\n","Current batch: Loss-> 1.2602, Train accuracy->   8.33%\n","Current batch: Loss-> 1.1287, Train accuracy->   8.41%\n","Current batch: Loss-> 1.1216, Train accuracy->   8.48%\n","Current batch: Loss-> 1.3443, Train accuracy->   8.54%\n","Current batch: Loss-> 1.2467, Train accuracy->   8.59%\n","Current batch: Loss-> 1.1520, Train accuracy->   8.66%\n","Current batch: Loss-> 1.1390, Train accuracy->   8.73%\n","Current batch: Loss-> 1.2709, Train accuracy->   8.80%\n","Current batch: Loss-> 1.0934, Train accuracy->   8.87%\n","Current batch: Loss-> 1.4836, Train accuracy->   8.94%\n","Current batch: Loss-> 1.2326, Train accuracy->   9.01%\n","Current batch: Loss-> 1.3526, Train accuracy->   9.07%\n","Current batch: Loss-> 1.1974, Train accuracy->   9.15%\n","Current batch: Loss-> 1.1698, Train accuracy->   9.22%\n","Current batch: Loss-> 1.1407, Train accuracy->   9.30%\n","Current batch: Loss-> 1.0609, Train accuracy->   9.39%\n","Current batch: Loss-> 1.2122, Train accuracy->   9.47%\n","Current batch: Loss-> 1.2598, Train accuracy->   9.55%\n","Current batch: Loss-> 1.2656, Train accuracy->   9.61%\n","Current batch: Loss-> 1.2219, Train accuracy->   9.68%\n","Current batch: Loss-> 1.1414, Train accuracy->   9.76%\n","Current batch: Loss-> 1.1759, Train accuracy->   9.83%\n","Current batch: Loss-> 1.4962, Train accuracy->   9.89%\n","Current batch: Loss-> 1.3219, Train accuracy->   9.94%\n","Current batch: Loss-> 1.1271, Train accuracy->  10.01%\n","Current batch: Loss-> 1.2795, Train accuracy->  10.08%\n","Current batch: Loss-> 1.3489, Train accuracy->  10.14%\n","Current batch: Loss-> 1.1418, Train accuracy->  10.21%\n","Current batch: Loss-> 1.1665, Train accuracy->  10.28%\n","Current batch: Loss-> 1.0171, Train accuracy->  10.36%\n","Current batch: Loss-> 1.3269, Train accuracy->  10.42%\n","Current batch: Loss-> 1.2029, Train accuracy->  10.50%\n","Current batch: Loss-> 1.2829, Train accuracy->  10.56%\n","Current batch: Loss-> 1.3547, Train accuracy->  10.62%\n","Current batch: Loss-> 1.3104, Train accuracy->  10.69%\n","Current batch: Loss-> 1.1807, Train accuracy->  10.75%\n","Current batch: Loss-> 1.6491, Train accuracy->  10.79%\n","Current batch: Loss-> 1.1125, Train accuracy->  10.88%\n","Current batch: Loss-> 1.3016, Train accuracy->  10.94%\n","Current batch: Loss-> 1.2770, Train accuracy->  11.01%\n","Current batch: Loss-> 1.0233, Train accuracy->  11.10%\n","Current batch: Loss-> 1.0478, Train accuracy->  11.16%\n","Current batch: Loss-> 1.2303, Train accuracy->  11.23%\n","Current batch: Loss-> 1.3362, Train accuracy->  11.30%\n","Current batch: Loss-> 1.1514, Train accuracy->  11.38%\n","Current batch: Loss-> 1.3190, Train accuracy->  11.44%\n","Current batch: Loss-> 1.1461, Train accuracy->  11.52%\n","Current batch: Loss-> 1.2028, Train accuracy->  11.59%\n","Current batch: Loss-> 1.3120, Train accuracy->  11.66%\n","Current batch: Loss-> 1.1608, Train accuracy->  11.75%\n","Current batch: Loss-> 1.1349, Train accuracy->  11.82%\n","Current batch: Loss-> 1.2625, Train accuracy->  11.89%\n","Current batch: Loss-> 1.3429, Train accuracy->  11.96%\n","Current batch: Loss-> 1.1965, Train accuracy->  12.03%\n","Current batch: Loss-> 1.1671, Train accuracy->  12.12%\n","Current batch: Loss-> 1.2715, Train accuracy->  12.18%\n","Current batch: Loss-> 1.3056, Train accuracy->  12.25%\n","Current batch: Loss-> 1.3012, Train accuracy->  12.31%\n","Current batch: Loss-> 1.2962, Train accuracy->  12.37%\n","Current batch: Loss-> 1.1283, Train accuracy->  12.43%\n","Current batch: Loss-> 1.1192, Train accuracy->  12.50%\n","Current batch: Loss-> 1.1641, Train accuracy->  12.58%\n","Current batch: Loss-> 1.3865, Train accuracy->  12.64%\n","Current batch: Loss-> 1.2604, Train accuracy->  12.71%\n","Current batch: Loss-> 1.2870, Train accuracy->  12.78%\n","Current batch: Loss-> 1.3376, Train accuracy->  12.83%\n","Current batch: Loss-> 1.1392, Train accuracy->  12.91%\n","Current batch: Loss-> 1.2549, Train accuracy->  12.99%\n","Current batch: Loss-> 1.1938, Train accuracy->  13.06%\n","Current batch: Loss-> 1.3304, Train accuracy->  13.14%\n","Current batch: Loss-> 1.2595, Train accuracy->  13.21%\n","Current batch: Loss-> 1.1174, Train accuracy->  13.29%\n","Current batch: Loss-> 0.9827, Train accuracy->  13.38%\n","Current batch: Loss-> 1.1105, Train accuracy->  13.47%\n","Current batch: Loss-> 1.1211, Train accuracy->  13.54%\n","Current batch: Loss-> 1.6575, Train accuracy->  13.60%\n","Current batch: Loss-> 1.1812, Train accuracy->  13.67%\n","Current batch: Loss-> 1.2257, Train accuracy->  13.74%\n","Current batch: Loss-> 1.3140, Train accuracy->  13.80%\n","Current batch: Loss-> 1.3330, Train accuracy->  13.86%\n","Current batch: Loss-> 1.1641, Train accuracy->  13.93%\n","Current batch: Loss-> 1.1540, Train accuracy->  14.00%\n","Current batch: Loss-> 1.0763, Train accuracy->  14.07%\n","Current batch: Loss-> 1.3922, Train accuracy->  14.14%\n","Current batch: Loss-> 1.3453, Train accuracy->  14.21%\n","Current batch: Loss-> 1.1998, Train accuracy->  14.27%\n","Current batch: Loss-> 1.3253, Train accuracy->  14.33%\n","Current batch: Loss-> 1.4948, Train accuracy->  14.39%\n","Current batch: Loss-> 1.2985, Train accuracy->  14.44%\n","Current batch: Loss-> 1.1663, Train accuracy->  14.52%\n","Current batch: Loss-> 1.2596, Train accuracy->  14.58%\n","Current batch: Loss-> 1.3649, Train accuracy->  14.64%\n","Current batch: Loss-> 1.6117, Train accuracy->  14.71%\n","Current batch: Loss-> 1.2260, Train accuracy->  14.78%\n","Current batch: Loss-> 1.3424, Train accuracy->  14.83%\n","Current batch: Loss-> 1.1569, Train accuracy->  14.90%\n","Current batch: Loss-> 1.1572, Train accuracy->  14.96%\n","Current batch: Loss-> 1.1284, Train accuracy->  15.04%\n","Current batch: Loss-> 1.1790, Train accuracy->  15.12%\n","Current batch: Loss-> 1.3307, Train accuracy->  15.17%\n","Current batch: Loss-> 1.2778, Train accuracy->  15.22%\n","Current batch: Loss-> 1.4945, Train accuracy->  15.28%\n","Current batch: Loss-> 1.1177, Train accuracy->  15.35%\n","Current batch: Loss-> 1.1756, Train accuracy->  15.43%\n","Current batch: Loss-> 1.0180, Train accuracy->  15.51%\n","Current batch: Loss-> 1.1507, Train accuracy->  15.57%\n","Current batch: Loss-> 1.3794, Train accuracy->  15.62%\n","Current batch: Loss-> 1.1115, Train accuracy->  15.69%\n","Current batch: Loss-> 1.2615, Train accuracy->  15.75%\n","Current batch: Loss-> 1.3003, Train accuracy->  15.81%\n","Current batch: Loss-> 1.3757, Train accuracy->  15.87%\n","Current batch: Loss-> 1.4493, Train accuracy->  15.94%\n","Current batch: Loss-> 1.5404, Train accuracy->  16.01%\n","Current batch: Loss-> 1.3578, Train accuracy->  16.07%\n","Current batch: Loss-> 1.4716, Train accuracy->  16.13%\n","Current batch: Loss-> 1.3418, Train accuracy->  16.17%\n","Current batch: Loss-> 1.2834, Train accuracy->  16.23%\n","Current batch: Loss-> 1.2071, Train accuracy->  16.30%\n","Current batch: Loss-> 1.2605, Train accuracy->  16.37%\n","Current batch: Loss-> 1.2738, Train accuracy->  16.44%\n","Current batch: Loss-> 1.4564, Train accuracy->  16.50%\n","Current batch: Loss-> 1.2710, Train accuracy->  16.56%\n","Current batch: Loss-> 1.1797, Train accuracy->  16.63%\n","Current batch: Loss-> 1.1087, Train accuracy->  16.70%\n","Current batch: Loss-> 1.3803, Train accuracy->  16.76%\n","Current batch: Loss-> 1.1997, Train accuracy->  16.82%\n","Current batch: Loss-> 1.3728, Train accuracy->  16.89%\n","Current batch: Loss-> 1.0726, Train accuracy->  16.97%\n","Current batch: Loss-> 1.2049, Train accuracy->  17.05%\n","Current batch: Loss-> 1.1526, Train accuracy->  17.12%\n","Current batch: Loss-> 1.1623, Train accuracy->  17.19%\n","Current batch: Loss-> 1.2196, Train accuracy->  17.25%\n","Current batch: Loss-> 1.3597, Train accuracy->  17.33%\n","Current batch: Loss-> 1.3950, Train accuracy->  17.40%\n","Current batch: Loss-> 1.0880, Train accuracy->  17.49%\n","Current batch: Loss-> 1.1185, Train accuracy->  17.57%\n","Current batch: Loss-> 1.0460, Train accuracy->  17.65%\n","Current batch: Loss-> 1.2941, Train accuracy->  17.71%\n","Current batch: Loss-> 1.4521, Train accuracy->  17.77%\n","Current batch: Loss-> 1.0945, Train accuracy->  17.84%\n","Current batch: Loss-> 1.5041, Train accuracy->  17.89%\n","Current batch: Loss-> 1.3030, Train accuracy->  17.95%\n","Current batch: Loss-> 1.2398, Train accuracy->  18.02%\n","Current batch: Loss-> 1.1606, Train accuracy->  18.10%\n","Current batch: Loss-> 1.1473, Train accuracy->  18.18%\n","Current batch: Loss-> 1.3585, Train accuracy->  18.25%\n","Current batch: Loss-> 1.0478, Train accuracy->  18.32%\n","Current batch: Loss-> 1.2047, Train accuracy->  18.39%\n","Current batch: Loss-> 1.3082, Train accuracy->  18.46%\n","Current batch: Loss-> 1.2376, Train accuracy->  18.52%\n","Current batch: Loss-> 1.1307, Train accuracy->  18.59%\n","Current batch: Loss-> 1.0522, Train accuracy->  18.67%\n","Current batch: Loss-> 1.0707, Train accuracy->  18.75%\n","Current batch: Loss-> 1.1868, Train accuracy->  18.80%\n","Current batch: Loss-> 1.1322, Train accuracy->  18.88%\n","Current batch: Loss-> 1.2328, Train accuracy->  18.95%\n","Current batch: Loss-> 0.9691, Train accuracy->  19.03%\n","Current batch: Loss-> 1.2800, Train accuracy->  19.09%\n","Current batch: Loss-> 1.1747, Train accuracy->  19.17%\n","Current batch: Loss-> 1.2934, Train accuracy->  19.24%\n","Current batch: Loss-> 1.3094, Train accuracy->  19.30%\n","Current batch: Loss-> 1.1544, Train accuracy->  19.38%\n","Current batch: Loss-> 1.5111, Train accuracy->  19.44%\n","Current batch: Loss-> 1.3227, Train accuracy->  19.50%\n","Current batch: Loss-> 1.1223, Train accuracy->  19.58%\n","Current batch: Loss-> 1.1573, Train accuracy->  19.65%\n","Current batch: Loss-> 1.1987, Train accuracy->  19.72%\n","Current batch: Loss-> 1.3197, Train accuracy->  19.78%\n","Current batch: Loss-> 1.3338, Train accuracy->  19.84%\n","Current batch: Loss-> 1.3060, Train accuracy->  19.92%\n","Current batch: Loss-> 1.2204, Train accuracy->  19.99%\n","Current batch: Loss-> 1.1626, Train accuracy->  20.05%\n","Current batch: Loss-> 1.3587, Train accuracy->  20.12%\n","Current batch: Loss-> 1.3198, Train accuracy->  20.19%\n","Current batch: Loss-> 1.2022, Train accuracy->  20.25%\n","Current batch: Loss-> 1.0906, Train accuracy->  20.33%\n","Current batch: Loss-> 1.3728, Train accuracy->  20.40%\n","Current batch: Loss-> 1.0312, Train accuracy->  20.46%\n","Current batch: Loss-> 1.2057, Train accuracy->  20.54%\n","Current batch: Loss-> 1.4496, Train accuracy->  20.60%\n","Current batch: Loss-> 1.6090, Train accuracy->  20.65%\n","Current batch: Loss-> 1.1005, Train accuracy->  20.73%\n","Current batch: Loss-> 1.2102, Train accuracy->  20.80%\n","Current batch: Loss-> 1.2472, Train accuracy->  20.86%\n","Current batch: Loss-> 1.4054, Train accuracy->  20.94%\n","Current batch: Loss-> 1.2761, Train accuracy->  21.00%\n","Current batch: Loss-> 1.1975, Train accuracy->  21.06%\n","Current batch: Loss-> 1.3365, Train accuracy->  21.13%\n","Current batch: Loss-> 1.0214, Train accuracy->  21.20%\n","Current batch: Loss-> 1.1320, Train accuracy->  21.27%\n","Current batch: Loss-> 1.2303, Train accuracy->  21.36%\n","Current batch: Loss-> 1.0948, Train accuracy->  21.44%\n","Current batch: Loss-> 1.2081, Train accuracy->  21.51%\n","Current batch: Loss-> 1.2048, Train accuracy->  21.58%\n","Current batch: Loss-> 1.3474, Train accuracy->  21.64%\n","Current batch: Loss-> 1.2238, Train accuracy->  21.70%\n","Current batch: Loss-> 1.1165, Train accuracy->  21.78%\n","Current batch: Loss-> 1.2495, Train accuracy->  21.85%\n","Current batch: Loss-> 1.1102, Train accuracy->  21.92%\n","Current batch: Loss-> 1.3839, Train accuracy->  21.97%\n","Current batch: Loss-> 1.2842, Train accuracy->  22.04%\n","Current batch: Loss-> 1.1641, Train accuracy->  22.10%\n","Current batch: Loss-> 1.1468, Train accuracy->  22.18%\n","Current batch: Loss-> 0.8830, Train accuracy->  22.27%\n","Current batch: Loss-> 1.1834, Train accuracy->  22.35%\n","Current batch: Loss-> 1.1578, Train accuracy->  22.41%\n","Current batch: Loss-> 1.1162, Train accuracy->  22.47%\n","Current batch: Loss-> 1.0192, Train accuracy->  22.55%\n","Current batch: Loss-> 1.0933, Train accuracy->  22.63%\n","Current batch: Loss-> 1.3709, Train accuracy->  22.70%\n","Current batch: Loss-> 1.2705, Train accuracy->  22.77%\n","Current batch: Loss-> 1.0949, Train accuracy->  22.85%\n","Current batch: Loss-> 1.1482, Train accuracy->  22.92%\n","Current batch: Loss-> 1.5010, Train accuracy->  22.98%\n","Current batch: Loss-> 1.2777, Train accuracy->  23.04%\n","Current batch: Loss-> 1.2155, Train accuracy->  23.10%\n","Current batch: Loss-> 1.2098, Train accuracy->  23.16%\n","Current batch: Loss-> 1.1650, Train accuracy->  23.24%\n","Current batch: Loss-> 1.1948, Train accuracy->  23.30%\n","Current batch: Loss-> 1.0000, Train accuracy->  23.38%\n","Current batch: Loss-> 1.2302, Train accuracy->  23.45%\n","Current batch: Loss-> 1.2943, Train accuracy->  23.52%\n","Current batch: Loss-> 1.2530, Train accuracy->  23.59%\n","Current batch: Loss-> 1.1076, Train accuracy->  23.65%\n","Current batch: Loss-> 1.3124, Train accuracy->  23.71%\n","Current batch: Loss-> 1.3665, Train accuracy->  23.78%\n","Current batch: Loss-> 1.0790, Train accuracy->  23.86%\n","Current batch: Loss-> 1.1717, Train accuracy->  23.93%\n","Current batch: Loss-> 1.1039, Train accuracy->  24.01%\n","Current batch: Loss-> 1.0725, Train accuracy->  24.08%\n","Current batch: Loss-> 1.2632, Train accuracy->  24.14%\n","Current batch: Loss-> 1.3448, Train accuracy->  24.21%\n","Current batch: Loss-> 1.1622, Train accuracy->  24.28%\n","Current batch: Loss-> 1.2663, Train accuracy->  24.35%\n","Current batch: Loss-> 1.1201, Train accuracy->  24.42%\n","Current batch: Loss-> 1.1441, Train accuracy->  24.49%\n","Current batch: Loss-> 1.2401, Train accuracy->  24.55%\n","Current batch: Loss-> 0.9989, Train accuracy->  24.64%\n","Current batch: Loss-> 1.2897, Train accuracy->  24.70%\n","Current batch: Loss-> 1.2242, Train accuracy->  24.77%\n","Current batch: Loss-> 0.9993, Train accuracy->  24.84%\n","Current batch: Loss-> 1.3406, Train accuracy->  24.91%\n","Current batch: Loss-> 1.0434, Train accuracy->  25.00%\n","Current batch: Loss-> 1.1310, Train accuracy->  25.06%\n","Current batch: Loss-> 1.4432, Train accuracy->  25.12%\n","Current batch: Loss-> 1.2337, Train accuracy->  25.19%\n","Current batch: Loss-> 1.0864, Train accuracy->  25.26%\n","Current batch: Loss-> 1.2878, Train accuracy->  25.34%\n","Current batch: Loss-> 1.2260, Train accuracy->  25.40%\n","Current batch: Loss-> 1.1047, Train accuracy->  25.48%\n","Current batch: Loss-> 1.3509, Train accuracy->  25.54%\n","Current batch: Loss-> 1.2372, Train accuracy->  25.59%\n","Current batch: Loss-> 1.5671, Train accuracy->  25.65%\n","Current batch: Loss-> 1.0945, Train accuracy->  25.72%\n","Current batch: Loss-> 1.4963, Train accuracy->  25.79%\n","Current batch: Loss-> 1.3238, Train accuracy->  25.86%\n","Current batch: Loss-> 1.2338, Train accuracy->  25.93%\n","Current batch: Loss-> 1.2183, Train accuracy->  25.99%\n","Current batch: Loss-> 1.3961, Train accuracy->  26.05%\n","Current batch: Loss-> 1.0388, Train accuracy->  26.12%\n","Current batch: Loss-> 1.1992, Train accuracy->  26.20%\n","Current batch: Loss-> 1.3454, Train accuracy->  26.27%\n","Current batch: Loss-> 1.1549, Train accuracy->  26.33%\n","Current batch: Loss-> 1.3315, Train accuracy->  26.38%\n","Current batch: Loss-> 1.3157, Train accuracy->  26.44%\n","Current batch: Loss-> 1.1490, Train accuracy->  26.49%\n","Current batch: Loss-> 1.0993, Train accuracy->  26.57%\n","Current batch: Loss-> 1.4164, Train accuracy->  26.62%\n","Current batch: Loss-> 1.3183, Train accuracy->  26.67%\n","Current batch: Loss-> 1.1641, Train accuracy->  26.75%\n","Current batch: Loss-> 1.3678, Train accuracy->  26.82%\n","Current batch: Loss-> 1.5271, Train accuracy->  26.86%\n","Current batch: Loss-> 1.3159, Train accuracy->  26.91%\n","Current batch: Loss-> 1.0777, Train accuracy->  26.98%\n","Current batch: Loss-> 1.5160, Train accuracy->  27.03%\n","Current batch: Loss-> 1.2586, Train accuracy->  27.11%\n","Current batch: Loss-> 1.2364, Train accuracy->  27.18%\n","Current batch: Loss-> 1.1806, Train accuracy->  27.25%\n","Current batch: Loss-> 1.1302, Train accuracy->  27.32%\n","Current batch: Loss-> 1.1977, Train accuracy->  27.40%\n","Current batch: Loss-> 1.0751, Train accuracy->  27.48%\n","Current batch: Loss-> 1.0524, Train accuracy->  27.55%\n","Current batch: Loss-> 1.0760, Train accuracy->  27.63%\n","Current batch: Loss-> 1.5216, Train accuracy->  27.68%\n","Current batch: Loss-> 1.0336, Train accuracy->  27.76%\n","Current batch: Loss-> 1.2360, Train accuracy->  27.83%\n","Current batch: Loss-> 0.9985, Train accuracy->  27.90%\n","Current batch: Loss-> 1.3141, Train accuracy->  27.96%\n","Current batch: Loss-> 1.1543, Train accuracy->  28.02%\n","Current batch: Loss-> 0.9384, Train accuracy->  28.10%\n","Current batch: Loss-> 1.1579, Train accuracy->  28.17%\n","Current batch: Loss-> 1.0867, Train accuracy->  28.25%\n","Current batch: Loss-> 1.1188, Train accuracy->  28.33%\n","Current batch: Loss-> 1.1377, Train accuracy->  28.41%\n","Current batch: Loss-> 1.1898, Train accuracy->  28.48%\n","Current batch: Loss-> 1.2038, Train accuracy->  28.55%\n","Current batch: Loss-> 1.1523, Train accuracy->  28.63%\n","Current batch: Loss-> 1.0726, Train accuracy->  28.70%\n","Current batch: Loss-> 1.1596, Train accuracy->  28.78%\n","Current batch: Loss-> 1.0998, Train accuracy->  28.85%\n","Current batch: Loss-> 1.4351, Train accuracy->  28.91%\n","Current batch: Loss-> 1.2777, Train accuracy->  28.98%\n","Current batch: Loss-> 1.0096, Train accuracy->  29.05%\n","Current batch: Loss-> 1.4641, Train accuracy->  29.11%\n","Current batch: Loss-> 1.2442, Train accuracy->  29.19%\n","Current batch: Loss-> 1.1751, Train accuracy->  29.25%\n","Current batch: Loss-> 1.3136, Train accuracy->  29.32%\n","Current batch: Loss-> 1.1845, Train accuracy->  29.39%\n","Current batch: Loss-> 1.1118, Train accuracy->  29.46%\n","Current batch: Loss-> 1.1835, Train accuracy->  29.53%\n","Current batch: Loss-> 1.1421, Train accuracy->  29.61%\n","Current batch: Loss-> 1.0483, Train accuracy->  29.69%\n","Current batch: Loss-> 1.0455, Train accuracy->  29.77%\n","Current batch: Loss-> 1.4720, Train accuracy->  29.82%\n","Current batch: Loss-> 1.2940, Train accuracy->  29.89%\n","Current batch: Loss-> 1.2640, Train accuracy->  29.96%\n","Current batch: Loss-> 1.3075, Train accuracy->  30.03%\n","Current batch: Loss-> 1.2510, Train accuracy->  30.11%\n","Current batch: Loss-> 1.3451, Train accuracy->  30.17%\n","Current batch: Loss-> 1.5028, Train accuracy->  30.23%\n","Current batch: Loss-> 1.2942, Train accuracy->  30.29%\n","Current batch: Loss-> 1.2165, Train accuracy->  30.37%\n","Current batch: Loss-> 1.1591, Train accuracy->  30.44%\n","Current batch: Loss-> 1.1173, Train accuracy->  30.51%\n","Current batch: Loss-> 1.3002, Train accuracy->  30.59%\n","Current batch: Loss-> 1.1027, Train accuracy->  30.67%\n","Current batch: Loss-> 1.2197, Train accuracy->  30.73%\n","Current batch: Loss-> 1.3309, Train accuracy->  30.79%\n","Current batch: Loss-> 1.1827, Train accuracy->  30.86%\n","Current batch: Loss-> 1.3336, Train accuracy->  30.93%\n","Current batch: Loss-> 1.0500, Train accuracy->  31.01%\n","Current batch: Loss-> 1.4245, Train accuracy->  31.07%\n","Current batch: Loss-> 1.2315, Train accuracy->  31.13%\n","Current batch: Loss-> 1.2072, Train accuracy->  31.20%\n","Current batch: Loss-> 1.2245, Train accuracy->  31.26%\n","Current batch: Loss-> 1.0137, Train accuracy->  31.35%\n","Current batch: Loss-> 1.2246, Train accuracy->  31.42%\n","Current batch: Loss-> 1.1658, Train accuracy->  31.49%\n","Current batch: Loss-> 1.1416, Train accuracy->  31.57%\n","Current batch: Loss-> 1.1453, Train accuracy->  31.64%\n","Current batch: Loss-> 1.2341, Train accuracy->  31.71%\n","Current batch: Loss-> 1.2164, Train accuracy->  31.79%\n","Current batch: Loss-> 0.9894, Train accuracy->  31.86%\n","Current batch: Loss-> 1.3322, Train accuracy->  31.93%\n","Current batch: Loss-> 0.9952, Train accuracy->  32.01%\n","Current batch: Loss-> 1.2474, Train accuracy->  32.08%\n","Current batch: Loss-> 1.2393, Train accuracy->  32.15%\n","Current batch: Loss-> 1.2448, Train accuracy->  32.21%\n","Current batch: Loss-> 1.2302, Train accuracy->  32.28%\n","Current batch: Loss-> 1.1549, Train accuracy->  32.36%\n","Current batch: Loss-> 0.9812, Train accuracy->  32.43%\n","Current batch: Loss-> 1.0946, Train accuracy->  32.52%\n","Current batch: Loss-> 1.0729, Train accuracy->  32.59%\n","Current batch: Loss-> 1.0621, Train accuracy->  32.68%\n","Current batch: Loss-> 1.0879, Train accuracy->  32.76%\n","Current batch: Loss-> 1.2220, Train accuracy->  32.82%\n","Current batch: Loss-> 1.4390, Train accuracy->  32.89%\n","Current batch: Loss-> 1.4267, Train accuracy->  32.93%\n","Current batch: Loss-> 1.0889, Train accuracy->  33.01%\n","Current batch: Loss-> 1.0196, Train accuracy->  33.09%\n","Current batch: Loss-> 1.2163, Train accuracy->  33.17%\n","Current batch: Loss-> 1.3609, Train accuracy->  33.23%\n","Current batch: Loss-> 1.1207, Train accuracy->  33.32%\n","Current batch: Loss-> 1.2114, Train accuracy->  33.38%\n","Current batch: Loss-> 1.1236, Train accuracy->  33.47%\n","Current batch: Loss-> 1.2660, Train accuracy->  33.54%\n","Current batch: Loss-> 1.0289, Train accuracy->  33.63%\n","Current batch: Loss-> 1.0228, Train accuracy->  33.71%\n","Current batch: Loss-> 1.4980, Train accuracy->  33.78%\n","Current batch: Loss-> 1.2187, Train accuracy->  33.84%\n","Current batch: Loss-> 1.1694, Train accuracy->  33.91%\n","Current batch: Loss-> 1.2701, Train accuracy->  33.99%\n","Current batch: Loss-> 1.4212, Train accuracy->  34.05%\n","Current batch: Loss-> 1.4683, Train accuracy->  34.11%\n","Current batch: Loss-> 1.0531, Train accuracy->  34.20%\n","Current batch: Loss-> 1.2318, Train accuracy->  34.26%\n","Current batch: Loss-> 1.2070, Train accuracy->  34.34%\n","Current batch: Loss-> 1.4106, Train accuracy->  34.40%\n","Current batch: Loss-> 1.6838, Train accuracy->  34.44%\n","Current batch: Loss-> 1.4844, Train accuracy->  34.50%\n","Current batch: Loss-> 1.1732, Train accuracy->  34.59%\n","Current batch: Loss-> 1.3519, Train accuracy->  34.64%\n","Current batch: Loss-> 1.1922, Train accuracy->  34.71%\n","Current batch: Loss-> 1.1610, Train accuracy->  34.80%\n","Current batch: Loss-> 1.0109, Train accuracy->  34.88%\n","Current batch: Loss-> 1.2151, Train accuracy->  34.95%\n","Current batch: Loss-> 1.1878, Train accuracy->  35.03%\n","Current batch: Loss-> 1.0747, Train accuracy->  35.10%\n","Current batch: Loss-> 1.2432, Train accuracy->  35.16%\n","Current batch: Loss-> 1.3164, Train accuracy->  35.24%\n","Current batch: Loss-> 1.2395, Train accuracy->  35.30%\n","Current batch: Loss-> 1.0961, Train accuracy->  35.38%\n","Current batch: Loss-> 1.1319, Train accuracy->  35.44%\n","Current batch: Loss-> 0.9380, Train accuracy->  35.52%\n","Current batch: Loss-> 1.0818, Train accuracy->  35.60%\n","Current batch: Loss-> 1.4302, Train accuracy->  35.65%\n","Current batch: Loss-> 1.2694, Train accuracy->  35.71%\n","Current batch: Loss-> 1.2902, Train accuracy->  35.79%\n","Current batch: Loss-> 1.1903, Train accuracy->  35.87%\n","Current batch: Loss-> 1.1221, Train accuracy->  35.95%\n","Current batch: Loss-> 1.0737, Train accuracy->  36.02%\n","Current batch: Loss-> 1.0587, Train accuracy->  36.12%\n","Current batch: Loss-> 1.1428, Train accuracy->  36.18%\n","Current batch: Loss-> 1.2584, Train accuracy->  36.25%\n","Current batch: Loss-> 1.4532, Train accuracy->  36.32%\n","Current batch: Loss-> 1.1923, Train accuracy->  36.39%\n","Current batch: Loss-> 1.5839, Train accuracy->  36.44%\n","Current batch: Loss-> 1.2462, Train accuracy->  36.49%\n","Current batch: Loss-> 0.9065, Train accuracy->  36.59%\n","Current batch: Loss-> 1.1430, Train accuracy->  36.66%\n","Current batch: Loss-> 0.9745, Train accuracy->  36.75%\n","Current batch: Loss-> 1.3744, Train accuracy->  36.81%\n","Current batch: Loss-> 1.2409, Train accuracy->  36.88%\n","Current batch: Loss-> 1.2588, Train accuracy->  36.95%\n","Current batch: Loss-> 1.2938, Train accuracy->  37.01%\n","Current batch: Loss-> 1.0815, Train accuracy->  37.10%\n","Current batch: Loss-> 1.2086, Train accuracy->  37.17%\n","Current batch: Loss-> 1.0814, Train accuracy->  37.26%\n","Current batch: Loss-> 1.3681, Train accuracy->  37.33%\n","Current batch: Loss-> 1.1937, Train accuracy->  37.40%\n","Current batch: Loss-> 1.1644, Train accuracy->  37.47%\n","Current batch: Loss-> 1.1616, Train accuracy->  37.54%\n","Current batch: Loss-> 1.2404, Train accuracy->  37.61%\n","Current batch: Loss-> 1.2312, Train accuracy->  37.69%\n","Current batch: Loss-> 1.1273, Train accuracy->  37.77%\n","Current batch: Loss-> 1.2788, Train accuracy->  37.82%\n","Current batch: Loss-> 1.3693, Train accuracy->  37.88%\n","Current batch: Loss-> 1.2378, Train accuracy->  37.95%\n","Current batch: Loss-> 1.2189, Train accuracy->  38.03%\n","Current batch: Loss-> 1.3230, Train accuracy->  38.09%\n","Current batch: Loss-> 1.2578, Train accuracy->  38.16%\n","Current batch: Loss-> 1.2984, Train accuracy->  38.21%\n","Current batch: Loss-> 1.1146, Train accuracy->  38.29%\n","Current batch: Loss-> 1.1546, Train accuracy->  38.36%\n","Current batch: Loss-> 1.2583, Train accuracy->  38.43%\n","Current batch: Loss-> 1.2277, Train accuracy->  38.49%\n","Current batch: Loss-> 1.3202, Train accuracy->  38.56%\n","Current batch: Loss-> 1.3160, Train accuracy->  38.62%\n","Current batch: Loss-> 1.1587, Train accuracy->  38.69%\n","Current batch: Loss-> 1.1989, Train accuracy->  38.77%\n","Current batch: Loss-> 1.0349, Train accuracy->  38.85%\n","Current batch: Loss-> 1.0756, Train accuracy->  38.92%\n","Current batch: Loss-> 1.1739, Train accuracy->  39.00%\n","Current batch: Loss-> 0.9098, Train accuracy->  39.08%\n","Current batch: Loss-> 1.0778, Train accuracy->  39.16%\n","Current batch: Loss-> 1.0189, Train accuracy->  39.22%\n","Current batch: Loss-> 1.2887, Train accuracy->  39.30%\n","Current batch: Loss-> 1.2879, Train accuracy->  39.36%\n","Current batch: Loss-> 1.2012, Train accuracy->  39.43%\n","Current batch: Loss-> 1.2699, Train accuracy->  39.50%\n","Current batch: Loss-> 1.0318, Train accuracy->  39.58%\n","Current batch: Loss-> 1.1070, Train accuracy->  39.66%\n","Current batch: Loss-> 1.3631, Train accuracy->  39.72%\n","Current batch: Loss-> 1.1391, Train accuracy->  39.79%\n","Current batch: Loss-> 1.0908, Train accuracy->  39.87%\n","Current batch: Loss-> 1.1605, Train accuracy->  39.96%\n","Current batch: Loss-> 1.3565, Train accuracy->  40.03%\n","Current batch: Loss-> 1.1826, Train accuracy->  40.10%\n","Current batch: Loss-> 1.1406, Train accuracy->  40.18%\n","Current batch: Loss-> 1.1108, Train accuracy->  40.26%\n","Current batch: Loss-> 1.0497, Train accuracy->  40.35%\n","Current batch: Loss-> 1.3578, Train accuracy->  40.42%\n","Current batch: Loss-> 1.0220, Train accuracy->  40.50%\n","Current batch: Loss-> 1.3143, Train accuracy->  40.57%\n","Current batch: Loss-> 1.1846, Train accuracy->  40.65%\n","Current batch: Loss-> 1.3322, Train accuracy->  40.71%\n","Current batch: Loss-> 1.2090, Train accuracy->  40.79%\n","Current batch: Loss-> 1.2443, Train accuracy->  40.85%\n","Current batch: Loss-> 1.1227, Train accuracy->  40.92%\n","Current batch: Loss-> 1.1924, Train accuracy->  40.99%\n","Current batch: Loss-> 1.1092, Train accuracy->  41.06%\n","Current batch: Loss-> 1.2879, Train accuracy->  41.12%\n","Current batch: Loss-> 1.3891, Train accuracy->  41.19%\n","Current batch: Loss-> 1.4009, Train accuracy->  41.25%\n","Current batch: Loss-> 1.0634, Train accuracy->  41.32%\n","Current batch: Loss-> 0.9371, Train accuracy->  41.40%\n","Current batch: Loss-> 1.3077, Train accuracy->  41.47%\n","Current batch: Loss-> 1.3357, Train accuracy->  41.54%\n","Current batch: Loss-> 1.3399, Train accuracy->  41.59%\n","Current batch: Loss-> 1.1066, Train accuracy->  41.65%\n","Current batch: Loss-> 1.3286, Train accuracy->  41.71%\n","Current batch: Loss-> 1.2179, Train accuracy->  41.77%\n","Current batch: Loss-> 1.3627, Train accuracy->  41.84%\n","Current batch: Loss-> 1.0186, Train accuracy->  41.92%\n","Current batch: Loss-> 1.0011, Train accuracy->  42.00%\n","Current batch: Loss-> 1.3190, Train accuracy->  42.08%\n","Current batch: Loss-> 1.0088, Train accuracy->  42.16%\n","Current batch: Loss-> 1.2278, Train accuracy->  42.23%\n","Current batch: Loss-> 1.3691, Train accuracy->  42.30%\n","Current batch: Loss-> 1.4580, Train accuracy->  42.36%\n","Current batch: Loss-> 1.3279, Train accuracy->  42.42%\n","Current batch: Loss-> 1.0390, Train accuracy->  42.49%\n","Current batch: Loss-> 1.3303, Train accuracy->  42.55%\n","Current batch: Loss-> 1.3578, Train accuracy->  42.62%\n","Current batch: Loss-> 1.3205, Train accuracy->  42.68%\n","Current batch: Loss-> 1.4021, Train accuracy->  42.74%\n","Current batch: Loss-> 1.1278, Train accuracy->  42.80%\n","Current batch: Loss-> 1.3137, Train accuracy->  42.86%\n","Current batch: Loss-> 1.1517, Train accuracy->  42.91%\n","Current batch: Loss-> 1.1550, Train accuracy->  42.98%\n","Current batch: Loss-> 1.3963, Train accuracy->  43.03%\n","Current batch: Loss-> 1.2230, Train accuracy->  43.10%\n","Current batch: Loss-> 1.0197, Train accuracy->  43.19%\n","Current batch: Loss-> 1.0309, Train accuracy->  43.26%\n","Current batch: Loss-> 1.0453, Train accuracy->  43.34%\n","Current batch: Loss-> 1.1889, Train accuracy->  43.41%\n","Current batch: Loss-> 1.3486, Train accuracy->  43.49%\n","Current batch: Loss-> 1.1823, Train accuracy->  43.55%\n","Current batch: Loss-> 1.6233, Train accuracy->  43.59%\n","Current batch: Loss-> 1.1514, Train accuracy->  43.66%\n","Current batch: Loss-> 0.9909, Train accuracy->  43.75%\n","Current batch: Loss-> 1.0313, Train accuracy->  43.83%\n","Current batch: Loss-> 1.3961, Train accuracy->  43.89%\n","Current batch: Loss-> 1.1362, Train accuracy->  43.95%\n","Current batch: Loss-> 1.4115, Train accuracy->  44.02%\n","Current batch: Loss-> 1.1468, Train accuracy->  44.09%\n","Current batch: Loss-> 1.3415, Train accuracy->  44.15%\n","Current batch: Loss-> 1.2123, Train accuracy->  44.21%\n","Current batch: Loss-> 1.3290, Train accuracy->  44.29%\n","Current batch: Loss-> 1.3106, Train accuracy->  44.36%\n","Current batch: Loss-> 1.1879, Train accuracy->  44.44%\n","Current batch: Loss-> 1.2657, Train accuracy->  44.50%\n","Current batch: Loss-> 1.0804, Train accuracy->  44.58%\n","Current batch: Loss-> 1.2874, Train accuracy->  44.63%\n","Current batch: Loss-> 1.1771, Train accuracy->  44.70%\n","Current batch: Loss-> 1.3078, Train accuracy->  44.78%\n","Current batch: Loss-> 1.4217, Train accuracy->  44.84%\n","Current batch: Loss-> 1.2394, Train accuracy->  44.91%\n","Current batch: Loss-> 1.3013, Train accuracy->  44.98%\n","Current batch: Loss-> 1.2658, Train accuracy->  45.04%\n","Current batch: Loss-> 1.2440, Train accuracy->  45.11%\n","Current batch: Loss-> 1.2804, Train accuracy->  45.18%\n","Current batch: Loss-> 1.3077, Train accuracy->  45.25%\n","Current batch: Loss-> 1.2576, Train accuracy->  45.33%\n","Current batch: Loss-> 1.2109, Train accuracy->  45.39%\n","Current batch: Loss-> 1.1697, Train accuracy->  45.46%\n","Current batch: Loss-> 1.2758, Train accuracy->  45.52%\n","Current batch: Loss-> 1.0608, Train accuracy->  45.60%\n","Current batch: Loss-> 1.3154, Train accuracy->  45.66%\n","Current batch: Loss-> 0.9923, Train accuracy->  45.75%\n","Current batch: Loss-> 1.3407, Train accuracy->  45.81%\n","Current batch: Loss-> 1.0713, Train accuracy->  45.90%\n","Current batch: Loss-> 1.1139, Train accuracy->  45.97%\n","Current batch: Loss-> 1.0964, Train accuracy->  46.03%\n","Current batch: Loss-> 1.2855, Train accuracy->  46.12%\n","Current batch: Loss-> 1.0099, Train accuracy->  46.20%\n","Current batch: Loss-> 1.1607, Train accuracy->  46.29%\n","Current batch: Loss-> 1.1935, Train accuracy->  46.35%\n","Current batch: Loss-> 1.1122, Train accuracy->  46.44%\n","Current batch: Loss-> 1.0886, Train accuracy->  46.53%\n","Current batch: Loss-> 1.1903, Train accuracy->  46.60%\n","Current batch: Loss-> 1.0978, Train accuracy->  46.69%\n","Current batch: Loss-> 0.9595, Train accuracy->  46.77%\n","Current batch: Loss-> 1.1954, Train accuracy->  46.85%\n","Current batch: Loss-> 1.1469, Train accuracy->  46.94%\n","Current batch: Loss-> 1.3828, Train accuracy->  47.01%\n","Current batch: Loss-> 1.2510, Train accuracy->  47.08%\n","Current batch: Loss-> 1.1995, Train accuracy->  47.16%\n","Current batch: Loss-> 1.1986, Train accuracy->  47.23%\n","Current batch: Loss-> 1.3637, Train accuracy->  47.29%\n","Current batch: Loss-> 1.1598, Train accuracy->  47.36%\n","Current batch: Loss-> 0.9990, Train accuracy->  47.45%\n","Current batch: Loss-> 1.1354, Train accuracy->  47.52%\n","Current batch: Loss-> 1.1255, Train accuracy->  47.60%\n","Current batch: Loss-> 1.4280, Train accuracy->  47.64%\n","Current batch: Loss-> 1.1033, Train accuracy->  47.71%\n","Current batch: Loss-> 1.1415, Train accuracy->  47.79%\n","Current batch: Loss-> 1.2990, Train accuracy->  47.87%\n","Current batch: Loss-> 1.2950, Train accuracy->  47.94%\n","Current batch: Loss-> 1.0800, Train accuracy->  48.02%\n","Current batch: Loss-> 1.1686, Train accuracy->  48.10%\n","Current batch: Loss-> 1.2474, Train accuracy->  48.17%\n","Current batch: Loss-> 1.0653, Train accuracy->  48.25%\n","Current batch: Loss-> 1.0462, Train accuracy->  48.33%\n","Current batch: Loss-> 1.0552, Train accuracy->  48.41%\n","Current batch: Loss-> 1.2178, Train accuracy->  48.47%\n","Current batch: Loss-> 1.2128, Train accuracy->  48.54%\n","Current batch: Loss-> 1.3425, Train accuracy->  48.60%\n","Current batch: Loss-> 1.1460, Train accuracy->  48.66%\n","Current batch: Loss-> 1.0350, Train accuracy->  48.74%\n","Current batch: Loss-> 0.9877, Train accuracy->  48.81%\n","Current batch: Loss-> 1.5426, Train accuracy->  48.88%\n","Current batch: Loss-> 1.2418, Train accuracy->  48.95%\n","Current batch: Loss-> 1.1280, Train accuracy->  49.01%\n","Current batch: Loss-> 1.3042, Train accuracy->  49.09%\n","Current batch: Loss-> 1.0868, Train accuracy->  49.17%\n","Current batch: Loss-> 1.2525, Train accuracy->  49.24%\n","Current batch: Loss-> 1.0169, Train accuracy->  49.32%\n","Current batch: Loss-> 1.3760, Train accuracy->  49.39%\n","Current batch: Loss-> 1.2987, Train accuracy->  49.47%\n","Current batch: Loss-> 1.0783, Train accuracy->  49.54%\n","Current batch: Loss-> 1.1875, Train accuracy->  49.60%\n","Current batch: Loss-> 1.2636, Train accuracy->  49.67%\n","Current batch: Loss-> 1.2535, Train accuracy->  49.74%\n","Current batch: Loss-> 1.2196, Train accuracy->  49.82%\n","Current batch: Loss-> 1.2790, Train accuracy->  49.89%\n","Current batch: Loss-> 1.2850, Train accuracy->  49.96%\n","Current batch: Loss-> 1.0639, Train accuracy->  50.05%\n","Current batch: Loss-> 1.2117, Train accuracy->  50.11%\n","Current batch: Loss-> 1.6237, Train accuracy->  50.15%\n","Current batch: Loss-> 1.2633, Train accuracy->  50.21%\n","Current batch: Loss-> 1.1245, Train accuracy->  50.30%\n","Current batch: Loss-> 1.4250, Train accuracy->  50.38%\n","Current batch: Loss-> 1.1530, Train accuracy->  50.45%\n","Current batch: Loss-> 1.1749, Train accuracy->  50.52%\n","Current batch: Loss-> 1.2372, Train accuracy->  50.59%\n","Current batch: Loss-> 1.1135, Train accuracy->  50.67%\n","Current batch: Loss-> 1.1321, Train accuracy->  50.75%\n","Current batch: Loss-> 1.0896, Train accuracy->  50.81%\n","Current batch: Loss-> 1.3733, Train accuracy->  50.87%\n","Current batch: Loss-> 0.9900, Train accuracy->  50.94%\n","Current batch: Loss-> 0.9857, Train accuracy->  51.01%\n","Current batch: Loss-> 1.1459, Train accuracy->  51.09%\n","Current batch: Loss-> 1.0378, Train accuracy->  51.17%\n","Current batch: Loss-> 1.1571, Train accuracy->  51.25%\n","Current batch: Loss-> 1.3702, Train accuracy->  51.31%\n","Current batch: Loss-> 1.2908, Train accuracy->  51.37%\n","Current batch: Loss-> 1.2869, Train accuracy->  51.43%\n","Current batch: Loss-> 1.3006, Train accuracy->  51.49%\n","Current batch: Loss-> 1.2915, Train accuracy->  51.54%\n","Current batch: Loss-> 1.1135, Train accuracy->  51.61%\n","Current batch: Loss-> 1.2351, Train accuracy->  51.67%\n","Current batch: Loss-> 0.9014, Train accuracy->  51.76%\n","Current batch: Loss-> 1.1586, Train accuracy->  51.83%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 47.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.0821, Train accuracy->  51.91%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.10it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.7899, Accuracy: 3656/12000 (30%)\n","\n","Current batch: Loss-> 1.2960, Train accuracy->   0.07%\n","Current batch: Loss-> 1.0818, Train accuracy->   0.15%\n","Current batch: Loss-> 1.1798, Train accuracy->   0.24%\n","Current batch: Loss-> 1.2585, Train accuracy->   0.32%\n","Current batch: Loss-> 1.2438, Train accuracy->   0.39%\n","Current batch: Loss-> 1.3014, Train accuracy->   0.46%\n","Current batch: Loss-> 1.3129, Train accuracy->   0.52%\n","Current batch: Loss-> 1.0471, Train accuracy->   0.59%\n","Current batch: Loss-> 1.3355, Train accuracy->   0.65%\n","Current batch: Loss-> 1.2049, Train accuracy->   0.72%\n","Current batch: Loss-> 1.0440, Train accuracy->   0.81%\n","Current batch: Loss-> 1.2007, Train accuracy->   0.88%\n","Current batch: Loss-> 1.2168, Train accuracy->   0.95%\n","Current batch: Loss-> 1.5488, Train accuracy->   1.00%\n","Current batch: Loss-> 1.4664, Train accuracy->   1.08%\n","Current batch: Loss-> 1.0201, Train accuracy->   1.16%\n","Current batch: Loss-> 1.0576, Train accuracy->   1.23%\n","Current batch: Loss-> 1.1656, Train accuracy->   1.30%\n","Current batch: Loss-> 1.0960, Train accuracy->   1.38%\n","Current batch: Loss-> 1.2737, Train accuracy->   1.44%\n","Current batch: Loss-> 1.2593, Train accuracy->   1.51%\n","Current batch: Loss-> 1.1639, Train accuracy->   1.59%\n","Current batch: Loss-> 1.2271, Train accuracy->   1.66%\n","Current batch: Loss-> 1.2314, Train accuracy->   1.72%\n","Current batch: Loss-> 1.2465, Train accuracy->   1.78%\n","Current batch: Loss-> 1.1933, Train accuracy->   1.84%\n","Current batch: Loss-> 0.8969, Train accuracy->   1.93%\n","Current batch: Loss-> 1.3442, Train accuracy->   2.00%\n","Current batch: Loss-> 1.1108, Train accuracy->   2.07%\n","Current batch: Loss-> 1.4027, Train accuracy->   2.12%\n","Current batch: Loss-> 1.3450, Train accuracy->   2.20%\n","Current batch: Loss-> 1.2778, Train accuracy->   2.26%\n","Current batch: Loss-> 1.1074, Train accuracy->   2.33%\n","Current batch: Loss-> 1.2102, Train accuracy->   2.40%\n","Current batch: Loss-> 1.0749, Train accuracy->   2.46%\n","Current batch: Loss-> 1.0604, Train accuracy->   2.55%\n","Current batch: Loss-> 1.0508, Train accuracy->   2.64%\n","Current batch: Loss-> 1.0886, Train accuracy->   2.72%\n","Current batch: Loss-> 1.1620, Train accuracy->   2.79%\n","Current batch: Loss-> 1.1421, Train accuracy->   2.86%\n","Current batch: Loss-> 1.3435, Train accuracy->   2.92%\n","Current batch: Loss-> 1.1306, Train accuracy->   2.99%\n","Current batch: Loss-> 1.3545, Train accuracy->   3.05%\n","Current batch: Loss-> 1.1488, Train accuracy->   3.12%\n","Current batch: Loss-> 1.2134, Train accuracy->   3.19%\n","Current batch: Loss-> 1.1232, Train accuracy->   3.27%\n","Current batch: Loss-> 1.1894, Train accuracy->   3.35%\n","Current batch: Loss-> 1.1218, Train accuracy->   3.42%\n","Current batch: Loss-> 1.1947, Train accuracy->   3.50%\n","Current batch: Loss-> 1.2259, Train accuracy->   3.58%\n","Current batch: Loss-> 1.2290, Train accuracy->   3.64%\n","Current batch: Loss-> 1.3201, Train accuracy->   3.70%\n","Current batch: Loss-> 1.0144, Train accuracy->   3.78%\n","Current batch: Loss-> 1.0517, Train accuracy->   3.86%\n","Current batch: Loss-> 1.2863, Train accuracy->   3.93%\n","Current batch: Loss-> 1.2153, Train accuracy->   4.00%\n","Current batch: Loss-> 1.0611, Train accuracy->   4.08%\n","Current batch: Loss-> 1.3221, Train accuracy->   4.14%\n","Current batch: Loss-> 1.3902, Train accuracy->   4.21%\n","Current batch: Loss-> 1.0143, Train accuracy->   4.29%\n","Current batch: Loss-> 1.3293, Train accuracy->   4.37%\n","Current batch: Loss-> 1.0080, Train accuracy->   4.45%\n","Current batch: Loss-> 1.2336, Train accuracy->   4.51%\n","Current batch: Loss-> 1.0834, Train accuracy->   4.57%\n","Current batch: Loss-> 1.1609, Train accuracy->   4.64%\n","Current batch: Loss-> 1.1728, Train accuracy->   4.71%\n","Current batch: Loss-> 1.0114, Train accuracy->   4.79%\n","Current batch: Loss-> 1.1447, Train accuracy->   4.86%\n","Current batch: Loss-> 1.2932, Train accuracy->   4.93%\n","Current batch: Loss-> 0.9580, Train accuracy->   5.01%\n","Current batch: Loss-> 1.1203, Train accuracy->   5.07%\n","Current batch: Loss-> 1.4207, Train accuracy->   5.12%\n","Current batch: Loss-> 1.2069, Train accuracy->   5.20%\n","Current batch: Loss-> 1.2889, Train accuracy->   5.27%\n","Current batch: Loss-> 0.9311, Train accuracy->   5.35%\n","Current batch: Loss-> 1.2514, Train accuracy->   5.42%\n","Current batch: Loss-> 1.0728, Train accuracy->   5.49%\n","Current batch: Loss-> 1.1965, Train accuracy->   5.56%\n","Current batch: Loss-> 1.2139, Train accuracy->   5.63%\n","Current batch: Loss-> 1.2853, Train accuracy->   5.70%\n","Current batch: Loss-> 1.1436, Train accuracy->   5.76%\n","Current batch: Loss-> 1.0281, Train accuracy->   5.86%\n","Current batch: Loss-> 1.0153, Train accuracy->   5.94%\n","Current batch: Loss-> 0.9987, Train accuracy->   6.02%\n","Current batch: Loss-> 1.0719, Train accuracy->   6.10%\n","Current batch: Loss-> 1.1580, Train accuracy->   6.19%\n","Current batch: Loss-> 1.1882, Train accuracy->   6.25%\n","Current batch: Loss-> 1.4158, Train accuracy->   6.31%\n","Current batch: Loss-> 0.9840, Train accuracy->   6.40%\n","Current batch: Loss-> 1.4911, Train accuracy->   6.47%\n","Current batch: Loss-> 1.1357, Train accuracy->   6.56%\n","Current batch: Loss-> 1.1777, Train accuracy->   6.63%\n","Current batch: Loss-> 1.2329, Train accuracy->   6.70%\n","Current batch: Loss-> 1.0947, Train accuracy->   6.76%\n","Current batch: Loss-> 1.2617, Train accuracy->   6.83%\n","Current batch: Loss-> 1.0808, Train accuracy->   6.90%\n","Current batch: Loss-> 1.7561, Train accuracy->   6.95%\n","Current batch: Loss-> 1.1089, Train accuracy->   7.02%\n","Current batch: Loss-> 1.2172, Train accuracy->   7.08%\n","Current batch: Loss-> 1.3138, Train accuracy->   7.16%\n","Current batch: Loss-> 1.3816, Train accuracy->   7.22%\n","Current batch: Loss-> 1.1500, Train accuracy->   7.28%\n","Current batch: Loss-> 1.0393, Train accuracy->   7.36%\n","Current batch: Loss-> 1.3685, Train accuracy->   7.42%\n","Current batch: Loss-> 1.2861, Train accuracy->   7.48%\n","Current batch: Loss-> 1.2034, Train accuracy->   7.57%\n","Current batch: Loss-> 1.1522, Train accuracy->   7.65%\n","Current batch: Loss-> 1.2418, Train accuracy->   7.74%\n","Current batch: Loss-> 1.2201, Train accuracy->   7.81%\n","Current batch: Loss-> 1.2485, Train accuracy->   7.89%\n","Current batch: Loss-> 1.0829, Train accuracy->   7.98%\n","Current batch: Loss-> 1.0602, Train accuracy->   8.06%\n","Current batch: Loss-> 1.1431, Train accuracy->   8.13%\n","Current batch: Loss-> 0.9871, Train accuracy->   8.21%\n","Current batch: Loss-> 1.1834, Train accuracy->   8.29%\n","Current batch: Loss-> 1.0828, Train accuracy->   8.38%\n","Current batch: Loss-> 1.1925, Train accuracy->   8.44%\n","Current batch: Loss-> 1.2577, Train accuracy->   8.51%\n","Current batch: Loss-> 1.0144, Train accuracy->   8.59%\n","Current batch: Loss-> 0.9974, Train accuracy->   8.68%\n","Current batch: Loss-> 1.1527, Train accuracy->   8.75%\n","Current batch: Loss-> 1.3079, Train accuracy->   8.82%\n","Current batch: Loss-> 1.1841, Train accuracy->   8.89%\n","Current batch: Loss-> 1.1313, Train accuracy->   8.97%\n","Current batch: Loss-> 1.2613, Train accuracy->   9.04%\n","Current batch: Loss-> 0.9701, Train accuracy->   9.12%\n","Current batch: Loss-> 1.1475, Train accuracy->   9.20%\n","Current batch: Loss-> 0.9983, Train accuracy->   9.29%\n","Current batch: Loss-> 1.2138, Train accuracy->   9.35%\n","Current batch: Loss-> 1.1841, Train accuracy->   9.43%\n","Current batch: Loss-> 1.0990, Train accuracy->   9.52%\n","Current batch: Loss-> 1.1048, Train accuracy->   9.60%\n","Current batch: Loss-> 1.3316, Train accuracy->   9.65%\n","Current batch: Loss-> 1.1327, Train accuracy->   9.72%\n","Current batch: Loss-> 1.3090, Train accuracy->   9.78%\n","Current batch: Loss-> 1.2776, Train accuracy->   9.85%\n","Current batch: Loss-> 1.0541, Train accuracy->   9.94%\n","Current batch: Loss-> 1.1066, Train accuracy->  10.02%\n","Current batch: Loss-> 0.9390, Train accuracy->  10.10%\n","Current batch: Loss-> 1.3121, Train accuracy->  10.18%\n","Current batch: Loss-> 0.9729, Train accuracy->  10.27%\n","Current batch: Loss-> 1.2350, Train accuracy->  10.35%\n","Current batch: Loss-> 1.3102, Train accuracy->  10.41%\n","Current batch: Loss-> 1.4463, Train accuracy->  10.49%\n","Current batch: Loss-> 1.3433, Train accuracy->  10.57%\n","Current batch: Loss-> 1.0612, Train accuracy->  10.65%\n","Current batch: Loss-> 1.0930, Train accuracy->  10.73%\n","Current batch: Loss-> 0.9423, Train accuracy->  10.82%\n","Current batch: Loss-> 1.2617, Train accuracy->  10.89%\n","Current batch: Loss-> 0.8901, Train accuracy->  10.97%\n","Current batch: Loss-> 1.2830, Train accuracy->  11.03%\n","Current batch: Loss-> 1.0230, Train accuracy->  11.11%\n","Current batch: Loss-> 1.0438, Train accuracy->  11.18%\n","Current batch: Loss-> 0.8623, Train accuracy->  11.28%\n","Current batch: Loss-> 1.0705, Train accuracy->  11.37%\n","Current batch: Loss-> 1.2694, Train accuracy->  11.43%\n","Current batch: Loss-> 0.8730, Train accuracy->  11.52%\n","Current batch: Loss-> 1.2326, Train accuracy->  11.59%\n","Current batch: Loss-> 1.1470, Train accuracy->  11.66%\n","Current batch: Loss-> 1.2633, Train accuracy->  11.73%\n","Current batch: Loss-> 1.2539, Train accuracy->  11.79%\n","Current batch: Loss-> 1.0918, Train accuracy->  11.88%\n","Current batch: Loss-> 1.0877, Train accuracy->  11.95%\n","Current batch: Loss-> 1.0934, Train accuracy->  12.03%\n","Current batch: Loss-> 1.1609, Train accuracy->  12.11%\n","Current batch: Loss-> 1.0006, Train accuracy->  12.21%\n","Current batch: Loss-> 1.1372, Train accuracy->  12.28%\n","Current batch: Loss-> 1.0692, Train accuracy->  12.36%\n","Current batch: Loss-> 1.2403, Train accuracy->  12.45%\n","Current batch: Loss-> 1.1905, Train accuracy->  12.51%\n","Current batch: Loss-> 1.1873, Train accuracy->  12.58%\n","Current batch: Loss-> 1.1822, Train accuracy->  12.65%\n","Current batch: Loss-> 1.0734, Train accuracy->  12.75%\n","Current batch: Loss-> 1.0892, Train accuracy->  12.83%\n","Current batch: Loss-> 1.0218, Train accuracy->  12.92%\n","Current batch: Loss-> 1.0910, Train accuracy->  13.00%\n","Current batch: Loss-> 1.0585, Train accuracy->  13.07%\n","Current batch: Loss-> 1.1605, Train accuracy->  13.14%\n","Current batch: Loss-> 1.0901, Train accuracy->  13.22%\n","Current batch: Loss-> 1.1295, Train accuracy->  13.30%\n","Current batch: Loss-> 1.1143, Train accuracy->  13.37%\n","Current batch: Loss-> 1.1878, Train accuracy->  13.45%\n","Current batch: Loss-> 1.3763, Train accuracy->  13.52%\n","Current batch: Loss-> 1.4320, Train accuracy->  13.58%\n","Current batch: Loss-> 1.2242, Train accuracy->  13.67%\n","Current batch: Loss-> 1.0542, Train accuracy->  13.76%\n","Current batch: Loss-> 0.9049, Train accuracy->  13.85%\n","Current batch: Loss-> 1.0569, Train accuracy->  13.93%\n","Current batch: Loss-> 1.2955, Train accuracy->  14.00%\n","Current batch: Loss-> 1.0350, Train accuracy->  14.07%\n","Current batch: Loss-> 1.3424, Train accuracy->  14.14%\n","Current batch: Loss-> 1.1441, Train accuracy->  14.23%\n","Current batch: Loss-> 1.0954, Train accuracy->  14.31%\n","Current batch: Loss-> 1.1857, Train accuracy->  14.38%\n","Current batch: Loss-> 1.5771, Train accuracy->  14.42%\n","Current batch: Loss-> 1.2802, Train accuracy->  14.48%\n","Current batch: Loss-> 1.1704, Train accuracy->  14.56%\n","Current batch: Loss-> 1.2500, Train accuracy->  14.64%\n","Current batch: Loss-> 1.2533, Train accuracy->  14.71%\n","Current batch: Loss-> 1.0572, Train accuracy->  14.79%\n","Current batch: Loss-> 1.1910, Train accuracy->  14.86%\n","Current batch: Loss-> 1.2722, Train accuracy->  14.95%\n","Current batch: Loss-> 1.3302, Train accuracy->  15.02%\n","Current batch: Loss-> 1.2092, Train accuracy->  15.11%\n","Current batch: Loss-> 1.0507, Train accuracy->  15.19%\n","Current batch: Loss-> 1.0985, Train accuracy->  15.27%\n","Current batch: Loss-> 0.9935, Train accuracy->  15.36%\n","Current batch: Loss-> 1.1400, Train accuracy->  15.44%\n","Current batch: Loss-> 1.1610, Train accuracy->  15.52%\n","Current batch: Loss-> 1.2146, Train accuracy->  15.58%\n","Current batch: Loss-> 1.2535, Train accuracy->  15.64%\n","Current batch: Loss-> 1.0614, Train accuracy->  15.71%\n","Current batch: Loss-> 1.0459, Train accuracy->  15.80%\n","Current batch: Loss-> 1.1549, Train accuracy->  15.88%\n","Current batch: Loss-> 0.9673, Train accuracy->  15.97%\n","Current batch: Loss-> 0.9510, Train accuracy->  16.04%\n","Current batch: Loss-> 1.1523, Train accuracy->  16.12%\n","Current batch: Loss-> 1.2013, Train accuracy->  16.19%\n","Current batch: Loss-> 1.1245, Train accuracy->  16.26%\n","Current batch: Loss-> 0.9022, Train accuracy->  16.35%\n","Current batch: Loss-> 1.0388, Train accuracy->  16.43%\n","Current batch: Loss-> 1.2297, Train accuracy->  16.50%\n","Current batch: Loss-> 1.0398, Train accuracy->  16.59%\n","Current batch: Loss-> 1.2389, Train accuracy->  16.66%\n","Current batch: Loss-> 1.2446, Train accuracy->  16.73%\n","Current batch: Loss-> 1.1282, Train accuracy->  16.82%\n","Current batch: Loss-> 1.1934, Train accuracy->  16.91%\n","Current batch: Loss-> 1.3314, Train accuracy->  16.98%\n","Current batch: Loss-> 1.0305, Train accuracy->  17.06%\n","Current batch: Loss-> 1.1630, Train accuracy->  17.14%\n","Current batch: Loss-> 1.0665, Train accuracy->  17.22%\n","Current batch: Loss-> 0.9481, Train accuracy->  17.29%\n","Current batch: Loss-> 0.9857, Train accuracy->  17.38%\n","Current batch: Loss-> 1.2237, Train accuracy->  17.45%\n","Current batch: Loss-> 0.9910, Train accuracy->  17.53%\n","Current batch: Loss-> 1.3760, Train accuracy->  17.60%\n","Current batch: Loss-> 1.3205, Train accuracy->  17.65%\n","Current batch: Loss-> 1.1615, Train accuracy->  17.72%\n","Current batch: Loss-> 1.0825, Train accuracy->  17.79%\n","Current batch: Loss-> 1.0101, Train accuracy->  17.89%\n","Current batch: Loss-> 1.1005, Train accuracy->  17.96%\n","Current batch: Loss-> 1.0493, Train accuracy->  18.05%\n","Current batch: Loss-> 1.0230, Train accuracy->  18.14%\n","Current batch: Loss-> 1.3046, Train accuracy->  18.20%\n","Current batch: Loss-> 1.2041, Train accuracy->  18.26%\n","Current batch: Loss-> 1.1682, Train accuracy->  18.32%\n","Current batch: Loss-> 1.1992, Train accuracy->  18.39%\n","Current batch: Loss-> 1.1231, Train accuracy->  18.48%\n","Current batch: Loss-> 1.1743, Train accuracy->  18.54%\n","Current batch: Loss-> 1.2133, Train accuracy->  18.62%\n","Current batch: Loss-> 1.1632, Train accuracy->  18.70%\n","Current batch: Loss-> 0.8979, Train accuracy->  18.79%\n","Current batch: Loss-> 1.1504, Train accuracy->  18.86%\n","Current batch: Loss-> 1.1791, Train accuracy->  18.92%\n","Current batch: Loss-> 0.8535, Train accuracy->  19.01%\n","Current batch: Loss-> 1.0073, Train accuracy->  19.10%\n","Current batch: Loss-> 1.2105, Train accuracy->  19.16%\n","Current batch: Loss-> 1.0146, Train accuracy->  19.25%\n","Current batch: Loss-> 1.0722, Train accuracy->  19.33%\n","Current batch: Loss-> 1.1641, Train accuracy->  19.40%\n","Current batch: Loss-> 1.2141, Train accuracy->  19.47%\n","Current batch: Loss-> 1.3238, Train accuracy->  19.55%\n","Current batch: Loss-> 1.1847, Train accuracy->  19.62%\n","Current batch: Loss-> 0.9572, Train accuracy->  19.71%\n","Current batch: Loss-> 1.2643, Train accuracy->  19.78%\n","Current batch: Loss-> 1.3528, Train accuracy->  19.86%\n","Current batch: Loss-> 0.9678, Train accuracy->  19.94%\n","Current batch: Loss-> 1.3419, Train accuracy->  20.01%\n","Current batch: Loss-> 1.0689, Train accuracy->  20.09%\n","Current batch: Loss-> 1.3784, Train accuracy->  20.16%\n","Current batch: Loss-> 1.6951, Train accuracy->  20.22%\n","Current batch: Loss-> 1.1103, Train accuracy->  20.31%\n","Current batch: Loss-> 1.3524, Train accuracy->  20.38%\n","Current batch: Loss-> 1.0276, Train accuracy->  20.46%\n","Current batch: Loss-> 0.8794, Train accuracy->  20.55%\n","Current batch: Loss-> 0.9981, Train accuracy->  20.62%\n","Current batch: Loss-> 1.1805, Train accuracy->  20.70%\n","Current batch: Loss-> 1.0921, Train accuracy->  20.78%\n","Current batch: Loss-> 1.1231, Train accuracy->  20.86%\n","Current batch: Loss-> 1.3020, Train accuracy->  20.93%\n","Current batch: Loss-> 1.4297, Train accuracy->  20.99%\n","Current batch: Loss-> 1.2800, Train accuracy->  21.07%\n","Current batch: Loss-> 1.1674, Train accuracy->  21.15%\n","Current batch: Loss-> 0.9948, Train accuracy->  21.23%\n","Current batch: Loss-> 1.3386, Train accuracy->  21.28%\n","Current batch: Loss-> 1.3038, Train accuracy->  21.35%\n","Current batch: Loss-> 0.9833, Train accuracy->  21.44%\n","Current batch: Loss-> 1.0133, Train accuracy->  21.52%\n","Current batch: Loss-> 1.0298, Train accuracy->  21.60%\n","Current batch: Loss-> 1.2590, Train accuracy->  21.67%\n","Current batch: Loss-> 1.0292, Train accuracy->  21.75%\n","Current batch: Loss-> 1.0736, Train accuracy->  21.83%\n","Current batch: Loss-> 1.1554, Train accuracy->  21.91%\n","Current batch: Loss-> 1.2285, Train accuracy->  21.97%\n","Current batch: Loss-> 1.2176, Train accuracy->  22.04%\n","Current batch: Loss-> 0.9905, Train accuracy->  22.12%\n","Current batch: Loss-> 1.3282, Train accuracy->  22.18%\n","Current batch: Loss-> 1.1046, Train accuracy->  22.26%\n","Current batch: Loss-> 1.2068, Train accuracy->  22.33%\n","Current batch: Loss-> 1.1380, Train accuracy->  22.41%\n","Current batch: Loss-> 1.0492, Train accuracy->  22.50%\n","Current batch: Loss-> 1.1254, Train accuracy->  22.58%\n","Current batch: Loss-> 1.1213, Train accuracy->  22.66%\n","Current batch: Loss-> 1.0814, Train accuracy->  22.74%\n","Current batch: Loss-> 1.0538, Train accuracy->  22.83%\n","Current batch: Loss-> 1.0820, Train accuracy->  22.89%\n","Current batch: Loss-> 1.0348, Train accuracy->  22.97%\n","Current batch: Loss-> 1.2102, Train accuracy->  23.06%\n","Current batch: Loss-> 1.0685, Train accuracy->  23.14%\n","Current batch: Loss-> 1.1257, Train accuracy->  23.22%\n","Current batch: Loss-> 1.1702, Train accuracy->  23.29%\n","Current batch: Loss-> 1.1099, Train accuracy->  23.36%\n","Current batch: Loss-> 1.2579, Train accuracy->  23.44%\n","Current batch: Loss-> 1.0843, Train accuracy->  23.52%\n","Current batch: Loss-> 1.1571, Train accuracy->  23.60%\n","Current batch: Loss-> 1.1799, Train accuracy->  23.67%\n","Current batch: Loss-> 1.0816, Train accuracy->  23.76%\n","Current batch: Loss-> 1.0119, Train accuracy->  23.84%\n","Current batch: Loss-> 1.0304, Train accuracy->  23.92%\n","Current batch: Loss-> 1.0498, Train accuracy->  24.00%\n","Current batch: Loss-> 1.0022, Train accuracy->  24.09%\n","Current batch: Loss-> 1.2219, Train accuracy->  24.17%\n","Current batch: Loss-> 1.1735, Train accuracy->  24.23%\n","Current batch: Loss-> 1.2971, Train accuracy->  24.30%\n","Current batch: Loss-> 1.1098, Train accuracy->  24.36%\n","Current batch: Loss-> 1.1983, Train accuracy->  24.44%\n","Current batch: Loss-> 1.1995, Train accuracy->  24.49%\n","Current batch: Loss-> 1.0012, Train accuracy->  24.57%\n","Current batch: Loss-> 0.8336, Train accuracy->  24.67%\n","Current batch: Loss-> 1.0076, Train accuracy->  24.76%\n","Current batch: Loss-> 1.2907, Train accuracy->  24.84%\n","Current batch: Loss-> 1.1210, Train accuracy->  24.91%\n","Current batch: Loss-> 1.1687, Train accuracy->  24.98%\n","Current batch: Loss-> 0.9406, Train accuracy->  25.07%\n","Current batch: Loss-> 1.1867, Train accuracy->  25.14%\n","Current batch: Loss-> 1.0990, Train accuracy->  25.21%\n","Current batch: Loss-> 1.2147, Train accuracy->  25.29%\n","Current batch: Loss-> 1.1352, Train accuracy->  25.36%\n","Current batch: Loss-> 1.2606, Train accuracy->  25.42%\n","Current batch: Loss-> 1.2592, Train accuracy->  25.49%\n","Current batch: Loss-> 1.4926, Train accuracy->  25.55%\n","Current batch: Loss-> 1.0489, Train accuracy->  25.64%\n","Current batch: Loss-> 1.2008, Train accuracy->  25.71%\n","Current batch: Loss-> 0.8603, Train accuracy->  25.81%\n","Current batch: Loss-> 1.3117, Train accuracy->  25.88%\n","Current batch: Loss-> 1.0234, Train accuracy->  25.96%\n","Current batch: Loss-> 1.0333, Train accuracy->  26.04%\n","Current batch: Loss-> 1.3354, Train accuracy->  26.11%\n","Current batch: Loss-> 0.8770, Train accuracy->  26.19%\n","Current batch: Loss-> 1.1559, Train accuracy->  26.27%\n","Current batch: Loss-> 1.2248, Train accuracy->  26.34%\n","Current batch: Loss-> 0.9896, Train accuracy->  26.43%\n","Current batch: Loss-> 1.0141, Train accuracy->  26.52%\n","Current batch: Loss-> 1.5671, Train accuracy->  26.59%\n","Current batch: Loss-> 0.9971, Train accuracy->  26.67%\n","Current batch: Loss-> 1.3532, Train accuracy->  26.74%\n","Current batch: Loss-> 1.0069, Train accuracy->  26.82%\n","Current batch: Loss-> 1.1454, Train accuracy->  26.91%\n","Current batch: Loss-> 0.8588, Train accuracy->  26.99%\n","Current batch: Loss-> 1.5786, Train accuracy->  27.06%\n","Current batch: Loss-> 1.2661, Train accuracy->  27.13%\n","Current batch: Loss-> 1.2090, Train accuracy->  27.21%\n","Current batch: Loss-> 1.0887, Train accuracy->  27.30%\n","Current batch: Loss-> 1.2796, Train accuracy->  27.36%\n","Current batch: Loss-> 1.0436, Train accuracy->  27.44%\n","Current batch: Loss-> 1.0853, Train accuracy->  27.51%\n","Current batch: Loss-> 1.2627, Train accuracy->  27.57%\n","Current batch: Loss-> 1.0985, Train accuracy->  27.66%\n","Current batch: Loss-> 1.2261, Train accuracy->  27.72%\n","Current batch: Loss-> 0.8483, Train accuracy->  27.82%\n","Current batch: Loss-> 1.0355, Train accuracy->  27.90%\n","Current batch: Loss-> 1.0035, Train accuracy->  27.98%\n","Current batch: Loss-> 1.1681, Train accuracy->  28.05%\n","Current batch: Loss-> 1.2179, Train accuracy->  28.11%\n","Current batch: Loss-> 0.9338, Train accuracy->  28.19%\n","Current batch: Loss-> 0.9936, Train accuracy->  28.28%\n","Current batch: Loss-> 0.9998, Train accuracy->  28.37%\n","Current batch: Loss-> 1.0524, Train accuracy->  28.46%\n","Current batch: Loss-> 1.0221, Train accuracy->  28.54%\n","Current batch: Loss-> 0.9694, Train accuracy->  28.63%\n","Current batch: Loss-> 1.1154, Train accuracy->  28.71%\n","Current batch: Loss-> 1.2846, Train accuracy->  28.78%\n","Current batch: Loss-> 1.2091, Train accuracy->  28.86%\n","Current batch: Loss-> 1.0887, Train accuracy->  28.94%\n","Current batch: Loss-> 1.1439, Train accuracy->  29.02%\n","Current batch: Loss-> 1.1066, Train accuracy->  29.10%\n","Current batch: Loss-> 1.0759, Train accuracy->  29.18%\n","Current batch: Loss-> 1.0625, Train accuracy->  29.26%\n","Current batch: Loss-> 1.2593, Train accuracy->  29.33%\n","Current batch: Loss-> 1.2088, Train accuracy->  29.39%\n","Current batch: Loss-> 1.0595, Train accuracy->  29.48%\n","Current batch: Loss-> 1.3741, Train accuracy->  29.55%\n","Current batch: Loss-> 1.0222, Train accuracy->  29.64%\n","Current batch: Loss-> 1.0616, Train accuracy->  29.71%\n","Current batch: Loss-> 1.1110, Train accuracy->  29.78%\n","Current batch: Loss-> 0.9846, Train accuracy->  29.88%\n","Current batch: Loss-> 1.0896, Train accuracy->  29.96%\n","Current batch: Loss-> 1.4464, Train accuracy->  30.01%\n","Current batch: Loss-> 1.0115, Train accuracy->  30.10%\n","Current batch: Loss-> 1.2821, Train accuracy->  30.17%\n","Current batch: Loss-> 1.2347, Train accuracy->  30.24%\n","Current batch: Loss-> 1.3136, Train accuracy->  30.31%\n","Current batch: Loss-> 1.2279, Train accuracy->  30.38%\n","Current batch: Loss-> 1.0943, Train accuracy->  30.46%\n","Current batch: Loss-> 1.1058, Train accuracy->  30.55%\n","Current batch: Loss-> 1.1842, Train accuracy->  30.61%\n","Current batch: Loss-> 1.2180, Train accuracy->  30.69%\n","Current batch: Loss-> 1.1543, Train accuracy->  30.76%\n","Current batch: Loss-> 1.1445, Train accuracy->  30.85%\n","Current batch: Loss-> 1.2070, Train accuracy->  30.93%\n","Current batch: Loss-> 1.2714, Train accuracy->  31.00%\n","Current batch: Loss-> 0.9390, Train accuracy->  31.09%\n","Current batch: Loss-> 1.1333, Train accuracy->  31.15%\n","Current batch: Loss-> 1.0009, Train accuracy->  31.25%\n","Current batch: Loss-> 1.1352, Train accuracy->  31.33%\n","Current batch: Loss-> 1.0208, Train accuracy->  31.42%\n","Current batch: Loss-> 1.1812, Train accuracy->  31.49%\n","Current batch: Loss-> 1.1110, Train accuracy->  31.56%\n","Current batch: Loss-> 1.1014, Train accuracy->  31.63%\n","Current batch: Loss-> 0.9950, Train accuracy->  31.71%\n","Current batch: Loss-> 1.1232, Train accuracy->  31.77%\n","Current batch: Loss-> 0.9772, Train accuracy->  31.86%\n","Current batch: Loss-> 0.9083, Train accuracy->  31.95%\n","Current batch: Loss-> 1.0797, Train accuracy->  32.02%\n","Current batch: Loss-> 1.3526, Train accuracy->  32.08%\n","Current batch: Loss-> 1.0421, Train accuracy->  32.17%\n","Current batch: Loss-> 1.1154, Train accuracy->  32.25%\n","Current batch: Loss-> 1.3102, Train accuracy->  32.31%\n","Current batch: Loss-> 1.1309, Train accuracy->  32.40%\n","Current batch: Loss-> 1.1037, Train accuracy->  32.49%\n","Current batch: Loss-> 1.2378, Train accuracy->  32.56%\n","Current batch: Loss-> 1.0606, Train accuracy->  32.65%\n","Current batch: Loss-> 0.9358, Train accuracy->  32.73%\n","Current batch: Loss-> 1.1176, Train accuracy->  32.80%\n","Current batch: Loss-> 1.1320, Train accuracy->  32.88%\n","Current batch: Loss-> 1.1632, Train accuracy->  32.95%\n","Current batch: Loss-> 1.0476, Train accuracy->  33.03%\n","Current batch: Loss-> 1.0601, Train accuracy->  33.10%\n","Current batch: Loss-> 1.0873, Train accuracy->  33.18%\n","Current batch: Loss-> 1.3970, Train accuracy->  33.24%\n","Current batch: Loss-> 0.9238, Train accuracy->  33.33%\n","Current batch: Loss-> 1.1943, Train accuracy->  33.40%\n","Current batch: Loss-> 0.9742, Train accuracy->  33.48%\n","Current batch: Loss-> 1.1430, Train accuracy->  33.57%\n","Current batch: Loss-> 1.1536, Train accuracy->  33.65%\n","Current batch: Loss-> 1.0769, Train accuracy->  33.73%\n","Current batch: Loss-> 1.0753, Train accuracy->  33.82%\n","Current batch: Loss-> 1.0645, Train accuracy->  33.90%\n","Current batch: Loss-> 1.1695, Train accuracy->  33.99%\n","Current batch: Loss-> 1.2492, Train accuracy->  34.05%\n","Current batch: Loss-> 1.3541, Train accuracy->  34.11%\n","Current batch: Loss-> 1.3736, Train accuracy->  34.17%\n","Current batch: Loss-> 1.1175, Train accuracy->  34.25%\n","Current batch: Loss-> 1.0125, Train accuracy->  34.34%\n","Current batch: Loss-> 0.9145, Train accuracy->  34.43%\n","Current batch: Loss-> 0.9125, Train accuracy->  34.53%\n","Current batch: Loss-> 0.8761, Train accuracy->  34.62%\n","Current batch: Loss-> 1.2224, Train accuracy->  34.70%\n","Current batch: Loss-> 0.9635, Train accuracy->  34.79%\n","Current batch: Loss-> 1.5701, Train accuracy->  34.86%\n","Current batch: Loss-> 1.3190, Train accuracy->  34.92%\n","Current batch: Loss-> 1.1603, Train accuracy->  35.00%\n","Current batch: Loss-> 1.2112, Train accuracy->  35.09%\n","Current batch: Loss-> 0.9387, Train accuracy->  35.17%\n","Current batch: Loss-> 1.0137, Train accuracy->  35.25%\n","Current batch: Loss-> 1.1621, Train accuracy->  35.34%\n","Current batch: Loss-> 1.0520, Train accuracy->  35.42%\n","Current batch: Loss-> 1.1438, Train accuracy->  35.49%\n","Current batch: Loss-> 0.9732, Train accuracy->  35.58%\n","Current batch: Loss-> 1.0774, Train accuracy->  35.66%\n","Current batch: Loss-> 1.0865, Train accuracy->  35.73%\n","Current batch: Loss-> 1.0464, Train accuracy->  35.82%\n","Current batch: Loss-> 1.1948, Train accuracy->  35.89%\n","Current batch: Loss-> 1.3525, Train accuracy->  35.96%\n","Current batch: Loss-> 1.1166, Train accuracy->  36.04%\n","Current batch: Loss-> 0.9331, Train accuracy->  36.12%\n","Current batch: Loss-> 1.1185, Train accuracy->  36.20%\n","Current batch: Loss-> 1.0765, Train accuracy->  36.28%\n","Current batch: Loss-> 1.1044, Train accuracy->  36.35%\n","Current batch: Loss-> 1.1966, Train accuracy->  36.43%\n","Current batch: Loss-> 1.0192, Train accuracy->  36.51%\n","Current batch: Loss-> 0.8576, Train accuracy->  36.61%\n","Current batch: Loss-> 0.9731, Train accuracy->  36.71%\n","Current batch: Loss-> 1.0711, Train accuracy->  36.79%\n","Current batch: Loss-> 1.0706, Train accuracy->  36.88%\n","Current batch: Loss-> 0.8245, Train accuracy->  36.97%\n","Current batch: Loss-> 1.1750, Train accuracy->  37.05%\n","Current batch: Loss-> 1.1050, Train accuracy->  37.13%\n","Current batch: Loss-> 1.3539, Train accuracy->  37.20%\n","Current batch: Loss-> 1.2248, Train accuracy->  37.29%\n","Current batch: Loss-> 1.1799, Train accuracy->  37.37%\n","Current batch: Loss-> 1.0386, Train accuracy->  37.44%\n","Current batch: Loss-> 0.9332, Train accuracy->  37.54%\n","Current batch: Loss-> 1.0929, Train accuracy->  37.62%\n","Current batch: Loss-> 1.1170, Train accuracy->  37.70%\n","Current batch: Loss-> 1.2361, Train accuracy->  37.76%\n","Current batch: Loss-> 1.3068, Train accuracy->  37.84%\n","Current batch: Loss-> 0.9560, Train accuracy->  37.93%\n","Current batch: Loss-> 1.3813, Train accuracy->  38.00%\n","Current batch: Loss-> 1.2132, Train accuracy->  38.08%\n","Current batch: Loss-> 1.0422, Train accuracy->  38.16%\n","Current batch: Loss-> 0.9948, Train accuracy->  38.25%\n","Current batch: Loss-> 1.0555, Train accuracy->  38.33%\n","Current batch: Loss-> 1.2799, Train accuracy->  38.40%\n","Current batch: Loss-> 1.0020, Train accuracy->  38.48%\n","Current batch: Loss-> 1.3271, Train accuracy->  38.55%\n","Current batch: Loss-> 1.2109, Train accuracy->  38.62%\n","Current batch: Loss-> 1.2767, Train accuracy->  38.69%\n","Current batch: Loss-> 1.1758, Train accuracy->  38.76%\n","Current batch: Loss-> 1.0764, Train accuracy->  38.84%\n","Current batch: Loss-> 1.0919, Train accuracy->  38.92%\n","Current batch: Loss-> 1.0936, Train accuracy->  39.01%\n","Current batch: Loss-> 1.2278, Train accuracy->  39.08%\n","Current batch: Loss-> 1.2692, Train accuracy->  39.16%\n","Current batch: Loss-> 0.9863, Train accuracy->  39.25%\n","Current batch: Loss-> 1.2102, Train accuracy->  39.32%\n","Current batch: Loss-> 0.8721, Train accuracy->  39.42%\n","Current batch: Loss-> 1.1307, Train accuracy->  39.50%\n","Current batch: Loss-> 1.0980, Train accuracy->  39.58%\n","Current batch: Loss-> 1.0887, Train accuracy->  39.67%\n","Current batch: Loss-> 1.0617, Train accuracy->  39.75%\n","Current batch: Loss-> 1.1359, Train accuracy->  39.82%\n","Current batch: Loss-> 1.0583, Train accuracy->  39.89%\n","Current batch: Loss-> 1.1415, Train accuracy->  39.97%\n","Current batch: Loss-> 1.0898, Train accuracy->  40.06%\n","Current batch: Loss-> 0.9227, Train accuracy->  40.15%\n","Current batch: Loss-> 1.0097, Train accuracy->  40.23%\n","Current batch: Loss-> 1.1400, Train accuracy->  40.31%\n","Current batch: Loss-> 1.1983, Train accuracy->  40.39%\n","Current batch: Loss-> 1.2741, Train accuracy->  40.46%\n","Current batch: Loss-> 1.0130, Train accuracy->  40.53%\n","Current batch: Loss-> 1.2719, Train accuracy->  40.59%\n","Current batch: Loss-> 1.1720, Train accuracy->  40.66%\n","Current batch: Loss-> 1.0684, Train accuracy->  40.75%\n","Current batch: Loss-> 1.1782, Train accuracy->  40.83%\n","Current batch: Loss-> 1.1942, Train accuracy->  40.91%\n","Current batch: Loss-> 0.8496, Train accuracy->  41.00%\n","Current batch: Loss-> 1.1939, Train accuracy->  41.08%\n","Current batch: Loss-> 1.0569, Train accuracy->  41.15%\n","Current batch: Loss-> 1.0284, Train accuracy->  41.24%\n","Current batch: Loss-> 1.3516, Train accuracy->  41.30%\n","Current batch: Loss-> 1.0504, Train accuracy->  41.38%\n","Current batch: Loss-> 1.3385, Train accuracy->  41.45%\n","Current batch: Loss-> 1.3479, Train accuracy->  41.52%\n","Current batch: Loss-> 0.9491, Train accuracy->  41.60%\n","Current batch: Loss-> 1.1285, Train accuracy->  41.67%\n","Current batch: Loss-> 1.0845, Train accuracy->  41.75%\n","Current batch: Loss-> 1.1869, Train accuracy->  41.83%\n","Current batch: Loss-> 1.4830, Train accuracy->  41.87%\n","Current batch: Loss-> 1.4713, Train accuracy->  41.91%\n","Current batch: Loss-> 1.1187, Train accuracy->  41.98%\n","Current batch: Loss-> 1.1940, Train accuracy->  42.07%\n","Current batch: Loss-> 1.0146, Train accuracy->  42.15%\n","Current batch: Loss-> 0.9477, Train accuracy->  42.23%\n","Current batch: Loss-> 1.1742, Train accuracy->  42.30%\n","Current batch: Loss-> 1.1079, Train accuracy->  42.38%\n","Current batch: Loss-> 1.0893, Train accuracy->  42.45%\n","Current batch: Loss-> 0.9929, Train accuracy->  42.54%\n","Current batch: Loss-> 1.1002, Train accuracy->  42.62%\n","Current batch: Loss-> 1.2825, Train accuracy->  42.67%\n","Current batch: Loss-> 1.0188, Train accuracy->  42.77%\n","Current batch: Loss-> 1.1470, Train accuracy->  42.85%\n","Current batch: Loss-> 1.0693, Train accuracy->  42.93%\n","Current batch: Loss-> 1.4200, Train accuracy->  42.99%\n","Current batch: Loss-> 1.2295, Train accuracy->  43.06%\n","Current batch: Loss-> 1.2092, Train accuracy->  43.14%\n","Current batch: Loss-> 1.1207, Train accuracy->  43.21%\n","Current batch: Loss-> 1.2625, Train accuracy->  43.30%\n","Current batch: Loss-> 1.2524, Train accuracy->  43.38%\n","Current batch: Loss-> 1.1215, Train accuracy->  43.45%\n","Current batch: Loss-> 1.0911, Train accuracy->  43.54%\n","Current batch: Loss-> 0.7783, Train accuracy->  43.63%\n","Current batch: Loss-> 1.1852, Train accuracy->  43.71%\n","Current batch: Loss-> 0.8955, Train accuracy->  43.80%\n","Current batch: Loss-> 1.0165, Train accuracy->  43.88%\n","Current batch: Loss-> 0.8769, Train accuracy->  43.96%\n","Current batch: Loss-> 0.9705, Train accuracy->  44.04%\n","Current batch: Loss-> 1.3467, Train accuracy->  44.11%\n","Current batch: Loss-> 1.0675, Train accuracy->  44.19%\n","Current batch: Loss-> 1.0954, Train accuracy->  44.27%\n","Current batch: Loss-> 1.0234, Train accuracy->  44.36%\n","Current batch: Loss-> 1.0836, Train accuracy->  44.45%\n","Current batch: Loss-> 1.2946, Train accuracy->  44.51%\n","Current batch: Loss-> 1.2300, Train accuracy->  44.60%\n","Current batch: Loss-> 1.2624, Train accuracy->  44.67%\n","Current batch: Loss-> 1.1288, Train accuracy->  44.75%\n","Current batch: Loss-> 1.1361, Train accuracy->  44.82%\n","Current batch: Loss-> 1.1121, Train accuracy->  44.89%\n","Current batch: Loss-> 1.1445, Train accuracy->  44.96%\n","Current batch: Loss-> 1.0147, Train accuracy->  45.05%\n","Current batch: Loss-> 1.0278, Train accuracy->  45.13%\n","Current batch: Loss-> 1.2972, Train accuracy->  45.20%\n","Current batch: Loss-> 1.0114, Train accuracy->  45.27%\n","Current batch: Loss-> 0.9783, Train accuracy->  45.35%\n","Current batch: Loss-> 1.3618, Train accuracy->  45.43%\n","Current batch: Loss-> 1.2947, Train accuracy->  45.49%\n","Current batch: Loss-> 1.3539, Train accuracy->  45.56%\n","Current batch: Loss-> 0.9895, Train accuracy->  45.63%\n","Current batch: Loss-> 1.0737, Train accuracy->  45.71%\n","Current batch: Loss-> 1.2308, Train accuracy->  45.79%\n","Current batch: Loss-> 1.3622, Train accuracy->  45.84%\n","Current batch: Loss-> 0.9128, Train accuracy->  45.95%\n","Current batch: Loss-> 1.0599, Train accuracy->  46.01%\n","Current batch: Loss-> 1.0240, Train accuracy->  46.10%\n","Current batch: Loss-> 0.8767, Train accuracy->  46.19%\n","Current batch: Loss-> 1.1941, Train accuracy->  46.26%\n","Current batch: Loss-> 1.2325, Train accuracy->  46.33%\n","Current batch: Loss-> 1.3342, Train accuracy->  46.40%\n","Current batch: Loss-> 1.0993, Train accuracy->  46.49%\n","Current batch: Loss-> 1.1984, Train accuracy->  46.56%\n","Current batch: Loss-> 1.1911, Train accuracy->  46.64%\n","Current batch: Loss-> 1.2354, Train accuracy->  46.72%\n","Current batch: Loss-> 1.1980, Train accuracy->  46.79%\n","Current batch: Loss-> 0.9504, Train accuracy->  46.87%\n","Current batch: Loss-> 1.0558, Train accuracy->  46.96%\n","Current batch: Loss-> 1.0103, Train accuracy->  47.03%\n","Current batch: Loss-> 0.9667, Train accuracy->  47.11%\n","Current batch: Loss-> 1.2439, Train accuracy->  47.19%\n","Current batch: Loss-> 0.9241, Train accuracy->  47.28%\n","Current batch: Loss-> 1.0112, Train accuracy->  47.36%\n","Current batch: Loss-> 1.0614, Train accuracy->  47.45%\n","Current batch: Loss-> 1.2279, Train accuracy->  47.50%\n","Current batch: Loss-> 1.1837, Train accuracy->  47.58%\n","Current batch: Loss-> 1.1550, Train accuracy->  47.65%\n","Current batch: Loss-> 1.4348, Train accuracy->  47.71%\n","Current batch: Loss-> 1.2080, Train accuracy->  47.78%\n","Current batch: Loss-> 0.9929, Train accuracy->  47.85%\n","Current batch: Loss-> 1.4971, Train accuracy->  47.91%\n","Current batch: Loss-> 1.1081, Train accuracy->  47.98%\n","Current batch: Loss-> 1.3288, Train accuracy->  48.06%\n","Current batch: Loss-> 1.2739, Train accuracy->  48.13%\n","Current batch: Loss-> 1.2144, Train accuracy->  48.19%\n","Current batch: Loss-> 1.3637, Train accuracy->  48.26%\n","Current batch: Loss-> 1.3418, Train accuracy->  48.32%\n","Current batch: Loss-> 1.1098, Train accuracy->  48.40%\n","Current batch: Loss-> 1.3632, Train accuracy->  48.46%\n","Current batch: Loss-> 0.9689, Train accuracy->  48.55%\n","Current batch: Loss-> 1.3111, Train accuracy->  48.63%\n","Current batch: Loss-> 1.0418, Train accuracy->  48.72%\n","Current batch: Loss-> 1.0875, Train accuracy->  48.80%\n","Current batch: Loss-> 1.4293, Train accuracy->  48.87%\n","Current batch: Loss-> 1.2036, Train accuracy->  48.94%\n","Current batch: Loss-> 1.1438, Train accuracy->  49.02%\n","Current batch: Loss-> 1.3173, Train accuracy->  49.11%\n","Current batch: Loss-> 1.2054, Train accuracy->  49.19%\n","Current batch: Loss-> 1.3002, Train accuracy->  49.25%\n","Current batch: Loss-> 1.0938, Train accuracy->  49.34%\n","Current batch: Loss-> 1.1792, Train accuracy->  49.41%\n","Current batch: Loss-> 1.4477, Train accuracy->  49.47%\n","Current batch: Loss-> 1.2223, Train accuracy->  49.54%\n","Current batch: Loss-> 1.3356, Train accuracy->  49.62%\n","Current batch: Loss-> 1.1590, Train accuracy->  49.70%\n","Current batch: Loss-> 1.4280, Train accuracy->  49.78%\n","Current batch: Loss-> 0.9604, Train accuracy->  49.87%\n","Current batch: Loss-> 1.2875, Train accuracy->  49.96%\n","Current batch: Loss-> 1.0191, Train accuracy->  50.04%\n","Current batch: Loss-> 1.2794, Train accuracy->  50.11%\n","Current batch: Loss-> 1.1273, Train accuracy->  50.17%\n","Current batch: Loss-> 1.0142, Train accuracy->  50.25%\n","Current batch: Loss-> 1.2248, Train accuracy->  50.32%\n","Current batch: Loss-> 1.0831, Train accuracy->  50.40%\n","Current batch: Loss-> 1.1163, Train accuracy->  50.48%\n","Current batch: Loss-> 1.1430, Train accuracy->  50.56%\n","Current batch: Loss-> 1.1092, Train accuracy->  50.64%\n","Current batch: Loss-> 1.1714, Train accuracy->  50.72%\n","Current batch: Loss-> 1.2017, Train accuracy->  50.80%\n","Current batch: Loss-> 1.0947, Train accuracy->  50.88%\n","Current batch: Loss-> 1.2610, Train accuracy->  50.95%\n","Current batch: Loss-> 1.0747, Train accuracy->  51.04%\n","Current batch: Loss-> 1.1706, Train accuracy->  51.11%\n","Current batch: Loss-> 0.9785, Train accuracy->  51.19%\n","Current batch: Loss-> 0.9531, Train accuracy->  51.28%\n","Current batch: Loss-> 1.1148, Train accuracy->  51.36%\n","Current batch: Loss-> 0.9830, Train accuracy->  51.43%\n","Current batch: Loss-> 0.9340, Train accuracy->  51.52%\n","Current batch: Loss-> 0.8701, Train accuracy->  51.62%\n","Current batch: Loss-> 0.9115, Train accuracy->  51.71%\n","Current batch: Loss-> 1.0680, Train accuracy->  51.81%\n","Current batch: Loss-> 1.1147, Train accuracy->  51.90%\n","Current batch: Loss-> 1.1676, Train accuracy->  51.96%\n","Current batch: Loss-> 0.9252, Train accuracy->  52.06%\n","Current batch: Loss-> 1.2220, Train accuracy->  52.13%\n","Current batch: Loss-> 0.9325, Train accuracy->  52.22%\n","Current batch: Loss-> 0.9802, Train accuracy->  52.32%\n","Current batch: Loss-> 1.2528, Train accuracy->  52.40%\n","Current batch: Loss-> 0.9595, Train accuracy->  52.49%\n","Current batch: Loss-> 1.2657, Train accuracy->  52.57%\n","Current batch: Loss-> 1.0730, Train accuracy->  52.66%\n","Current batch: Loss-> 1.1604, Train accuracy->  52.73%\n","Current batch: Loss-> 1.1930, Train accuracy->  52.81%\n","Current batch: Loss-> 0.8996, Train accuracy->  52.88%\n","Current batch: Loss-> 1.3546, Train accuracy->  52.96%\n","Current batch: Loss-> 1.0860, Train accuracy->  53.04%\n","Current batch: Loss-> 1.0810, Train accuracy->  53.14%\n","Current batch: Loss-> 1.0004, Train accuracy->  53.23%\n","Current batch: Loss-> 1.0619, Train accuracy->  53.32%\n","Current batch: Loss-> 1.2631, Train accuracy->  53.39%\n","Current batch: Loss-> 1.2326, Train accuracy->  53.46%\n","Current batch: Loss-> 1.1372, Train accuracy->  53.54%\n","Current batch: Loss-> 1.3355, Train accuracy->  53.61%\n","Current batch: Loss-> 1.0292, Train accuracy->  53.70%\n","Current batch: Loss-> 1.4914, Train accuracy->  53.75%\n","Current batch: Loss-> 1.3230, Train accuracy->  53.82%\n","Current batch: Loss-> 1.2281, Train accuracy->  53.89%\n","Current batch: Loss-> 1.2363, Train accuracy->  53.96%\n","Current batch: Loss-> 1.0422, Train accuracy->  54.04%\n","Current batch: Loss-> 1.0149, Train accuracy->  54.11%\n","Current batch: Loss-> 1.4068, Train accuracy->  54.18%\n","Current batch: Loss-> 1.0122, Train accuracy->  54.26%\n","Current batch: Loss-> 1.1382, Train accuracy->  54.35%\n","Current batch: Loss-> 1.1622, Train accuracy->  54.44%\n","Current batch: Loss-> 1.0154, Train accuracy->  54.54%\n","Current batch: Loss-> 1.1550, Train accuracy->  54.61%\n","Current batch: Loss-> 1.1968, Train accuracy->  54.69%\n","Current batch: Loss-> 0.9160, Train accuracy->  54.78%\n","Current batch: Loss-> 1.1293, Train accuracy->  54.86%\n","Current batch: Loss-> 1.0097, Train accuracy->  54.94%\n","Current batch: Loss-> 1.0918, Train accuracy->  55.02%\n","Current batch: Loss-> 1.2138, Train accuracy->  55.10%\n","Current batch: Loss-> 1.1400, Train accuracy->  55.17%\n","Current batch: Loss-> 1.0428, Train accuracy->  55.26%\n","Current batch: Loss-> 1.0578, Train accuracy->  55.35%\n","Current batch: Loss-> 1.1199, Train accuracy->  55.43%\n","Current batch: Loss-> 1.0537, Train accuracy->  55.51%\n","Current batch: Loss-> 0.9182, Train accuracy->  55.61%\n","Current batch: Loss-> 0.9264, Train accuracy->  55.70%\n","Current batch: Loss-> 0.8668, Train accuracy->  55.77%\n","Current batch: Loss-> 0.8882, Train accuracy->  55.87%\n","Current batch: Loss-> 1.2204, Train accuracy->  55.95%\n","Current batch: Loss-> 0.9948, Train accuracy->  56.03%\n","Current batch: Loss-> 1.2335, Train accuracy->  56.09%\n","Current batch: Loss-> 1.2882, Train accuracy->  56.17%\n","Current batch: Loss-> 1.1911, Train accuracy->  56.25%\n","Current batch: Loss-> 1.0143, Train accuracy->  56.33%\n","Current batch: Loss-> 1.0969, Train accuracy->  56.40%\n","Current batch: Loss-> 0.8647, Train accuracy->  56.50%\n","Current batch: Loss-> 1.1774, Train accuracy->  56.58%\n","Current batch: Loss-> 1.0403, Train accuracy->  56.66%\n","Current batch: Loss-> 1.0459, Train accuracy->  56.75%\n","Current batch: Loss-> 0.8366, Train accuracy->  56.84%\n","Current batch: Loss-> 1.1075, Train accuracy->  56.91%\n","Current batch: Loss-> 1.1352, Train accuracy->  56.99%\n","Current batch: Loss-> 0.9658, Train accuracy->  57.08%\n","Current batch: Loss-> 0.8835, Train accuracy->  57.17%\n","Current batch: Loss-> 1.0927, Train accuracy->  57.25%\n","Current batch: Loss-> 1.3213, Train accuracy->  57.33%\n","Current batch: Loss-> 1.1917, Train accuracy->  57.41%\n","Current batch: Loss-> 1.0121, Train accuracy->  57.50%\n","Current batch: Loss-> 1.1481, Train accuracy->  57.59%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 46.83it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.9620, Train accuracy->  57.68%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.17it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.3535, Accuracy: 4390/12000 (37%)\n","\n","Current batch: Loss-> 0.9817, Train accuracy->   0.08%\n","Current batch: Loss-> 0.9549, Train accuracy->   0.16%\n","Current batch: Loss-> 1.0339, Train accuracy->   0.24%\n","Current batch: Loss-> 1.2529, Train accuracy->   0.31%\n","Current batch: Loss-> 1.0146, Train accuracy->   0.41%\n","Current batch: Loss-> 1.0415, Train accuracy->   0.50%\n","Current batch: Loss-> 1.2297, Train accuracy->   0.57%\n","Current batch: Loss-> 1.0996, Train accuracy->   0.64%\n","Current batch: Loss-> 0.8866, Train accuracy->   0.71%\n","Current batch: Loss-> 1.5353, Train accuracy->   0.77%\n","Current batch: Loss-> 0.8713, Train accuracy->   0.87%\n","Current batch: Loss-> 0.9839, Train accuracy->   0.95%\n","Current batch: Loss-> 1.0159, Train accuracy->   1.04%\n","Current batch: Loss-> 1.1250, Train accuracy->   1.12%\n","Current batch: Loss-> 0.9333, Train accuracy->   1.21%\n","Current batch: Loss-> 1.0215, Train accuracy->   1.29%\n","Current batch: Loss-> 0.8504, Train accuracy->   1.38%\n","Current batch: Loss-> 1.2137, Train accuracy->   1.46%\n","Current batch: Loss-> 1.2221, Train accuracy->   1.55%\n","Current batch: Loss-> 1.0820, Train accuracy->   1.63%\n","Current batch: Loss-> 0.9878, Train accuracy->   1.71%\n","Current batch: Loss-> 1.0983, Train accuracy->   1.80%\n","Current batch: Loss-> 1.3969, Train accuracy->   1.87%\n","Current batch: Loss-> 1.3061, Train accuracy->   1.94%\n","Current batch: Loss-> 1.0265, Train accuracy->   2.03%\n","Current batch: Loss-> 0.9981, Train accuracy->   2.12%\n","Current batch: Loss-> 1.0890, Train accuracy->   2.20%\n","Current batch: Loss-> 0.9815, Train accuracy->   2.28%\n","Current batch: Loss-> 0.9928, Train accuracy->   2.36%\n","Current batch: Loss-> 1.0910, Train accuracy->   2.43%\n","Current batch: Loss-> 1.0070, Train accuracy->   2.51%\n","Current batch: Loss-> 0.9879, Train accuracy->   2.59%\n","Current batch: Loss-> 1.1224, Train accuracy->   2.68%\n","Current batch: Loss-> 0.9125, Train accuracy->   2.76%\n","Current batch: Loss-> 1.1887, Train accuracy->   2.84%\n","Current batch: Loss-> 1.1730, Train accuracy->   2.91%\n","Current batch: Loss-> 1.2225, Train accuracy->   2.99%\n","Current batch: Loss-> 1.0488, Train accuracy->   3.08%\n","Current batch: Loss-> 1.0085, Train accuracy->   3.17%\n","Current batch: Loss-> 0.9768, Train accuracy->   3.26%\n","Current batch: Loss-> 0.9959, Train accuracy->   3.36%\n","Current batch: Loss-> 1.2798, Train accuracy->   3.42%\n","Current batch: Loss-> 1.4713, Train accuracy->   3.49%\n","Current batch: Loss-> 1.2131, Train accuracy->   3.57%\n","Current batch: Loss-> 0.9294, Train accuracy->   3.66%\n","Current batch: Loss-> 1.1013, Train accuracy->   3.75%\n","Current batch: Loss-> 1.2166, Train accuracy->   3.83%\n","Current batch: Loss-> 0.9314, Train accuracy->   3.91%\n","Current batch: Loss-> 1.2879, Train accuracy->   3.98%\n","Current batch: Loss-> 1.1647, Train accuracy->   4.07%\n","Current batch: Loss-> 1.0157, Train accuracy->   4.17%\n","Current batch: Loss-> 0.9710, Train accuracy->   4.25%\n","Current batch: Loss-> 1.2269, Train accuracy->   4.31%\n","Current batch: Loss-> 0.9364, Train accuracy->   4.40%\n","Current batch: Loss-> 1.0925, Train accuracy->   4.49%\n","Current batch: Loss-> 1.1818, Train accuracy->   4.58%\n","Current batch: Loss-> 0.9471, Train accuracy->   4.67%\n","Current batch: Loss-> 1.0437, Train accuracy->   4.76%\n","Current batch: Loss-> 1.1590, Train accuracy->   4.84%\n","Current batch: Loss-> 1.1435, Train accuracy->   4.92%\n","Current batch: Loss-> 1.4679, Train accuracy->   4.98%\n","Current batch: Loss-> 1.2367, Train accuracy->   5.06%\n","Current batch: Loss-> 0.9145, Train accuracy->   5.15%\n","Current batch: Loss-> 1.3778, Train accuracy->   5.23%\n","Current batch: Loss-> 1.4465, Train accuracy->   5.31%\n","Current batch: Loss-> 1.3659, Train accuracy->   5.39%\n","Current batch: Loss-> 1.0279, Train accuracy->   5.47%\n","Current batch: Loss-> 1.2268, Train accuracy->   5.55%\n","Current batch: Loss-> 1.0656, Train accuracy->   5.63%\n","Current batch: Loss-> 1.2205, Train accuracy->   5.72%\n","Current batch: Loss-> 0.8929, Train accuracy->   5.81%\n","Current batch: Loss-> 1.2613, Train accuracy->   5.89%\n","Current batch: Loss-> 0.9525, Train accuracy->   5.97%\n","Current batch: Loss-> 1.2194, Train accuracy->   6.05%\n","Current batch: Loss-> 1.1555, Train accuracy->   6.12%\n","Current batch: Loss-> 1.2313, Train accuracy->   6.20%\n","Current batch: Loss-> 0.9938, Train accuracy->   6.29%\n","Current batch: Loss-> 1.1144, Train accuracy->   6.37%\n","Current batch: Loss-> 1.0561, Train accuracy->   6.46%\n","Current batch: Loss-> 1.1113, Train accuracy->   6.54%\n","Current batch: Loss-> 1.0696, Train accuracy->   6.61%\n","Current batch: Loss-> 1.1433, Train accuracy->   6.70%\n","Current batch: Loss-> 1.1293, Train accuracy->   6.78%\n","Current batch: Loss-> 1.0288, Train accuracy->   6.87%\n","Current batch: Loss-> 1.0720, Train accuracy->   6.94%\n","Current batch: Loss-> 0.8735, Train accuracy->   7.02%\n","Current batch: Loss-> 0.8402, Train accuracy->   7.12%\n","Current batch: Loss-> 1.1945, Train accuracy->   7.18%\n","Current batch: Loss-> 1.3337, Train accuracy->   7.25%\n","Current batch: Loss-> 1.0487, Train accuracy->   7.34%\n","Current batch: Loss-> 1.0085, Train accuracy->   7.43%\n","Current batch: Loss-> 0.9300, Train accuracy->   7.52%\n","Current batch: Loss-> 1.1580, Train accuracy->   7.60%\n","Current batch: Loss-> 1.3018, Train accuracy->   7.67%\n","Current batch: Loss-> 0.9915, Train accuracy->   7.75%\n","Current batch: Loss-> 0.9875, Train accuracy->   7.84%\n","Current batch: Loss-> 1.1959, Train accuracy->   7.92%\n","Current batch: Loss-> 1.5669, Train accuracy->   7.98%\n","Current batch: Loss-> 1.0804, Train accuracy->   8.05%\n","Current batch: Loss-> 0.7919, Train accuracy->   8.14%\n","Current batch: Loss-> 1.0895, Train accuracy->   8.23%\n","Current batch: Loss-> 0.8801, Train accuracy->   8.31%\n","Current batch: Loss-> 1.1708, Train accuracy->   8.39%\n","Current batch: Loss-> 1.0888, Train accuracy->   8.47%\n","Current batch: Loss-> 1.1535, Train accuracy->   8.56%\n","Current batch: Loss-> 1.1066, Train accuracy->   8.64%\n","Current batch: Loss-> 1.0937, Train accuracy->   8.73%\n","Current batch: Loss-> 1.0493, Train accuracy->   8.80%\n","Current batch: Loss-> 1.1851, Train accuracy->   8.89%\n","Current batch: Loss-> 1.1217, Train accuracy->   8.96%\n","Current batch: Loss-> 0.8264, Train accuracy->   9.06%\n","Current batch: Loss-> 1.2191, Train accuracy->   9.12%\n","Current batch: Loss-> 1.4191, Train accuracy->   9.18%\n","Current batch: Loss-> 1.0805, Train accuracy->   9.26%\n","Current batch: Loss-> 1.1196, Train accuracy->   9.34%\n","Current batch: Loss-> 0.9467, Train accuracy->   9.42%\n","Current batch: Loss-> 1.0430, Train accuracy->   9.50%\n","Current batch: Loss-> 1.1202, Train accuracy->   9.59%\n","Current batch: Loss-> 1.1199, Train accuracy->   9.66%\n","Current batch: Loss-> 1.1714, Train accuracy->   9.74%\n","Current batch: Loss-> 0.9938, Train accuracy->   9.83%\n","Current batch: Loss-> 0.8806, Train accuracy->   9.92%\n","Current batch: Loss-> 0.9096, Train accuracy->  10.01%\n","Current batch: Loss-> 0.9823, Train accuracy->  10.09%\n","Current batch: Loss-> 1.1298, Train accuracy->  10.16%\n","Current batch: Loss-> 1.3396, Train accuracy->  10.24%\n","Current batch: Loss-> 1.1545, Train accuracy->  10.30%\n","Current batch: Loss-> 1.3017, Train accuracy->  10.38%\n","Current batch: Loss-> 1.1225, Train accuracy->  10.46%\n","Current batch: Loss-> 0.9933, Train accuracy->  10.55%\n","Current batch: Loss-> 1.3744, Train accuracy->  10.62%\n","Current batch: Loss-> 1.2906, Train accuracy->  10.68%\n","Current batch: Loss-> 1.3182, Train accuracy->  10.75%\n","Current batch: Loss-> 1.1399, Train accuracy->  10.82%\n","Current batch: Loss-> 1.1022, Train accuracy->  10.89%\n","Current batch: Loss-> 1.0012, Train accuracy->  10.97%\n","Current batch: Loss-> 1.0638, Train accuracy->  11.05%\n","Current batch: Loss-> 0.9593, Train accuracy->  11.13%\n","Current batch: Loss-> 1.2703, Train accuracy->  11.20%\n","Current batch: Loss-> 1.1680, Train accuracy->  11.28%\n","Current batch: Loss-> 0.9730, Train accuracy->  11.36%\n","Current batch: Loss-> 1.3241, Train accuracy->  11.43%\n","Current batch: Loss-> 1.2248, Train accuracy->  11.51%\n","Current batch: Loss-> 0.9864, Train accuracy->  11.58%\n","Current batch: Loss-> 1.4315, Train accuracy->  11.66%\n","Current batch: Loss-> 0.9757, Train accuracy->  11.75%\n","Current batch: Loss-> 1.0967, Train accuracy->  11.83%\n","Current batch: Loss-> 0.8900, Train accuracy->  11.93%\n","Current batch: Loss-> 1.1226, Train accuracy->  12.01%\n","Current batch: Loss-> 0.9109, Train accuracy->  12.11%\n","Current batch: Loss-> 1.0093, Train accuracy->  12.19%\n","Current batch: Loss-> 0.9864, Train accuracy->  12.27%\n","Current batch: Loss-> 1.0241, Train accuracy->  12.36%\n","Current batch: Loss-> 0.9838, Train accuracy->  12.44%\n","Current batch: Loss-> 1.0365, Train accuracy->  12.52%\n","Current batch: Loss-> 1.2870, Train accuracy->  12.60%\n","Current batch: Loss-> 0.8979, Train accuracy->  12.69%\n","Current batch: Loss-> 1.1022, Train accuracy->  12.76%\n","Current batch: Loss-> 0.9036, Train accuracy->  12.84%\n","Current batch: Loss-> 1.1465, Train accuracy->  12.92%\n","Current batch: Loss-> 1.2911, Train accuracy->  12.99%\n","Current batch: Loss-> 0.9787, Train accuracy->  13.07%\n","Current batch: Loss-> 1.1494, Train accuracy->  13.16%\n","Current batch: Loss-> 1.2467, Train accuracy->  13.23%\n","Current batch: Loss-> 1.1484, Train accuracy->  13.31%\n","Current batch: Loss-> 0.9344, Train accuracy->  13.40%\n","Current batch: Loss-> 1.1171, Train accuracy->  13.48%\n","Current batch: Loss-> 1.0680, Train accuracy->  13.56%\n","Current batch: Loss-> 1.1904, Train accuracy->  13.64%\n","Current batch: Loss-> 1.0479, Train accuracy->  13.71%\n","Current batch: Loss-> 0.9333, Train accuracy->  13.81%\n","Current batch: Loss-> 1.0185, Train accuracy->  13.89%\n","Current batch: Loss-> 1.1635, Train accuracy->  13.96%\n","Current batch: Loss-> 1.0257, Train accuracy->  14.04%\n","Current batch: Loss-> 1.0402, Train accuracy->  14.13%\n","Current batch: Loss-> 1.0719, Train accuracy->  14.21%\n","Current batch: Loss-> 1.3938, Train accuracy->  14.29%\n","Current batch: Loss-> 1.3296, Train accuracy->  14.36%\n","Current batch: Loss-> 1.0288, Train accuracy->  14.43%\n","Current batch: Loss-> 1.1427, Train accuracy->  14.50%\n","Current batch: Loss-> 1.1322, Train accuracy->  14.57%\n","Current batch: Loss-> 1.1168, Train accuracy->  14.65%\n","Current batch: Loss-> 0.9184, Train accuracy->  14.73%\n","Current batch: Loss-> 1.0385, Train accuracy->  14.81%\n","Current batch: Loss-> 1.1107, Train accuracy->  14.88%\n","Current batch: Loss-> 1.1812, Train accuracy->  14.95%\n","Current batch: Loss-> 0.9991, Train accuracy->  15.03%\n","Current batch: Loss-> 1.1628, Train accuracy->  15.10%\n","Current batch: Loss-> 0.8671, Train accuracy->  15.19%\n","Current batch: Loss-> 1.1938, Train accuracy->  15.26%\n","Current batch: Loss-> 1.0179, Train accuracy->  15.32%\n","Current batch: Loss-> 1.2213, Train accuracy->  15.40%\n","Current batch: Loss-> 0.8953, Train accuracy->  15.49%\n","Current batch: Loss-> 1.1614, Train accuracy->  15.56%\n","Current batch: Loss-> 1.0142, Train accuracy->  15.65%\n","Current batch: Loss-> 0.8117, Train accuracy->  15.74%\n","Current batch: Loss-> 0.9528, Train accuracy->  15.82%\n","Current batch: Loss-> 1.0742, Train accuracy->  15.89%\n","Current batch: Loss-> 0.9959, Train accuracy->  15.97%\n","Current batch: Loss-> 0.9218, Train accuracy->  16.06%\n","Current batch: Loss-> 1.0451, Train accuracy->  16.14%\n","Current batch: Loss-> 1.0546, Train accuracy->  16.23%\n","Current batch: Loss-> 0.8991, Train accuracy->  16.33%\n","Current batch: Loss-> 1.0752, Train accuracy->  16.41%\n","Current batch: Loss-> 1.0516, Train accuracy->  16.49%\n","Current batch: Loss-> 1.1534, Train accuracy->  16.57%\n","Current batch: Loss-> 0.9645, Train accuracy->  16.66%\n","Current batch: Loss-> 0.9528, Train accuracy->  16.74%\n","Current batch: Loss-> 1.0644, Train accuracy->  16.82%\n","Current batch: Loss-> 0.8684, Train accuracy->  16.91%\n","Current batch: Loss-> 0.9602, Train accuracy->  17.00%\n","Current batch: Loss-> 1.0265, Train accuracy->  17.09%\n","Current batch: Loss-> 1.1928, Train accuracy->  17.18%\n","Current batch: Loss-> 0.9578, Train accuracy->  17.27%\n","Current batch: Loss-> 1.0264, Train accuracy->  17.36%\n","Current batch: Loss-> 1.2039, Train accuracy->  17.43%\n","Current batch: Loss-> 1.1531, Train accuracy->  17.51%\n","Current batch: Loss-> 1.3334, Train accuracy->  17.56%\n","Current batch: Loss-> 1.0348, Train accuracy->  17.64%\n","Current batch: Loss-> 1.0053, Train accuracy->  17.73%\n","Current batch: Loss-> 1.0899, Train accuracy->  17.81%\n","Current batch: Loss-> 1.1985, Train accuracy->  17.89%\n","Current batch: Loss-> 1.3797, Train accuracy->  17.97%\n","Current batch: Loss-> 1.2032, Train accuracy->  18.05%\n","Current batch: Loss-> 1.1510, Train accuracy->  18.14%\n","Current batch: Loss-> 1.0038, Train accuracy->  18.22%\n","Current batch: Loss-> 1.1973, Train accuracy->  18.30%\n","Current batch: Loss-> 1.0102, Train accuracy->  18.36%\n","Current batch: Loss-> 0.8800, Train accuracy->  18.46%\n","Current batch: Loss-> 1.2331, Train accuracy->  18.54%\n","Current batch: Loss-> 1.0246, Train accuracy->  18.61%\n","Current batch: Loss-> 1.6227, Train accuracy->  18.66%\n","Current batch: Loss-> 1.1889, Train accuracy->  18.75%\n","Current batch: Loss-> 1.1218, Train accuracy->  18.82%\n","Current batch: Loss-> 0.9413, Train accuracy->  18.89%\n","Current batch: Loss-> 0.9162, Train accuracy->  18.98%\n","Current batch: Loss-> 1.0884, Train accuracy->  19.06%\n","Current batch: Loss-> 0.9078, Train accuracy->  19.15%\n","Current batch: Loss-> 1.1835, Train accuracy->  19.23%\n","Current batch: Loss-> 1.0235, Train accuracy->  19.31%\n","Current batch: Loss-> 1.0350, Train accuracy->  19.39%\n","Current batch: Loss-> 0.9766, Train accuracy->  19.48%\n","Current batch: Loss-> 1.1105, Train accuracy->  19.55%\n","Current batch: Loss-> 1.1626, Train accuracy->  19.64%\n","Current batch: Loss-> 1.0010, Train accuracy->  19.73%\n","Current batch: Loss-> 0.9580, Train accuracy->  19.83%\n","Current batch: Loss-> 0.9224, Train accuracy->  19.92%\n","Current batch: Loss-> 1.0675, Train accuracy->  19.99%\n","Current batch: Loss-> 1.1287, Train accuracy->  20.06%\n","Current batch: Loss-> 1.1368, Train accuracy->  20.16%\n","Current batch: Loss-> 1.1901, Train accuracy->  20.23%\n","Current batch: Loss-> 0.9402, Train accuracy->  20.33%\n","Current batch: Loss-> 1.2455, Train accuracy->  20.40%\n","Current batch: Loss-> 1.1347, Train accuracy->  20.47%\n","Current batch: Loss-> 1.1900, Train accuracy->  20.54%\n","Current batch: Loss-> 1.2429, Train accuracy->  20.62%\n","Current batch: Loss-> 0.9732, Train accuracy->  20.71%\n","Current batch: Loss-> 1.3524, Train accuracy->  20.78%\n","Current batch: Loss-> 1.0635, Train accuracy->  20.85%\n","Current batch: Loss-> 1.0741, Train accuracy->  20.95%\n","Current batch: Loss-> 1.1509, Train accuracy->  21.03%\n","Current batch: Loss-> 0.9472, Train accuracy->  21.12%\n","Current batch: Loss-> 1.1823, Train accuracy->  21.19%\n","Current batch: Loss-> 0.9115, Train accuracy->  21.28%\n","Current batch: Loss-> 1.4653, Train accuracy->  21.36%\n","Current batch: Loss-> 1.0714, Train accuracy->  21.43%\n","Current batch: Loss-> 0.7677, Train accuracy->  21.53%\n","Current batch: Loss-> 1.0441, Train accuracy->  21.62%\n","Current batch: Loss-> 0.9230, Train accuracy->  21.71%\n","Current batch: Loss-> 1.2106, Train accuracy->  21.79%\n","Current batch: Loss-> 1.1105, Train accuracy->  21.88%\n","Current batch: Loss-> 0.9687, Train accuracy->  21.96%\n","Current batch: Loss-> 0.9083, Train accuracy->  22.05%\n","Current batch: Loss-> 1.0776, Train accuracy->  22.14%\n","Current batch: Loss-> 0.9846, Train accuracy->  22.23%\n","Current batch: Loss-> 1.0760, Train accuracy->  22.32%\n","Current batch: Loss-> 1.1150, Train accuracy->  22.41%\n","Current batch: Loss-> 1.1785, Train accuracy->  22.49%\n","Current batch: Loss-> 1.0060, Train accuracy->  22.58%\n","Current batch: Loss-> 0.9180, Train accuracy->  22.67%\n","Current batch: Loss-> 1.2586, Train accuracy->  22.74%\n","Current batch: Loss-> 1.0559, Train accuracy->  22.82%\n","Current batch: Loss-> 0.9766, Train accuracy->  22.91%\n","Current batch: Loss-> 1.1323, Train accuracy->  22.99%\n","Current batch: Loss-> 1.1065, Train accuracy->  23.07%\n","Current batch: Loss-> 1.0301, Train accuracy->  23.16%\n","Current batch: Loss-> 0.9421, Train accuracy->  23.24%\n","Current batch: Loss-> 0.9810, Train accuracy->  23.32%\n","Current batch: Loss-> 1.0621, Train accuracy->  23.40%\n","Current batch: Loss-> 1.0586, Train accuracy->  23.50%\n","Current batch: Loss-> 0.9766, Train accuracy->  23.58%\n","Current batch: Loss-> 0.9426, Train accuracy->  23.68%\n","Current batch: Loss-> 0.9355, Train accuracy->  23.76%\n","Current batch: Loss-> 1.0111, Train accuracy->  23.84%\n","Current batch: Loss-> 1.1950, Train accuracy->  23.92%\n","Current batch: Loss-> 1.1211, Train accuracy->  24.01%\n","Current batch: Loss-> 0.9258, Train accuracy->  24.10%\n","Current batch: Loss-> 1.1479, Train accuracy->  24.18%\n","Current batch: Loss-> 1.4367, Train accuracy->  24.24%\n","Current batch: Loss-> 1.2422, Train accuracy->  24.32%\n","Current batch: Loss-> 1.4039, Train accuracy->  24.38%\n","Current batch: Loss-> 1.0788, Train accuracy->  24.48%\n","Current batch: Loss-> 1.0723, Train accuracy->  24.55%\n","Current batch: Loss-> 0.9817, Train accuracy->  24.64%\n","Current batch: Loss-> 1.0629, Train accuracy->  24.72%\n","Current batch: Loss-> 1.1523, Train accuracy->  24.79%\n","Current batch: Loss-> 1.1650, Train accuracy->  24.85%\n","Current batch: Loss-> 1.1515, Train accuracy->  24.91%\n","Current batch: Loss-> 1.0946, Train accuracy->  25.00%\n","Current batch: Loss-> 1.0232, Train accuracy->  25.09%\n","Current batch: Loss-> 1.0807, Train accuracy->  25.16%\n","Current batch: Loss-> 1.3483, Train accuracy->  25.24%\n","Current batch: Loss-> 1.0639, Train accuracy->  25.32%\n","Current batch: Loss-> 1.0755, Train accuracy->  25.40%\n","Current batch: Loss-> 1.1090, Train accuracy->  25.48%\n","Current batch: Loss-> 0.9976, Train accuracy->  25.57%\n","Current batch: Loss-> 0.8301, Train accuracy->  25.67%\n","Current batch: Loss-> 1.1309, Train accuracy->  25.74%\n","Current batch: Loss-> 1.0694, Train accuracy->  25.82%\n","Current batch: Loss-> 1.0025, Train accuracy->  25.92%\n","Current batch: Loss-> 1.0959, Train accuracy->  25.99%\n","Current batch: Loss-> 1.3635, Train accuracy->  26.07%\n","Current batch: Loss-> 0.8227, Train accuracy->  26.17%\n","Current batch: Loss-> 1.3833, Train accuracy->  26.25%\n","Current batch: Loss-> 1.1249, Train accuracy->  26.32%\n","Current batch: Loss-> 0.9828, Train accuracy->  26.41%\n","Current batch: Loss-> 1.0294, Train accuracy->  26.49%\n","Current batch: Loss-> 1.0980, Train accuracy->  26.57%\n","Current batch: Loss-> 1.0679, Train accuracy->  26.65%\n","Current batch: Loss-> 1.1855, Train accuracy->  26.72%\n","Current batch: Loss-> 0.9274, Train accuracy->  26.81%\n","Current batch: Loss-> 0.8298, Train accuracy->  26.91%\n","Current batch: Loss-> 1.0506, Train accuracy->  26.98%\n","Current batch: Loss-> 0.9823, Train accuracy->  27.07%\n","Current batch: Loss-> 1.3751, Train accuracy->  27.14%\n","Current batch: Loss-> 0.9314, Train accuracy->  27.23%\n","Current batch: Loss-> 1.0532, Train accuracy->  27.31%\n","Current batch: Loss-> 0.9839, Train accuracy->  27.39%\n","Current batch: Loss-> 1.0944, Train accuracy->  27.48%\n","Current batch: Loss-> 1.1783, Train accuracy->  27.54%\n","Current batch: Loss-> 1.0626, Train accuracy->  27.62%\n","Current batch: Loss-> 0.8943, Train accuracy->  27.71%\n","Current batch: Loss-> 1.1557, Train accuracy->  27.79%\n","Current batch: Loss-> 1.0096, Train accuracy->  27.89%\n","Current batch: Loss-> 1.1557, Train accuracy->  27.96%\n","Current batch: Loss-> 0.9190, Train accuracy->  28.05%\n","Current batch: Loss-> 0.9456, Train accuracy->  28.14%\n","Current batch: Loss-> 1.1731, Train accuracy->  28.22%\n","Current batch: Loss-> 1.1649, Train accuracy->  28.31%\n","Current batch: Loss-> 1.0963, Train accuracy->  28.39%\n","Current batch: Loss-> 0.9063, Train accuracy->  28.48%\n","Current batch: Loss-> 1.1185, Train accuracy->  28.57%\n","Current batch: Loss-> 1.0542, Train accuracy->  28.65%\n","Current batch: Loss-> 0.9689, Train accuracy->  28.74%\n","Current batch: Loss-> 1.0173, Train accuracy->  28.81%\n","Current batch: Loss-> 1.0150, Train accuracy->  28.89%\n","Current batch: Loss-> 1.2067, Train accuracy->  28.97%\n","Current batch: Loss-> 1.2344, Train accuracy->  29.04%\n","Current batch: Loss-> 0.9396, Train accuracy->  29.13%\n","Current batch: Loss-> 1.0712, Train accuracy->  29.21%\n","Current batch: Loss-> 1.1539, Train accuracy->  29.29%\n","Current batch: Loss-> 1.1824, Train accuracy->  29.36%\n","Current batch: Loss-> 1.1948, Train accuracy->  29.45%\n","Current batch: Loss-> 0.9934, Train accuracy->  29.52%\n","Current batch: Loss-> 0.9481, Train accuracy->  29.61%\n","Current batch: Loss-> 1.2492, Train accuracy->  29.70%\n","Current batch: Loss-> 0.9148, Train accuracy->  29.80%\n","Current batch: Loss-> 0.9834, Train accuracy->  29.88%\n","Current batch: Loss-> 1.2451, Train accuracy->  29.95%\n","Current batch: Loss-> 1.1694, Train accuracy->  30.03%\n","Current batch: Loss-> 0.9474, Train accuracy->  30.11%\n","Current batch: Loss-> 1.5069, Train accuracy->  30.19%\n","Current batch: Loss-> 1.2741, Train accuracy->  30.25%\n","Current batch: Loss-> 1.0552, Train accuracy->  30.34%\n","Current batch: Loss-> 1.1065, Train accuracy->  30.42%\n","Current batch: Loss-> 1.0779, Train accuracy->  30.50%\n","Current batch: Loss-> 1.0224, Train accuracy->  30.60%\n","Current batch: Loss-> 1.0076, Train accuracy->  30.68%\n","Current batch: Loss-> 1.1480, Train accuracy->  30.76%\n","Current batch: Loss-> 0.9859, Train accuracy->  30.85%\n","Current batch: Loss-> 0.9728, Train accuracy->  30.92%\n","Current batch: Loss-> 0.9799, Train accuracy->  31.00%\n","Current batch: Loss-> 0.8785, Train accuracy->  31.08%\n","Current batch: Loss-> 1.0325, Train accuracy->  31.18%\n","Current batch: Loss-> 1.0746, Train accuracy->  31.27%\n","Current batch: Loss-> 1.1713, Train accuracy->  31.35%\n","Current batch: Loss-> 0.9802, Train accuracy->  31.42%\n","Current batch: Loss-> 0.9638, Train accuracy->  31.50%\n","Current batch: Loss-> 1.1590, Train accuracy->  31.55%\n","Current batch: Loss-> 1.0576, Train accuracy->  31.64%\n","Current batch: Loss-> 0.9366, Train accuracy->  31.73%\n","Current batch: Loss-> 0.9140, Train accuracy->  31.81%\n","Current batch: Loss-> 1.0517, Train accuracy->  31.89%\n","Current batch: Loss-> 0.9094, Train accuracy->  31.98%\n","Current batch: Loss-> 0.8646, Train accuracy->  32.06%\n","Current batch: Loss-> 1.1878, Train accuracy->  32.14%\n","Current batch: Loss-> 1.1537, Train accuracy->  32.21%\n","Current batch: Loss-> 0.8976, Train accuracy->  32.30%\n","Current batch: Loss-> 1.3520, Train accuracy->  32.37%\n","Current batch: Loss-> 1.2145, Train accuracy->  32.44%\n","Current batch: Loss-> 0.9791, Train accuracy->  32.54%\n","Current batch: Loss-> 1.5841, Train accuracy->  32.61%\n","Current batch: Loss-> 0.8397, Train accuracy->  32.70%\n","Current batch: Loss-> 0.9022, Train accuracy->  32.80%\n","Current batch: Loss-> 1.0162, Train accuracy->  32.88%\n","Current batch: Loss-> 0.8632, Train accuracy->  32.97%\n","Current batch: Loss-> 1.3343, Train accuracy->  33.04%\n","Current batch: Loss-> 1.0179, Train accuracy->  33.11%\n","Current batch: Loss-> 1.0926, Train accuracy->  33.20%\n","Current batch: Loss-> 1.0569, Train accuracy->  33.27%\n","Current batch: Loss-> 1.0187, Train accuracy->  33.35%\n","Current batch: Loss-> 0.8398, Train accuracy->  33.44%\n","Current batch: Loss-> 1.0807, Train accuracy->  33.52%\n","Current batch: Loss-> 1.0791, Train accuracy->  33.59%\n","Current batch: Loss-> 1.2552, Train accuracy->  33.67%\n","Current batch: Loss-> 1.0308, Train accuracy->  33.76%\n","Current batch: Loss-> 0.9916, Train accuracy->  33.86%\n","Current batch: Loss-> 0.9390, Train accuracy->  33.95%\n","Current batch: Loss-> 1.0249, Train accuracy->  34.04%\n","Current batch: Loss-> 0.9002, Train accuracy->  34.15%\n","Current batch: Loss-> 0.9491, Train accuracy->  34.23%\n","Current batch: Loss-> 1.1434, Train accuracy->  34.33%\n","Current batch: Loss-> 1.2470, Train accuracy->  34.39%\n","Current batch: Loss-> 1.1024, Train accuracy->  34.48%\n","Current batch: Loss-> 1.1833, Train accuracy->  34.55%\n","Current batch: Loss-> 0.9404, Train accuracy->  34.65%\n","Current batch: Loss-> 1.1869, Train accuracy->  34.72%\n","Current batch: Loss-> 1.0627, Train accuracy->  34.81%\n","Current batch: Loss-> 1.0531, Train accuracy->  34.89%\n","Current batch: Loss-> 0.9370, Train accuracy->  34.98%\n","Current batch: Loss-> 0.8526, Train accuracy->  35.08%\n","Current batch: Loss-> 1.1180, Train accuracy->  35.15%\n","Current batch: Loss-> 1.1976, Train accuracy->  35.23%\n","Current batch: Loss-> 1.0244, Train accuracy->  35.31%\n","Current batch: Loss-> 0.8994, Train accuracy->  35.40%\n","Current batch: Loss-> 0.7907, Train accuracy->  35.49%\n","Current batch: Loss-> 0.9382, Train accuracy->  35.57%\n","Current batch: Loss-> 0.9546, Train accuracy->  35.66%\n","Current batch: Loss-> 1.0808, Train accuracy->  35.74%\n","Current batch: Loss-> 1.1394, Train accuracy->  35.83%\n","Current batch: Loss-> 0.9803, Train accuracy->  35.92%\n","Current batch: Loss-> 1.0552, Train accuracy->  36.00%\n","Current batch: Loss-> 1.0176, Train accuracy->  36.09%\n","Current batch: Loss-> 1.0900, Train accuracy->  36.17%\n","Current batch: Loss-> 1.2283, Train accuracy->  36.24%\n","Current batch: Loss-> 1.1249, Train accuracy->  36.31%\n","Current batch: Loss-> 1.0500, Train accuracy->  36.39%\n","Current batch: Loss-> 1.2489, Train accuracy->  36.47%\n","Current batch: Loss-> 1.3922, Train accuracy->  36.54%\n","Current batch: Loss-> 1.1550, Train accuracy->  36.61%\n","Current batch: Loss-> 1.0096, Train accuracy->  36.70%\n","Current batch: Loss-> 0.9762, Train accuracy->  36.78%\n","Current batch: Loss-> 0.9503, Train accuracy->  36.87%\n","Current batch: Loss-> 1.2345, Train accuracy->  36.94%\n","Current batch: Loss-> 1.3442, Train accuracy->  37.01%\n","Current batch: Loss-> 1.0338, Train accuracy->  37.09%\n","Current batch: Loss-> 0.9137, Train accuracy->  37.17%\n","Current batch: Loss-> 0.8823, Train accuracy->  37.26%\n","Current batch: Loss-> 1.0306, Train accuracy->  37.34%\n","Current batch: Loss-> 1.2020, Train accuracy->  37.42%\n","Current batch: Loss-> 1.1569, Train accuracy->  37.50%\n","Current batch: Loss-> 1.0716, Train accuracy->  37.58%\n","Current batch: Loss-> 1.1180, Train accuracy->  37.67%\n","Current batch: Loss-> 0.6591, Train accuracy->  37.78%\n","Current batch: Loss-> 1.0533, Train accuracy->  37.87%\n","Current batch: Loss-> 0.9045, Train accuracy->  37.95%\n","Current batch: Loss-> 0.7888, Train accuracy->  38.06%\n","Current batch: Loss-> 0.9182, Train accuracy->  38.14%\n","Current batch: Loss-> 0.9729, Train accuracy->  38.23%\n","Current batch: Loss-> 0.9798, Train accuracy->  38.31%\n","Current batch: Loss-> 1.0805, Train accuracy->  38.40%\n","Current batch: Loss-> 0.9916, Train accuracy->  38.49%\n","Current batch: Loss-> 0.8927, Train accuracy->  38.58%\n","Current batch: Loss-> 1.0771, Train accuracy->  38.67%\n","Current batch: Loss-> 0.9841, Train accuracy->  38.76%\n","Current batch: Loss-> 0.9234, Train accuracy->  38.87%\n","Current batch: Loss-> 0.8992, Train accuracy->  38.95%\n","Current batch: Loss-> 1.2713, Train accuracy->  39.03%\n","Current batch: Loss-> 0.9955, Train accuracy->  39.13%\n","Current batch: Loss-> 1.0852, Train accuracy->  39.21%\n","Current batch: Loss-> 0.9353, Train accuracy->  39.29%\n","Current batch: Loss-> 0.8904, Train accuracy->  39.39%\n","Current batch: Loss-> 0.9457, Train accuracy->  39.47%\n","Current batch: Loss-> 1.1100, Train accuracy->  39.55%\n","Current batch: Loss-> 0.8885, Train accuracy->  39.65%\n","Current batch: Loss-> 1.0567, Train accuracy->  39.74%\n","Current batch: Loss-> 1.1150, Train accuracy->  39.83%\n","Current batch: Loss-> 0.8419, Train accuracy->  39.92%\n","Current batch: Loss-> 1.2242, Train accuracy->  40.00%\n","Current batch: Loss-> 0.8893, Train accuracy->  40.10%\n","Current batch: Loss-> 1.0049, Train accuracy->  40.19%\n","Current batch: Loss-> 1.0463, Train accuracy->  40.27%\n","Current batch: Loss-> 1.2125, Train accuracy->  40.36%\n","Current batch: Loss-> 0.9953, Train accuracy->  40.45%\n","Current batch: Loss-> 1.1962, Train accuracy->  40.52%\n","Current batch: Loss-> 0.8929, Train accuracy->  40.60%\n","Current batch: Loss-> 1.0650, Train accuracy->  40.68%\n","Current batch: Loss-> 1.2378, Train accuracy->  40.74%\n","Current batch: Loss-> 1.1364, Train accuracy->  40.82%\n","Current batch: Loss-> 0.9134, Train accuracy->  40.91%\n","Current batch: Loss-> 1.1248, Train accuracy->  40.99%\n","Current batch: Loss-> 1.0162, Train accuracy->  41.07%\n","Current batch: Loss-> 1.1903, Train accuracy->  41.15%\n","Current batch: Loss-> 0.7953, Train accuracy->  41.24%\n","Current batch: Loss-> 0.9601, Train accuracy->  41.33%\n","Current batch: Loss-> 1.0901, Train accuracy->  41.42%\n","Current batch: Loss-> 1.1177, Train accuracy->  41.50%\n","Current batch: Loss-> 1.1018, Train accuracy->  41.58%\n","Current batch: Loss-> 1.0071, Train accuracy->  41.65%\n","Current batch: Loss-> 1.1115, Train accuracy->  41.74%\n","Current batch: Loss-> 1.2129, Train accuracy->  41.81%\n","Current batch: Loss-> 0.8491, Train accuracy->  41.90%\n","Current batch: Loss-> 1.2935, Train accuracy->  41.97%\n","Current batch: Loss-> 1.1897, Train accuracy->  42.05%\n","Current batch: Loss-> 0.9261, Train accuracy->  42.13%\n","Current batch: Loss-> 0.9109, Train accuracy->  42.21%\n","Current batch: Loss-> 0.8470, Train accuracy->  42.30%\n","Current batch: Loss-> 1.2101, Train accuracy->  42.39%\n","Current batch: Loss-> 1.0685, Train accuracy->  42.47%\n","Current batch: Loss-> 0.9699, Train accuracy->  42.55%\n","Current batch: Loss-> 1.1617, Train accuracy->  42.65%\n","Current batch: Loss-> 0.8433, Train accuracy->  42.73%\n","Current batch: Loss-> 0.7500, Train accuracy->  42.85%\n","Current batch: Loss-> 0.7555, Train accuracy->  42.95%\n","Current batch: Loss-> 0.7665, Train accuracy->  43.05%\n","Current batch: Loss-> 1.0680, Train accuracy->  43.12%\n","Current batch: Loss-> 0.9275, Train accuracy->  43.22%\n","Current batch: Loss-> 1.2150, Train accuracy->  43.30%\n","Current batch: Loss-> 0.9460, Train accuracy->  43.38%\n","Current batch: Loss-> 0.9643, Train accuracy->  43.46%\n","Current batch: Loss-> 1.1001, Train accuracy->  43.55%\n","Current batch: Loss-> 1.3297, Train accuracy->  43.63%\n","Current batch: Loss-> 1.1284, Train accuracy->  43.71%\n","Current batch: Loss-> 1.2055, Train accuracy->  43.80%\n","Current batch: Loss-> 1.1329, Train accuracy->  43.88%\n","Current batch: Loss-> 1.1550, Train accuracy->  43.96%\n","Current batch: Loss-> 1.1169, Train accuracy->  44.04%\n","Current batch: Loss-> 0.9580, Train accuracy->  44.12%\n","Current batch: Loss-> 1.0340, Train accuracy->  44.20%\n","Current batch: Loss-> 0.8451, Train accuracy->  44.30%\n","Current batch: Loss-> 1.0980, Train accuracy->  44.37%\n","Current batch: Loss-> 0.9855, Train accuracy->  44.47%\n","Current batch: Loss-> 0.9965, Train accuracy->  44.56%\n","Current batch: Loss-> 0.9462, Train accuracy->  44.65%\n","Current batch: Loss-> 0.8095, Train accuracy->  44.75%\n","Current batch: Loss-> 0.8361, Train accuracy->  44.84%\n","Current batch: Loss-> 1.1957, Train accuracy->  44.91%\n","Current batch: Loss-> 1.2049, Train accuracy->  45.00%\n","Current batch: Loss-> 0.8914, Train accuracy->  45.10%\n","Current batch: Loss-> 0.8170, Train accuracy->  45.19%\n","Current batch: Loss-> 0.8834, Train accuracy->  45.28%\n","Current batch: Loss-> 0.8426, Train accuracy->  45.37%\n","Current batch: Loss-> 1.0451, Train accuracy->  45.45%\n","Current batch: Loss-> 0.9542, Train accuracy->  45.54%\n","Current batch: Loss-> 0.8875, Train accuracy->  45.63%\n","Current batch: Loss-> 0.8853, Train accuracy->  45.72%\n","Current batch: Loss-> 1.0129, Train accuracy->  45.82%\n","Current batch: Loss-> 1.1113, Train accuracy->  45.90%\n","Current batch: Loss-> 1.1655, Train accuracy->  45.98%\n","Current batch: Loss-> 1.0008, Train accuracy->  46.06%\n","Current batch: Loss-> 1.2829, Train accuracy->  46.13%\n","Current batch: Loss-> 1.1728, Train accuracy->  46.21%\n","Current batch: Loss-> 1.0936, Train accuracy->  46.29%\n","Current batch: Loss-> 0.8532, Train accuracy->  46.39%\n","Current batch: Loss-> 0.9847, Train accuracy->  46.48%\n","Current batch: Loss-> 0.9497, Train accuracy->  46.57%\n","Current batch: Loss-> 0.9742, Train accuracy->  46.65%\n","Current batch: Loss-> 0.8950, Train accuracy->  46.73%\n","Current batch: Loss-> 0.9693, Train accuracy->  46.82%\n","Current batch: Loss-> 1.3563, Train accuracy->  46.89%\n","Current batch: Loss-> 1.3609, Train accuracy->  46.96%\n","Current batch: Loss-> 1.1456, Train accuracy->  47.04%\n","Current batch: Loss-> 1.2291, Train accuracy->  47.11%\n","Current batch: Loss-> 0.7412, Train accuracy->  47.21%\n","Current batch: Loss-> 1.1149, Train accuracy->  47.30%\n","Current batch: Loss-> 0.9658, Train accuracy->  47.39%\n","Current batch: Loss-> 1.0025, Train accuracy->  47.47%\n","Current batch: Loss-> 0.9710, Train accuracy->  47.57%\n","Current batch: Loss-> 1.0691, Train accuracy->  47.65%\n","Current batch: Loss-> 1.1456, Train accuracy->  47.73%\n","Current batch: Loss-> 1.0706, Train accuracy->  47.81%\n","Current batch: Loss-> 0.9951, Train accuracy->  47.90%\n","Current batch: Loss-> 1.1849, Train accuracy->  47.98%\n","Current batch: Loss-> 1.2042, Train accuracy->  48.06%\n","Current batch: Loss-> 0.9828, Train accuracy->  48.15%\n","Current batch: Loss-> 0.9141, Train accuracy->  48.24%\n","Current batch: Loss-> 0.9363, Train accuracy->  48.33%\n","Current batch: Loss-> 0.9750, Train accuracy->  48.42%\n","Current batch: Loss-> 0.9991, Train accuracy->  48.51%\n","Current batch: Loss-> 0.9048, Train accuracy->  48.60%\n","Current batch: Loss-> 1.2994, Train accuracy->  48.68%\n","Current batch: Loss-> 1.1053, Train accuracy->  48.76%\n","Current batch: Loss-> 0.9657, Train accuracy->  48.85%\n","Current batch: Loss-> 0.8657, Train accuracy->  48.94%\n","Current batch: Loss-> 0.9005, Train accuracy->  49.04%\n","Current batch: Loss-> 0.8924, Train accuracy->  49.13%\n","Current batch: Loss-> 0.8250, Train accuracy->  49.22%\n","Current batch: Loss-> 0.9562, Train accuracy->  49.30%\n","Current batch: Loss-> 1.1243, Train accuracy->  49.39%\n","Current batch: Loss-> 0.9241, Train accuracy->  49.48%\n","Current batch: Loss-> 1.0243, Train accuracy->  49.57%\n","Current batch: Loss-> 1.0891, Train accuracy->  49.66%\n","Current batch: Loss-> 0.7628, Train accuracy->  49.76%\n","Current batch: Loss-> 0.9196, Train accuracy->  49.85%\n","Current batch: Loss-> 1.0442, Train accuracy->  49.94%\n","Current batch: Loss-> 0.8289, Train accuracy->  50.02%\n","Current batch: Loss-> 1.1590, Train accuracy->  50.10%\n","Current batch: Loss-> 1.1153, Train accuracy->  50.17%\n","Current batch: Loss-> 0.9819, Train accuracy->  50.26%\n","Current batch: Loss-> 0.8628, Train accuracy->  50.35%\n","Current batch: Loss-> 1.0853, Train accuracy->  50.42%\n","Current batch: Loss-> 1.3796, Train accuracy->  50.49%\n","Current batch: Loss-> 1.0993, Train accuracy->  50.57%\n","Current batch: Loss-> 1.0135, Train accuracy->  50.65%\n","Current batch: Loss-> 1.0195, Train accuracy->  50.73%\n","Current batch: Loss-> 0.9961, Train accuracy->  50.83%\n","Current batch: Loss-> 1.1402, Train accuracy->  50.90%\n","Current batch: Loss-> 0.9722, Train accuracy->  50.99%\n","Current batch: Loss-> 0.9596, Train accuracy->  51.07%\n","Current batch: Loss-> 1.0438, Train accuracy->  51.16%\n","Current batch: Loss-> 1.0523, Train accuracy->  51.24%\n","Current batch: Loss-> 1.0836, Train accuracy->  51.32%\n","Current batch: Loss-> 0.8371, Train accuracy->  51.41%\n","Current batch: Loss-> 0.9952, Train accuracy->  51.50%\n","Current batch: Loss-> 1.1697, Train accuracy->  51.58%\n","Current batch: Loss-> 0.9141, Train accuracy->  51.68%\n","Current batch: Loss-> 1.0711, Train accuracy->  51.76%\n","Current batch: Loss-> 0.8120, Train accuracy->  51.85%\n","Current batch: Loss-> 0.8654, Train accuracy->  51.95%\n","Current batch: Loss-> 1.0826, Train accuracy->  52.04%\n","Current batch: Loss-> 1.2628, Train accuracy->  52.12%\n","Current batch: Loss-> 0.7632, Train accuracy->  52.23%\n","Current batch: Loss-> 0.8372, Train accuracy->  52.33%\n","Current batch: Loss-> 0.9741, Train accuracy->  52.42%\n","Current batch: Loss-> 1.2307, Train accuracy->  52.50%\n","Current batch: Loss-> 0.9408, Train accuracy->  52.60%\n","Current batch: Loss-> 1.2089, Train accuracy->  52.68%\n","Current batch: Loss-> 0.8234, Train accuracy->  52.79%\n","Current batch: Loss-> 0.8096, Train accuracy->  52.89%\n","Current batch: Loss-> 1.1862, Train accuracy->  52.96%\n","Current batch: Loss-> 1.1389, Train accuracy->  53.04%\n","Current batch: Loss-> 1.0365, Train accuracy->  53.14%\n","Current batch: Loss-> 1.1559, Train accuracy->  53.22%\n","Current batch: Loss-> 0.9235, Train accuracy->  53.32%\n","Current batch: Loss-> 1.1239, Train accuracy->  53.40%\n","Current batch: Loss-> 0.9001, Train accuracy->  53.50%\n","Current batch: Loss-> 1.0073, Train accuracy->  53.59%\n","Current batch: Loss-> 1.0883, Train accuracy->  53.67%\n","Current batch: Loss-> 1.0093, Train accuracy->  53.76%\n","Current batch: Loss-> 1.0847, Train accuracy->  53.85%\n","Current batch: Loss-> 0.8862, Train accuracy->  53.95%\n","Current batch: Loss-> 0.9939, Train accuracy->  54.03%\n","Current batch: Loss-> 0.9355, Train accuracy->  54.11%\n","Current batch: Loss-> 1.0790, Train accuracy->  54.20%\n","Current batch: Loss-> 1.0070, Train accuracy->  54.29%\n","Current batch: Loss-> 1.0872, Train accuracy->  54.38%\n","Current batch: Loss-> 1.1107, Train accuracy->  54.45%\n","Current batch: Loss-> 0.9114, Train accuracy->  54.54%\n","Current batch: Loss-> 0.7808, Train accuracy->  54.63%\n","Current batch: Loss-> 1.1756, Train accuracy->  54.71%\n","Current batch: Loss-> 0.8008, Train accuracy->  54.81%\n","Current batch: Loss-> 1.0110, Train accuracy->  54.90%\n","Current batch: Loss-> 1.1482, Train accuracy->  54.98%\n","Current batch: Loss-> 1.1113, Train accuracy->  55.07%\n","Current batch: Loss-> 1.0948, Train accuracy->  55.16%\n","Current batch: Loss-> 0.9536, Train accuracy->  55.25%\n","Current batch: Loss-> 1.0539, Train accuracy->  55.34%\n","Current batch: Loss-> 1.2258, Train accuracy->  55.42%\n","Current batch: Loss-> 0.9631, Train accuracy->  55.49%\n","Current batch: Loss-> 1.0765, Train accuracy->  55.57%\n","Current batch: Loss-> 1.0095, Train accuracy->  55.65%\n","Current batch: Loss-> 1.0093, Train accuracy->  55.74%\n","Current batch: Loss-> 0.9025, Train accuracy->  55.82%\n","Current batch: Loss-> 0.8354, Train accuracy->  55.91%\n","Current batch: Loss-> 1.0913, Train accuracy->  56.00%\n","Current batch: Loss-> 1.1066, Train accuracy->  56.08%\n","Current batch: Loss-> 1.1517, Train accuracy->  56.16%\n","Current batch: Loss-> 0.9783, Train accuracy->  56.24%\n","Current batch: Loss-> 0.9706, Train accuracy->  56.32%\n","Current batch: Loss-> 0.7966, Train accuracy->  56.42%\n","Current batch: Loss-> 0.9082, Train accuracy->  56.52%\n","Current batch: Loss-> 0.8540, Train accuracy->  56.62%\n","Current batch: Loss-> 0.8037, Train accuracy->  56.71%\n","Current batch: Loss-> 0.9199, Train accuracy->  56.80%\n","Current batch: Loss-> 0.8430, Train accuracy->  56.90%\n","Current batch: Loss-> 0.9424, Train accuracy->  56.98%\n","Current batch: Loss-> 1.2163, Train accuracy->  57.06%\n","Current batch: Loss-> 1.1721, Train accuracy->  57.15%\n","Current batch: Loss-> 1.2194, Train accuracy->  57.22%\n","Current batch: Loss-> 1.3074, Train accuracy->  57.29%\n","Current batch: Loss-> 1.1157, Train accuracy->  57.37%\n","Current batch: Loss-> 0.9571, Train accuracy->  57.45%\n","Current batch: Loss-> 1.1275, Train accuracy->  57.52%\n","Current batch: Loss-> 1.0990, Train accuracy->  57.61%\n","Current batch: Loss-> 1.0336, Train accuracy->  57.70%\n","Current batch: Loss-> 0.8837, Train accuracy->  57.80%\n","Current batch: Loss-> 0.9573, Train accuracy->  57.89%\n","Current batch: Loss-> 0.7974, Train accuracy->  57.99%\n","Current batch: Loss-> 0.9173, Train accuracy->  58.08%\n","Current batch: Loss-> 0.8769, Train accuracy->  58.17%\n","Current batch: Loss-> 0.9221, Train accuracy->  58.27%\n","Current batch: Loss-> 0.8349, Train accuracy->  58.36%\n","Current batch: Loss-> 1.1284, Train accuracy->  58.45%\n","Current batch: Loss-> 1.3021, Train accuracy->  58.52%\n","Current batch: Loss-> 0.9410, Train accuracy->  58.60%\n","Current batch: Loss-> 1.1233, Train accuracy->  58.70%\n","Current batch: Loss-> 1.0177, Train accuracy->  58.79%\n","Current batch: Loss-> 0.7870, Train accuracy->  58.89%\n","Current batch: Loss-> 0.9771, Train accuracy->  58.99%\n","Current batch: Loss-> 1.1158, Train accuracy->  59.08%\n","Current batch: Loss-> 0.8010, Train accuracy->  59.18%\n","Current batch: Loss-> 1.0764, Train accuracy->  59.27%\n","Current batch: Loss-> 0.9634, Train accuracy->  59.36%\n","Current batch: Loss-> 1.0753, Train accuracy->  59.45%\n","Current batch: Loss-> 1.1536, Train accuracy->  59.53%\n","Current batch: Loss-> 1.1047, Train accuracy->  59.60%\n","Current batch: Loss-> 0.9749, Train accuracy->  59.69%\n","Current batch: Loss-> 1.2265, Train accuracy->  59.78%\n","Current batch: Loss-> 1.0251, Train accuracy->  59.87%\n","Current batch: Loss-> 0.8967, Train accuracy->  59.97%\n","Current batch: Loss-> 1.0801, Train accuracy->  60.05%\n","Current batch: Loss-> 1.0040, Train accuracy->  60.14%\n","Current batch: Loss-> 1.0140, Train accuracy->  60.24%\n","Current batch: Loss-> 1.0621, Train accuracy->  60.33%\n","Current batch: Loss-> 1.0097, Train accuracy->  60.42%\n","Current batch: Loss-> 1.1706, Train accuracy->  60.50%\n","Current batch: Loss-> 1.0826, Train accuracy->  60.59%\n","Current batch: Loss-> 1.1209, Train accuracy->  60.66%\n","Current batch: Loss-> 1.1813, Train accuracy->  60.74%\n","Current batch: Loss-> 1.2789, Train accuracy->  60.79%\n","Current batch: Loss-> 1.0583, Train accuracy->  60.87%\n","Current batch: Loss-> 0.9439, Train accuracy->  60.97%\n","Current batch: Loss-> 0.9321, Train accuracy->  61.05%\n","Current batch: Loss-> 1.1561, Train accuracy->  61.14%\n","Current batch: Loss-> 1.1733, Train accuracy->  61.21%\n","Current batch: Loss-> 1.2152, Train accuracy->  61.30%\n","Current batch: Loss-> 1.1065, Train accuracy->  61.38%\n","Current batch: Loss-> 1.4215, Train accuracy->  61.45%\n","Current batch: Loss-> 1.3114, Train accuracy->  61.51%\n","Current batch: Loss-> 1.1506, Train accuracy->  61.60%\n","Current batch: Loss-> 1.1548, Train accuracy->  61.68%\n","Current batch: Loss-> 1.1710, Train accuracy->  61.76%\n","Current batch: Loss-> 1.0603, Train accuracy->  61.85%\n","Current batch: Loss-> 1.0073, Train accuracy->  61.94%\n","Current batch: Loss-> 1.0919, Train accuracy->  62.01%\n","Current batch: Loss-> 1.1926, Train accuracy->  62.09%\n","Current batch: Loss-> 0.9624, Train accuracy->  62.18%\n","Current batch: Loss-> 1.0167, Train accuracy->  62.27%\n","Current batch: Loss-> 1.1475, Train accuracy->  62.35%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:04, 44.72it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.2589, Train accuracy->  62.42%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.5772, Accuracy: 4386/12000 (37%)\n","\n","Current batch: Loss-> 1.1585, Train accuracy->   0.08%\n","Current batch: Loss-> 1.1872, Train accuracy->   0.16%\n","Current batch: Loss-> 1.2288, Train accuracy->   0.23%\n","Current batch: Loss-> 1.0377, Train accuracy->   0.31%\n","Current batch: Loss-> 0.9056, Train accuracy->   0.40%\n","Current batch: Loss-> 1.0392, Train accuracy->   0.49%\n","Current batch: Loss-> 0.9678, Train accuracy->   0.57%\n","Current batch: Loss-> 1.0308, Train accuracy->   0.66%\n","Current batch: Loss-> 1.0541, Train accuracy->   0.75%\n","Current batch: Loss-> 0.9747, Train accuracy->   0.84%\n","Current batch: Loss-> 0.8983, Train accuracy->   0.93%\n","Current batch: Loss-> 0.9496, Train accuracy->   1.01%\n","Current batch: Loss-> 0.9564, Train accuracy->   1.11%\n","Current batch: Loss-> 1.0286, Train accuracy->   1.20%\n","Current batch: Loss-> 0.9668, Train accuracy->   1.30%\n","Current batch: Loss-> 1.1055, Train accuracy->   1.37%\n","Current batch: Loss-> 0.9423, Train accuracy->   1.46%\n","Current batch: Loss-> 1.2646, Train accuracy->   1.55%\n","Current batch: Loss-> 1.0366, Train accuracy->   1.64%\n","Current batch: Loss-> 1.0148, Train accuracy->   1.72%\n","Current batch: Loss-> 0.9215, Train accuracy->   1.80%\n","Current batch: Loss-> 1.1100, Train accuracy->   1.88%\n","Current batch: Loss-> 0.9436, Train accuracy->   1.97%\n","Current batch: Loss-> 1.1039, Train accuracy->   2.06%\n","Current batch: Loss-> 1.1568, Train accuracy->   2.14%\n","Current batch: Loss-> 1.1142, Train accuracy->   2.22%\n","Current batch: Loss-> 1.0148, Train accuracy->   2.30%\n","Current batch: Loss-> 1.2340, Train accuracy->   2.39%\n","Current batch: Loss-> 0.9717, Train accuracy->   2.48%\n","Current batch: Loss-> 1.0103, Train accuracy->   2.58%\n","Current batch: Loss-> 1.0177, Train accuracy->   2.66%\n","Current batch: Loss-> 1.0178, Train accuracy->   2.76%\n","Current batch: Loss-> 0.7577, Train accuracy->   2.87%\n","Current batch: Loss-> 1.1081, Train accuracy->   2.95%\n","Current batch: Loss-> 0.8875, Train accuracy->   3.06%\n","Current batch: Loss-> 0.8880, Train accuracy->   3.15%\n","Current batch: Loss-> 1.1510, Train accuracy->   3.23%\n","Current batch: Loss-> 0.9650, Train accuracy->   3.32%\n","Current batch: Loss-> 1.0164, Train accuracy->   3.40%\n","Current batch: Loss-> 1.1331, Train accuracy->   3.47%\n","Current batch: Loss-> 0.8820, Train accuracy->   3.56%\n","Current batch: Loss-> 1.0549, Train accuracy->   3.65%\n","Current batch: Loss-> 1.0021, Train accuracy->   3.74%\n","Current batch: Loss-> 1.1451, Train accuracy->   3.82%\n","Current batch: Loss-> 0.9658, Train accuracy->   3.91%\n","Current batch: Loss-> 0.7827, Train accuracy->   4.01%\n","Current batch: Loss-> 1.2601, Train accuracy->   4.06%\n","Current batch: Loss-> 0.9414, Train accuracy->   4.16%\n","Current batch: Loss-> 1.2976, Train accuracy->   4.25%\n","Current batch: Loss-> 1.0086, Train accuracy->   4.33%\n","Current batch: Loss-> 0.9246, Train accuracy->   4.42%\n","Current batch: Loss-> 1.0706, Train accuracy->   4.49%\n","Current batch: Loss-> 1.0008, Train accuracy->   4.58%\n","Current batch: Loss-> 1.4583, Train accuracy->   4.65%\n","Current batch: Loss-> 0.9040, Train accuracy->   4.74%\n","Current batch: Loss-> 1.0548, Train accuracy->   4.83%\n","Current batch: Loss-> 0.9053, Train accuracy->   4.93%\n","Current batch: Loss-> 1.0148, Train accuracy->   5.01%\n","Current batch: Loss-> 0.8763, Train accuracy->   5.11%\n","Current batch: Loss-> 0.9487, Train accuracy->   5.19%\n","Current batch: Loss-> 0.9071, Train accuracy->   5.29%\n","Current batch: Loss-> 0.8648, Train accuracy->   5.37%\n","Current batch: Loss-> 0.9259, Train accuracy->   5.46%\n","Current batch: Loss-> 1.0720, Train accuracy->   5.55%\n","Current batch: Loss-> 1.1394, Train accuracy->   5.62%\n","Current batch: Loss-> 1.2689, Train accuracy->   5.70%\n","Current batch: Loss-> 0.9570, Train accuracy->   5.79%\n","Current batch: Loss-> 1.0927, Train accuracy->   5.86%\n","Current batch: Loss-> 0.9617, Train accuracy->   5.95%\n","Current batch: Loss-> 0.8400, Train accuracy->   6.05%\n","Current batch: Loss-> 0.7887, Train accuracy->   6.15%\n","Current batch: Loss-> 1.3280, Train accuracy->   6.23%\n","Current batch: Loss-> 1.1820, Train accuracy->   6.31%\n","Current batch: Loss-> 1.1467, Train accuracy->   6.39%\n","Current batch: Loss-> 0.9975, Train accuracy->   6.49%\n","Current batch: Loss-> 0.9972, Train accuracy->   6.57%\n","Current batch: Loss-> 0.9538, Train accuracy->   6.66%\n","Current batch: Loss-> 0.9690, Train accuracy->   6.74%\n","Current batch: Loss-> 0.9358, Train accuracy->   6.83%\n","Current batch: Loss-> 0.8599, Train accuracy->   6.93%\n","Current batch: Loss-> 1.2255, Train accuracy->   7.00%\n","Current batch: Loss-> 0.8347, Train accuracy->   7.09%\n","Current batch: Loss-> 1.0705, Train accuracy->   7.16%\n","Current batch: Loss-> 0.8279, Train accuracy->   7.26%\n","Current batch: Loss-> 0.9865, Train accuracy->   7.34%\n","Current batch: Loss-> 1.0928, Train accuracy->   7.44%\n","Current batch: Loss-> 0.8730, Train accuracy->   7.54%\n","Current batch: Loss-> 0.6845, Train accuracy->   7.63%\n","Current batch: Loss-> 0.8921, Train accuracy->   7.73%\n","Current batch: Loss-> 0.9539, Train accuracy->   7.84%\n","Current batch: Loss-> 0.7775, Train accuracy->   7.94%\n","Current batch: Loss-> 1.0295, Train accuracy->   8.02%\n","Current batch: Loss-> 0.9894, Train accuracy->   8.10%\n","Current batch: Loss-> 0.8128, Train accuracy->   8.21%\n","Current batch: Loss-> 1.1833, Train accuracy->   8.30%\n","Current batch: Loss-> 0.8932, Train accuracy->   8.41%\n","Current batch: Loss-> 1.1181, Train accuracy->   8.48%\n","Current batch: Loss-> 1.2733, Train accuracy->   8.56%\n","Current batch: Loss-> 1.2017, Train accuracy->   8.64%\n","Current batch: Loss-> 1.0192, Train accuracy->   8.73%\n","Current batch: Loss-> 0.9129, Train accuracy->   8.82%\n","Current batch: Loss-> 0.9768, Train accuracy->   8.91%\n","Current batch: Loss-> 1.2856, Train accuracy->   8.99%\n","Current batch: Loss-> 1.0418, Train accuracy->   9.08%\n","Current batch: Loss-> 0.8259, Train accuracy->   9.18%\n","Current batch: Loss-> 1.0205, Train accuracy->   9.26%\n","Current batch: Loss-> 1.0176, Train accuracy->   9.35%\n","Current batch: Loss-> 1.0442, Train accuracy->   9.44%\n","Current batch: Loss-> 0.9017, Train accuracy->   9.54%\n","Current batch: Loss-> 1.3757, Train accuracy->   9.61%\n","Current batch: Loss-> 0.8774, Train accuracy->   9.70%\n","Current batch: Loss-> 1.1966, Train accuracy->   9.79%\n","Current batch: Loss-> 1.2366, Train accuracy->   9.86%\n","Current batch: Loss-> 0.9496, Train accuracy->   9.95%\n","Current batch: Loss-> 0.9820, Train accuracy->  10.02%\n","Current batch: Loss-> 1.1936, Train accuracy->  10.11%\n","Current batch: Loss-> 1.0358, Train accuracy->  10.19%\n","Current batch: Loss-> 1.2080, Train accuracy->  10.27%\n","Current batch: Loss-> 0.9544, Train accuracy->  10.35%\n","Current batch: Loss-> 0.9157, Train accuracy->  10.43%\n","Current batch: Loss-> 0.9948, Train accuracy->  10.51%\n","Current batch: Loss-> 1.3228, Train accuracy->  10.58%\n","Current batch: Loss-> 0.7701, Train accuracy->  10.67%\n","Current batch: Loss-> 0.8217, Train accuracy->  10.77%\n","Current batch: Loss-> 1.1207, Train accuracy->  10.84%\n","Current batch: Loss-> 0.9974, Train accuracy->  10.92%\n","Current batch: Loss-> 0.8254, Train accuracy->  11.02%\n","Current batch: Loss-> 0.8323, Train accuracy->  11.11%\n","Current batch: Loss-> 1.3348, Train accuracy->  11.19%\n","Current batch: Loss-> 1.0333, Train accuracy->  11.28%\n","Current batch: Loss-> 0.9985, Train accuracy->  11.36%\n","Current batch: Loss-> 0.8976, Train accuracy->  11.45%\n","Current batch: Loss-> 0.9820, Train accuracy->  11.54%\n","Current batch: Loss-> 0.9117, Train accuracy->  11.63%\n","Current batch: Loss-> 1.0885, Train accuracy->  11.70%\n","Current batch: Loss-> 0.8395, Train accuracy->  11.79%\n","Current batch: Loss-> 1.1005, Train accuracy->  11.88%\n","Current batch: Loss-> 1.0169, Train accuracy->  11.97%\n","Current batch: Loss-> 1.1536, Train accuracy->  12.06%\n","Current batch: Loss-> 0.9808, Train accuracy->  12.14%\n","Current batch: Loss-> 0.9812, Train accuracy->  12.22%\n","Current batch: Loss-> 0.9730, Train accuracy->  12.31%\n","Current batch: Loss-> 1.0138, Train accuracy->  12.40%\n","Current batch: Loss-> 1.3470, Train accuracy->  12.46%\n","Current batch: Loss-> 1.0948, Train accuracy->  12.54%\n","Current batch: Loss-> 1.0580, Train accuracy->  12.64%\n","Current batch: Loss-> 1.0452, Train accuracy->  12.72%\n","Current batch: Loss-> 1.1838, Train accuracy->  12.80%\n","Current batch: Loss-> 1.0453, Train accuracy->  12.89%\n","Current batch: Loss-> 1.0158, Train accuracy->  12.97%\n","Current batch: Loss-> 0.8965, Train accuracy->  13.07%\n","Current batch: Loss-> 0.9189, Train accuracy->  13.16%\n","Current batch: Loss-> 1.0261, Train accuracy->  13.26%\n","Current batch: Loss-> 0.9330, Train accuracy->  13.35%\n","Current batch: Loss-> 0.9611, Train accuracy->  13.45%\n","Current batch: Loss-> 0.9231, Train accuracy->  13.54%\n","Current batch: Loss-> 0.9219, Train accuracy->  13.64%\n","Current batch: Loss-> 1.1527, Train accuracy->  13.71%\n","Current batch: Loss-> 0.8348, Train accuracy->  13.81%\n","Current batch: Loss-> 0.9397, Train accuracy->  13.90%\n","Current batch: Loss-> 1.1458, Train accuracy->  13.99%\n","Current batch: Loss-> 0.7551, Train accuracy->  14.08%\n","Current batch: Loss-> 0.9511, Train accuracy->  14.16%\n","Current batch: Loss-> 0.9870, Train accuracy->  14.25%\n","Current batch: Loss-> 1.0971, Train accuracy->  14.33%\n","Current batch: Loss-> 0.8287, Train accuracy->  14.43%\n","Current batch: Loss-> 1.2277, Train accuracy->  14.52%\n","Current batch: Loss-> 0.9955, Train accuracy->  14.61%\n","Current batch: Loss-> 1.0422, Train accuracy->  14.70%\n","Current batch: Loss-> 1.0850, Train accuracy->  14.79%\n","Current batch: Loss-> 0.8986, Train accuracy->  14.87%\n","Current batch: Loss-> 0.8848, Train accuracy->  14.97%\n","Current batch: Loss-> 0.8056, Train accuracy->  15.06%\n","Current batch: Loss-> 1.0898, Train accuracy->  15.15%\n","Current batch: Loss-> 0.8196, Train accuracy->  15.25%\n","Current batch: Loss-> 0.7427, Train accuracy->  15.35%\n","Current batch: Loss-> 0.9271, Train accuracy->  15.43%\n","Current batch: Loss-> 0.9795, Train accuracy->  15.50%\n","Current batch: Loss-> 0.7098, Train accuracy->  15.60%\n","Current batch: Loss-> 1.0583, Train accuracy->  15.67%\n","Current batch: Loss-> 1.1486, Train accuracy->  15.76%\n","Current batch: Loss-> 1.1536, Train accuracy->  15.82%\n","Current batch: Loss-> 0.8466, Train accuracy->  15.91%\n","Current batch: Loss-> 0.9517, Train accuracy->  16.00%\n","Current batch: Loss-> 1.2948, Train accuracy->  16.08%\n","Current batch: Loss-> 0.9371, Train accuracy->  16.16%\n","Current batch: Loss-> 1.1714, Train accuracy->  16.25%\n","Current batch: Loss-> 0.7581, Train accuracy->  16.35%\n","Current batch: Loss-> 1.1545, Train accuracy->  16.43%\n","Current batch: Loss-> 1.0188, Train accuracy->  16.54%\n","Current batch: Loss-> 0.8718, Train accuracy->  16.64%\n","Current batch: Loss-> 1.2922, Train accuracy->  16.71%\n","Current batch: Loss-> 1.0342, Train accuracy->  16.81%\n","Current batch: Loss-> 1.1020, Train accuracy->  16.89%\n","Current batch: Loss-> 1.0048, Train accuracy->  16.98%\n","Current batch: Loss-> 0.9836, Train accuracy->  17.07%\n","Current batch: Loss-> 0.7896, Train accuracy->  17.16%\n","Current batch: Loss-> 0.9782, Train accuracy->  17.25%\n","Current batch: Loss-> 1.1572, Train accuracy->  17.33%\n","Current batch: Loss-> 0.9496, Train accuracy->  17.41%\n","Current batch: Loss-> 1.0289, Train accuracy->  17.48%\n","Current batch: Loss-> 1.0241, Train accuracy->  17.58%\n","Current batch: Loss-> 1.0765, Train accuracy->  17.67%\n","Current batch: Loss-> 1.2182, Train accuracy->  17.75%\n","Current batch: Loss-> 1.0986, Train accuracy->  17.83%\n","Current batch: Loss-> 0.9995, Train accuracy->  17.92%\n","Current batch: Loss-> 0.9810, Train accuracy->  18.02%\n","Current batch: Loss-> 0.7729, Train accuracy->  18.11%\n","Current batch: Loss-> 0.9172, Train accuracy->  18.20%\n","Current batch: Loss-> 1.0377, Train accuracy->  18.28%\n","Current batch: Loss-> 0.9459, Train accuracy->  18.36%\n","Current batch: Loss-> 0.9506, Train accuracy->  18.46%\n","Current batch: Loss-> 0.8624, Train accuracy->  18.55%\n","Current batch: Loss-> 1.0450, Train accuracy->  18.63%\n","Current batch: Loss-> 0.7926, Train accuracy->  18.73%\n","Current batch: Loss-> 1.0536, Train accuracy->  18.80%\n","Current batch: Loss-> 0.9654, Train accuracy->  18.89%\n","Current batch: Loss-> 1.2354, Train accuracy->  18.96%\n","Current batch: Loss-> 1.1857, Train accuracy->  19.04%\n","Current batch: Loss-> 1.1717, Train accuracy->  19.12%\n","Current batch: Loss-> 1.0585, Train accuracy->  19.22%\n","Current batch: Loss-> 1.1208, Train accuracy->  19.29%\n","Current batch: Loss-> 1.2802, Train accuracy->  19.35%\n","Current batch: Loss-> 0.8391, Train accuracy->  19.44%\n","Current batch: Loss-> 1.0051, Train accuracy->  19.52%\n","Current batch: Loss-> 0.9660, Train accuracy->  19.61%\n","Current batch: Loss-> 0.9283, Train accuracy->  19.70%\n","Current batch: Loss-> 1.0580, Train accuracy->  19.78%\n","Current batch: Loss-> 0.7457, Train accuracy->  19.88%\n","Current batch: Loss-> 1.0387, Train accuracy->  19.96%\n","Current batch: Loss-> 0.9171, Train accuracy->  20.05%\n","Current batch: Loss-> 0.9843, Train accuracy->  20.14%\n","Current batch: Loss-> 0.9794, Train accuracy->  20.23%\n","Current batch: Loss-> 0.8298, Train accuracy->  20.32%\n","Current batch: Loss-> 1.0228, Train accuracy->  20.41%\n","Current batch: Loss-> 1.0761, Train accuracy->  20.50%\n","Current batch: Loss-> 1.2053, Train accuracy->  20.58%\n","Current batch: Loss-> 0.9599, Train accuracy->  20.66%\n","Current batch: Loss-> 0.7589, Train accuracy->  20.75%\n","Current batch: Loss-> 0.9326, Train accuracy->  20.84%\n","Current batch: Loss-> 0.8564, Train accuracy->  20.94%\n","Current batch: Loss-> 1.2621, Train accuracy->  21.02%\n","Current batch: Loss-> 1.0674, Train accuracy->  21.11%\n","Current batch: Loss-> 0.7837, Train accuracy->  21.20%\n","Current batch: Loss-> 0.9934, Train accuracy->  21.30%\n","Current batch: Loss-> 0.9899, Train accuracy->  21.39%\n","Current batch: Loss-> 0.8840, Train accuracy->  21.48%\n","Current batch: Loss-> 1.1651, Train accuracy->  21.57%\n","Current batch: Loss-> 1.0003, Train accuracy->  21.66%\n","Current batch: Loss-> 0.7519, Train accuracy->  21.75%\n","Current batch: Loss-> 1.0207, Train accuracy->  21.84%\n","Current batch: Loss-> 1.1464, Train accuracy->  21.93%\n","Current batch: Loss-> 0.8645, Train accuracy->  22.03%\n","Current batch: Loss-> 1.1354, Train accuracy->  22.11%\n","Current batch: Loss-> 0.9014, Train accuracy->  22.21%\n","Current batch: Loss-> 1.0078, Train accuracy->  22.30%\n","Current batch: Loss-> 0.8426, Train accuracy->  22.40%\n","Current batch: Loss-> 0.9670, Train accuracy->  22.48%\n","Current batch: Loss-> 0.9659, Train accuracy->  22.55%\n","Current batch: Loss-> 0.9314, Train accuracy->  22.65%\n","Current batch: Loss-> 1.0414, Train accuracy->  22.75%\n","Current batch: Loss-> 0.8248, Train accuracy->  22.84%\n","Current batch: Loss-> 0.8457, Train accuracy->  22.93%\n","Current batch: Loss-> 1.0881, Train accuracy->  23.01%\n","Current batch: Loss-> 1.1586, Train accuracy->  23.09%\n","Current batch: Loss-> 1.2463, Train accuracy->  23.16%\n","Current batch: Loss-> 1.0622, Train accuracy->  23.24%\n","Current batch: Loss-> 1.3510, Train accuracy->  23.30%\n","Current batch: Loss-> 0.8924, Train accuracy->  23.39%\n","Current batch: Loss-> 1.1166, Train accuracy->  23.48%\n","Current batch: Loss-> 1.0751, Train accuracy->  23.57%\n","Current batch: Loss-> 1.1455, Train accuracy->  23.66%\n","Current batch: Loss-> 0.8223, Train accuracy->  23.75%\n","Current batch: Loss-> 1.1189, Train accuracy->  23.82%\n","Current batch: Loss-> 1.4174, Train accuracy->  23.87%\n","Current batch: Loss-> 1.2613, Train accuracy->  23.95%\n","Current batch: Loss-> 0.9464, Train accuracy->  24.04%\n","Current batch: Loss-> 1.0068, Train accuracy->  24.12%\n","Current batch: Loss-> 0.9549, Train accuracy->  24.21%\n","Current batch: Loss-> 0.9527, Train accuracy->  24.30%\n","Current batch: Loss-> 1.0446, Train accuracy->  24.38%\n","Current batch: Loss-> 1.1562, Train accuracy->  24.45%\n","Current batch: Loss-> 0.8826, Train accuracy->  24.54%\n","Current batch: Loss-> 1.1772, Train accuracy->  24.62%\n","Current batch: Loss-> 1.1641, Train accuracy->  24.71%\n","Current batch: Loss-> 0.9233, Train accuracy->  24.79%\n","Current batch: Loss-> 0.9401, Train accuracy->  24.88%\n","Current batch: Loss-> 0.9293, Train accuracy->  24.96%\n","Current batch: Loss-> 1.0887, Train accuracy->  25.04%\n","Current batch: Loss-> 1.0257, Train accuracy->  25.11%\n","Current batch: Loss-> 0.8544, Train accuracy->  25.21%\n","Current batch: Loss-> 1.0918, Train accuracy->  25.29%\n","Current batch: Loss-> 0.9590, Train accuracy->  25.38%\n","Current batch: Loss-> 0.9208, Train accuracy->  25.47%\n","Current batch: Loss-> 0.8371, Train accuracy->  25.56%\n","Current batch: Loss-> 1.1148, Train accuracy->  25.64%\n","Current batch: Loss-> 1.0231, Train accuracy->  25.72%\n","Current batch: Loss-> 1.0345, Train accuracy->  25.81%\n","Current batch: Loss-> 1.0548, Train accuracy->  25.89%\n","Current batch: Loss-> 0.9944, Train accuracy->  25.97%\n","Current batch: Loss-> 0.8106, Train accuracy->  26.07%\n","Current batch: Loss-> 0.8539, Train accuracy->  26.16%\n","Current batch: Loss-> 1.0806, Train accuracy->  26.24%\n","Current batch: Loss-> 1.3034, Train accuracy->  26.32%\n","Current batch: Loss-> 0.8342, Train accuracy->  26.42%\n","Current batch: Loss-> 1.1164, Train accuracy->  26.50%\n","Current batch: Loss-> 0.7994, Train accuracy->  26.59%\n","Current batch: Loss-> 0.7192, Train accuracy->  26.70%\n","Current batch: Loss-> 0.9430, Train accuracy->  26.78%\n","Current batch: Loss-> 1.6433, Train accuracy->  26.86%\n","Current batch: Loss-> 0.9503, Train accuracy->  26.95%\n","Current batch: Loss-> 0.9060, Train accuracy->  27.03%\n","Current batch: Loss-> 1.0555, Train accuracy->  27.10%\n","Current batch: Loss-> 0.9862, Train accuracy->  27.19%\n","Current batch: Loss-> 1.0938, Train accuracy->  27.28%\n","Current batch: Loss-> 1.0171, Train accuracy->  27.37%\n","Current batch: Loss-> 1.0913, Train accuracy->  27.46%\n","Current batch: Loss-> 1.0452, Train accuracy->  27.55%\n","Current batch: Loss-> 0.9863, Train accuracy->  27.65%\n","Current batch: Loss-> 0.9339, Train accuracy->  27.73%\n","Current batch: Loss-> 1.2429, Train accuracy->  27.80%\n","Current batch: Loss-> 1.2745, Train accuracy->  27.87%\n","Current batch: Loss-> 1.0237, Train accuracy->  27.95%\n","Current batch: Loss-> 1.1263, Train accuracy->  28.04%\n","Current batch: Loss-> 1.1639, Train accuracy->  28.12%\n","Current batch: Loss-> 1.0123, Train accuracy->  28.21%\n","Current batch: Loss-> 0.9627, Train accuracy->  28.29%\n","Current batch: Loss-> 1.3384, Train accuracy->  28.36%\n","Current batch: Loss-> 1.2665, Train accuracy->  28.44%\n","Current batch: Loss-> 1.0525, Train accuracy->  28.52%\n","Current batch: Loss-> 0.9908, Train accuracy->  28.61%\n","Current batch: Loss-> 0.9773, Train accuracy->  28.70%\n","Current batch: Loss-> 1.2498, Train accuracy->  28.76%\n","Current batch: Loss-> 0.8980, Train accuracy->  28.86%\n","Current batch: Loss-> 0.9772, Train accuracy->  28.95%\n","Current batch: Loss-> 0.8864, Train accuracy->  29.05%\n","Current batch: Loss-> 1.0126, Train accuracy->  29.15%\n","Current batch: Loss-> 1.0353, Train accuracy->  29.24%\n","Current batch: Loss-> 1.0932, Train accuracy->  29.33%\n","Current batch: Loss-> 1.1374, Train accuracy->  29.41%\n","Current batch: Loss-> 1.2401, Train accuracy->  29.49%\n","Current batch: Loss-> 0.8702, Train accuracy->  29.58%\n","Current batch: Loss-> 0.9814, Train accuracy->  29.67%\n","Current batch: Loss-> 1.1455, Train accuracy->  29.76%\n","Current batch: Loss-> 1.1845, Train accuracy->  29.85%\n","Current batch: Loss-> 1.0771, Train accuracy->  29.93%\n","Current batch: Loss-> 0.8720, Train accuracy->  30.04%\n","Current batch: Loss-> 0.7404, Train accuracy->  30.14%\n","Current batch: Loss-> 0.9971, Train accuracy->  30.22%\n","Current batch: Loss-> 1.0727, Train accuracy->  30.31%\n","Current batch: Loss-> 1.2328, Train accuracy->  30.40%\n","Current batch: Loss-> 0.7393, Train accuracy->  30.51%\n","Current batch: Loss-> 1.0782, Train accuracy->  30.59%\n","Current batch: Loss-> 1.0328, Train accuracy->  30.68%\n","Current batch: Loss-> 1.0871, Train accuracy->  30.76%\n","Current batch: Loss-> 0.9350, Train accuracy->  30.85%\n","Current batch: Loss-> 1.2063, Train accuracy->  30.94%\n","Current batch: Loss-> 1.0215, Train accuracy->  31.02%\n","Current batch: Loss-> 0.9430, Train accuracy->  31.12%\n","Current batch: Loss-> 1.1065, Train accuracy->  31.19%\n","Current batch: Loss-> 0.9691, Train accuracy->  31.28%\n","Current batch: Loss-> 1.1472, Train accuracy->  31.35%\n","Current batch: Loss-> 0.8336, Train accuracy->  31.45%\n","Current batch: Loss-> 1.1260, Train accuracy->  31.54%\n","Current batch: Loss-> 0.7449, Train accuracy->  31.65%\n","Current batch: Loss-> 0.9204, Train accuracy->  31.75%\n","Current batch: Loss-> 1.0804, Train accuracy->  31.83%\n","Current batch: Loss-> 0.8066, Train accuracy->  31.94%\n","Current batch: Loss-> 1.2261, Train accuracy->  32.03%\n","Current batch: Loss-> 0.9762, Train accuracy->  32.11%\n","Current batch: Loss-> 0.9662, Train accuracy->  32.19%\n","Current batch: Loss-> 0.9165, Train accuracy->  32.28%\n","Current batch: Loss-> 1.2328, Train accuracy->  32.35%\n","Current batch: Loss-> 1.1604, Train accuracy->  32.43%\n","Current batch: Loss-> 0.8389, Train accuracy->  32.52%\n","Current batch: Loss-> 0.8843, Train accuracy->  32.61%\n","Current batch: Loss-> 0.9331, Train accuracy->  32.71%\n","Current batch: Loss-> 0.8743, Train accuracy->  32.79%\n","Current batch: Loss-> 1.2298, Train accuracy->  32.88%\n","Current batch: Loss-> 0.9770, Train accuracy->  32.96%\n","Current batch: Loss-> 1.4211, Train accuracy->  33.04%\n","Current batch: Loss-> 1.2449, Train accuracy->  33.12%\n","Current batch: Loss-> 1.1811, Train accuracy->  33.19%\n","Current batch: Loss-> 0.8366, Train accuracy->  33.29%\n","Current batch: Loss-> 1.2206, Train accuracy->  33.36%\n","Current batch: Loss-> 0.7329, Train accuracy->  33.46%\n","Current batch: Loss-> 1.0718, Train accuracy->  33.54%\n","Current batch: Loss-> 1.0928, Train accuracy->  33.63%\n","Current batch: Loss-> 1.0409, Train accuracy->  33.71%\n","Current batch: Loss-> 0.9545, Train accuracy->  33.79%\n","Current batch: Loss-> 1.0286, Train accuracy->  33.88%\n","Current batch: Loss-> 1.2129, Train accuracy->  33.96%\n","Current batch: Loss-> 0.9918, Train accuracy->  34.06%\n","Current batch: Loss-> 0.9529, Train accuracy->  34.14%\n","Current batch: Loss-> 1.0316, Train accuracy->  34.23%\n","Current batch: Loss-> 1.1196, Train accuracy->  34.32%\n","Current batch: Loss-> 1.3644, Train accuracy->  34.39%\n","Current batch: Loss-> 1.4068, Train accuracy->  34.47%\n","Current batch: Loss-> 1.3342, Train accuracy->  34.54%\n","Current batch: Loss-> 1.0030, Train accuracy->  34.62%\n","Current batch: Loss-> 1.0972, Train accuracy->  34.71%\n","Current batch: Loss-> 1.0434, Train accuracy->  34.79%\n","Current batch: Loss-> 0.7894, Train accuracy->  34.88%\n","Current batch: Loss-> 0.8717, Train accuracy->  34.98%\n","Current batch: Loss-> 1.0887, Train accuracy->  35.06%\n","Current batch: Loss-> 0.9668, Train accuracy->  35.16%\n","Current batch: Loss-> 1.0705, Train accuracy->  35.24%\n","Current batch: Loss-> 1.0367, Train accuracy->  35.32%\n","Current batch: Loss-> 0.9634, Train accuracy->  35.42%\n","Current batch: Loss-> 0.9640, Train accuracy->  35.51%\n","Current batch: Loss-> 0.8499, Train accuracy->  35.61%\n","Current batch: Loss-> 1.0157, Train accuracy->  35.70%\n","Current batch: Loss-> 1.1345, Train accuracy->  35.77%\n","Current batch: Loss-> 0.9278, Train accuracy->  35.85%\n","Current batch: Loss-> 1.2140, Train accuracy->  35.93%\n","Current batch: Loss-> 1.3353, Train accuracy->  36.00%\n","Current batch: Loss-> 1.0466, Train accuracy->  36.09%\n","Current batch: Loss-> 1.0439, Train accuracy->  36.19%\n","Current batch: Loss-> 1.1484, Train accuracy->  36.26%\n","Current batch: Loss-> 0.9282, Train accuracy->  36.36%\n","Current batch: Loss-> 0.8222, Train accuracy->  36.45%\n","Current batch: Loss-> 1.2800, Train accuracy->  36.53%\n","Current batch: Loss-> 1.0562, Train accuracy->  36.61%\n","Current batch: Loss-> 1.0475, Train accuracy->  36.70%\n","Current batch: Loss-> 1.0771, Train accuracy->  36.78%\n","Current batch: Loss-> 0.9357, Train accuracy->  36.87%\n","Current batch: Loss-> 0.9173, Train accuracy->  36.97%\n","Current batch: Loss-> 0.8356, Train accuracy->  37.05%\n","Current batch: Loss-> 1.0628, Train accuracy->  37.14%\n","Current batch: Loss-> 1.1783, Train accuracy->  37.21%\n","Current batch: Loss-> 1.0794, Train accuracy->  37.29%\n","Current batch: Loss-> 0.9604, Train accuracy->  37.38%\n","Current batch: Loss-> 0.9223, Train accuracy->  37.47%\n","Current batch: Loss-> 0.8667, Train accuracy->  37.56%\n","Current batch: Loss-> 0.9427, Train accuracy->  37.66%\n","Current batch: Loss-> 1.2189, Train accuracy->  37.74%\n","Current batch: Loss-> 0.8905, Train accuracy->  37.84%\n","Current batch: Loss-> 1.1167, Train accuracy->  37.91%\n","Current batch: Loss-> 0.9929, Train accuracy->  38.00%\n","Current batch: Loss-> 1.1547, Train accuracy->  38.09%\n","Current batch: Loss-> 0.8960, Train accuracy->  38.17%\n","Current batch: Loss-> 1.0456, Train accuracy->  38.26%\n","Current batch: Loss-> 1.2022, Train accuracy->  38.35%\n","Current batch: Loss-> 0.9487, Train accuracy->  38.45%\n","Current batch: Loss-> 0.9754, Train accuracy->  38.52%\n","Current batch: Loss-> 0.9700, Train accuracy->  38.61%\n","Current batch: Loss-> 1.0190, Train accuracy->  38.70%\n","Current batch: Loss-> 0.8804, Train accuracy->  38.79%\n","Current batch: Loss-> 0.9260, Train accuracy->  38.88%\n","Current batch: Loss-> 1.1325, Train accuracy->  38.95%\n","Current batch: Loss-> 0.8999, Train accuracy->  39.04%\n","Current batch: Loss-> 0.9001, Train accuracy->  39.13%\n","Current batch: Loss-> 1.0266, Train accuracy->  39.21%\n","Current batch: Loss-> 0.9802, Train accuracy->  39.31%\n","Current batch: Loss-> 0.8953, Train accuracy->  39.40%\n","Current batch: Loss-> 1.0373, Train accuracy->  39.49%\n","Current batch: Loss-> 1.0132, Train accuracy->  39.58%\n","Current batch: Loss-> 0.8950, Train accuracy->  39.67%\n","Current batch: Loss-> 1.3194, Train accuracy->  39.75%\n","Current batch: Loss-> 1.1591, Train accuracy->  39.83%\n","Current batch: Loss-> 1.0355, Train accuracy->  39.91%\n","Current batch: Loss-> 1.1501, Train accuracy->  39.99%\n","Current batch: Loss-> 0.9490, Train accuracy->  40.09%\n","Current batch: Loss-> 0.8912, Train accuracy->  40.17%\n","Current batch: Loss-> 0.9719, Train accuracy->  40.26%\n","Current batch: Loss-> 1.4417, Train accuracy->  40.34%\n","Current batch: Loss-> 0.8938, Train accuracy->  40.44%\n","Current batch: Loss-> 1.1057, Train accuracy->  40.52%\n","Current batch: Loss-> 0.9767, Train accuracy->  40.62%\n","Current batch: Loss-> 1.0504, Train accuracy->  40.70%\n","Current batch: Loss-> 0.9539, Train accuracy->  40.79%\n","Current batch: Loss-> 1.1558, Train accuracy->  40.87%\n","Current batch: Loss-> 0.9130, Train accuracy->  40.96%\n","Current batch: Loss-> 0.9275, Train accuracy->  41.05%\n","Current batch: Loss-> 0.9524, Train accuracy->  41.15%\n","Current batch: Loss-> 1.0681, Train accuracy->  41.23%\n","Current batch: Loss-> 0.8132, Train accuracy->  41.32%\n","Current batch: Loss-> 1.0429, Train accuracy->  41.40%\n","Current batch: Loss-> 1.2085, Train accuracy->  41.48%\n","Current batch: Loss-> 0.8483, Train accuracy->  41.58%\n","Current batch: Loss-> 0.9670, Train accuracy->  41.66%\n","Current batch: Loss-> 0.9463, Train accuracy->  41.75%\n","Current batch: Loss-> 0.9596, Train accuracy->  41.85%\n","Current batch: Loss-> 0.9232, Train accuracy->  41.93%\n","Current batch: Loss-> 1.0928, Train accuracy->  42.03%\n","Current batch: Loss-> 1.0117, Train accuracy->  42.11%\n","Current batch: Loss-> 0.8268, Train accuracy->  42.21%\n","Current batch: Loss-> 0.9400, Train accuracy->  42.29%\n","Current batch: Loss-> 0.9999, Train accuracy->  42.38%\n","Current batch: Loss-> 0.8139, Train accuracy->  42.48%\n","Current batch: Loss-> 1.1776, Train accuracy->  42.57%\n","Current batch: Loss-> 1.0397, Train accuracy->  42.65%\n","Current batch: Loss-> 0.8922, Train accuracy->  42.74%\n","Current batch: Loss-> 1.0488, Train accuracy->  42.83%\n","Current batch: Loss-> 0.9327, Train accuracy->  42.91%\n","Current batch: Loss-> 1.1708, Train accuracy->  43.00%\n","Current batch: Loss-> 1.1405, Train accuracy->  43.08%\n","Current batch: Loss-> 1.1659, Train accuracy->  43.16%\n","Current batch: Loss-> 1.1114, Train accuracy->  43.23%\n","Current batch: Loss-> 1.1521, Train accuracy->  43.31%\n","Current batch: Loss-> 1.1134, Train accuracy->  43.39%\n","Current batch: Loss-> 1.1158, Train accuracy->  43.47%\n","Current batch: Loss-> 0.9682, Train accuracy->  43.57%\n","Current batch: Loss-> 0.9809, Train accuracy->  43.66%\n","Current batch: Loss-> 1.1133, Train accuracy->  43.74%\n","Current batch: Loss-> 1.2180, Train accuracy->  43.81%\n","Current batch: Loss-> 1.0379, Train accuracy->  43.90%\n","Current batch: Loss-> 1.2281, Train accuracy->  43.98%\n","Current batch: Loss-> 0.7962, Train accuracy->  44.08%\n","Current batch: Loss-> 0.8843, Train accuracy->  44.18%\n","Current batch: Loss-> 0.9979, Train accuracy->  44.27%\n","Current batch: Loss-> 0.9862, Train accuracy->  44.36%\n","Current batch: Loss-> 0.7394, Train accuracy->  44.46%\n","Current batch: Loss-> 0.8690, Train accuracy->  44.56%\n","Current batch: Loss-> 0.8633, Train accuracy->  44.66%\n","Current batch: Loss-> 1.0284, Train accuracy->  44.75%\n","Current batch: Loss-> 0.9676, Train accuracy->  44.84%\n","Current batch: Loss-> 0.9181, Train accuracy->  44.93%\n","Current batch: Loss-> 0.8482, Train accuracy->  45.02%\n","Current batch: Loss-> 1.3293, Train accuracy->  45.10%\n","Current batch: Loss-> 0.9329, Train accuracy->  45.19%\n","Current batch: Loss-> 0.8862, Train accuracy->  45.29%\n","Current batch: Loss-> 0.9266, Train accuracy->  45.38%\n","Current batch: Loss-> 1.1469, Train accuracy->  45.46%\n","Current batch: Loss-> 0.9724, Train accuracy->  45.55%\n","Current batch: Loss-> 0.9897, Train accuracy->  45.64%\n","Current batch: Loss-> 0.9618, Train accuracy->  45.74%\n","Current batch: Loss-> 0.9381, Train accuracy->  45.83%\n","Current batch: Loss-> 0.8902, Train accuracy->  45.92%\n","Current batch: Loss-> 0.9628, Train accuracy->  46.02%\n","Current batch: Loss-> 1.1777, Train accuracy->  46.10%\n","Current batch: Loss-> 0.8883, Train accuracy->  46.20%\n","Current batch: Loss-> 1.1009, Train accuracy->  46.28%\n","Current batch: Loss-> 1.3259, Train accuracy->  46.35%\n","Current batch: Loss-> 0.9738, Train accuracy->  46.45%\n","Current batch: Loss-> 1.2053, Train accuracy->  46.52%\n","Current batch: Loss-> 0.8959, Train accuracy->  46.62%\n","Current batch: Loss-> 0.8922, Train accuracy->  46.71%\n","Current batch: Loss-> 1.0206, Train accuracy->  46.79%\n","Current batch: Loss-> 0.7294, Train accuracy->  46.89%\n","Current batch: Loss-> 0.9253, Train accuracy->  46.99%\n","Current batch: Loss-> 1.1857, Train accuracy->  47.08%\n","Current batch: Loss-> 0.8932, Train accuracy->  47.19%\n","Current batch: Loss-> 0.8335, Train accuracy->  47.27%\n","Current batch: Loss-> 1.3277, Train accuracy->  47.35%\n","Current batch: Loss-> 1.0843, Train accuracy->  47.42%\n","Current batch: Loss-> 0.9238, Train accuracy->  47.51%\n","Current batch: Loss-> 0.9054, Train accuracy->  47.60%\n","Current batch: Loss-> 1.4683, Train accuracy->  47.68%\n","Current batch: Loss-> 0.7991, Train accuracy->  47.78%\n","Current batch: Loss-> 0.9760, Train accuracy->  47.86%\n","Current batch: Loss-> 1.1807, Train accuracy->  47.95%\n","Current batch: Loss-> 1.1042, Train accuracy->  48.04%\n","Current batch: Loss-> 1.0214, Train accuracy->  48.13%\n","Current batch: Loss-> 0.9636, Train accuracy->  48.23%\n","Current batch: Loss-> 0.8631, Train accuracy->  48.33%\n","Current batch: Loss-> 0.8219, Train accuracy->  48.42%\n","Current batch: Loss-> 1.0445, Train accuracy->  48.50%\n","Current batch: Loss-> 1.0350, Train accuracy->  48.59%\n","Current batch: Loss-> 0.9570, Train accuracy->  48.67%\n","Current batch: Loss-> 0.8813, Train accuracy->  48.77%\n","Current batch: Loss-> 0.9033, Train accuracy->  48.86%\n","Current batch: Loss-> 0.9124, Train accuracy->  48.95%\n","Current batch: Loss-> 1.2221, Train accuracy->  49.02%\n","Current batch: Loss-> 0.8459, Train accuracy->  49.11%\n","Current batch: Loss-> 0.9897, Train accuracy->  49.19%\n","Current batch: Loss-> 0.9752, Train accuracy->  49.28%\n","Current batch: Loss-> 1.0092, Train accuracy->  49.37%\n","Current batch: Loss-> 1.0465, Train accuracy->  49.47%\n","Current batch: Loss-> 1.0487, Train accuracy->  49.55%\n","Current batch: Loss-> 1.0358, Train accuracy->  49.64%\n","Current batch: Loss-> 1.1322, Train accuracy->  49.71%\n","Current batch: Loss-> 0.9144, Train accuracy->  49.80%\n","Current batch: Loss-> 1.1076, Train accuracy->  49.87%\n","Current batch: Loss-> 1.0918, Train accuracy->  49.96%\n","Current batch: Loss-> 1.3247, Train accuracy->  50.03%\n","Current batch: Loss-> 0.9915, Train accuracy->  50.11%\n","Current batch: Loss-> 1.2299, Train accuracy->  50.18%\n","Current batch: Loss-> 1.1902, Train accuracy->  50.26%\n","Current batch: Loss-> 0.9546, Train accuracy->  50.34%\n","Current batch: Loss-> 1.0206, Train accuracy->  50.42%\n","Current batch: Loss-> 0.8035, Train accuracy->  50.51%\n","Current batch: Loss-> 1.0318, Train accuracy->  50.59%\n","Current batch: Loss-> 1.0615, Train accuracy->  50.67%\n","Current batch: Loss-> 1.0257, Train accuracy->  50.75%\n","Current batch: Loss-> 1.0837, Train accuracy->  50.85%\n","Current batch: Loss-> 1.0922, Train accuracy->  50.93%\n","Current batch: Loss-> 0.9804, Train accuracy->  51.03%\n","Current batch: Loss-> 1.1146, Train accuracy->  51.11%\n","Current batch: Loss-> 1.1408, Train accuracy->  51.20%\n","Current batch: Loss-> 0.9579, Train accuracy->  51.29%\n","Current batch: Loss-> 1.0964, Train accuracy->  51.37%\n","Current batch: Loss-> 1.0096, Train accuracy->  51.47%\n","Current batch: Loss-> 0.9187, Train accuracy->  51.56%\n","Current batch: Loss-> 0.8455, Train accuracy->  51.66%\n","Current batch: Loss-> 1.0217, Train accuracy->  51.76%\n","Current batch: Loss-> 1.3447, Train accuracy->  51.83%\n","Current batch: Loss-> 0.9125, Train accuracy->  51.93%\n","Current batch: Loss-> 0.9260, Train accuracy->  52.03%\n","Current batch: Loss-> 0.9230, Train accuracy->  52.12%\n","Current batch: Loss-> 1.0492, Train accuracy->  52.22%\n","Current batch: Loss-> 1.1230, Train accuracy->  52.30%\n","Current batch: Loss-> 1.0780, Train accuracy->  52.38%\n","Current batch: Loss-> 0.9400, Train accuracy->  52.47%\n","Current batch: Loss-> 0.6756, Train accuracy->  52.58%\n","Current batch: Loss-> 1.0401, Train accuracy->  52.67%\n","Current batch: Loss-> 1.0187, Train accuracy->  52.76%\n","Current batch: Loss-> 0.8026, Train accuracy->  52.86%\n","Current batch: Loss-> 1.0439, Train accuracy->  52.95%\n","Current batch: Loss-> 0.8810, Train accuracy->  53.04%\n","Current batch: Loss-> 0.9277, Train accuracy->  53.14%\n","Current batch: Loss-> 0.8905, Train accuracy->  53.23%\n","Current batch: Loss-> 0.8993, Train accuracy->  53.33%\n","Current batch: Loss-> 0.9114, Train accuracy->  53.42%\n","Current batch: Loss-> 1.2492, Train accuracy->  53.50%\n","Current batch: Loss-> 0.8113, Train accuracy->  53.60%\n","Current batch: Loss-> 0.9738, Train accuracy->  53.70%\n","Current batch: Loss-> 1.2681, Train accuracy->  53.78%\n","Current batch: Loss-> 0.9794, Train accuracy->  53.87%\n","Current batch: Loss-> 0.8763, Train accuracy->  53.97%\n","Current batch: Loss-> 0.9040, Train accuracy->  54.06%\n","Current batch: Loss-> 0.7488, Train accuracy->  54.15%\n","Current batch: Loss-> 0.9756, Train accuracy->  54.23%\n","Current batch: Loss-> 1.0845, Train accuracy->  54.32%\n","Current batch: Loss-> 1.0743, Train accuracy->  54.40%\n","Current batch: Loss-> 0.9929, Train accuracy->  54.48%\n","Current batch: Loss-> 1.0940, Train accuracy->  54.57%\n","Current batch: Loss-> 1.0422, Train accuracy->  54.65%\n","Current batch: Loss-> 1.1027, Train accuracy->  54.73%\n","Current batch: Loss-> 0.8147, Train accuracy->  54.83%\n","Current batch: Loss-> 0.8636, Train accuracy->  54.92%\n","Current batch: Loss-> 0.8787, Train accuracy->  55.02%\n","Current batch: Loss-> 0.8322, Train accuracy->  55.11%\n","Current batch: Loss-> 0.9593, Train accuracy->  55.20%\n","Current batch: Loss-> 0.9280, Train accuracy->  55.28%\n","Current batch: Loss-> 1.1476, Train accuracy->  55.36%\n","Current batch: Loss-> 1.1026, Train accuracy->  55.45%\n","Current batch: Loss-> 0.8293, Train accuracy->  55.54%\n","Current batch: Loss-> 0.7111, Train accuracy->  55.64%\n","Current batch: Loss-> 0.6624, Train accuracy->  55.74%\n","Current batch: Loss-> 0.8095, Train accuracy->  55.85%\n","Current batch: Loss-> 0.9681, Train accuracy->  55.94%\n","Current batch: Loss-> 0.8506, Train accuracy->  56.04%\n","Current batch: Loss-> 1.2078, Train accuracy->  56.13%\n","Current batch: Loss-> 0.8101, Train accuracy->  56.22%\n","Current batch: Loss-> 0.8473, Train accuracy->  56.32%\n","Current batch: Loss-> 1.0961, Train accuracy->  56.41%\n","Current batch: Loss-> 1.2124, Train accuracy->  56.50%\n","Current batch: Loss-> 0.9951, Train accuracy->  56.59%\n","Current batch: Loss-> 0.5770, Train accuracy->  56.71%\n","Current batch: Loss-> 0.7601, Train accuracy->  56.81%\n","Current batch: Loss-> 1.0237, Train accuracy->  56.90%\n","Current batch: Loss-> 1.1246, Train accuracy->  56.98%\n","Current batch: Loss-> 0.8855, Train accuracy->  57.06%\n","Current batch: Loss-> 0.8224, Train accuracy->  57.16%\n","Current batch: Loss-> 0.9584, Train accuracy->  57.25%\n","Current batch: Loss-> 0.8266, Train accuracy->  57.36%\n","Current batch: Loss-> 0.6876, Train accuracy->  57.46%\n","Current batch: Loss-> 0.8829, Train accuracy->  57.56%\n","Current batch: Loss-> 0.9026, Train accuracy->  57.66%\n","Current batch: Loss-> 0.8070, Train accuracy->  57.76%\n","Current batch: Loss-> 0.8550, Train accuracy->  57.84%\n","Current batch: Loss-> 0.9154, Train accuracy->  57.94%\n","Current batch: Loss-> 0.8198, Train accuracy->  58.02%\n","Current batch: Loss-> 0.9220, Train accuracy->  58.12%\n","Current batch: Loss-> 0.9066, Train accuracy->  58.21%\n","Current batch: Loss-> 0.7400, Train accuracy->  58.31%\n","Current batch: Loss-> 1.0232, Train accuracy->  58.38%\n","Current batch: Loss-> 1.0714, Train accuracy->  58.47%\n","Current batch: Loss-> 0.7134, Train accuracy->  58.58%\n","Current batch: Loss-> 0.7467, Train accuracy->  58.67%\n","Current batch: Loss-> 0.9052, Train accuracy->  58.77%\n","Current batch: Loss-> 0.9381, Train accuracy->  58.86%\n","Current batch: Loss-> 1.1142, Train accuracy->  58.95%\n","Current batch: Loss-> 1.2381, Train accuracy->  59.03%\n","Current batch: Loss-> 0.9477, Train accuracy->  59.12%\n","Current batch: Loss-> 1.2193, Train accuracy->  59.20%\n","Current batch: Loss-> 1.0981, Train accuracy->  59.29%\n","Current batch: Loss-> 0.9821, Train accuracy->  59.38%\n","Current batch: Loss-> 0.7336, Train accuracy->  59.48%\n","Current batch: Loss-> 0.8198, Train accuracy->  59.58%\n","Current batch: Loss-> 0.7420, Train accuracy->  59.68%\n","Current batch: Loss-> 1.2446, Train accuracy->  59.74%\n","Current batch: Loss-> 0.9294, Train accuracy->  59.84%\n","Current batch: Loss-> 0.9901, Train accuracy->  59.92%\n","Current batch: Loss-> 1.1190, Train accuracy->  60.01%\n","Current batch: Loss-> 1.0224, Train accuracy->  60.10%\n","Current batch: Loss-> 1.1781, Train accuracy->  60.20%\n","Current batch: Loss-> 0.9408, Train accuracy->  60.28%\n","Current batch: Loss-> 1.0315, Train accuracy->  60.37%\n","Current batch: Loss-> 1.0019, Train accuracy->  60.45%\n","Current batch: Loss-> 0.8442, Train accuracy->  60.56%\n","Current batch: Loss-> 1.0695, Train accuracy->  60.64%\n","Current batch: Loss-> 0.9709, Train accuracy->  60.74%\n","Current batch: Loss-> 0.9037, Train accuracy->  60.83%\n","Current batch: Loss-> 1.5490, Train accuracy->  60.92%\n","Current batch: Loss-> 0.9023, Train accuracy->  61.01%\n","Current batch: Loss-> 1.0340, Train accuracy->  61.09%\n","Current batch: Loss-> 0.8354, Train accuracy->  61.19%\n","Current batch: Loss-> 0.8377, Train accuracy->  61.30%\n","Current batch: Loss-> 0.7997, Train accuracy->  61.40%\n","Current batch: Loss-> 0.7866, Train accuracy->  61.50%\n","Current batch: Loss-> 1.0142, Train accuracy->  61.58%\n","Current batch: Loss-> 0.7446, Train accuracy->  61.68%\n","Current batch: Loss-> 0.9407, Train accuracy->  61.76%\n","Current batch: Loss-> 0.8363, Train accuracy->  61.86%\n","Current batch: Loss-> 1.1124, Train accuracy->  61.94%\n","Current batch: Loss-> 1.0982, Train accuracy->  62.01%\n","Current batch: Loss-> 1.0130, Train accuracy->  62.08%\n","Current batch: Loss-> 1.0095, Train accuracy->  62.17%\n","Current batch: Loss-> 0.8978, Train accuracy->  62.25%\n","Current batch: Loss-> 0.7202, Train accuracy->  62.35%\n","Current batch: Loss-> 0.8641, Train accuracy->  62.44%\n","Current batch: Loss-> 0.8743, Train accuracy->  62.54%\n","Current batch: Loss-> 1.0102, Train accuracy->  62.63%\n","Current batch: Loss-> 1.0886, Train accuracy->  62.72%\n","Current batch: Loss-> 0.8930, Train accuracy->  62.81%\n","Current batch: Loss-> 1.0046, Train accuracy->  62.88%\n","Current batch: Loss-> 1.0184, Train accuracy->  62.97%\n","Current batch: Loss-> 0.8986, Train accuracy->  63.06%\n","Current batch: Loss-> 0.6693, Train accuracy->  63.16%\n","Current batch: Loss-> 0.8080, Train accuracy->  63.26%\n","Current batch: Loss-> 0.9001, Train accuracy->  63.34%\n","Current batch: Loss-> 0.8480, Train accuracy->  63.43%\n","Current batch: Loss-> 0.9658, Train accuracy->  63.53%\n","Current batch: Loss-> 0.8568, Train accuracy->  63.61%\n","Current batch: Loss-> 0.9750, Train accuracy->  63.69%\n","Current batch: Loss-> 0.9272, Train accuracy->  63.77%\n","Current batch: Loss-> 1.0400, Train accuracy->  63.85%\n","Current batch: Loss-> 1.4874, Train accuracy->  63.93%\n","Current batch: Loss-> 1.2136, Train accuracy->  64.02%\n","Current batch: Loss-> 1.2501, Train accuracy->  64.11%\n","Current batch: Loss-> 0.9128, Train accuracy->  64.20%\n","Current batch: Loss-> 0.9966, Train accuracy->  64.28%\n","Current batch: Loss-> 0.9700, Train accuracy->  64.37%\n","Current batch: Loss-> 1.0241, Train accuracy->  64.45%\n","Current batch: Loss-> 1.1871, Train accuracy->  64.53%\n","Current batch: Loss-> 1.1856, Train accuracy->  64.61%\n","Current batch: Loss-> 0.9507, Train accuracy->  64.71%\n","Current batch: Loss-> 1.2332, Train accuracy->  64.78%\n","Current batch: Loss-> 1.2372, Train accuracy->  64.86%\n","Current batch: Loss-> 1.0072, Train accuracy->  64.95%\n","Current batch: Loss-> 0.9390, Train accuracy->  65.03%\n","Current batch: Loss-> 1.1115, Train accuracy->  65.12%\n","Current batch: Loss-> 1.0730, Train accuracy->  65.21%\n","Current batch: Loss-> 1.2907, Train accuracy->  65.28%\n","Current batch: Loss-> 1.0824, Train accuracy->  65.37%\n","Current batch: Loss-> 0.9183, Train accuracy->  65.45%\n","Current batch: Loss-> 0.8602, Train accuracy->  65.55%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:04, 43.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.9546, Train accuracy->  65.65%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.03it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.8906, Accuracy: 4762/12000 (40%)\n","\n","Current batch: Loss-> 1.0186, Train accuracy->   0.08%\n","Current batch: Loss-> 0.9724, Train accuracy->   0.17%\n","Current batch: Loss-> 1.0571, Train accuracy->   0.24%\n","Current batch: Loss-> 0.8859, Train accuracy->   0.33%\n","Current batch: Loss-> 0.7886, Train accuracy->   0.44%\n","Current batch: Loss-> 0.9687, Train accuracy->   0.52%\n","Current batch: Loss-> 0.9478, Train accuracy->   0.61%\n","Current batch: Loss-> 1.0980, Train accuracy->   0.70%\n","Current batch: Loss-> 0.9283, Train accuracy->   0.79%\n","Current batch: Loss-> 0.9409, Train accuracy->   0.88%\n","Current batch: Loss-> 1.2295, Train accuracy->   0.96%\n","Current batch: Loss-> 0.9489, Train accuracy->   1.04%\n","Current batch: Loss-> 1.0628, Train accuracy->   1.12%\n","Current batch: Loss-> 0.7970, Train accuracy->   1.21%\n","Current batch: Loss-> 0.9641, Train accuracy->   1.29%\n","Current batch: Loss-> 0.9010, Train accuracy->   1.39%\n","Current batch: Loss-> 0.7417, Train accuracy->   1.48%\n","Current batch: Loss-> 0.7932, Train accuracy->   1.58%\n","Current batch: Loss-> 1.0942, Train accuracy->   1.66%\n","Current batch: Loss-> 1.0147, Train accuracy->   1.75%\n","Current batch: Loss-> 0.8023, Train accuracy->   1.85%\n","Current batch: Loss-> 0.8305, Train accuracy->   1.95%\n","Current batch: Loss-> 1.0162, Train accuracy->   2.04%\n","Current batch: Loss-> 0.8701, Train accuracy->   2.12%\n","Current batch: Loss-> 1.1727, Train accuracy->   2.20%\n","Current batch: Loss-> 1.0279, Train accuracy->   2.29%\n","Current batch: Loss-> 0.9132, Train accuracy->   2.38%\n","Current batch: Loss-> 0.8888, Train accuracy->   2.46%\n","Current batch: Loss-> 1.0066, Train accuracy->   2.55%\n","Current batch: Loss-> 0.9460, Train accuracy->   2.64%\n","Current batch: Loss-> 0.8027, Train accuracy->   2.73%\n","Current batch: Loss-> 1.1093, Train accuracy->   2.81%\n","Current batch: Loss-> 0.8203, Train accuracy->   2.92%\n","Current batch: Loss-> 1.1477, Train accuracy->   3.01%\n","Current batch: Loss-> 0.8538, Train accuracy->   3.10%\n","Current batch: Loss-> 0.7127, Train accuracy->   3.20%\n","Current batch: Loss-> 0.7824, Train accuracy->   3.29%\n","Current batch: Loss-> 0.9877, Train accuracy->   3.39%\n","Current batch: Loss-> 1.2019, Train accuracy->   3.47%\n","Current batch: Loss-> 0.9649, Train accuracy->   3.55%\n","Current batch: Loss-> 0.9566, Train accuracy->   3.65%\n","Current batch: Loss-> 0.8798, Train accuracy->   3.74%\n","Current batch: Loss-> 0.9107, Train accuracy->   3.84%\n","Current batch: Loss-> 0.8924, Train accuracy->   3.94%\n","Current batch: Loss-> 0.7680, Train accuracy->   4.04%\n","Current batch: Loss-> 0.8387, Train accuracy->   4.14%\n","Current batch: Loss-> 0.8243, Train accuracy->   4.23%\n","Current batch: Loss-> 1.0042, Train accuracy->   4.32%\n","Current batch: Loss-> 0.8418, Train accuracy->   4.42%\n","Current batch: Loss-> 1.1811, Train accuracy->   4.49%\n","Current batch: Loss-> 0.7589, Train accuracy->   4.59%\n","Current batch: Loss-> 0.9032, Train accuracy->   4.68%\n","Current batch: Loss-> 0.9223, Train accuracy->   4.77%\n","Current batch: Loss-> 0.7911, Train accuracy->   4.87%\n","Current batch: Loss-> 0.6130, Train accuracy->   4.98%\n","Current batch: Loss-> 0.7543, Train accuracy->   5.07%\n","Current batch: Loss-> 0.9277, Train accuracy->   5.16%\n","Current batch: Loss-> 0.8891, Train accuracy->   5.25%\n","Current batch: Loss-> 0.8059, Train accuracy->   5.35%\n","Current batch: Loss-> 1.0496, Train accuracy->   5.44%\n","Current batch: Loss-> 0.9376, Train accuracy->   5.53%\n","Current batch: Loss-> 0.9481, Train accuracy->   5.61%\n","Current batch: Loss-> 0.7387, Train accuracy->   5.71%\n","Current batch: Loss-> 0.8090, Train accuracy->   5.81%\n","Current batch: Loss-> 1.0480, Train accuracy->   5.90%\n","Current batch: Loss-> 0.7934, Train accuracy->   5.99%\n","Current batch: Loss-> 0.9169, Train accuracy->   6.09%\n","Current batch: Loss-> 0.9764, Train accuracy->   6.19%\n","Current batch: Loss-> 0.7231, Train accuracy->   6.29%\n","Current batch: Loss-> 0.8335, Train accuracy->   6.38%\n","Current batch: Loss-> 0.8107, Train accuracy->   6.47%\n","Current batch: Loss-> 0.8537, Train accuracy->   6.57%\n","Current batch: Loss-> 1.0781, Train accuracy->   6.65%\n","Current batch: Loss-> 1.3622, Train accuracy->   6.72%\n","Current batch: Loss-> 1.3689, Train accuracy->   6.79%\n","Current batch: Loss-> 1.2986, Train accuracy->   6.87%\n","Current batch: Loss-> 0.9080, Train accuracy->   6.95%\n","Current batch: Loss-> 0.9649, Train accuracy->   7.03%\n","Current batch: Loss-> 1.0501, Train accuracy->   7.11%\n","Current batch: Loss-> 1.0443, Train accuracy->   7.20%\n","Current batch: Loss-> 1.0526, Train accuracy->   7.28%\n","Current batch: Loss-> 1.3225, Train accuracy->   7.35%\n","Current batch: Loss-> 0.9955, Train accuracy->   7.42%\n","Current batch: Loss-> 1.0304, Train accuracy->   7.51%\n","Current batch: Loss-> 1.1042, Train accuracy->   7.60%\n","Current batch: Loss-> 0.7644, Train accuracy->   7.71%\n","Current batch: Loss-> 0.9499, Train accuracy->   7.80%\n","Current batch: Loss-> 0.7743, Train accuracy->   7.89%\n","Current batch: Loss-> 1.1330, Train accuracy->   7.97%\n","Current batch: Loss-> 0.9031, Train accuracy->   8.06%\n","Current batch: Loss-> 1.0680, Train accuracy->   8.15%\n","Current batch: Loss-> 0.7661, Train accuracy->   8.25%\n","Current batch: Loss-> 0.8876, Train accuracy->   8.35%\n","Current batch: Loss-> 0.9559, Train accuracy->   8.44%\n","Current batch: Loss-> 0.7753, Train accuracy->   8.55%\n","Current batch: Loss-> 0.9349, Train accuracy->   8.63%\n","Current batch: Loss-> 0.9387, Train accuracy->   8.71%\n","Current batch: Loss-> 0.8907, Train accuracy->   8.79%\n","Current batch: Loss-> 0.9506, Train accuracy->   8.87%\n","Current batch: Loss-> 1.0968, Train accuracy->   8.95%\n","Current batch: Loss-> 0.9427, Train accuracy->   9.05%\n","Current batch: Loss-> 0.8813, Train accuracy->   9.14%\n","Current batch: Loss-> 0.9258, Train accuracy->   9.23%\n","Current batch: Loss-> 0.8024, Train accuracy->   9.34%\n","Current batch: Loss-> 0.8352, Train accuracy->   9.44%\n","Current batch: Loss-> 1.0611, Train accuracy->   9.54%\n","Current batch: Loss-> 0.8878, Train accuracy->   9.64%\n","Current batch: Loss-> 0.9219, Train accuracy->   9.74%\n","Current batch: Loss-> 1.2576, Train accuracy->   9.81%\n","Current batch: Loss-> 1.0642, Train accuracy->   9.90%\n","Current batch: Loss-> 0.8741, Train accuracy->  10.00%\n","Current batch: Loss-> 1.1490, Train accuracy->  10.08%\n","Current batch: Loss-> 0.9063, Train accuracy->  10.16%\n","Current batch: Loss-> 0.7476, Train accuracy->  10.26%\n","Current batch: Loss-> 0.8638, Train accuracy->  10.35%\n","Current batch: Loss-> 0.8492, Train accuracy->  10.45%\n","Current batch: Loss-> 0.7759, Train accuracy->  10.55%\n","Current batch: Loss-> 1.0176, Train accuracy->  10.64%\n","Current batch: Loss-> 0.9795, Train accuracy->  10.73%\n","Current batch: Loss-> 0.8300, Train accuracy->  10.83%\n","Current batch: Loss-> 0.7858, Train accuracy->  10.93%\n","Current batch: Loss-> 0.9669, Train accuracy->  11.02%\n","Current batch: Loss-> 0.9601, Train accuracy->  11.11%\n","Current batch: Loss-> 1.0211, Train accuracy->  11.21%\n","Current batch: Loss-> 0.8430, Train accuracy->  11.31%\n","Current batch: Loss-> 1.1380, Train accuracy->  11.40%\n","Current batch: Loss-> 0.7595, Train accuracy->  11.49%\n","Current batch: Loss-> 0.8518, Train accuracy->  11.57%\n","Current batch: Loss-> 1.1683, Train accuracy->  11.67%\n","Current batch: Loss-> 1.0178, Train accuracy->  11.75%\n","Current batch: Loss-> 1.2045, Train accuracy->  11.84%\n","Current batch: Loss-> 0.7983, Train accuracy->  11.94%\n","Current batch: Loss-> 0.7964, Train accuracy->  12.02%\n","Current batch: Loss-> 0.9194, Train accuracy->  12.12%\n","Current batch: Loss-> 1.0939, Train accuracy->  12.21%\n","Current batch: Loss-> 1.2233, Train accuracy->  12.29%\n","Current batch: Loss-> 1.2489, Train accuracy->  12.37%\n","Current batch: Loss-> 0.9214, Train accuracy->  12.46%\n","Current batch: Loss-> 0.7347, Train accuracy->  12.57%\n","Current batch: Loss-> 0.7444, Train accuracy->  12.67%\n","Current batch: Loss-> 1.0477, Train accuracy->  12.75%\n","Current batch: Loss-> 0.8236, Train accuracy->  12.84%\n","Current batch: Loss-> 1.1369, Train accuracy->  12.93%\n","Current batch: Loss-> 0.9848, Train accuracy->  13.01%\n","Current batch: Loss-> 0.8122, Train accuracy->  13.11%\n","Current batch: Loss-> 0.8670, Train accuracy->  13.19%\n","Current batch: Loss-> 0.8483, Train accuracy->  13.28%\n","Current batch: Loss-> 0.8710, Train accuracy->  13.38%\n","Current batch: Loss-> 0.9142, Train accuracy->  13.47%\n","Current batch: Loss-> 0.8175, Train accuracy->  13.58%\n","Current batch: Loss-> 0.7683, Train accuracy->  13.68%\n","Current batch: Loss-> 1.0532, Train accuracy->  13.76%\n","Current batch: Loss-> 1.0548, Train accuracy->  13.86%\n","Current batch: Loss-> 1.0832, Train accuracy->  13.95%\n","Current batch: Loss-> 0.8557, Train accuracy->  14.04%\n","Current batch: Loss-> 1.2717, Train accuracy->  14.13%\n","Current batch: Loss-> 0.8350, Train accuracy->  14.22%\n","Current batch: Loss-> 1.1829, Train accuracy->  14.31%\n","Current batch: Loss-> 0.8712, Train accuracy->  14.40%\n","Current batch: Loss-> 0.8398, Train accuracy->  14.49%\n","Current batch: Loss-> 0.9576, Train accuracy->  14.59%\n","Current batch: Loss-> 0.9211, Train accuracy->  14.68%\n","Current batch: Loss-> 1.1013, Train accuracy->  14.77%\n","Current batch: Loss-> 1.0093, Train accuracy->  14.85%\n","Current batch: Loss-> 0.8413, Train accuracy->  14.95%\n","Current batch: Loss-> 0.9031, Train accuracy->  15.04%\n","Current batch: Loss-> 1.1737, Train accuracy->  15.12%\n","Current batch: Loss-> 0.9412, Train accuracy->  15.22%\n","Current batch: Loss-> 0.8610, Train accuracy->  15.32%\n","Current batch: Loss-> 0.8418, Train accuracy->  15.41%\n","Current batch: Loss-> 0.8716, Train accuracy->  15.51%\n","Current batch: Loss-> 0.8483, Train accuracy->  15.61%\n","Current batch: Loss-> 1.0558, Train accuracy->  15.71%\n","Current batch: Loss-> 1.0225, Train accuracy->  15.79%\n","Current batch: Loss-> 0.8784, Train accuracy->  15.88%\n","Current batch: Loss-> 1.0964, Train accuracy->  15.97%\n","Current batch: Loss-> 0.8808, Train accuracy->  16.07%\n","Current batch: Loss-> 0.9596, Train accuracy->  16.16%\n","Current batch: Loss-> 0.8614, Train accuracy->  16.26%\n","Current batch: Loss-> 1.0996, Train accuracy->  16.36%\n","Current batch: Loss-> 1.0261, Train accuracy->  16.44%\n","Current batch: Loss-> 1.0389, Train accuracy->  16.52%\n","Current batch: Loss-> 0.9407, Train accuracy->  16.60%\n","Current batch: Loss-> 0.8297, Train accuracy->  16.70%\n","Current batch: Loss-> 0.7321, Train accuracy->  16.81%\n","Current batch: Loss-> 0.8524, Train accuracy->  16.90%\n","Current batch: Loss-> 0.8140, Train accuracy->  17.00%\n","Current batch: Loss-> 0.8946, Train accuracy->  17.09%\n","Current batch: Loss-> 0.8760, Train accuracy->  17.19%\n","Current batch: Loss-> 1.2442, Train accuracy->  17.26%\n","Current batch: Loss-> 0.8196, Train accuracy->  17.35%\n","Current batch: Loss-> 0.9084, Train accuracy->  17.44%\n","Current batch: Loss-> 0.9579, Train accuracy->  17.53%\n","Current batch: Loss-> 1.0443, Train accuracy->  17.63%\n","Current batch: Loss-> 0.9306, Train accuracy->  17.72%\n","Current batch: Loss-> 0.7786, Train accuracy->  17.82%\n","Current batch: Loss-> 1.0330, Train accuracy->  17.92%\n","Current batch: Loss-> 1.0048, Train accuracy->  18.01%\n","Current batch: Loss-> 0.7312, Train accuracy->  18.12%\n","Current batch: Loss-> 0.8687, Train accuracy->  18.22%\n","Current batch: Loss-> 1.0447, Train accuracy->  18.30%\n","Current batch: Loss-> 0.8774, Train accuracy->  18.39%\n","Current batch: Loss-> 1.0928, Train accuracy->  18.48%\n","Current batch: Loss-> 1.0826, Train accuracy->  18.56%\n","Current batch: Loss-> 0.9461, Train accuracy->  18.65%\n","Current batch: Loss-> 0.9607, Train accuracy->  18.75%\n","Current batch: Loss-> 0.8176, Train accuracy->  18.84%\n","Current batch: Loss-> 0.8448, Train accuracy->  18.95%\n","Current batch: Loss-> 1.2170, Train accuracy->  19.02%\n","Current batch: Loss-> 1.0358, Train accuracy->  19.11%\n","Current batch: Loss-> 0.9361, Train accuracy->  19.20%\n","Current batch: Loss-> 1.0227, Train accuracy->  19.29%\n","Current batch: Loss-> 0.7600, Train accuracy->  19.39%\n","Current batch: Loss-> 0.9486, Train accuracy->  19.48%\n","Current batch: Loss-> 0.9261, Train accuracy->  19.58%\n","Current batch: Loss-> 0.8987, Train accuracy->  19.68%\n","Current batch: Loss-> 1.0042, Train accuracy->  19.79%\n","Current batch: Loss-> 0.9038, Train accuracy->  19.89%\n","Current batch: Loss-> 0.7787, Train accuracy->  19.99%\n","Current batch: Loss-> 0.8506, Train accuracy->  20.09%\n","Current batch: Loss-> 1.0256, Train accuracy->  20.17%\n","Current batch: Loss-> 0.9001, Train accuracy->  20.27%\n","Current batch: Loss-> 0.8070, Train accuracy->  20.37%\n","Current batch: Loss-> 0.8810, Train accuracy->  20.46%\n","Current batch: Loss-> 0.8224, Train accuracy->  20.56%\n","Current batch: Loss-> 0.9680, Train accuracy->  20.65%\n","Current batch: Loss-> 0.9027, Train accuracy->  20.74%\n","Current batch: Loss-> 0.8489, Train accuracy->  20.84%\n","Current batch: Loss-> 1.4200, Train accuracy->  20.91%\n","Current batch: Loss-> 0.7226, Train accuracy->  21.01%\n","Current batch: Loss-> 1.2200, Train accuracy->  21.10%\n","Current batch: Loss-> 1.2447, Train accuracy->  21.17%\n","Current batch: Loss-> 1.2905, Train accuracy->  21.25%\n","Current batch: Loss-> 1.2688, Train accuracy->  21.34%\n","Current batch: Loss-> 0.9941, Train accuracy->  21.43%\n","Current batch: Loss-> 1.1068, Train accuracy->  21.51%\n","Current batch: Loss-> 0.9848, Train accuracy->  21.59%\n","Current batch: Loss-> 1.0364, Train accuracy->  21.68%\n","Current batch: Loss-> 0.8446, Train accuracy->  21.78%\n","Current batch: Loss-> 1.1457, Train accuracy->  21.85%\n","Current batch: Loss-> 0.9607, Train accuracy->  21.94%\n","Current batch: Loss-> 1.1324, Train accuracy->  22.02%\n","Current batch: Loss-> 0.9566, Train accuracy->  22.11%\n","Current batch: Loss-> 1.0551, Train accuracy->  22.20%\n","Current batch: Loss-> 1.0465, Train accuracy->  22.27%\n","Current batch: Loss-> 0.9884, Train accuracy->  22.35%\n","Current batch: Loss-> 1.3404, Train accuracy->  22.43%\n","Current batch: Loss-> 0.9704, Train accuracy->  22.52%\n","Current batch: Loss-> 1.0172, Train accuracy->  22.61%\n","Current batch: Loss-> 1.0739, Train accuracy->  22.69%\n","Current batch: Loss-> 1.1975, Train accuracy->  22.76%\n","Current batch: Loss-> 1.2407, Train accuracy->  22.85%\n","Current batch: Loss-> 1.1077, Train accuracy->  22.93%\n","Current batch: Loss-> 0.8348, Train accuracy->  23.02%\n","Current batch: Loss-> 0.9858, Train accuracy->  23.12%\n","Current batch: Loss-> 0.9336, Train accuracy->  23.20%\n","Current batch: Loss-> 1.0395, Train accuracy->  23.27%\n","Current batch: Loss-> 1.1186, Train accuracy->  23.36%\n","Current batch: Loss-> 1.1084, Train accuracy->  23.44%\n","Current batch: Loss-> 0.9606, Train accuracy->  23.51%\n","Current batch: Loss-> 0.7247, Train accuracy->  23.60%\n","Current batch: Loss-> 1.0660, Train accuracy->  23.69%\n","Current batch: Loss-> 0.9523, Train accuracy->  23.78%\n","Current batch: Loss-> 0.8219, Train accuracy->  23.87%\n","Current batch: Loss-> 1.0090, Train accuracy->  23.95%\n","Current batch: Loss-> 0.9244, Train accuracy->  24.05%\n","Current batch: Loss-> 0.9549, Train accuracy->  24.14%\n","Current batch: Loss-> 1.0946, Train accuracy->  24.23%\n","Current batch: Loss-> 1.0424, Train accuracy->  24.32%\n","Current batch: Loss-> 1.1236, Train accuracy->  24.40%\n","Current batch: Loss-> 0.7577, Train accuracy->  24.51%\n","Current batch: Loss-> 0.7757, Train accuracy->  24.61%\n","Current batch: Loss-> 0.8787, Train accuracy->  24.70%\n","Current batch: Loss-> 0.6844, Train accuracy->  24.81%\n","Current batch: Loss-> 0.9381, Train accuracy->  24.90%\n","Current batch: Loss-> 1.5582, Train accuracy->  24.99%\n","Current batch: Loss-> 0.7843, Train accuracy->  25.09%\n","Current batch: Loss-> 1.1152, Train accuracy->  25.17%\n","Current batch: Loss-> 1.0014, Train accuracy->  25.26%\n","Current batch: Loss-> 0.9241, Train accuracy->  25.35%\n","Current batch: Loss-> 0.8549, Train accuracy->  25.43%\n","Current batch: Loss-> 0.8830, Train accuracy->  25.53%\n","Current batch: Loss-> 0.9014, Train accuracy->  25.63%\n","Current batch: Loss-> 0.6926, Train accuracy->  25.73%\n","Current batch: Loss-> 0.8310, Train accuracy->  25.83%\n","Current batch: Loss-> 1.0295, Train accuracy->  25.92%\n","Current batch: Loss-> 0.7788, Train accuracy->  26.03%\n","Current batch: Loss-> 1.0412, Train accuracy->  26.12%\n","Current batch: Loss-> 0.9670, Train accuracy->  26.21%\n","Current batch: Loss-> 1.0548, Train accuracy->  26.30%\n","Current batch: Loss-> 1.2612, Train accuracy->  26.38%\n","Current batch: Loss-> 0.8250, Train accuracy->  26.47%\n","Current batch: Loss-> 0.8745, Train accuracy->  26.56%\n","Current batch: Loss-> 0.8761, Train accuracy->  26.65%\n","Current batch: Loss-> 0.9039, Train accuracy->  26.73%\n","Current batch: Loss-> 0.8725, Train accuracy->  26.83%\n","Current batch: Loss-> 0.9142, Train accuracy->  26.93%\n","Current batch: Loss-> 1.1223, Train accuracy->  27.01%\n","Current batch: Loss-> 1.2502, Train accuracy->  27.09%\n","Current batch: Loss-> 0.8110, Train accuracy->  27.19%\n","Current batch: Loss-> 1.0687, Train accuracy->  27.27%\n","Current batch: Loss-> 0.8246, Train accuracy->  27.36%\n","Current batch: Loss-> 0.8459, Train accuracy->  27.45%\n","Current batch: Loss-> 0.9139, Train accuracy->  27.55%\n","Current batch: Loss-> 0.8777, Train accuracy->  27.65%\n","Current batch: Loss-> 1.0641, Train accuracy->  27.73%\n","Current batch: Loss-> 1.1810, Train accuracy->  27.81%\n","Current batch: Loss-> 0.8103, Train accuracy->  27.91%\n","Current batch: Loss-> 1.1447, Train accuracy->  28.00%\n","Current batch: Loss-> 1.1492, Train accuracy->  28.09%\n","Current batch: Loss-> 1.0273, Train accuracy->  28.17%\n","Current batch: Loss-> 0.8516, Train accuracy->  28.27%\n","Current batch: Loss-> 1.0529, Train accuracy->  28.36%\n","Current batch: Loss-> 0.7243, Train accuracy->  28.46%\n","Current batch: Loss-> 0.9778, Train accuracy->  28.56%\n","Current batch: Loss-> 0.8984, Train accuracy->  28.65%\n","Current batch: Loss-> 0.9101, Train accuracy->  28.75%\n","Current batch: Loss-> 1.1900, Train accuracy->  28.84%\n","Current batch: Loss-> 0.7409, Train accuracy->  28.94%\n","Current batch: Loss-> 1.1057, Train accuracy->  29.03%\n","Current batch: Loss-> 0.9619, Train accuracy->  29.12%\n","Current batch: Loss-> 0.9952, Train accuracy->  29.21%\n","Current batch: Loss-> 1.1549, Train accuracy->  29.28%\n","Current batch: Loss-> 0.9829, Train accuracy->  29.37%\n","Current batch: Loss-> 0.7818, Train accuracy->  29.46%\n","Current batch: Loss-> 0.7259, Train accuracy->  29.55%\n","Current batch: Loss-> 0.8418, Train accuracy->  29.65%\n","Current batch: Loss-> 0.7648, Train accuracy->  29.75%\n","Current batch: Loss-> 0.8153, Train accuracy->  29.84%\n","Current batch: Loss-> 0.9207, Train accuracy->  29.93%\n","Current batch: Loss-> 1.0175, Train accuracy->  30.02%\n","Current batch: Loss-> 0.9440, Train accuracy->  30.12%\n","Current batch: Loss-> 0.8851, Train accuracy->  30.22%\n","Current batch: Loss-> 0.8224, Train accuracy->  30.32%\n","Current batch: Loss-> 0.8666, Train accuracy->  30.42%\n","Current batch: Loss-> 0.8652, Train accuracy->  30.52%\n","Current batch: Loss-> 1.1826, Train accuracy->  30.60%\n","Current batch: Loss-> 0.8897, Train accuracy->  30.69%\n","Current batch: Loss-> 0.6488, Train accuracy->  30.80%\n","Current batch: Loss-> 0.7784, Train accuracy->  30.90%\n","Current batch: Loss-> 0.9050, Train accuracy->  31.00%\n","Current batch: Loss-> 0.7713, Train accuracy->  31.10%\n","Current batch: Loss-> 0.8369, Train accuracy->  31.19%\n","Current batch: Loss-> 0.6921, Train accuracy->  31.29%\n","Current batch: Loss-> 1.1024, Train accuracy->  31.38%\n","Current batch: Loss-> 0.9859, Train accuracy->  31.48%\n","Current batch: Loss-> 0.7350, Train accuracy->  31.58%\n","Current batch: Loss-> 0.9280, Train accuracy->  31.69%\n","Current batch: Loss-> 1.1361, Train accuracy->  31.77%\n","Current batch: Loss-> 0.9348, Train accuracy->  31.86%\n","Current batch: Loss-> 0.7269, Train accuracy->  31.96%\n","Current batch: Loss-> 0.9992, Train accuracy->  32.05%\n","Current batch: Loss-> 0.8988, Train accuracy->  32.14%\n","Current batch: Loss-> 0.6105, Train accuracy->  32.25%\n","Current batch: Loss-> 0.8121, Train accuracy->  32.35%\n","Current batch: Loss-> 0.9071, Train accuracy->  32.44%\n","Current batch: Loss-> 0.8990, Train accuracy->  32.54%\n","Current batch: Loss-> 0.7561, Train accuracy->  32.64%\n","Current batch: Loss-> 0.6748, Train accuracy->  32.75%\n","Current batch: Loss-> 0.8450, Train accuracy->  32.85%\n","Current batch: Loss-> 1.2493, Train accuracy->  32.90%\n","Current batch: Loss-> 1.0332, Train accuracy->  33.00%\n","Current batch: Loss-> 0.8669, Train accuracy->  33.10%\n","Current batch: Loss-> 0.8008, Train accuracy->  33.19%\n","Current batch: Loss-> 1.1120, Train accuracy->  33.28%\n","Current batch: Loss-> 1.0629, Train accuracy->  33.37%\n","Current batch: Loss-> 1.2709, Train accuracy->  33.45%\n","Current batch: Loss-> 1.0840, Train accuracy->  33.53%\n","Current batch: Loss-> 1.5688, Train accuracy->  33.60%\n","Current batch: Loss-> 1.1184, Train accuracy->  33.68%\n","Current batch: Loss-> 1.2079, Train accuracy->  33.76%\n","Current batch: Loss-> 0.9868, Train accuracy->  33.85%\n","Current batch: Loss-> 0.8051, Train accuracy->  33.95%\n","Current batch: Loss-> 1.1151, Train accuracy->  34.05%\n","Current batch: Loss-> 1.1057, Train accuracy->  34.12%\n","Current batch: Loss-> 0.9340, Train accuracy->  34.21%\n","Current batch: Loss-> 1.0288, Train accuracy->  34.29%\n","Current batch: Loss-> 1.2527, Train accuracy->  34.37%\n","Current batch: Loss-> 0.8024, Train accuracy->  34.48%\n","Current batch: Loss-> 0.6987, Train accuracy->  34.57%\n","Current batch: Loss-> 0.9552, Train accuracy->  34.67%\n","Current batch: Loss-> 1.0843, Train accuracy->  34.76%\n","Current batch: Loss-> 1.1981, Train accuracy->  34.84%\n","Current batch: Loss-> 0.9519, Train accuracy->  34.93%\n","Current batch: Loss-> 1.2628, Train accuracy->  35.01%\n","Current batch: Loss-> 0.7734, Train accuracy->  35.12%\n","Current batch: Loss-> 0.6048, Train accuracy->  35.22%\n","Current batch: Loss-> 0.8337, Train accuracy->  35.33%\n","Current batch: Loss-> 0.9004, Train accuracy->  35.42%\n","Current batch: Loss-> 1.0920, Train accuracy->  35.51%\n","Current batch: Loss-> 0.8592, Train accuracy->  35.59%\n","Current batch: Loss-> 0.9591, Train accuracy->  35.68%\n","Current batch: Loss-> 0.8464, Train accuracy->  35.78%\n","Current batch: Loss-> 0.8575, Train accuracy->  35.87%\n","Current batch: Loss-> 0.7257, Train accuracy->  35.97%\n","Current batch: Loss-> 0.9907, Train accuracy->  36.06%\n","Current batch: Loss-> 0.8655, Train accuracy->  36.15%\n","Current batch: Loss-> 0.9246, Train accuracy->  36.24%\n","Current batch: Loss-> 1.0254, Train accuracy->  36.33%\n","Current batch: Loss-> 1.2515, Train accuracy->  36.41%\n","Current batch: Loss-> 0.7407, Train accuracy->  36.51%\n","Current batch: Loss-> 1.0248, Train accuracy->  36.59%\n","Current batch: Loss-> 1.2504, Train accuracy->  36.68%\n","Current batch: Loss-> 1.0102, Train accuracy->  36.77%\n","Current batch: Loss-> 1.0439, Train accuracy->  36.86%\n","Current batch: Loss-> 1.0340, Train accuracy->  36.95%\n","Current batch: Loss-> 1.0451, Train accuracy->  37.04%\n","Current batch: Loss-> 0.8325, Train accuracy->  37.14%\n","Current batch: Loss-> 0.8547, Train accuracy->  37.22%\n","Current batch: Loss-> 1.1528, Train accuracy->  37.31%\n","Current batch: Loss-> 0.9657, Train accuracy->  37.40%\n","Current batch: Loss-> 0.8048, Train accuracy->  37.50%\n","Current batch: Loss-> 0.8591, Train accuracy->  37.60%\n","Current batch: Loss-> 0.8908, Train accuracy->  37.69%\n","Current batch: Loss-> 0.9254, Train accuracy->  37.79%\n","Current batch: Loss-> 1.1834, Train accuracy->  37.88%\n","Current batch: Loss-> 1.0059, Train accuracy->  37.96%\n","Current batch: Loss-> 0.8508, Train accuracy->  38.06%\n","Current batch: Loss-> 0.7473, Train accuracy->  38.16%\n","Current batch: Loss-> 0.8015, Train accuracy->  38.26%\n","Current batch: Loss-> 1.1213, Train accuracy->  38.35%\n","Current batch: Loss-> 1.1512, Train accuracy->  38.44%\n","Current batch: Loss-> 1.1849, Train accuracy->  38.53%\n","Current batch: Loss-> 1.1275, Train accuracy->  38.61%\n","Current batch: Loss-> 0.8842, Train accuracy->  38.70%\n","Current batch: Loss-> 0.8506, Train accuracy->  38.79%\n","Current batch: Loss-> 1.0189, Train accuracy->  38.88%\n","Current batch: Loss-> 0.9187, Train accuracy->  38.97%\n","Current batch: Loss-> 0.9529, Train accuracy->  39.06%\n","Current batch: Loss-> 1.0049, Train accuracy->  39.15%\n","Current batch: Loss-> 1.1547, Train accuracy->  39.25%\n","Current batch: Loss-> 0.9408, Train accuracy->  39.33%\n","Current batch: Loss-> 1.0400, Train accuracy->  39.42%\n","Current batch: Loss-> 0.8432, Train accuracy->  39.52%\n","Current batch: Loss-> 1.0350, Train accuracy->  39.59%\n","Current batch: Loss-> 0.7602, Train accuracy->  39.70%\n","Current batch: Loss-> 0.7776, Train accuracy->  39.80%\n","Current batch: Loss-> 1.1404, Train accuracy->  39.88%\n","Current batch: Loss-> 0.7878, Train accuracy->  39.96%\n","Current batch: Loss-> 0.9170, Train accuracy->  40.06%\n","Current batch: Loss-> 0.8907, Train accuracy->  40.15%\n","Current batch: Loss-> 0.9683, Train accuracy->  40.23%\n","Current batch: Loss-> 1.0102, Train accuracy->  40.32%\n","Current batch: Loss-> 1.0373, Train accuracy->  40.41%\n","Current batch: Loss-> 0.6870, Train accuracy->  40.51%\n","Current batch: Loss-> 1.1190, Train accuracy->  40.59%\n","Current batch: Loss-> 1.0744, Train accuracy->  40.67%\n","Current batch: Loss-> 0.6707, Train accuracy->  40.78%\n","Current batch: Loss-> 1.0354, Train accuracy->  40.87%\n","Current batch: Loss-> 1.0204, Train accuracy->  40.96%\n","Current batch: Loss-> 1.3025, Train accuracy->  41.04%\n","Current batch: Loss-> 1.3806, Train accuracy->  41.12%\n","Current batch: Loss-> 1.1256, Train accuracy->  41.20%\n","Current batch: Loss-> 1.0198, Train accuracy->  41.29%\n","Current batch: Loss-> 0.8829, Train accuracy->  41.38%\n","Current batch: Loss-> 0.8838, Train accuracy->  41.48%\n","Current batch: Loss-> 0.7987, Train accuracy->  41.58%\n","Current batch: Loss-> 1.0637, Train accuracy->  41.66%\n","Current batch: Loss-> 0.9248, Train accuracy->  41.76%\n","Current batch: Loss-> 0.8539, Train accuracy->  41.86%\n","Current batch: Loss-> 0.9481, Train accuracy->  41.96%\n","Current batch: Loss-> 0.7042, Train accuracy->  42.07%\n","Current batch: Loss-> 1.0699, Train accuracy->  42.16%\n","Current batch: Loss-> 1.0614, Train accuracy->  42.24%\n","Current batch: Loss-> 0.7762, Train accuracy->  42.35%\n","Current batch: Loss-> 0.8102, Train accuracy->  42.45%\n","Current batch: Loss-> 1.0255, Train accuracy->  42.52%\n","Current batch: Loss-> 1.0073, Train accuracy->  42.61%\n","Current batch: Loss-> 0.7916, Train accuracy->  42.70%\n","Current batch: Loss-> 1.2142, Train accuracy->  42.78%\n","Current batch: Loss-> 0.9614, Train accuracy->  42.88%\n","Current batch: Loss-> 0.9468, Train accuracy->  42.98%\n","Current batch: Loss-> 0.9831, Train accuracy->  43.06%\n","Current batch: Loss-> 1.0515, Train accuracy->  43.15%\n","Current batch: Loss-> 0.7585, Train accuracy->  43.25%\n","Current batch: Loss-> 0.8411, Train accuracy->  43.35%\n","Current batch: Loss-> 1.0563, Train accuracy->  43.43%\n","Current batch: Loss-> 0.7331, Train accuracy->  43.53%\n","Current batch: Loss-> 0.9719, Train accuracy->  43.62%\n","Current batch: Loss-> 0.9791, Train accuracy->  43.71%\n","Current batch: Loss-> 1.0573, Train accuracy->  43.80%\n","Current batch: Loss-> 0.7968, Train accuracy->  43.90%\n","Current batch: Loss-> 0.7986, Train accuracy->  44.00%\n","Current batch: Loss-> 1.1045, Train accuracy->  44.09%\n","Current batch: Loss-> 1.0652, Train accuracy->  44.17%\n","Current batch: Loss-> 1.1596, Train accuracy->  44.25%\n","Current batch: Loss-> 1.0551, Train accuracy->  44.33%\n","Current batch: Loss-> 0.9492, Train accuracy->  44.43%\n","Current batch: Loss-> 0.7660, Train accuracy->  44.53%\n","Current batch: Loss-> 0.6598, Train accuracy->  44.64%\n","Current batch: Loss-> 0.8549, Train accuracy->  44.73%\n","Current batch: Loss-> 0.8614, Train accuracy->  44.83%\n","Current batch: Loss-> 1.1232, Train accuracy->  44.91%\n","Current batch: Loss-> 0.9777, Train accuracy->  45.00%\n","Current batch: Loss-> 0.6541, Train accuracy->  45.11%\n","Current batch: Loss-> 1.0066, Train accuracy->  45.20%\n","Current batch: Loss-> 0.8859, Train accuracy->  45.30%\n","Current batch: Loss-> 0.7253, Train accuracy->  45.40%\n","Current batch: Loss-> 0.8750, Train accuracy->  45.51%\n","Current batch: Loss-> 0.8264, Train accuracy->  45.60%\n","Current batch: Loss-> 0.9455, Train accuracy->  45.69%\n","Current batch: Loss-> 0.7973, Train accuracy->  45.78%\n","Current batch: Loss-> 0.9706, Train accuracy->  45.87%\n","Current batch: Loss-> 0.9403, Train accuracy->  45.95%\n","Current batch: Loss-> 0.9001, Train accuracy->  46.04%\n","Current batch: Loss-> 0.8581, Train accuracy->  46.14%\n","Current batch: Loss-> 0.8129, Train accuracy->  46.23%\n","Current batch: Loss-> 0.7476, Train accuracy->  46.33%\n","Current batch: Loss-> 1.0708, Train accuracy->  46.41%\n","Current batch: Loss-> 0.7254, Train accuracy->  46.52%\n","Current batch: Loss-> 1.2286, Train accuracy->  46.60%\n","Current batch: Loss-> 1.2835, Train accuracy->  46.69%\n","Current batch: Loss-> 1.1142, Train accuracy->  46.77%\n","Current batch: Loss-> 1.1467, Train accuracy->  46.86%\n","Current batch: Loss-> 1.0897, Train accuracy->  46.95%\n","Current batch: Loss-> 1.0908, Train accuracy->  47.03%\n","Current batch: Loss-> 0.9481, Train accuracy->  47.12%\n","Current batch: Loss-> 0.7893, Train accuracy->  47.21%\n","Current batch: Loss-> 0.8085, Train accuracy->  47.31%\n","Current batch: Loss-> 1.0063, Train accuracy->  47.40%\n","Current batch: Loss-> 0.9610, Train accuracy->  47.50%\n","Current batch: Loss-> 0.9564, Train accuracy->  47.59%\n","Current batch: Loss-> 1.1151, Train accuracy->  47.68%\n","Current batch: Loss-> 0.8855, Train accuracy->  47.77%\n","Current batch: Loss-> 0.9840, Train accuracy->  47.87%\n","Current batch: Loss-> 1.1309, Train accuracy->  47.96%\n","Current batch: Loss-> 1.0494, Train accuracy->  48.04%\n","Current batch: Loss-> 0.9387, Train accuracy->  48.13%\n","Current batch: Loss-> 0.7756, Train accuracy->  48.24%\n","Current batch: Loss-> 0.9935, Train accuracy->  48.33%\n","Current batch: Loss-> 0.9961, Train accuracy->  48.41%\n","Current batch: Loss-> 0.9064, Train accuracy->  48.50%\n","Current batch: Loss-> 0.8637, Train accuracy->  48.60%\n","Current batch: Loss-> 1.1214, Train accuracy->  48.68%\n","Current batch: Loss-> 0.7271, Train accuracy->  48.78%\n","Current batch: Loss-> 1.0324, Train accuracy->  48.87%\n","Current batch: Loss-> 0.9206, Train accuracy->  48.96%\n","Current batch: Loss-> 0.9390, Train accuracy->  49.06%\n","Current batch: Loss-> 0.8894, Train accuracy->  49.14%\n","Current batch: Loss-> 0.8411, Train accuracy->  49.24%\n","Current batch: Loss-> 0.8273, Train accuracy->  49.33%\n","Current batch: Loss-> 0.9429, Train accuracy->  49.42%\n","Current batch: Loss-> 1.1201, Train accuracy->  49.51%\n","Current batch: Loss-> 1.1013, Train accuracy->  49.59%\n","Current batch: Loss-> 0.9870, Train accuracy->  49.68%\n","Current batch: Loss-> 0.6706, Train accuracy->  49.78%\n","Current batch: Loss-> 1.0105, Train accuracy->  49.88%\n","Current batch: Loss-> 1.0581, Train accuracy->  49.97%\n","Current batch: Loss-> 0.9895, Train accuracy->  50.06%\n","Current batch: Loss-> 0.9426, Train accuracy->  50.16%\n","Current batch: Loss-> 1.2901, Train accuracy->  50.24%\n","Current batch: Loss-> 0.8032, Train accuracy->  50.35%\n","Current batch: Loss-> 1.1158, Train accuracy->  50.44%\n","Current batch: Loss-> 0.9075, Train accuracy->  50.53%\n","Current batch: Loss-> 1.3262, Train accuracy->  50.61%\n","Current batch: Loss-> 0.9088, Train accuracy->  50.70%\n","Current batch: Loss-> 0.9839, Train accuracy->  50.80%\n","Current batch: Loss-> 0.7623, Train accuracy->  50.90%\n","Current batch: Loss-> 0.6921, Train accuracy->  51.01%\n","Current batch: Loss-> 0.6907, Train accuracy->  51.11%\n","Current batch: Loss-> 0.8276, Train accuracy->  51.21%\n","Current batch: Loss-> 0.6342, Train accuracy->  51.31%\n","Current batch: Loss-> 1.4592, Train accuracy->  51.39%\n","Current batch: Loss-> 1.1999, Train accuracy->  51.46%\n","Current batch: Loss-> 0.8704, Train accuracy->  51.56%\n","Current batch: Loss-> 1.2380, Train accuracy->  51.63%\n","Current batch: Loss-> 0.7830, Train accuracy->  51.73%\n","Current batch: Loss-> 0.8903, Train accuracy->  51.84%\n","Current batch: Loss-> 1.1075, Train accuracy->  51.92%\n","Current batch: Loss-> 0.9740, Train accuracy->  52.02%\n","Current batch: Loss-> 0.7647, Train accuracy->  52.11%\n","Current batch: Loss-> 0.9715, Train accuracy->  52.21%\n","Current batch: Loss-> 1.0534, Train accuracy->  52.30%\n","Current batch: Loss-> 0.8922, Train accuracy->  52.39%\n","Current batch: Loss-> 1.0287, Train accuracy->  52.48%\n","Current batch: Loss-> 1.0235, Train accuracy->  52.57%\n","Current batch: Loss-> 0.8830, Train accuracy->  52.66%\n","Current batch: Loss-> 0.8913, Train accuracy->  52.75%\n","Current batch: Loss-> 0.8058, Train accuracy->  52.86%\n","Current batch: Loss-> 0.8004, Train accuracy->  52.97%\n","Current batch: Loss-> 1.0343, Train accuracy->  53.06%\n","Current batch: Loss-> 1.1824, Train accuracy->  53.14%\n","Current batch: Loss-> 0.8549, Train accuracy->  53.24%\n","Current batch: Loss-> 0.8319, Train accuracy->  53.34%\n","Current batch: Loss-> 1.0399, Train accuracy->  53.42%\n","Current batch: Loss-> 0.9016, Train accuracy->  53.51%\n","Current batch: Loss-> 0.9228, Train accuracy->  53.60%\n","Current batch: Loss-> 1.1251, Train accuracy->  53.69%\n","Current batch: Loss-> 0.7984, Train accuracy->  53.78%\n","Current batch: Loss-> 0.9923, Train accuracy->  53.87%\n","Current batch: Loss-> 0.9832, Train accuracy->  53.96%\n","Current batch: Loss-> 1.1150, Train accuracy->  54.05%\n","Current batch: Loss-> 1.2985, Train accuracy->  54.14%\n","Current batch: Loss-> 0.7421, Train accuracy->  54.24%\n","Current batch: Loss-> 1.0082, Train accuracy->  54.32%\n","Current batch: Loss-> 0.9719, Train accuracy->  54.41%\n","Current batch: Loss-> 0.9627, Train accuracy->  54.50%\n","Current batch: Loss-> 0.9366, Train accuracy->  54.60%\n","Current batch: Loss-> 1.0936, Train accuracy->  54.70%\n","Current batch: Loss-> 1.1536, Train accuracy->  54.77%\n","Current batch: Loss-> 0.6042, Train accuracy->  54.88%\n","Current batch: Loss-> 0.8496, Train accuracy->  54.98%\n","Current batch: Loss-> 0.9486, Train accuracy->  55.07%\n","Current batch: Loss-> 0.7700, Train accuracy->  55.17%\n","Current batch: Loss-> 0.8500, Train accuracy->  55.27%\n","Current batch: Loss-> 0.9536, Train accuracy->  55.36%\n","Current batch: Loss-> 0.9258, Train accuracy->  55.44%\n","Current batch: Loss-> 0.7515, Train accuracy->  55.54%\n","Current batch: Loss-> 0.7139, Train accuracy->  55.63%\n","Current batch: Loss-> 0.8321, Train accuracy->  55.73%\n","Current batch: Loss-> 0.8652, Train accuracy->  55.83%\n","Current batch: Loss-> 0.7106, Train accuracy->  55.94%\n","Current batch: Loss-> 1.0920, Train accuracy->  56.02%\n","Current batch: Loss-> 0.6625, Train accuracy->  56.13%\n","Current batch: Loss-> 1.0073, Train accuracy->  56.21%\n","Current batch: Loss-> 0.9243, Train accuracy->  56.31%\n","Current batch: Loss-> 1.0196, Train accuracy->  56.40%\n","Current batch: Loss-> 0.8640, Train accuracy->  56.49%\n","Current batch: Loss-> 0.8601, Train accuracy->  56.59%\n","Current batch: Loss-> 0.7567, Train accuracy->  56.69%\n","Current batch: Loss-> 1.1045, Train accuracy->  56.77%\n","Current batch: Loss-> 0.8389, Train accuracy->  56.87%\n","Current batch: Loss-> 1.1799, Train accuracy->  56.96%\n","Current batch: Loss-> 1.0565, Train accuracy->  57.04%\n","Current batch: Loss-> 0.9295, Train accuracy->  57.13%\n","Current batch: Loss-> 0.8188, Train accuracy->  57.23%\n","Current batch: Loss-> 0.8357, Train accuracy->  57.33%\n","Current batch: Loss-> 1.0547, Train accuracy->  57.42%\n","Current batch: Loss-> 0.8692, Train accuracy->  57.52%\n","Current batch: Loss-> 0.8065, Train accuracy->  57.63%\n","Current batch: Loss-> 0.8801, Train accuracy->  57.71%\n","Current batch: Loss-> 0.6650, Train accuracy->  57.81%\n","Current batch: Loss-> 0.8533, Train accuracy->  57.91%\n","Current batch: Loss-> 0.9309, Train accuracy->  58.01%\n","Current batch: Loss-> 0.8561, Train accuracy->  58.10%\n","Current batch: Loss-> 0.8353, Train accuracy->  58.20%\n","Current batch: Loss-> 1.0179, Train accuracy->  58.29%\n","Current batch: Loss-> 1.0715, Train accuracy->  58.37%\n","Current batch: Loss-> 0.9633, Train accuracy->  58.47%\n","Current batch: Loss-> 0.8292, Train accuracy->  58.56%\n","Current batch: Loss-> 0.9614, Train accuracy->  58.66%\n","Current batch: Loss-> 0.8990, Train accuracy->  58.75%\n","Current batch: Loss-> 0.6972, Train accuracy->  58.86%\n","Current batch: Loss-> 1.2169, Train accuracy->  58.92%\n","Current batch: Loss-> 0.9954, Train accuracy->  59.00%\n","Current batch: Loss-> 0.8125, Train accuracy->  59.10%\n","Current batch: Loss-> 1.2924, Train accuracy->  59.17%\n","Current batch: Loss-> 0.7512, Train accuracy->  59.28%\n","Current batch: Loss-> 0.9292, Train accuracy->  59.37%\n","Current batch: Loss-> 0.5672, Train accuracy->  59.48%\n","Current batch: Loss-> 0.9456, Train accuracy->  59.57%\n","Current batch: Loss-> 0.9683, Train accuracy->  59.66%\n","Current batch: Loss-> 0.9207, Train accuracy->  59.75%\n","Current batch: Loss-> 0.7360, Train accuracy->  59.85%\n","Current batch: Loss-> 0.9129, Train accuracy->  59.95%\n","Current batch: Loss-> 0.8052, Train accuracy->  60.05%\n","Current batch: Loss-> 1.0085, Train accuracy->  60.15%\n","Current batch: Loss-> 0.9584, Train accuracy->  60.23%\n","Current batch: Loss-> 1.0899, Train accuracy->  60.31%\n","Current batch: Loss-> 1.0256, Train accuracy->  60.41%\n","Current batch: Loss-> 1.3728, Train accuracy->  60.49%\n","Current batch: Loss-> 0.6475, Train accuracy->  60.60%\n","Current batch: Loss-> 1.1408, Train accuracy->  60.68%\n","Current batch: Loss-> 1.0064, Train accuracy->  60.78%\n","Current batch: Loss-> 1.0425, Train accuracy->  60.88%\n","Current batch: Loss-> 0.6807, Train accuracy->  60.97%\n","Current batch: Loss-> 0.9977, Train accuracy->  61.07%\n","Current batch: Loss-> 1.0654, Train accuracy->  61.15%\n","Current batch: Loss-> 0.8439, Train accuracy->  61.24%\n","Current batch: Loss-> 0.8981, Train accuracy->  61.33%\n","Current batch: Loss-> 1.0178, Train accuracy->  61.42%\n","Current batch: Loss-> 0.9200, Train accuracy->  61.51%\n","Current batch: Loss-> 1.1095, Train accuracy->  61.60%\n","Current batch: Loss-> 0.6666, Train accuracy->  61.70%\n","Current batch: Loss-> 1.1339, Train accuracy->  61.80%\n","Current batch: Loss-> 1.3492, Train accuracy->  61.88%\n","Current batch: Loss-> 0.9782, Train accuracy->  61.96%\n","Current batch: Loss-> 1.1655, Train accuracy->  62.05%\n","Current batch: Loss-> 1.0137, Train accuracy->  62.14%\n","Current batch: Loss-> 1.0282, Train accuracy->  62.24%\n","Current batch: Loss-> 0.9944, Train accuracy->  62.32%\n","Current batch: Loss-> 1.2294, Train accuracy->  62.39%\n","Current batch: Loss-> 0.9490, Train accuracy->  62.47%\n","Current batch: Loss-> 0.9600, Train accuracy->  62.57%\n","Current batch: Loss-> 1.0068, Train accuracy->  62.66%\n","Current batch: Loss-> 0.7197, Train accuracy->  62.77%\n","Current batch: Loss-> 1.5290, Train accuracy->  62.83%\n","Current batch: Loss-> 0.7043, Train accuracy->  62.94%\n","Current batch: Loss-> 0.8973, Train accuracy->  63.04%\n","Current batch: Loss-> 1.0549, Train accuracy->  63.12%\n","Current batch: Loss-> 1.0095, Train accuracy->  63.21%\n","Current batch: Loss-> 1.2750, Train accuracy->  63.28%\n","Current batch: Loss-> 1.3878, Train accuracy->  63.35%\n","Current batch: Loss-> 0.7639, Train accuracy->  63.44%\n","Current batch: Loss-> 0.9690, Train accuracy->  63.52%\n","Current batch: Loss-> 1.0015, Train accuracy->  63.62%\n","Current batch: Loss-> 0.9827, Train accuracy->  63.71%\n","Current batch: Loss-> 1.0773, Train accuracy->  63.80%\n","Current batch: Loss-> 1.0776, Train accuracy->  63.88%\n","Current batch: Loss-> 1.1818, Train accuracy->  63.97%\n","Current batch: Loss-> 0.9571, Train accuracy->  64.06%\n","Current batch: Loss-> 1.1046, Train accuracy->  64.14%\n","Current batch: Loss-> 0.7342, Train accuracy->  64.24%\n","Current batch: Loss-> 1.2164, Train accuracy->  64.32%\n","Current batch: Loss-> 0.7444, Train accuracy->  64.42%\n","Current batch: Loss-> 0.7884, Train accuracy->  64.52%\n","Current batch: Loss-> 0.9564, Train accuracy->  64.61%\n","Current batch: Loss-> 1.0747, Train accuracy->  64.69%\n","Current batch: Loss-> 0.9154, Train accuracy->  64.78%\n","Current batch: Loss-> 0.9630, Train accuracy->  64.86%\n","Current batch: Loss-> 1.1467, Train accuracy->  64.96%\n","Current batch: Loss-> 0.8329, Train accuracy->  65.06%\n","Current batch: Loss-> 1.0400, Train accuracy->  65.16%\n","Current batch: Loss-> 0.9254, Train accuracy->  65.25%\n","Current batch: Loss-> 1.0953, Train accuracy->  65.33%\n","Current batch: Loss-> 0.8638, Train accuracy->  65.42%\n","Current batch: Loss-> 1.1798, Train accuracy->  65.51%\n","Current batch: Loss-> 1.0542, Train accuracy->  65.58%\n","Current batch: Loss-> 1.0019, Train accuracy->  65.67%\n","Current batch: Loss-> 0.9108, Train accuracy->  65.76%\n","Current batch: Loss-> 0.7249, Train accuracy->  65.86%\n","Current batch: Loss-> 0.8166, Train accuracy->  65.95%\n","Current batch: Loss-> 0.8043, Train accuracy->  66.05%\n","Current batch: Loss-> 1.0000, Train accuracy->  66.14%\n","Current batch: Loss-> 0.9505, Train accuracy->  66.22%\n","Current batch: Loss-> 1.1018, Train accuracy->  66.31%\n","Current batch: Loss-> 1.4224, Train accuracy->  66.40%\n","Current batch: Loss-> 0.8783, Train accuracy->  66.49%\n","Current batch: Loss-> 0.8347, Train accuracy->  66.59%\n","Current batch: Loss-> 1.1476, Train accuracy->  66.68%\n","Current batch: Loss-> 0.9779, Train accuracy->  66.77%\n","Current batch: Loss-> 0.8707, Train accuracy->  66.85%\n","Current batch: Loss-> 1.0523, Train accuracy->  66.93%\n","Current batch: Loss-> 0.8005, Train accuracy->  67.03%\n","Current batch: Loss-> 0.7175, Train accuracy->  67.13%\n","Current batch: Loss-> 0.9212, Train accuracy->  67.22%\n","Current batch: Loss-> 0.9995, Train accuracy->  67.32%\n","Current batch: Loss-> 1.0047, Train accuracy->  67.40%\n","Current batch: Loss-> 0.8362, Train accuracy->  67.50%\n","Current batch: Loss-> 0.8217, Train accuracy->  67.60%\n","Current batch: Loss-> 0.7543, Train accuracy->  67.70%\n","Current batch: Loss-> 1.1678, Train accuracy->  67.78%\n","Current batch: Loss-> 0.8945, Train accuracy->  67.88%\n","Current batch: Loss-> 0.8438, Train accuracy->  67.98%\n","Current batch: Loss-> 1.0396, Train accuracy->  68.07%\n","Current batch: Loss-> 1.0005, Train accuracy->  68.17%\n","Current batch: Loss-> 0.9439, Train accuracy->  68.26%\n","Current batch: Loss-> 0.9119, Train accuracy->  68.35%\n","Current batch: Loss-> 1.0567, Train accuracy->  68.44%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 46.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.8589, Train accuracy->  68.54%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.62it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.7392, Accuracy: 5380/12000 (45%)\n","\n","Current batch: Loss-> 0.7331, Train accuracy->   0.11%\n","Current batch: Loss-> 0.9184, Train accuracy->   0.21%\n","Current batch: Loss-> 0.7365, Train accuracy->   0.31%\n","Current batch: Loss-> 0.8385, Train accuracy->   0.40%\n","Current batch: Loss-> 0.9805, Train accuracy->   0.49%\n","Current batch: Loss-> 0.9241, Train accuracy->   0.59%\n","Current batch: Loss-> 0.7663, Train accuracy->   0.70%\n","Current batch: Loss-> 0.7841, Train accuracy->   0.79%\n","Current batch: Loss-> 0.9496, Train accuracy->   0.88%\n","Current batch: Loss-> 0.7718, Train accuracy->   0.98%\n","Current batch: Loss-> 0.9583, Train accuracy->   1.08%\n","Current batch: Loss-> 0.7915, Train accuracy->   1.17%\n","Current batch: Loss-> 1.0509, Train accuracy->   1.26%\n","Current batch: Loss-> 0.9061, Train accuracy->   1.35%\n","Current batch: Loss-> 0.7818, Train accuracy->   1.44%\n","Current batch: Loss-> 0.7278, Train accuracy->   1.54%\n","Current batch: Loss-> 0.7003, Train accuracy->   1.65%\n","Current batch: Loss-> 1.0067, Train accuracy->   1.74%\n","Current batch: Loss-> 0.9232, Train accuracy->   1.83%\n","Current batch: Loss-> 1.1909, Train accuracy->   1.91%\n","Current batch: Loss-> 0.9681, Train accuracy->   2.00%\n","Current batch: Loss-> 1.0137, Train accuracy->   2.09%\n","Current batch: Loss-> 0.8154, Train accuracy->   2.19%\n","Current batch: Loss-> 1.0415, Train accuracy->   2.27%\n","Current batch: Loss-> 0.8355, Train accuracy->   2.37%\n","Current batch: Loss-> 1.4220, Train accuracy->   2.45%\n","Current batch: Loss-> 1.0757, Train accuracy->   2.53%\n","Current batch: Loss-> 0.7222, Train accuracy->   2.64%\n","Current batch: Loss-> 0.8172, Train accuracy->   2.74%\n","Current batch: Loss-> 0.9283, Train accuracy->   2.83%\n","Current batch: Loss-> 0.6448, Train accuracy->   2.94%\n","Current batch: Loss-> 0.9390, Train accuracy->   3.03%\n","Current batch: Loss-> 0.9220, Train accuracy->   3.12%\n","Current batch: Loss-> 0.8471, Train accuracy->   3.22%\n","Current batch: Loss-> 0.5972, Train accuracy->   3.32%\n","Current batch: Loss-> 0.7859, Train accuracy->   3.42%\n","Current batch: Loss-> 0.9722, Train accuracy->   3.50%\n","Current batch: Loss-> 0.7194, Train accuracy->   3.61%\n","Current batch: Loss-> 0.9051, Train accuracy->   3.71%\n","Current batch: Loss-> 0.8899, Train accuracy->   3.81%\n","Current batch: Loss-> 0.9939, Train accuracy->   3.90%\n","Current batch: Loss-> 0.7123, Train accuracy->   4.00%\n","Current batch: Loss-> 0.7337, Train accuracy->   4.09%\n","Current batch: Loss-> 0.7274, Train accuracy->   4.19%\n","Current batch: Loss-> 0.9345, Train accuracy->   4.28%\n","Current batch: Loss-> 0.8799, Train accuracy->   4.37%\n","Current batch: Loss-> 0.8781, Train accuracy->   4.46%\n","Current batch: Loss-> 0.9275, Train accuracy->   4.54%\n","Current batch: Loss-> 0.8727, Train accuracy->   4.63%\n","Current batch: Loss-> 0.7231, Train accuracy->   4.74%\n","Current batch: Loss-> 1.0802, Train accuracy->   4.83%\n","Current batch: Loss-> 0.7002, Train accuracy->   4.94%\n","Current batch: Loss-> 0.9674, Train accuracy->   5.03%\n","Current batch: Loss-> 0.9890, Train accuracy->   5.12%\n","Current batch: Loss-> 1.1177, Train accuracy->   5.21%\n","Current batch: Loss-> 0.8440, Train accuracy->   5.30%\n","Current batch: Loss-> 0.8761, Train accuracy->   5.40%\n","Current batch: Loss-> 1.0477, Train accuracy->   5.49%\n","Current batch: Loss-> 0.7743, Train accuracy->   5.59%\n","Current batch: Loss-> 0.7374, Train accuracy->   5.69%\n","Current batch: Loss-> 1.1263, Train accuracy->   5.78%\n","Current batch: Loss-> 1.0340, Train accuracy->   5.88%\n","Current batch: Loss-> 0.9251, Train accuracy->   5.97%\n","Current batch: Loss-> 1.1275, Train accuracy->   6.05%\n","Current batch: Loss-> 0.7904, Train accuracy->   6.15%\n","Current batch: Loss-> 0.6583, Train accuracy->   6.26%\n","Current batch: Loss-> 0.8335, Train accuracy->   6.36%\n","Current batch: Loss-> 0.8165, Train accuracy->   6.46%\n","Current batch: Loss-> 1.0565, Train accuracy->   6.54%\n","Current batch: Loss-> 0.8435, Train accuracy->   6.64%\n","Current batch: Loss-> 0.8659, Train accuracy->   6.73%\n","Current batch: Loss-> 0.9383, Train accuracy->   6.83%\n","Current batch: Loss-> 0.6460, Train accuracy->   6.94%\n","Current batch: Loss-> 0.7168, Train accuracy->   7.04%\n","Current batch: Loss-> 1.1242, Train accuracy->   7.13%\n","Current batch: Loss-> 0.8711, Train accuracy->   7.23%\n","Current batch: Loss-> 1.0102, Train accuracy->   7.32%\n","Current batch: Loss-> 0.9439, Train accuracy->   7.41%\n","Current batch: Loss-> 0.7583, Train accuracy->   7.53%\n","Current batch: Loss-> 0.9566, Train accuracy->   7.62%\n","Current batch: Loss-> 1.0724, Train accuracy->   7.71%\n","Current batch: Loss-> 1.0141, Train accuracy->   7.79%\n","Current batch: Loss-> 0.9086, Train accuracy->   7.89%\n","Current batch: Loss-> 0.6958, Train accuracy->   7.99%\n","Current batch: Loss-> 0.7773, Train accuracy->   8.08%\n","Current batch: Loss-> 0.9716, Train accuracy->   8.18%\n","Current batch: Loss-> 0.7575, Train accuracy->   8.27%\n","Current batch: Loss-> 0.8810, Train accuracy->   8.38%\n","Current batch: Loss-> 0.7879, Train accuracy->   8.47%\n","Current batch: Loss-> 1.0571, Train accuracy->   8.55%\n","Current batch: Loss-> 0.9573, Train accuracy->   8.65%\n","Current batch: Loss-> 0.7869, Train accuracy->   8.75%\n","Current batch: Loss-> 0.9329, Train accuracy->   8.84%\n","Current batch: Loss-> 0.7820, Train accuracy->   8.94%\n","Current batch: Loss-> 1.0529, Train accuracy->   9.02%\n","Current batch: Loss-> 0.8112, Train accuracy->   9.11%\n","Current batch: Loss-> 1.0019, Train accuracy->   9.21%\n","Current batch: Loss-> 0.6707, Train accuracy->   9.32%\n","Current batch: Loss-> 0.9579, Train accuracy->   9.41%\n","Current batch: Loss-> 0.8378, Train accuracy->   9.51%\n","Current batch: Loss-> 0.7472, Train accuracy->   9.61%\n","Current batch: Loss-> 1.0244, Train accuracy->   9.69%\n","Current batch: Loss-> 0.7184, Train accuracy->   9.79%\n","Current batch: Loss-> 0.9341, Train accuracy->   9.87%\n","Current batch: Loss-> 0.6905, Train accuracy->   9.97%\n","Current batch: Loss-> 1.1331, Train accuracy->  10.06%\n","Current batch: Loss-> 0.8496, Train accuracy->  10.16%\n","Current batch: Loss-> 0.9291, Train accuracy->  10.25%\n","Current batch: Loss-> 0.9543, Train accuracy->  10.35%\n","Current batch: Loss-> 1.1443, Train accuracy->  10.43%\n","Current batch: Loss-> 0.5816, Train accuracy->  10.55%\n","Current batch: Loss-> 1.0321, Train accuracy->  10.64%\n","Current batch: Loss-> 1.0607, Train accuracy->  10.72%\n","Current batch: Loss-> 0.7087, Train accuracy->  10.82%\n","Current batch: Loss-> 0.7245, Train accuracy->  10.93%\n","Current batch: Loss-> 0.8172, Train accuracy->  11.03%\n","Current batch: Loss-> 0.9176, Train accuracy->  11.12%\n","Current batch: Loss-> 0.7643, Train accuracy->  11.22%\n","Current batch: Loss-> 0.8608, Train accuracy->  11.32%\n","Current batch: Loss-> 0.8396, Train accuracy->  11.41%\n","Current batch: Loss-> 0.7261, Train accuracy->  11.51%\n","Current batch: Loss-> 0.9808, Train accuracy->  11.60%\n","Current batch: Loss-> 0.6618, Train accuracy->  11.71%\n","Current batch: Loss-> 0.7467, Train accuracy->  11.81%\n","Current batch: Loss-> 1.0604, Train accuracy->  11.90%\n","Current batch: Loss-> 0.6154, Train accuracy->  12.01%\n","Current batch: Loss-> 0.9213, Train accuracy->  12.11%\n","Current batch: Loss-> 0.8327, Train accuracy->  12.20%\n","Current batch: Loss-> 0.8330, Train accuracy->  12.30%\n","Current batch: Loss-> 0.7731, Train accuracy->  12.40%\n","Current batch: Loss-> 1.2545, Train accuracy->  12.49%\n","Current batch: Loss-> 0.9163, Train accuracy->  12.58%\n","Current batch: Loss-> 0.7027, Train accuracy->  12.69%\n","Current batch: Loss-> 1.2503, Train accuracy->  12.79%\n","Current batch: Loss-> 0.8928, Train accuracy->  12.89%\n","Current batch: Loss-> 0.7612, Train accuracy->  12.99%\n","Current batch: Loss-> 0.6699, Train accuracy->  13.10%\n","Current batch: Loss-> 0.7048, Train accuracy->  13.19%\n","Current batch: Loss-> 0.9581, Train accuracy->  13.29%\n","Current batch: Loss-> 0.7902, Train accuracy->  13.39%\n","Current batch: Loss-> 0.6192, Train accuracy->  13.49%\n","Current batch: Loss-> 1.0863, Train accuracy->  13.59%\n","Current batch: Loss-> 0.6275, Train accuracy->  13.70%\n","Current batch: Loss-> 0.9124, Train accuracy->  13.80%\n","Current batch: Loss-> 0.6360, Train accuracy->  13.91%\n","Current batch: Loss-> 0.9541, Train accuracy->  14.00%\n","Current batch: Loss-> 1.0139, Train accuracy->  14.10%\n","Current batch: Loss-> 1.0434, Train accuracy->  14.19%\n","Current batch: Loss-> 0.8363, Train accuracy->  14.28%\n","Current batch: Loss-> 1.0010, Train accuracy->  14.37%\n","Current batch: Loss-> 0.6329, Train accuracy->  14.48%\n","Current batch: Loss-> 0.7763, Train accuracy->  14.57%\n","Current batch: Loss-> 0.9065, Train accuracy->  14.65%\n","Current batch: Loss-> 0.8721, Train accuracy->  14.75%\n","Current batch: Loss-> 1.0857, Train accuracy->  14.83%\n","Current batch: Loss-> 0.7285, Train accuracy->  14.93%\n","Current batch: Loss-> 0.8462, Train accuracy->  15.03%\n","Current batch: Loss-> 0.8480, Train accuracy->  15.13%\n","Current batch: Loss-> 0.8541, Train accuracy->  15.22%\n","Current batch: Loss-> 0.6157, Train accuracy->  15.33%\n","Current batch: Loss-> 0.7879, Train accuracy->  15.43%\n","Current batch: Loss-> 0.7273, Train accuracy->  15.53%\n","Current batch: Loss-> 1.1639, Train accuracy->  15.61%\n","Current batch: Loss-> 1.0845, Train accuracy->  15.69%\n","Current batch: Loss-> 0.9779, Train accuracy->  15.78%\n","Current batch: Loss-> 0.7887, Train accuracy->  15.88%\n","Current batch: Loss-> 0.8343, Train accuracy->  15.98%\n","Current batch: Loss-> 0.9171, Train accuracy->  16.07%\n","Current batch: Loss-> 0.6719, Train accuracy->  16.17%\n","Current batch: Loss-> 0.8779, Train accuracy->  16.27%\n","Current batch: Loss-> 1.1042, Train accuracy->  16.36%\n","Current batch: Loss-> 0.6850, Train accuracy->  16.46%\n","Current batch: Loss-> 0.9612, Train accuracy->  16.55%\n","Current batch: Loss-> 0.8837, Train accuracy->  16.65%\n","Current batch: Loss-> 0.8438, Train accuracy->  16.75%\n","Current batch: Loss-> 0.8031, Train accuracy->  16.85%\n","Current batch: Loss-> 0.9980, Train accuracy->  16.95%\n","Current batch: Loss-> 0.9276, Train accuracy->  17.04%\n","Current batch: Loss-> 0.8360, Train accuracy->  17.15%\n","Current batch: Loss-> 1.1110, Train accuracy->  17.24%\n","Current batch: Loss-> 0.8645, Train accuracy->  17.34%\n","Current batch: Loss-> 0.6944, Train accuracy->  17.45%\n","Current batch: Loss-> 1.0821, Train accuracy->  17.54%\n","Current batch: Loss-> 0.8688, Train accuracy->  17.64%\n","Current batch: Loss-> 1.0716, Train accuracy->  17.73%\n","Current batch: Loss-> 1.0328, Train accuracy->  17.81%\n","Current batch: Loss-> 0.7789, Train accuracy->  17.91%\n","Current batch: Loss-> 0.8917, Train accuracy->  18.00%\n","Current batch: Loss-> 1.0162, Train accuracy->  18.10%\n","Current batch: Loss-> 0.6256, Train accuracy->  18.21%\n","Current batch: Loss-> 0.9168, Train accuracy->  18.31%\n","Current batch: Loss-> 0.8337, Train accuracy->  18.40%\n","Current batch: Loss-> 0.8940, Train accuracy->  18.51%\n","Current batch: Loss-> 1.0081, Train accuracy->  18.60%\n","Current batch: Loss-> 0.7361, Train accuracy->  18.71%\n","Current batch: Loss-> 0.8391, Train accuracy->  18.81%\n","Current batch: Loss-> 0.9918, Train accuracy->  18.91%\n","Current batch: Loss-> 1.0261, Train accuracy->  19.00%\n","Current batch: Loss-> 0.9375, Train accuracy->  19.11%\n","Current batch: Loss-> 0.8678, Train accuracy->  19.21%\n","Current batch: Loss-> 1.0772, Train accuracy->  19.30%\n","Current batch: Loss-> 0.8072, Train accuracy->  19.39%\n","Current batch: Loss-> 0.9398, Train accuracy->  19.48%\n","Current batch: Loss-> 0.8647, Train accuracy->  19.58%\n","Current batch: Loss-> 1.0472, Train accuracy->  19.67%\n","Current batch: Loss-> 0.9157, Train accuracy->  19.76%\n","Current batch: Loss-> 0.7494, Train accuracy->  19.87%\n","Current batch: Loss-> 0.9797, Train accuracy->  19.97%\n","Current batch: Loss-> 0.7409, Train accuracy->  20.07%\n","Current batch: Loss-> 0.7331, Train accuracy->  20.17%\n","Current batch: Loss-> 0.7737, Train accuracy->  20.27%\n","Current batch: Loss-> 0.9950, Train accuracy->  20.34%\n","Current batch: Loss-> 0.8490, Train accuracy->  20.44%\n","Current batch: Loss-> 0.6420, Train accuracy->  20.55%\n","Current batch: Loss-> 0.6929, Train accuracy->  20.65%\n","Current batch: Loss-> 1.2010, Train accuracy->  20.74%\n","Current batch: Loss-> 1.0575, Train accuracy->  20.83%\n","Current batch: Loss-> 0.8734, Train accuracy->  20.93%\n","Current batch: Loss-> 0.8951, Train accuracy->  21.02%\n","Current batch: Loss-> 0.8473, Train accuracy->  21.11%\n","Current batch: Loss-> 1.0106, Train accuracy->  21.21%\n","Current batch: Loss-> 0.7998, Train accuracy->  21.30%\n","Current batch: Loss-> 1.2202, Train accuracy->  21.38%\n","Current batch: Loss-> 0.8614, Train accuracy->  21.47%\n","Current batch: Loss-> 0.7678, Train accuracy->  21.56%\n","Current batch: Loss-> 1.0155, Train accuracy->  21.64%\n","Current batch: Loss-> 0.6052, Train accuracy->  21.74%\n","Current batch: Loss-> 0.7424, Train accuracy->  21.84%\n","Current batch: Loss-> 0.7865, Train accuracy->  21.95%\n","Current batch: Loss-> 0.8344, Train accuracy->  22.04%\n","Current batch: Loss-> 0.8348, Train accuracy->  22.14%\n","Current batch: Loss-> 0.8874, Train accuracy->  22.22%\n","Current batch: Loss-> 0.8013, Train accuracy->  22.32%\n","Current batch: Loss-> 1.2160, Train accuracy->  22.41%\n","Current batch: Loss-> 0.7843, Train accuracy->  22.51%\n","Current batch: Loss-> 0.8165, Train accuracy->  22.60%\n","Current batch: Loss-> 0.9993, Train accuracy->  22.69%\n","Current batch: Loss-> 0.8487, Train accuracy->  22.79%\n","Current batch: Loss-> 0.8780, Train accuracy->  22.88%\n","Current batch: Loss-> 0.7676, Train accuracy->  22.98%\n","Current batch: Loss-> 0.6970, Train accuracy->  23.08%\n","Current batch: Loss-> 1.0420, Train accuracy->  23.16%\n","Current batch: Loss-> 0.7062, Train accuracy->  23.26%\n","Current batch: Loss-> 0.9165, Train accuracy->  23.35%\n","Current batch: Loss-> 0.8379, Train accuracy->  23.45%\n","Current batch: Loss-> 0.9332, Train accuracy->  23.55%\n","Current batch: Loss-> 0.7579, Train accuracy->  23.64%\n","Current batch: Loss-> 0.6599, Train accuracy->  23.74%\n","Current batch: Loss-> 0.7341, Train accuracy->  23.85%\n","Current batch: Loss-> 0.6807, Train accuracy->  23.95%\n","Current batch: Loss-> 0.6523, Train accuracy->  24.05%\n","Current batch: Loss-> 0.9456, Train accuracy->  24.14%\n","Current batch: Loss-> 0.9327, Train accuracy->  24.23%\n","Current batch: Loss-> 1.1326, Train accuracy->  24.31%\n","Current batch: Loss-> 0.7636, Train accuracy->  24.41%\n","Current batch: Loss-> 0.9069, Train accuracy->  24.51%\n","Current batch: Loss-> 0.9523, Train accuracy->  24.59%\n","Current batch: Loss-> 0.8154, Train accuracy->  24.70%\n","Current batch: Loss-> 0.7568, Train accuracy->  24.80%\n","Current batch: Loss-> 0.7054, Train accuracy->  24.90%\n","Current batch: Loss-> 0.8930, Train accuracy->  24.99%\n","Current batch: Loss-> 0.8900, Train accuracy->  25.08%\n","Current batch: Loss-> 1.2911, Train accuracy->  25.17%\n","Current batch: Loss-> 0.9166, Train accuracy->  25.26%\n","Current batch: Loss-> 0.7214, Train accuracy->  25.37%\n","Current batch: Loss-> 0.7357, Train accuracy->  25.47%\n","Current batch: Loss-> 0.7569, Train accuracy->  25.56%\n","Current batch: Loss-> 1.0598, Train accuracy->  25.65%\n","Current batch: Loss-> 0.9950, Train accuracy->  25.75%\n","Current batch: Loss-> 0.8516, Train accuracy->  25.86%\n","Current batch: Loss-> 1.1479, Train accuracy->  25.94%\n","Current batch: Loss-> 0.8152, Train accuracy->  26.03%\n","Current batch: Loss-> 1.1704, Train accuracy->  26.11%\n","Current batch: Loss-> 0.9993, Train accuracy->  26.20%\n","Current batch: Loss-> 0.8357, Train accuracy->  26.31%\n","Current batch: Loss-> 0.7787, Train accuracy->  26.40%\n","Current batch: Loss-> 0.8288, Train accuracy->  26.50%\n","Current batch: Loss-> 0.9462, Train accuracy->  26.59%\n","Current batch: Loss-> 0.8393, Train accuracy->  26.68%\n","Current batch: Loss-> 0.7280, Train accuracy->  26.79%\n","Current batch: Loss-> 0.8468, Train accuracy->  26.89%\n","Current batch: Loss-> 0.9028, Train accuracy->  26.98%\n","Current batch: Loss-> 0.8464, Train accuracy->  27.07%\n","Current batch: Loss-> 0.8413, Train accuracy->  27.16%\n","Current batch: Loss-> 0.7586, Train accuracy->  27.26%\n","Current batch: Loss-> 0.7072, Train accuracy->  27.36%\n","Current batch: Loss-> 0.8482, Train accuracy->  27.46%\n","Current batch: Loss-> 1.0734, Train accuracy->  27.55%\n","Current batch: Loss-> 0.8673, Train accuracy->  27.65%\n","Current batch: Loss-> 0.6513, Train accuracy->  27.76%\n","Current batch: Loss-> 1.0380, Train accuracy->  27.84%\n","Current batch: Loss-> 0.8712, Train accuracy->  27.95%\n","Current batch: Loss-> 1.0009, Train accuracy->  28.04%\n","Current batch: Loss-> 1.0617, Train accuracy->  28.13%\n","Current batch: Loss-> 0.7221, Train accuracy->  28.23%\n","Current batch: Loss-> 1.2976, Train accuracy->  28.32%\n","Current batch: Loss-> 0.8724, Train accuracy->  28.41%\n","Current batch: Loss-> 0.9163, Train accuracy->  28.50%\n","Current batch: Loss-> 0.7581, Train accuracy->  28.60%\n","Current batch: Loss-> 0.6716, Train accuracy->  28.71%\n","Current batch: Loss-> 0.7623, Train accuracy->  28.81%\n","Current batch: Loss-> 0.8288, Train accuracy->  28.90%\n","Current batch: Loss-> 0.8135, Train accuracy->  29.00%\n","Current batch: Loss-> 0.7563, Train accuracy->  29.10%\n","Current batch: Loss-> 0.9359, Train accuracy->  29.19%\n","Current batch: Loss-> 0.8007, Train accuracy->  29.30%\n","Current batch: Loss-> 1.0932, Train accuracy->  29.39%\n","Current batch: Loss-> 0.8111, Train accuracy->  29.49%\n","Current batch: Loss-> 0.7740, Train accuracy->  29.58%\n","Current batch: Loss-> 0.8778, Train accuracy->  29.68%\n","Current batch: Loss-> 0.9620, Train accuracy->  29.77%\n","Current batch: Loss-> 0.9506, Train accuracy->  29.86%\n","Current batch: Loss-> 1.0030, Train accuracy->  29.95%\n","Current batch: Loss-> 0.7593, Train accuracy->  30.05%\n","Current batch: Loss-> 1.1762, Train accuracy->  30.13%\n","Current batch: Loss-> 0.8623, Train accuracy->  30.22%\n","Current batch: Loss-> 0.6772, Train accuracy->  30.32%\n","Current batch: Loss-> 1.0580, Train accuracy->  30.40%\n","Current batch: Loss-> 0.8780, Train accuracy->  30.50%\n","Current batch: Loss-> 0.8276, Train accuracy->  30.59%\n","Current batch: Loss-> 0.9295, Train accuracy->  30.68%\n","Current batch: Loss-> 0.9259, Train accuracy->  30.77%\n","Current batch: Loss-> 0.8222, Train accuracy->  30.87%\n","Current batch: Loss-> 0.7316, Train accuracy->  30.97%\n","Current batch: Loss-> 0.6719, Train accuracy->  31.08%\n","Current batch: Loss-> 0.8527, Train accuracy->  31.17%\n","Current batch: Loss-> 1.0452, Train accuracy->  31.25%\n","Current batch: Loss-> 0.8669, Train accuracy->  31.35%\n","Current batch: Loss-> 0.8156, Train accuracy->  31.44%\n","Current batch: Loss-> 1.1566, Train accuracy->  31.54%\n","Current batch: Loss-> 0.9370, Train accuracy->  31.63%\n","Current batch: Loss-> 1.0277, Train accuracy->  31.72%\n","Current batch: Loss-> 1.0292, Train accuracy->  31.81%\n","Current batch: Loss-> 1.0368, Train accuracy->  31.91%\n","Current batch: Loss-> 0.6837, Train accuracy->  32.01%\n","Current batch: Loss-> 1.0719, Train accuracy->  32.11%\n","Current batch: Loss-> 1.0637, Train accuracy->  32.19%\n","Current batch: Loss-> 1.0266, Train accuracy->  32.29%\n","Current batch: Loss-> 1.0810, Train accuracy->  32.38%\n","Current batch: Loss-> 0.9907, Train accuracy->  32.46%\n","Current batch: Loss-> 0.8343, Train accuracy->  32.56%\n","Current batch: Loss-> 1.2840, Train accuracy->  32.65%\n","Current batch: Loss-> 0.9056, Train accuracy->  32.73%\n","Current batch: Loss-> 0.9871, Train accuracy->  32.81%\n","Current batch: Loss-> 1.0704, Train accuracy->  32.90%\n","Current batch: Loss-> 0.7897, Train accuracy->  33.00%\n","Current batch: Loss-> 0.8330, Train accuracy->  33.09%\n","Current batch: Loss-> 0.8440, Train accuracy->  33.19%\n","Current batch: Loss-> 1.0886, Train accuracy->  33.27%\n","Current batch: Loss-> 0.8337, Train accuracy->  33.37%\n","Current batch: Loss-> 0.9615, Train accuracy->  33.46%\n","Current batch: Loss-> 0.8436, Train accuracy->  33.55%\n","Current batch: Loss-> 0.9412, Train accuracy->  33.65%\n","Current batch: Loss-> 0.9791, Train accuracy->  33.74%\n","Current batch: Loss-> 0.9174, Train accuracy->  33.83%\n","Current batch: Loss-> 0.9358, Train accuracy->  33.93%\n","Current batch: Loss-> 1.0392, Train accuracy->  34.02%\n","Current batch: Loss-> 1.2332, Train accuracy->  34.11%\n","Current batch: Loss-> 1.1885, Train accuracy->  34.20%\n","Current batch: Loss-> 1.0415, Train accuracy->  34.30%\n","Current batch: Loss-> 0.7903, Train accuracy->  34.41%\n","Current batch: Loss-> 0.8722, Train accuracy->  34.50%\n","Current batch: Loss-> 1.1879, Train accuracy->  34.58%\n","Current batch: Loss-> 0.6277, Train accuracy->  34.68%\n","Current batch: Loss-> 1.0255, Train accuracy->  34.77%\n","Current batch: Loss-> 0.8673, Train accuracy->  34.86%\n","Current batch: Loss-> 0.6863, Train accuracy->  34.96%\n","Current batch: Loss-> 0.7675, Train accuracy->  35.07%\n","Current batch: Loss-> 0.9276, Train accuracy->  35.15%\n","Current batch: Loss-> 0.7719, Train accuracy->  35.25%\n","Current batch: Loss-> 0.8204, Train accuracy->  35.35%\n","Current batch: Loss-> 1.0405, Train accuracy->  35.44%\n","Current batch: Loss-> 0.7860, Train accuracy->  35.54%\n","Current batch: Loss-> 0.9560, Train accuracy->  35.63%\n","Current batch: Loss-> 0.6060, Train accuracy->  35.75%\n","Current batch: Loss-> 0.7913, Train accuracy->  35.84%\n","Current batch: Loss-> 0.8992, Train accuracy->  35.94%\n","Current batch: Loss-> 0.9463, Train accuracy->  36.03%\n","Current batch: Loss-> 0.7705, Train accuracy->  36.13%\n","Current batch: Loss-> 0.8413, Train accuracy->  36.23%\n","Current batch: Loss-> 0.8819, Train accuracy->  36.31%\n","Current batch: Loss-> 1.1715, Train accuracy->  36.40%\n","Current batch: Loss-> 0.7563, Train accuracy->  36.50%\n","Current batch: Loss-> 0.9224, Train accuracy->  36.60%\n","Current batch: Loss-> 1.2520, Train accuracy->  36.67%\n","Current batch: Loss-> 0.7498, Train accuracy->  36.79%\n","Current batch: Loss-> 0.8127, Train accuracy->  36.89%\n","Current batch: Loss-> 0.8292, Train accuracy->  36.99%\n","Current batch: Loss-> 0.8870, Train accuracy->  37.09%\n","Current batch: Loss-> 0.8954, Train accuracy->  37.17%\n","Current batch: Loss-> 0.7087, Train accuracy->  37.28%\n","Current batch: Loss-> 0.8974, Train accuracy->  37.37%\n","Current batch: Loss-> 0.9537, Train accuracy->  37.46%\n","Current batch: Loss-> 0.8925, Train accuracy->  37.55%\n","Current batch: Loss-> 0.8513, Train accuracy->  37.65%\n","Current batch: Loss-> 0.7769, Train accuracy->  37.76%\n","Current batch: Loss-> 0.9081, Train accuracy->  37.86%\n","Current batch: Loss-> 0.5780, Train accuracy->  37.97%\n","Current batch: Loss-> 0.8885, Train accuracy->  38.07%\n","Current batch: Loss-> 0.9583, Train accuracy->  38.16%\n","Current batch: Loss-> 0.9782, Train accuracy->  38.24%\n","Current batch: Loss-> 0.8151, Train accuracy->  38.34%\n","Current batch: Loss-> 0.5067, Train accuracy->  38.45%\n","Current batch: Loss-> 0.9544, Train accuracy->  38.54%\n","Current batch: Loss-> 0.9363, Train accuracy->  38.64%\n","Current batch: Loss-> 1.1216, Train accuracy->  38.72%\n","Current batch: Loss-> 0.8053, Train accuracy->  38.82%\n","Current batch: Loss-> 0.7075, Train accuracy->  38.92%\n","Current batch: Loss-> 1.1241, Train accuracy->  39.02%\n","Current batch: Loss-> 0.6922, Train accuracy->  39.12%\n","Current batch: Loss-> 0.6710, Train accuracy->  39.23%\n","Current batch: Loss-> 1.1525, Train accuracy->  39.31%\n","Current batch: Loss-> 0.9959, Train accuracy->  39.39%\n","Current batch: Loss-> 0.7319, Train accuracy->  39.49%\n","Current batch: Loss-> 0.9646, Train accuracy->  39.59%\n","Current batch: Loss-> 0.7310, Train accuracy->  39.69%\n","Current batch: Loss-> 1.0740, Train accuracy->  39.79%\n","Current batch: Loss-> 0.9147, Train accuracy->  39.89%\n","Current batch: Loss-> 0.8689, Train accuracy->  39.99%\n","Current batch: Loss-> 0.7515, Train accuracy->  40.10%\n","Current batch: Loss-> 0.8327, Train accuracy->  40.19%\n","Current batch: Loss-> 0.8968, Train accuracy->  40.29%\n","Current batch: Loss-> 0.7403, Train accuracy->  40.38%\n","Current batch: Loss-> 0.7921, Train accuracy->  40.48%\n","Current batch: Loss-> 0.9485, Train accuracy->  40.57%\n","Current batch: Loss-> 0.6178, Train accuracy->  40.67%\n","Current batch: Loss-> 0.8889, Train accuracy->  40.75%\n","Current batch: Loss-> 0.7958, Train accuracy->  40.86%\n","Current batch: Loss-> 1.0422, Train accuracy->  40.95%\n","Current batch: Loss-> 1.1381, Train accuracy->  41.04%\n","Current batch: Loss-> 0.7632, Train accuracy->  41.13%\n","Current batch: Loss-> 1.1156, Train accuracy->  41.22%\n","Current batch: Loss-> 0.7695, Train accuracy->  41.31%\n","Current batch: Loss-> 0.7558, Train accuracy->  41.41%\n","Current batch: Loss-> 1.0477, Train accuracy->  41.50%\n","Current batch: Loss-> 0.8739, Train accuracy->  41.60%\n","Current batch: Loss-> 0.7604, Train accuracy->  41.70%\n","Current batch: Loss-> 0.6966, Train accuracy->  41.79%\n","Current batch: Loss-> 1.0348, Train accuracy->  41.87%\n","Current batch: Loss-> 0.5991, Train accuracy->  41.98%\n","Current batch: Loss-> 0.9193, Train accuracy->  42.07%\n","Current batch: Loss-> 0.8158, Train accuracy->  42.17%\n","Current batch: Loss-> 1.1599, Train accuracy->  42.26%\n","Current batch: Loss-> 0.9489, Train accuracy->  42.36%\n","Current batch: Loss-> 1.0923, Train accuracy->  42.45%\n","Current batch: Loss-> 0.8183, Train accuracy->  42.55%\n","Current batch: Loss-> 1.2265, Train accuracy->  42.64%\n","Current batch: Loss-> 0.8819, Train accuracy->  42.74%\n","Current batch: Loss-> 0.8524, Train accuracy->  42.83%\n","Current batch: Loss-> 0.9209, Train accuracy->  42.92%\n","Current batch: Loss-> 0.7831, Train accuracy->  43.02%\n","Current batch: Loss-> 0.8181, Train accuracy->  43.12%\n","Current batch: Loss-> 1.0011, Train accuracy->  43.20%\n","Current batch: Loss-> 0.8542, Train accuracy->  43.31%\n","Current batch: Loss-> 0.8687, Train accuracy->  43.40%\n","Current batch: Loss-> 0.8267, Train accuracy->  43.50%\n","Current batch: Loss-> 0.9021, Train accuracy->  43.60%\n","Current batch: Loss-> 0.9282, Train accuracy->  43.69%\n","Current batch: Loss-> 0.7469, Train accuracy->  43.80%\n","Current batch: Loss-> 0.7352, Train accuracy->  43.90%\n","Current batch: Loss-> 0.7551, Train accuracy->  44.00%\n","Current batch: Loss-> 0.6989, Train accuracy->  44.11%\n","Current batch: Loss-> 1.1117, Train accuracy->  44.21%\n","Current batch: Loss-> 0.8166, Train accuracy->  44.30%\n","Current batch: Loss-> 0.8096, Train accuracy->  44.40%\n","Current batch: Loss-> 0.7899, Train accuracy->  44.51%\n","Current batch: Loss-> 0.7535, Train accuracy->  44.61%\n","Current batch: Loss-> 0.6814, Train accuracy->  44.70%\n","Current batch: Loss-> 0.8699, Train accuracy->  44.79%\n","Current batch: Loss-> 0.7494, Train accuracy->  44.89%\n","Current batch: Loss-> 0.8781, Train accuracy->  44.99%\n","Current batch: Loss-> 1.0622, Train accuracy->  45.08%\n","Current batch: Loss-> 0.8147, Train accuracy->  45.18%\n","Current batch: Loss-> 0.7240, Train accuracy->  45.28%\n","Current batch: Loss-> 0.7620, Train accuracy->  45.38%\n","Current batch: Loss-> 0.7474, Train accuracy->  45.47%\n","Current batch: Loss-> 1.1311, Train accuracy->  45.55%\n","Current batch: Loss-> 0.7048, Train accuracy->  45.65%\n","Current batch: Loss-> 0.7304, Train accuracy->  45.75%\n","Current batch: Loss-> 0.8378, Train accuracy->  45.85%\n","Current batch: Loss-> 0.6703, Train accuracy->  45.95%\n","Current batch: Loss-> 0.7834, Train accuracy->  46.05%\n","Current batch: Loss-> 0.9246, Train accuracy->  46.14%\n","Current batch: Loss-> 1.0195, Train accuracy->  46.24%\n","Current batch: Loss-> 0.7079, Train accuracy->  46.34%\n","Current batch: Loss-> 0.8059, Train accuracy->  46.43%\n","Current batch: Loss-> 0.7188, Train accuracy->  46.54%\n","Current batch: Loss-> 0.6938, Train accuracy->  46.64%\n","Current batch: Loss-> 0.9895, Train accuracy->  46.72%\n","Current batch: Loss-> 1.0221, Train accuracy->  46.82%\n","Current batch: Loss-> 1.0368, Train accuracy->  46.90%\n","Current batch: Loss-> 0.8214, Train accuracy->  46.98%\n","Current batch: Loss-> 0.8178, Train accuracy->  47.08%\n","Current batch: Loss-> 0.8225, Train accuracy->  47.18%\n","Current batch: Loss-> 1.1510, Train accuracy->  47.27%\n","Current batch: Loss-> 1.0316, Train accuracy->  47.35%\n","Current batch: Loss-> 0.8575, Train accuracy->  47.44%\n","Current batch: Loss-> 0.9549, Train accuracy->  47.53%\n","Current batch: Loss-> 1.0224, Train accuracy->  47.62%\n","Current batch: Loss-> 0.7825, Train accuracy->  47.71%\n","Current batch: Loss-> 0.9148, Train accuracy->  47.81%\n","Current batch: Loss-> 0.7814, Train accuracy->  47.92%\n","Current batch: Loss-> 0.9359, Train accuracy->  48.02%\n","Current batch: Loss-> 1.0099, Train accuracy->  48.11%\n","Current batch: Loss-> 0.8733, Train accuracy->  48.21%\n","Current batch: Loss-> 0.6761, Train accuracy->  48.31%\n","Current batch: Loss-> 0.9231, Train accuracy->  48.40%\n","Current batch: Loss-> 0.7245, Train accuracy->  48.51%\n","Current batch: Loss-> 0.9295, Train accuracy->  48.60%\n","Current batch: Loss-> 0.7488, Train accuracy->  48.70%\n","Current batch: Loss-> 1.0385, Train accuracy->  48.78%\n","Current batch: Loss-> 0.7540, Train accuracy->  48.87%\n","Current batch: Loss-> 0.9025, Train accuracy->  48.96%\n","Current batch: Loss-> 0.6621, Train accuracy->  49.06%\n","Current batch: Loss-> 0.8344, Train accuracy->  49.16%\n","Current batch: Loss-> 0.7328, Train accuracy->  49.26%\n","Current batch: Loss-> 0.8657, Train accuracy->  49.36%\n","Current batch: Loss-> 0.7790, Train accuracy->  49.46%\n","Current batch: Loss-> 0.9874, Train accuracy->  49.56%\n","Current batch: Loss-> 0.9177, Train accuracy->  49.65%\n","Current batch: Loss-> 1.1157, Train accuracy->  49.73%\n","Current batch: Loss-> 0.7055, Train accuracy->  49.84%\n","Current batch: Loss-> 0.8473, Train accuracy->  49.94%\n","Current batch: Loss-> 0.6703, Train accuracy->  50.04%\n","Current batch: Loss-> 0.9364, Train accuracy->  50.14%\n","Current batch: Loss-> 1.1875, Train accuracy->  50.22%\n","Current batch: Loss-> 0.7336, Train accuracy->  50.33%\n","Current batch: Loss-> 0.9357, Train accuracy->  50.42%\n","Current batch: Loss-> 0.6320, Train accuracy->  50.52%\n","Current batch: Loss-> 1.0442, Train accuracy->  50.61%\n","Current batch: Loss-> 0.6704, Train accuracy->  50.71%\n","Current batch: Loss-> 0.9197, Train accuracy->  50.80%\n","Current batch: Loss-> 0.9998, Train accuracy->  50.90%\n","Current batch: Loss-> 0.8192, Train accuracy->  50.99%\n","Current batch: Loss-> 0.5264, Train accuracy->  51.10%\n","Current batch: Loss-> 1.1750, Train accuracy->  51.19%\n","Current batch: Loss-> 0.8100, Train accuracy->  51.29%\n","Current batch: Loss-> 0.8266, Train accuracy->  51.39%\n","Current batch: Loss-> 0.9120, Train accuracy->  51.49%\n","Current batch: Loss-> 0.6586, Train accuracy->  51.59%\n","Current batch: Loss-> 0.7896, Train accuracy->  51.69%\n","Current batch: Loss-> 0.7070, Train accuracy->  51.79%\n","Current batch: Loss-> 0.8630, Train accuracy->  51.89%\n","Current batch: Loss-> 1.0349, Train accuracy->  51.97%\n","Current batch: Loss-> 0.6999, Train accuracy->  52.09%\n","Current batch: Loss-> 1.0077, Train accuracy->  52.18%\n","Current batch: Loss-> 1.1963, Train accuracy->  52.26%\n","Current batch: Loss-> 0.8694, Train accuracy->  52.36%\n","Current batch: Loss-> 0.6814, Train accuracy->  52.46%\n","Current batch: Loss-> 0.9556, Train accuracy->  52.54%\n","Current batch: Loss-> 0.7241, Train accuracy->  52.64%\n","Current batch: Loss-> 1.0787, Train accuracy->  52.73%\n","Current batch: Loss-> 0.7867, Train accuracy->  52.83%\n","Current batch: Loss-> 0.9778, Train accuracy->  52.92%\n","Current batch: Loss-> 1.2369, Train accuracy->  53.01%\n","Current batch: Loss-> 0.6665, Train accuracy->  53.12%\n","Current batch: Loss-> 0.7058, Train accuracy->  53.22%\n","Current batch: Loss-> 0.9259, Train accuracy->  53.31%\n","Current batch: Loss-> 0.6263, Train accuracy->  53.42%\n","Current batch: Loss-> 0.8525, Train accuracy->  53.53%\n","Current batch: Loss-> 1.1532, Train accuracy->  53.62%\n","Current batch: Loss-> 1.0322, Train accuracy->  53.72%\n","Current batch: Loss-> 1.0222, Train accuracy->  53.81%\n","Current batch: Loss-> 1.0217, Train accuracy->  53.91%\n","Current batch: Loss-> 0.8349, Train accuracy->  54.01%\n","Current batch: Loss-> 0.8889, Train accuracy->  54.10%\n","Current batch: Loss-> 0.7118, Train accuracy->  54.20%\n","Current batch: Loss-> 0.7019, Train accuracy->  54.30%\n","Current batch: Loss-> 1.1224, Train accuracy->  54.38%\n","Current batch: Loss-> 0.7018, Train accuracy->  54.49%\n","Current batch: Loss-> 0.9452, Train accuracy->  54.59%\n","Current batch: Loss-> 0.6013, Train accuracy->  54.69%\n","Current batch: Loss-> 0.9071, Train accuracy->  54.78%\n","Current batch: Loss-> 0.9976, Train accuracy->  54.87%\n","Current batch: Loss-> 0.7660, Train accuracy->  54.96%\n","Current batch: Loss-> 0.7807, Train accuracy->  55.06%\n","Current batch: Loss-> 0.9240, Train accuracy->  55.15%\n","Current batch: Loss-> 0.8196, Train accuracy->  55.25%\n","Current batch: Loss-> 1.1155, Train accuracy->  55.35%\n","Current batch: Loss-> 0.7703, Train accuracy->  55.44%\n","Current batch: Loss-> 0.9411, Train accuracy->  55.54%\n","Current batch: Loss-> 1.0348, Train accuracy->  55.64%\n","Current batch: Loss-> 0.9873, Train accuracy->  55.73%\n","Current batch: Loss-> 1.0113, Train accuracy->  55.81%\n","Current batch: Loss-> 0.7968, Train accuracy->  55.91%\n","Current batch: Loss-> 0.8694, Train accuracy->  56.01%\n","Current batch: Loss-> 1.0331, Train accuracy->  56.10%\n","Current batch: Loss-> 0.5688, Train accuracy->  56.22%\n","Current batch: Loss-> 0.6854, Train accuracy->  56.32%\n","Current batch: Loss-> 0.5972, Train accuracy->  56.43%\n","Current batch: Loss-> 0.9306, Train accuracy->  56.52%\n","Current batch: Loss-> 0.6780, Train accuracy->  56.63%\n","Current batch: Loss-> 0.9841, Train accuracy->  56.72%\n","Current batch: Loss-> 0.7858, Train accuracy->  56.81%\n","Current batch: Loss-> 0.8919, Train accuracy->  56.92%\n","Current batch: Loss-> 0.7280, Train accuracy->  57.02%\n","Current batch: Loss-> 0.7241, Train accuracy->  57.12%\n","Current batch: Loss-> 0.7564, Train accuracy->  57.22%\n","Current batch: Loss-> 1.0803, Train accuracy->  57.31%\n","Current batch: Loss-> 0.7114, Train accuracy->  57.42%\n","Current batch: Loss-> 0.9573, Train accuracy->  57.51%\n","Current batch: Loss-> 0.8346, Train accuracy->  57.61%\n","Current batch: Loss-> 0.7673, Train accuracy->  57.71%\n","Current batch: Loss-> 0.8318, Train accuracy->  57.81%\n","Current batch: Loss-> 0.8036, Train accuracy->  57.90%\n","Current batch: Loss-> 0.8738, Train accuracy->  57.99%\n","Current batch: Loss-> 0.6917, Train accuracy->  58.10%\n","Current batch: Loss-> 0.7946, Train accuracy->  58.20%\n","Current batch: Loss-> 0.9277, Train accuracy->  58.29%\n","Current batch: Loss-> 1.2453, Train accuracy->  58.39%\n","Current batch: Loss-> 0.9615, Train accuracy->  58.49%\n","Current batch: Loss-> 0.6953, Train accuracy->  58.59%\n","Current batch: Loss-> 1.3143, Train accuracy->  58.68%\n","Current batch: Loss-> 0.7397, Train accuracy->  58.78%\n","Current batch: Loss-> 0.9544, Train accuracy->  58.88%\n","Current batch: Loss-> 0.9352, Train accuracy->  58.97%\n","Current batch: Loss-> 0.7109, Train accuracy->  59.07%\n","Current batch: Loss-> 1.0460, Train accuracy->  59.15%\n","Current batch: Loss-> 0.9147, Train accuracy->  59.25%\n","Current batch: Loss-> 0.9050, Train accuracy->  59.34%\n","Current batch: Loss-> 0.6981, Train accuracy->  59.44%\n","Current batch: Loss-> 1.0261, Train accuracy->  59.52%\n","Current batch: Loss-> 1.3170, Train accuracy->  59.61%\n","Current batch: Loss-> 0.9575, Train accuracy->  59.70%\n","Current batch: Loss-> 0.8661, Train accuracy->  59.79%\n","Current batch: Loss-> 0.7222, Train accuracy->  59.89%\n","Current batch: Loss-> 0.9300, Train accuracy->  59.98%\n","Current batch: Loss-> 0.6842, Train accuracy->  60.08%\n","Current batch: Loss-> 1.2388, Train accuracy->  60.16%\n","Current batch: Loss-> 0.6014, Train accuracy->  60.27%\n","Current batch: Loss-> 0.7408, Train accuracy->  60.36%\n","Current batch: Loss-> 0.9938, Train accuracy->  60.45%\n","Current batch: Loss-> 0.9473, Train accuracy->  60.55%\n","Current batch: Loss-> 0.7321, Train accuracy->  60.65%\n","Current batch: Loss-> 1.0228, Train accuracy->  60.74%\n","Current batch: Loss-> 1.3732, Train accuracy->  60.82%\n","Current batch: Loss-> 0.9689, Train accuracy->  60.91%\n","Current batch: Loss-> 0.7902, Train accuracy->  61.01%\n","Current batch: Loss-> 0.7857, Train accuracy->  61.11%\n","Current batch: Loss-> 1.0182, Train accuracy->  61.20%\n","Current batch: Loss-> 0.9080, Train accuracy->  61.29%\n","Current batch: Loss-> 1.1053, Train accuracy->  61.36%\n","Current batch: Loss-> 0.8768, Train accuracy->  61.45%\n","Current batch: Loss-> 0.9202, Train accuracy->  61.54%\n","Current batch: Loss-> 0.7106, Train accuracy->  61.65%\n","Current batch: Loss-> 0.5786, Train accuracy->  61.76%\n","Current batch: Loss-> 0.7451, Train accuracy->  61.86%\n","Current batch: Loss-> 1.0260, Train accuracy->  61.96%\n","Current batch: Loss-> 1.0101, Train accuracy->  62.05%\n","Current batch: Loss-> 0.8293, Train accuracy->  62.15%\n","Current batch: Loss-> 0.8720, Train accuracy->  62.25%\n","Current batch: Loss-> 0.7422, Train accuracy->  62.36%\n","Current batch: Loss-> 0.8278, Train accuracy->  62.46%\n","Current batch: Loss-> 0.9570, Train accuracy->  62.55%\n","Current batch: Loss-> 0.9650, Train accuracy->  62.64%\n","Current batch: Loss-> 0.7582, Train accuracy->  62.75%\n","Current batch: Loss-> 0.7290, Train accuracy->  62.84%\n","Current batch: Loss-> 0.8827, Train accuracy->  62.95%\n","Current batch: Loss-> 0.6993, Train accuracy->  63.05%\n","Current batch: Loss-> 1.0192, Train accuracy->  63.13%\n","Current batch: Loss-> 1.0498, Train accuracy->  63.22%\n","Current batch: Loss-> 0.7352, Train accuracy->  63.33%\n","Current batch: Loss-> 0.9372, Train accuracy->  63.43%\n","Current batch: Loss-> 0.6702, Train accuracy->  63.54%\n","Current batch: Loss-> 0.7901, Train accuracy->  63.64%\n","Current batch: Loss-> 1.4913, Train accuracy->  63.72%\n","Current batch: Loss-> 0.8413, Train accuracy->  63.82%\n","Current batch: Loss-> 1.3372, Train accuracy->  63.91%\n","Current batch: Loss-> 0.8152, Train accuracy->  64.01%\n","Current batch: Loss-> 0.8656, Train accuracy->  64.10%\n","Current batch: Loss-> 0.7441, Train accuracy->  64.20%\n","Current batch: Loss-> 0.9772, Train accuracy->  64.29%\n","Current batch: Loss-> 0.7624, Train accuracy->  64.39%\n","Current batch: Loss-> 1.0374, Train accuracy->  64.48%\n","Current batch: Loss-> 0.8136, Train accuracy->  64.59%\n","Current batch: Loss-> 0.6516, Train accuracy->  64.69%\n","Current batch: Loss-> 0.8003, Train accuracy->  64.79%\n","Current batch: Loss-> 0.7706, Train accuracy->  64.89%\n","Current batch: Loss-> 0.6708, Train accuracy->  65.00%\n","Current batch: Loss-> 0.8363, Train accuracy->  65.09%\n","Current batch: Loss-> 0.7767, Train accuracy->  65.19%\n","Current batch: Loss-> 0.7518, Train accuracy->  65.29%\n","Current batch: Loss-> 0.9508, Train accuracy->  65.38%\n","Current batch: Loss-> 0.8229, Train accuracy->  65.47%\n","Current batch: Loss-> 0.6572, Train accuracy->  65.58%\n","Current batch: Loss-> 1.0408, Train accuracy->  65.68%\n","Current batch: Loss-> 0.8053, Train accuracy->  65.77%\n","Current batch: Loss-> 0.7656, Train accuracy->  65.87%\n","Current batch: Loss-> 0.6974, Train accuracy->  65.97%\n","Current batch: Loss-> 1.0163, Train accuracy->  66.06%\n","Current batch: Loss-> 0.9893, Train accuracy->  66.16%\n","Current batch: Loss-> 0.7735, Train accuracy->  66.26%\n","Current batch: Loss-> 1.1117, Train accuracy->  66.34%\n","Current batch: Loss-> 0.6789, Train accuracy->  66.44%\n","Current batch: Loss-> 0.8865, Train accuracy->  66.54%\n","Current batch: Loss-> 0.8826, Train accuracy->  66.63%\n","Current batch: Loss-> 0.7538, Train accuracy->  66.74%\n","Current batch: Loss-> 0.7652, Train accuracy->  66.83%\n","Current batch: Loss-> 0.9136, Train accuracy->  66.92%\n","Current batch: Loss-> 0.8397, Train accuracy->  67.03%\n","Current batch: Loss-> 0.8007, Train accuracy->  67.12%\n","Current batch: Loss-> 0.7112, Train accuracy->  67.23%\n","Current batch: Loss-> 0.9102, Train accuracy->  67.32%\n","Current batch: Loss-> 1.0105, Train accuracy->  67.41%\n","Current batch: Loss-> 0.7726, Train accuracy->  67.51%\n","Current batch: Loss-> 0.8000, Train accuracy->  67.61%\n","Current batch: Loss-> 0.6472, Train accuracy->  67.72%\n","Current batch: Loss-> 1.2066, Train accuracy->  67.81%\n","Current batch: Loss-> 0.7458, Train accuracy->  67.91%\n","Current batch: Loss-> 1.1145, Train accuracy->  68.00%\n","Current batch: Loss-> 0.7128, Train accuracy->  68.11%\n","Current batch: Loss-> 0.6761, Train accuracy->  68.21%\n","Current batch: Loss-> 0.9952, Train accuracy->  68.30%\n","Current batch: Loss-> 1.1093, Train accuracy->  68.39%\n","Current batch: Loss-> 0.8199, Train accuracy->  68.48%\n","Current batch: Loss-> 0.8501, Train accuracy->  68.58%\n","Current batch: Loss-> 1.0987, Train accuracy->  68.66%\n","Current batch: Loss-> 0.8652, Train accuracy->  68.74%\n","Current batch: Loss-> 0.7655, Train accuracy->  68.84%\n","Current batch: Loss-> 0.6376, Train accuracy->  68.94%\n","Current batch: Loss-> 0.9260, Train accuracy->  69.04%\n","Current batch: Loss-> 1.0795, Train accuracy->  69.12%\n","Current batch: Loss-> 0.8900, Train accuracy->  69.22%\n","Current batch: Loss-> 0.7991, Train accuracy->  69.31%\n","Current batch: Loss-> 0.8688, Train accuracy->  69.41%\n","Current batch: Loss-> 0.7760, Train accuracy->  69.51%\n","Current batch: Loss-> 0.8922, Train accuracy->  69.61%\n","Current batch: Loss-> 0.9415, Train accuracy->  69.71%\n","Current batch: Loss-> 0.7188, Train accuracy->  69.81%\n","Current batch: Loss-> 0.7032, Train accuracy->  69.91%\n","Current batch: Loss-> 0.9203, Train accuracy->  70.00%\n","Current batch: Loss-> 0.9858, Train accuracy->  70.10%\n","Current batch: Loss-> 0.6928, Train accuracy->  70.20%\n","Current batch: Loss-> 0.7371, Train accuracy->  70.29%\n","Current batch: Loss-> 0.9024, Train accuracy->  70.39%\n","Current batch: Loss-> 0.7063, Train accuracy->  70.49%\n","Current batch: Loss-> 0.9356, Train accuracy->  70.59%\n","Current batch: Loss-> 0.8465, Train accuracy->  70.69%\n","Current batch: Loss-> 0.8801, Train accuracy->  70.79%\n","Current batch: Loss-> 0.8720, Train accuracy->  70.89%\n","Current batch: Loss-> 0.8675, Train accuracy->  70.97%\n","Current batch: Loss-> 0.8190, Train accuracy->  71.07%\n","Current batch: Loss-> 0.8613, Train accuracy->  71.17%\n","Current batch: Loss-> 0.5596, Train accuracy->  71.29%\n","Current batch: Loss-> 0.7733, Train accuracy->  71.40%\n","Current batch: Loss-> 0.6270, Train accuracy->  71.51%\n","Current batch: Loss-> 0.7140, Train accuracy->  71.61%\n","Current batch: Loss-> 0.8760, Train accuracy->  71.70%\n","Current batch: Loss-> 1.1659, Train accuracy->  71.79%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:04, 43.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.8482, Train accuracy->  71.90%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.56it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.4723, Accuracy: 5514/12000 (46%)\n","\n","Current batch: Loss-> 0.7668, Train accuracy->   0.10%\n","Current batch: Loss-> 0.9889, Train accuracy->   0.18%\n","Current batch: Loss-> 0.8407, Train accuracy->   0.28%\n","Current batch: Loss-> 0.7945, Train accuracy->   0.39%\n","Current batch: Loss-> 0.7179, Train accuracy->   0.49%\n","Current batch: Loss-> 0.8373, Train accuracy->   0.59%\n","Current batch: Loss-> 0.7327, Train accuracy->   0.70%\n","Current batch: Loss-> 0.8915, Train accuracy->   0.79%\n","Current batch: Loss-> 0.6928, Train accuracy->   0.90%\n","Current batch: Loss-> 1.1618, Train accuracy->   0.98%\n","Current batch: Loss-> 0.8346, Train accuracy->   1.08%\n","Current batch: Loss-> 0.8842, Train accuracy->   1.18%\n","Current batch: Loss-> 0.8556, Train accuracy->   1.28%\n","Current batch: Loss-> 0.8332, Train accuracy->   1.38%\n","Current batch: Loss-> 0.6029, Train accuracy->   1.48%\n","Current batch: Loss-> 1.0494, Train accuracy->   1.56%\n","Current batch: Loss-> 0.9779, Train accuracy->   1.66%\n","Current batch: Loss-> 0.9942, Train accuracy->   1.75%\n","Current batch: Loss-> 1.1801, Train accuracy->   1.84%\n","Current batch: Loss-> 1.0824, Train accuracy->   1.92%\n","Current batch: Loss-> 0.9677, Train accuracy->   2.02%\n","Current batch: Loss-> 0.8917, Train accuracy->   2.12%\n","Current batch: Loss-> 0.8434, Train accuracy->   2.22%\n","Current batch: Loss-> 0.6503, Train accuracy->   2.32%\n","Current batch: Loss-> 1.1016, Train accuracy->   2.40%\n","Current batch: Loss-> 0.7562, Train accuracy->   2.51%\n","Current batch: Loss-> 0.9348, Train accuracy->   2.59%\n","Current batch: Loss-> 0.8059, Train accuracy->   2.69%\n","Current batch: Loss-> 0.8150, Train accuracy->   2.80%\n","Current batch: Loss-> 0.9265, Train accuracy->   2.89%\n","Current batch: Loss-> 0.8600, Train accuracy->   2.99%\n","Current batch: Loss-> 0.7492, Train accuracy->   3.10%\n","Current batch: Loss-> 1.0528, Train accuracy->   3.20%\n","Current batch: Loss-> 0.7640, Train accuracy->   3.30%\n","Current batch: Loss-> 0.8166, Train accuracy->   3.39%\n","Current batch: Loss-> 0.6911, Train accuracy->   3.49%\n","Current batch: Loss-> 0.8110, Train accuracy->   3.60%\n","Current batch: Loss-> 0.6078, Train accuracy->   3.71%\n","Current batch: Loss-> 0.9909, Train accuracy->   3.80%\n","Current batch: Loss-> 0.8831, Train accuracy->   3.88%\n","Current batch: Loss-> 0.8656, Train accuracy->   3.97%\n","Current batch: Loss-> 0.8604, Train accuracy->   4.07%\n","Current batch: Loss-> 0.9960, Train accuracy->   4.17%\n","Current batch: Loss-> 1.1331, Train accuracy->   4.26%\n","Current batch: Loss-> 0.7624, Train accuracy->   4.36%\n","Current batch: Loss-> 0.6223, Train accuracy->   4.47%\n","Current batch: Loss-> 0.7749, Train accuracy->   4.57%\n","Current batch: Loss-> 0.6328, Train accuracy->   4.68%\n","Current batch: Loss-> 0.6089, Train accuracy->   4.79%\n","Current batch: Loss-> 0.8832, Train accuracy->   4.88%\n","Current batch: Loss-> 0.7266, Train accuracy->   4.98%\n","Current batch: Loss-> 0.8880, Train accuracy->   5.09%\n","Current batch: Loss-> 0.6996, Train accuracy->   5.19%\n","Current batch: Loss-> 0.8387, Train accuracy->   5.30%\n","Current batch: Loss-> 0.8498, Train accuracy->   5.40%\n","Current batch: Loss-> 0.6771, Train accuracy->   5.50%\n","Current batch: Loss-> 0.8616, Train accuracy->   5.60%\n","Current batch: Loss-> 0.8541, Train accuracy->   5.70%\n","Current batch: Loss-> 0.8774, Train accuracy->   5.80%\n","Current batch: Loss-> 0.6204, Train accuracy->   5.90%\n","Current batch: Loss-> 0.7278, Train accuracy->   6.00%\n","Current batch: Loss-> 0.8234, Train accuracy->   6.09%\n","Current batch: Loss-> 0.8315, Train accuracy->   6.19%\n","Current batch: Loss-> 0.7450, Train accuracy->   6.29%\n","Current batch: Loss-> 0.9300, Train accuracy->   6.39%\n","Current batch: Loss-> 0.8234, Train accuracy->   6.49%\n","Current batch: Loss-> 1.0306, Train accuracy->   6.58%\n","Current batch: Loss-> 0.7271, Train accuracy->   6.69%\n","Current batch: Loss-> 0.6834, Train accuracy->   6.79%\n","Current batch: Loss-> 0.5890, Train accuracy->   6.90%\n","Current batch: Loss-> 0.8462, Train accuracy->   6.99%\n","Current batch: Loss-> 0.9188, Train accuracy->   7.09%\n","Current batch: Loss-> 0.9553, Train accuracy->   7.18%\n","Current batch: Loss-> 0.8468, Train accuracy->   7.28%\n","Current batch: Loss-> 1.1184, Train accuracy->   7.36%\n","Current batch: Loss-> 0.7996, Train accuracy->   7.46%\n","Current batch: Loss-> 0.8165, Train accuracy->   7.56%\n","Current batch: Loss-> 0.7371, Train accuracy->   7.66%\n","Current batch: Loss-> 1.0643, Train accuracy->   7.75%\n","Current batch: Loss-> 0.6499, Train accuracy->   7.86%\n","Current batch: Loss-> 0.6520, Train accuracy->   7.96%\n","Current batch: Loss-> 0.7947, Train accuracy->   8.06%\n","Current batch: Loss-> 0.9625, Train accuracy->   8.16%\n","Current batch: Loss-> 0.6910, Train accuracy->   8.27%\n","Current batch: Loss-> 0.6391, Train accuracy->   8.37%\n","Current batch: Loss-> 1.0509, Train accuracy->   8.47%\n","Current batch: Loss-> 0.9930, Train accuracy->   8.56%\n","Current batch: Loss-> 0.9613, Train accuracy->   8.66%\n","Current batch: Loss-> 0.7761, Train accuracy->   8.76%\n","Current batch: Loss-> 0.7246, Train accuracy->   8.86%\n","Current batch: Loss-> 0.7032, Train accuracy->   8.97%\n","Current batch: Loss-> 0.8946, Train accuracy->   9.06%\n","Current batch: Loss-> 0.8573, Train accuracy->   9.16%\n","Current batch: Loss-> 1.2617, Train accuracy->   9.25%\n","Current batch: Loss-> 0.7374, Train accuracy->   9.34%\n","Current batch: Loss-> 0.7504, Train accuracy->   9.44%\n","Current batch: Loss-> 0.7176, Train accuracy->   9.54%\n","Current batch: Loss-> 0.9226, Train accuracy->   9.65%\n","Current batch: Loss-> 1.2104, Train accuracy->   9.75%\n","Current batch: Loss-> 0.8418, Train accuracy->   9.85%\n","Current batch: Loss-> 0.7473, Train accuracy->   9.94%\n","Current batch: Loss-> 1.0111, Train accuracy->  10.02%\n","Current batch: Loss-> 0.9156, Train accuracy->  10.10%\n","Current batch: Loss-> 0.8651, Train accuracy->  10.20%\n","Current batch: Loss-> 0.8854, Train accuracy->  10.30%\n","Current batch: Loss-> 0.8648, Train accuracy->  10.40%\n","Current batch: Loss-> 0.8692, Train accuracy->  10.49%\n","Current batch: Loss-> 0.9863, Train accuracy->  10.59%\n","Current batch: Loss-> 0.7314, Train accuracy->  10.69%\n","Current batch: Loss-> 0.6644, Train accuracy->  10.79%\n","Current batch: Loss-> 0.6619, Train accuracy->  10.90%\n","Current batch: Loss-> 0.5934, Train accuracy->  11.00%\n","Current batch: Loss-> 0.6609, Train accuracy->  11.12%\n","Current batch: Loss-> 0.9433, Train accuracy->  11.21%\n","Current batch: Loss-> 0.9207, Train accuracy->  11.29%\n","Current batch: Loss-> 0.6162, Train accuracy->  11.40%\n","Current batch: Loss-> 0.5662, Train accuracy->  11.50%\n","Current batch: Loss-> 0.6833, Train accuracy->  11.61%\n","Current batch: Loss-> 0.8341, Train accuracy->  11.71%\n","Current batch: Loss-> 0.8299, Train accuracy->  11.80%\n","Current batch: Loss-> 0.9854, Train accuracy->  11.89%\n","Current batch: Loss-> 0.9052, Train accuracy->  11.99%\n","Current batch: Loss-> 0.8983, Train accuracy->  12.08%\n","Current batch: Loss-> 0.8528, Train accuracy->  12.18%\n","Current batch: Loss-> 0.9445, Train accuracy->  12.26%\n","Current batch: Loss-> 0.9244, Train accuracy->  12.35%\n","Current batch: Loss-> 0.7704, Train accuracy->  12.45%\n","Current batch: Loss-> 0.8739, Train accuracy->  12.55%\n","Current batch: Loss-> 0.7334, Train accuracy->  12.64%\n","Current batch: Loss-> 0.7974, Train accuracy->  12.74%\n","Current batch: Loss-> 0.6832, Train accuracy->  12.84%\n","Current batch: Loss-> 0.6838, Train accuracy->  12.95%\n","Current batch: Loss-> 0.8497, Train accuracy->  13.05%\n","Current batch: Loss-> 0.8529, Train accuracy->  13.14%\n","Current batch: Loss-> 0.9405, Train accuracy->  13.23%\n","Current batch: Loss-> 0.8652, Train accuracy->  13.33%\n","Current batch: Loss-> 0.8525, Train accuracy->  13.42%\n","Current batch: Loss-> 0.8984, Train accuracy->  13.50%\n","Current batch: Loss-> 0.9742, Train accuracy->  13.59%\n","Current batch: Loss-> 0.8515, Train accuracy->  13.69%\n","Current batch: Loss-> 0.7534, Train accuracy->  13.79%\n","Current batch: Loss-> 0.7489, Train accuracy->  13.89%\n","Current batch: Loss-> 0.9871, Train accuracy->  13.99%\n","Current batch: Loss-> 0.7722, Train accuracy->  14.09%\n","Current batch: Loss-> 1.0316, Train accuracy->  14.18%\n","Current batch: Loss-> 0.8658, Train accuracy->  14.26%\n","Current batch: Loss-> 0.8794, Train accuracy->  14.35%\n","Current batch: Loss-> 0.7731, Train accuracy->  14.45%\n","Current batch: Loss-> 0.9564, Train accuracy->  14.55%\n","Current batch: Loss-> 0.8377, Train accuracy->  14.64%\n","Current batch: Loss-> 0.8545, Train accuracy->  14.73%\n","Current batch: Loss-> 0.6053, Train accuracy->  14.84%\n","Current batch: Loss-> 0.8842, Train accuracy->  14.94%\n","Current batch: Loss-> 0.7688, Train accuracy->  15.04%\n","Current batch: Loss-> 0.6973, Train accuracy->  15.15%\n","Current batch: Loss-> 0.8066, Train accuracy->  15.25%\n","Current batch: Loss-> 0.8217, Train accuracy->  15.34%\n","Current batch: Loss-> 1.0263, Train accuracy->  15.43%\n","Current batch: Loss-> 0.6338, Train accuracy->  15.54%\n","Current batch: Loss-> 1.1945, Train accuracy->  15.61%\n","Current batch: Loss-> 1.0783, Train accuracy->  15.70%\n","Current batch: Loss-> 0.8735, Train accuracy->  15.80%\n","Current batch: Loss-> 0.8478, Train accuracy->  15.90%\n","Current batch: Loss-> 0.7470, Train accuracy->  16.00%\n","Current batch: Loss-> 0.9114, Train accuracy->  16.09%\n","Current batch: Loss-> 0.9229, Train accuracy->  16.19%\n","Current batch: Loss-> 0.6971, Train accuracy->  16.28%\n","Current batch: Loss-> 0.9524, Train accuracy->  16.38%\n","Current batch: Loss-> 0.7194, Train accuracy->  16.49%\n","Current batch: Loss-> 0.6695, Train accuracy->  16.59%\n","Current batch: Loss-> 0.7411, Train accuracy->  16.69%\n","Current batch: Loss-> 0.5847, Train accuracy->  16.80%\n","Current batch: Loss-> 0.8370, Train accuracy->  16.90%\n","Current batch: Loss-> 0.8686, Train accuracy->  16.99%\n","Current batch: Loss-> 1.3024, Train accuracy->  17.08%\n","Current batch: Loss-> 0.8765, Train accuracy->  17.18%\n","Current batch: Loss-> 0.9832, Train accuracy->  17.27%\n","Current batch: Loss-> 0.7535, Train accuracy->  17.37%\n","Current batch: Loss-> 0.7638, Train accuracy->  17.47%\n","Current batch: Loss-> 0.6076, Train accuracy->  17.58%\n","Current batch: Loss-> 0.6977, Train accuracy->  17.69%\n","Current batch: Loss-> 0.8834, Train accuracy->  17.78%\n","Current batch: Loss-> 0.7894, Train accuracy->  17.88%\n","Current batch: Loss-> 0.7822, Train accuracy->  17.98%\n","Current batch: Loss-> 0.7452, Train accuracy->  18.09%\n","Current batch: Loss-> 0.8972, Train accuracy->  18.18%\n","Current batch: Loss-> 0.6999, Train accuracy->  18.28%\n","Current batch: Loss-> 0.8853, Train accuracy->  18.38%\n","Current batch: Loss-> 0.9577, Train accuracy->  18.46%\n","Current batch: Loss-> 0.8325, Train accuracy->  18.56%\n","Current batch: Loss-> 0.8865, Train accuracy->  18.67%\n","Current batch: Loss-> 0.8639, Train accuracy->  18.77%\n","Current batch: Loss-> 0.5879, Train accuracy->  18.87%\n","Current batch: Loss-> 0.6659, Train accuracy->  18.96%\n","Current batch: Loss-> 0.6687, Train accuracy->  19.06%\n","Current batch: Loss-> 1.0294, Train accuracy->  19.16%\n","Current batch: Loss-> 0.9567, Train accuracy->  19.24%\n","Current batch: Loss-> 0.8089, Train accuracy->  19.35%\n","Current batch: Loss-> 0.6220, Train accuracy->  19.46%\n","Current batch: Loss-> 0.8690, Train accuracy->  19.56%\n","Current batch: Loss-> 0.6054, Train accuracy->  19.67%\n","Current batch: Loss-> 0.7864, Train accuracy->  19.77%\n","Current batch: Loss-> 0.5729, Train accuracy->  19.89%\n","Current batch: Loss-> 0.8560, Train accuracy->  19.99%\n","Current batch: Loss-> 1.1930, Train accuracy->  20.09%\n","Current batch: Loss-> 0.7027, Train accuracy->  20.19%\n","Current batch: Loss-> 1.1747, Train accuracy->  20.27%\n","Current batch: Loss-> 0.5013, Train accuracy->  20.38%\n","Current batch: Loss-> 0.9324, Train accuracy->  20.46%\n","Current batch: Loss-> 0.7666, Train accuracy->  20.56%\n","Current batch: Loss-> 0.9362, Train accuracy->  20.65%\n","Current batch: Loss-> 1.0044, Train accuracy->  20.75%\n","Current batch: Loss-> 0.8483, Train accuracy->  20.85%\n","Current batch: Loss-> 0.9885, Train accuracy->  20.94%\n","Current batch: Loss-> 0.7976, Train accuracy->  21.03%\n","Current batch: Loss-> 1.1818, Train accuracy->  21.12%\n","Current batch: Loss-> 0.8934, Train accuracy->  21.21%\n","Current batch: Loss-> 0.8960, Train accuracy->  21.30%\n","Current batch: Loss-> 1.0420, Train accuracy->  21.39%\n","Current batch: Loss-> 0.7814, Train accuracy->  21.48%\n","Current batch: Loss-> 0.8373, Train accuracy->  21.57%\n","Current batch: Loss-> 0.9805, Train accuracy->  21.66%\n","Current batch: Loss-> 0.5417, Train accuracy->  21.77%\n","Current batch: Loss-> 0.8732, Train accuracy->  21.88%\n","Current batch: Loss-> 0.8252, Train accuracy->  21.96%\n","Current batch: Loss-> 1.0032, Train accuracy->  22.06%\n","Current batch: Loss-> 1.1283, Train accuracy->  22.14%\n","Current batch: Loss-> 0.9163, Train accuracy->  22.24%\n","Current batch: Loss-> 1.2155, Train accuracy->  22.32%\n","Current batch: Loss-> 0.5415, Train accuracy->  22.43%\n","Current batch: Loss-> 0.7422, Train accuracy->  22.53%\n","Current batch: Loss-> 0.9265, Train accuracy->  22.62%\n","Current batch: Loss-> 0.5953, Train accuracy->  22.73%\n","Current batch: Loss-> 1.2868, Train accuracy->  22.82%\n","Current batch: Loss-> 0.8175, Train accuracy->  22.92%\n","Current batch: Loss-> 1.0539, Train accuracy->  23.01%\n","Current batch: Loss-> 0.8892, Train accuracy->  23.11%\n","Current batch: Loss-> 0.9453, Train accuracy->  23.20%\n","Current batch: Loss-> 0.7772, Train accuracy->  23.31%\n","Current batch: Loss-> 0.8127, Train accuracy->  23.40%\n","Current batch: Loss-> 1.2147, Train accuracy->  23.49%\n","Current batch: Loss-> 1.2015, Train accuracy->  23.57%\n","Current batch: Loss-> 0.8816, Train accuracy->  23.66%\n","Current batch: Loss-> 0.7083, Train accuracy->  23.75%\n","Current batch: Loss-> 0.7751, Train accuracy->  23.86%\n","Current batch: Loss-> 0.8296, Train accuracy->  23.97%\n","Current batch: Loss-> 0.6781, Train accuracy->  24.07%\n","Current batch: Loss-> 0.7007, Train accuracy->  24.17%\n","Current batch: Loss-> 0.8992, Train accuracy->  24.27%\n","Current batch: Loss-> 0.7965, Train accuracy->  24.38%\n","Current batch: Loss-> 0.7817, Train accuracy->  24.48%\n","Current batch: Loss-> 0.7265, Train accuracy->  24.59%\n","Current batch: Loss-> 0.7652, Train accuracy->  24.68%\n","Current batch: Loss-> 1.0637, Train accuracy->  24.77%\n","Current batch: Loss-> 0.8219, Train accuracy->  24.86%\n","Current batch: Loss-> 0.8763, Train accuracy->  24.96%\n","Current batch: Loss-> 1.0803, Train accuracy->  25.05%\n","Current batch: Loss-> 0.8660, Train accuracy->  25.15%\n","Current batch: Loss-> 1.0311, Train accuracy->  25.24%\n","Current batch: Loss-> 1.1517, Train accuracy->  25.32%\n","Current batch: Loss-> 0.7795, Train accuracy->  25.42%\n","Current batch: Loss-> 1.0743, Train accuracy->  25.50%\n","Current batch: Loss-> 0.9989, Train accuracy->  25.59%\n","Current batch: Loss-> 0.9752, Train accuracy->  25.69%\n","Current batch: Loss-> 0.8090, Train accuracy->  25.79%\n","Current batch: Loss-> 0.7634, Train accuracy->  25.89%\n","Current batch: Loss-> 0.7199, Train accuracy->  25.99%\n","Current batch: Loss-> 0.8191, Train accuracy->  26.09%\n","Current batch: Loss-> 0.7746, Train accuracy->  26.19%\n","Current batch: Loss-> 0.7857, Train accuracy->  26.29%\n","Current batch: Loss-> 0.7305, Train accuracy->  26.39%\n","Current batch: Loss-> 0.9586, Train accuracy->  26.48%\n","Current batch: Loss-> 0.6570, Train accuracy->  26.59%\n","Current batch: Loss-> 0.7238, Train accuracy->  26.69%\n","Current batch: Loss-> 0.9665, Train accuracy->  26.78%\n","Current batch: Loss-> 1.1040, Train accuracy->  26.87%\n","Current batch: Loss-> 0.5730, Train accuracy->  26.98%\n","Current batch: Loss-> 0.8445, Train accuracy->  27.08%\n","Current batch: Loss-> 0.9626, Train accuracy->  27.18%\n","Current batch: Loss-> 0.7454, Train accuracy->  27.29%\n","Current batch: Loss-> 1.0520, Train accuracy->  27.36%\n","Current batch: Loss-> 0.9406, Train accuracy->  27.46%\n","Current batch: Loss-> 1.0228, Train accuracy->  27.55%\n","Current batch: Loss-> 0.8065, Train accuracy->  27.64%\n","Current batch: Loss-> 0.6751, Train accuracy->  27.75%\n","Current batch: Loss-> 0.6788, Train accuracy->  27.85%\n","Current batch: Loss-> 1.0293, Train accuracy->  27.95%\n","Current batch: Loss-> 0.6210, Train accuracy->  28.06%\n","Current batch: Loss-> 0.7868, Train accuracy->  28.17%\n","Current batch: Loss-> 0.9701, Train accuracy->  28.27%\n","Current batch: Loss-> 0.7076, Train accuracy->  28.37%\n","Current batch: Loss-> 1.1026, Train accuracy->  28.45%\n","Current batch: Loss-> 0.4982, Train accuracy->  28.56%\n","Current batch: Loss-> 0.7238, Train accuracy->  28.67%\n","Current batch: Loss-> 0.7833, Train accuracy->  28.76%\n","Current batch: Loss-> 0.8031, Train accuracy->  28.86%\n","Current batch: Loss-> 0.6611, Train accuracy->  28.96%\n","Current batch: Loss-> 0.6241, Train accuracy->  29.06%\n","Current batch: Loss-> 0.8784, Train accuracy->  29.16%\n","Current batch: Loss-> 0.8460, Train accuracy->  29.25%\n","Current batch: Loss-> 0.8419, Train accuracy->  29.35%\n","Current batch: Loss-> 0.7238, Train accuracy->  29.46%\n","Current batch: Loss-> 0.9979, Train accuracy->  29.54%\n","Current batch: Loss-> 0.6235, Train accuracy->  29.65%\n","Current batch: Loss-> 0.6853, Train accuracy->  29.76%\n","Current batch: Loss-> 0.7808, Train accuracy->  29.86%\n","Current batch: Loss-> 0.7820, Train accuracy->  29.97%\n","Current batch: Loss-> 1.0783, Train accuracy->  30.05%\n","Current batch: Loss-> 0.5900, Train accuracy->  30.16%\n","Current batch: Loss-> 0.7675, Train accuracy->  30.26%\n","Current batch: Loss-> 0.7357, Train accuracy->  30.36%\n","Current batch: Loss-> 0.7001, Train accuracy->  30.46%\n","Current batch: Loss-> 1.0525, Train accuracy->  30.55%\n","Current batch: Loss-> 0.7135, Train accuracy->  30.65%\n","Current batch: Loss-> 0.9215, Train accuracy->  30.75%\n","Current batch: Loss-> 0.7811, Train accuracy->  30.86%\n","Current batch: Loss-> 0.7725, Train accuracy->  30.96%\n","Current batch: Loss-> 0.7080, Train accuracy->  31.06%\n","Current batch: Loss-> 0.9625, Train accuracy->  31.16%\n","Current batch: Loss-> 0.7421, Train accuracy->  31.26%\n","Current batch: Loss-> 0.8719, Train accuracy->  31.36%\n","Current batch: Loss-> 0.8457, Train accuracy->  31.46%\n","Current batch: Loss-> 0.8012, Train accuracy->  31.56%\n","Current batch: Loss-> 0.8187, Train accuracy->  31.66%\n","Current batch: Loss-> 0.8698, Train accuracy->  31.76%\n","Current batch: Loss-> 0.8175, Train accuracy->  31.86%\n","Current batch: Loss-> 1.1394, Train accuracy->  31.95%\n","Current batch: Loss-> 0.9235, Train accuracy->  32.05%\n","Current batch: Loss-> 0.8012, Train accuracy->  32.16%\n","Current batch: Loss-> 0.6530, Train accuracy->  32.26%\n","Current batch: Loss-> 0.7393, Train accuracy->  32.36%\n","Current batch: Loss-> 0.9693, Train accuracy->  32.45%\n","Current batch: Loss-> 0.8224, Train accuracy->  32.55%\n","Current batch: Loss-> 0.7593, Train accuracy->  32.65%\n","Current batch: Loss-> 0.8633, Train accuracy->  32.76%\n","Current batch: Loss-> 0.6306, Train accuracy->  32.86%\n","Current batch: Loss-> 0.6468, Train accuracy->  32.97%\n","Current batch: Loss-> 0.8559, Train accuracy->  33.06%\n","Current batch: Loss-> 0.7195, Train accuracy->  33.16%\n","Current batch: Loss-> 0.9052, Train accuracy->  33.27%\n","Current batch: Loss-> 0.7409, Train accuracy->  33.36%\n","Current batch: Loss-> 0.6951, Train accuracy->  33.47%\n","Current batch: Loss-> 0.8640, Train accuracy->  33.58%\n","Current batch: Loss-> 0.8440, Train accuracy->  33.68%\n","Current batch: Loss-> 0.8941, Train accuracy->  33.77%\n","Current batch: Loss-> 0.8815, Train accuracy->  33.87%\n","Current batch: Loss-> 0.8114, Train accuracy->  33.97%\n","Current batch: Loss-> 1.3234, Train accuracy->  34.05%\n","Current batch: Loss-> 0.7310, Train accuracy->  34.15%\n","Current batch: Loss-> 0.9776, Train accuracy->  34.25%\n","Current batch: Loss-> 0.8461, Train accuracy->  34.34%\n","Current batch: Loss-> 1.0280, Train accuracy->  34.43%\n","Current batch: Loss-> 1.2206, Train accuracy->  34.51%\n","Current batch: Loss-> 0.7297, Train accuracy->  34.61%\n","Current batch: Loss-> 0.5693, Train accuracy->  34.72%\n","Current batch: Loss-> 0.8931, Train accuracy->  34.82%\n","Current batch: Loss-> 0.8015, Train accuracy->  34.91%\n","Current batch: Loss-> 1.0331, Train accuracy->  34.99%\n","Current batch: Loss-> 0.7161, Train accuracy->  35.09%\n","Current batch: Loss-> 0.8904, Train accuracy->  35.18%\n","Current batch: Loss-> 0.7927, Train accuracy->  35.28%\n","Current batch: Loss-> 0.7339, Train accuracy->  35.38%\n","Current batch: Loss-> 0.8138, Train accuracy->  35.49%\n","Current batch: Loss-> 0.7196, Train accuracy->  35.59%\n","Current batch: Loss-> 0.7062, Train accuracy->  35.69%\n","Current batch: Loss-> 0.8608, Train accuracy->  35.78%\n","Current batch: Loss-> 0.9322, Train accuracy->  35.87%\n","Current batch: Loss-> 0.7998, Train accuracy->  35.95%\n","Current batch: Loss-> 0.6713, Train accuracy->  36.06%\n","Current batch: Loss-> 0.7604, Train accuracy->  36.16%\n","Current batch: Loss-> 0.8625, Train accuracy->  36.25%\n","Current batch: Loss-> 0.5820, Train accuracy->  36.36%\n","Current batch: Loss-> 0.9631, Train accuracy->  36.45%\n","Current batch: Loss-> 0.8173, Train accuracy->  36.55%\n","Current batch: Loss-> 0.8767, Train accuracy->  36.64%\n","Current batch: Loss-> 1.1197, Train accuracy->  36.74%\n","Current batch: Loss-> 0.8180, Train accuracy->  36.84%\n","Current batch: Loss-> 0.8906, Train accuracy->  36.93%\n","Current batch: Loss-> 0.6955, Train accuracy->  37.03%\n","Current batch: Loss-> 0.7927, Train accuracy->  37.14%\n","Current batch: Loss-> 0.7350, Train accuracy->  37.24%\n","Current batch: Loss-> 0.6440, Train accuracy->  37.35%\n","Current batch: Loss-> 0.5709, Train accuracy->  37.46%\n","Current batch: Loss-> 1.0049, Train accuracy->  37.56%\n","Current batch: Loss-> 0.7293, Train accuracy->  37.66%\n","Current batch: Loss-> 1.0486, Train accuracy->  37.74%\n","Current batch: Loss-> 0.9363, Train accuracy->  37.85%\n","Current batch: Loss-> 0.7207, Train accuracy->  37.93%\n","Current batch: Loss-> 0.6785, Train accuracy->  38.04%\n","Current batch: Loss-> 0.5496, Train accuracy->  38.15%\n","Current batch: Loss-> 0.8835, Train accuracy->  38.25%\n","Current batch: Loss-> 0.8144, Train accuracy->  38.35%\n","Current batch: Loss-> 0.9362, Train accuracy->  38.44%\n","Current batch: Loss-> 0.8539, Train accuracy->  38.54%\n","Current batch: Loss-> 1.0900, Train accuracy->  38.62%\n","Current batch: Loss-> 0.8252, Train accuracy->  38.72%\n","Current batch: Loss-> 0.7427, Train accuracy->  38.81%\n","Current batch: Loss-> 0.7847, Train accuracy->  38.91%\n","Current batch: Loss-> 0.8892, Train accuracy->  39.01%\n","Current batch: Loss-> 1.1724, Train accuracy->  39.09%\n","Current batch: Loss-> 1.1655, Train accuracy->  39.16%\n","Current batch: Loss-> 0.5534, Train accuracy->  39.27%\n","Current batch: Loss-> 0.5049, Train accuracy->  39.38%\n","Current batch: Loss-> 0.7014, Train accuracy->  39.49%\n","Current batch: Loss-> 0.7388, Train accuracy->  39.59%\n","Current batch: Loss-> 1.1448, Train accuracy->  39.67%\n","Current batch: Loss-> 0.9415, Train accuracy->  39.77%\n","Current batch: Loss-> 0.7455, Train accuracy->  39.87%\n","Current batch: Loss-> 0.6711, Train accuracy->  39.97%\n","Current batch: Loss-> 0.9512, Train accuracy->  40.07%\n","Current batch: Loss-> 0.7227, Train accuracy->  40.18%\n","Current batch: Loss-> 0.7662, Train accuracy->  40.27%\n","Current batch: Loss-> 1.0451, Train accuracy->  40.36%\n","Current batch: Loss-> 1.0215, Train accuracy->  40.45%\n","Current batch: Loss-> 1.0229, Train accuracy->  40.54%\n","Current batch: Loss-> 1.0613, Train accuracy->  40.63%\n","Current batch: Loss-> 0.8553, Train accuracy->  40.73%\n","Current batch: Loss-> 0.5972, Train accuracy->  40.84%\n","Current batch: Loss-> 0.9561, Train accuracy->  40.93%\n","Current batch: Loss-> 0.9529, Train accuracy->  41.02%\n","Current batch: Loss-> 0.9581, Train accuracy->  41.11%\n","Current batch: Loss-> 0.8135, Train accuracy->  41.21%\n","Current batch: Loss-> 0.8833, Train accuracy->  41.30%\n","Current batch: Loss-> 0.7573, Train accuracy->  41.40%\n","Current batch: Loss-> 0.7866, Train accuracy->  41.51%\n","Current batch: Loss-> 0.9069, Train accuracy->  41.60%\n","Current batch: Loss-> 0.9434, Train accuracy->  41.69%\n","Current batch: Loss-> 0.9147, Train accuracy->  41.79%\n","Current batch: Loss-> 1.1302, Train accuracy->  41.88%\n","Current batch: Loss-> 0.8555, Train accuracy->  41.97%\n","Current batch: Loss-> 0.9099, Train accuracy->  42.07%\n","Current batch: Loss-> 0.8838, Train accuracy->  42.17%\n","Current batch: Loss-> 0.8694, Train accuracy->  42.27%\n","Current batch: Loss-> 0.9639, Train accuracy->  42.37%\n","Current batch: Loss-> 0.9230, Train accuracy->  42.46%\n","Current batch: Loss-> 0.7739, Train accuracy->  42.56%\n","Current batch: Loss-> 1.0036, Train accuracy->  42.65%\n","Current batch: Loss-> 0.9038, Train accuracy->  42.75%\n","Current batch: Loss-> 0.8573, Train accuracy->  42.86%\n","Current batch: Loss-> 0.9718, Train accuracy->  42.95%\n","Current batch: Loss-> 0.8350, Train accuracy->  43.04%\n","Current batch: Loss-> 1.0542, Train accuracy->  43.13%\n","Current batch: Loss-> 0.8805, Train accuracy->  43.23%\n","Current batch: Loss-> 0.7304, Train accuracy->  43.33%\n","Current batch: Loss-> 0.5366, Train accuracy->  43.45%\n","Current batch: Loss-> 0.7797, Train accuracy->  43.55%\n","Current batch: Loss-> 0.6277, Train accuracy->  43.66%\n","Current batch: Loss-> 0.9000, Train accuracy->  43.75%\n","Current batch: Loss-> 0.8186, Train accuracy->  43.85%\n","Current batch: Loss-> 0.8920, Train accuracy->  43.94%\n","Current batch: Loss-> 1.0648, Train accuracy->  44.04%\n","Current batch: Loss-> 0.6857, Train accuracy->  44.14%\n","Current batch: Loss-> 0.8980, Train accuracy->  44.24%\n","Current batch: Loss-> 0.8470, Train accuracy->  44.34%\n","Current batch: Loss-> 0.7413, Train accuracy->  44.45%\n","Current batch: Loss-> 0.6526, Train accuracy->  44.55%\n","Current batch: Loss-> 0.7218, Train accuracy->  44.66%\n","Current batch: Loss-> 0.6742, Train accuracy->  44.77%\n","Current batch: Loss-> 0.8380, Train accuracy->  44.88%\n","Current batch: Loss-> 0.8290, Train accuracy->  44.97%\n","Current batch: Loss-> 0.7416, Train accuracy->  45.07%\n","Current batch: Loss-> 0.6657, Train accuracy->  45.17%\n","Current batch: Loss-> 0.7763, Train accuracy->  45.28%\n","Current batch: Loss-> 0.7367, Train accuracy->  45.38%\n","Current batch: Loss-> 1.0259, Train accuracy->  45.48%\n","Current batch: Loss-> 0.6845, Train accuracy->  45.58%\n","Current batch: Loss-> 0.5546, Train accuracy->  45.68%\n","Current batch: Loss-> 0.7219, Train accuracy->  45.79%\n","Current batch: Loss-> 0.9577, Train accuracy->  45.88%\n","Current batch: Loss-> 0.6568, Train accuracy->  45.99%\n","Current batch: Loss-> 0.9336, Train accuracy->  46.09%\n","Current batch: Loss-> 1.0960, Train accuracy->  46.18%\n","Current batch: Loss-> 0.8961, Train accuracy->  46.28%\n","Current batch: Loss-> 0.8313, Train accuracy->  46.38%\n","Current batch: Loss-> 0.6733, Train accuracy->  46.49%\n","Current batch: Loss-> 0.9617, Train accuracy->  46.58%\n","Current batch: Loss-> 0.8443, Train accuracy->  46.67%\n","Current batch: Loss-> 1.1464, Train accuracy->  46.76%\n","Current batch: Loss-> 0.9201, Train accuracy->  46.85%\n","Current batch: Loss-> 1.1314, Train accuracy->  46.93%\n","Current batch: Loss-> 0.7823, Train accuracy->  47.02%\n","Current batch: Loss-> 0.9635, Train accuracy->  47.11%\n","Current batch: Loss-> 0.6788, Train accuracy->  47.21%\n","Current batch: Loss-> 0.7969, Train accuracy->  47.31%\n","Current batch: Loss-> 0.8830, Train accuracy->  47.41%\n","Current batch: Loss-> 0.9179, Train accuracy->  47.51%\n","Current batch: Loss-> 0.9186, Train accuracy->  47.61%\n","Current batch: Loss-> 0.6417, Train accuracy->  47.72%\n","Current batch: Loss-> 0.6443, Train accuracy->  47.83%\n","Current batch: Loss-> 0.7302, Train accuracy->  47.93%\n","Current batch: Loss-> 0.8482, Train accuracy->  48.03%\n","Current batch: Loss-> 0.6963, Train accuracy->  48.13%\n","Current batch: Loss-> 0.7701, Train accuracy->  48.24%\n","Current batch: Loss-> 0.6849, Train accuracy->  48.34%\n","Current batch: Loss-> 0.7638, Train accuracy->  48.45%\n","Current batch: Loss-> 0.6746, Train accuracy->  48.56%\n","Current batch: Loss-> 0.8790, Train accuracy->  48.67%\n","Current batch: Loss-> 0.8335, Train accuracy->  48.76%\n","Current batch: Loss-> 0.9271, Train accuracy->  48.85%\n","Current batch: Loss-> 0.7718, Train accuracy->  48.95%\n","Current batch: Loss-> 0.7759, Train accuracy->  49.05%\n","Current batch: Loss-> 0.9476, Train accuracy->  49.14%\n","Current batch: Loss-> 0.9350, Train accuracy->  49.23%\n","Current batch: Loss-> 0.8201, Train accuracy->  49.33%\n","Current batch: Loss-> 1.1084, Train accuracy->  49.41%\n","Current batch: Loss-> 0.6728, Train accuracy->  49.52%\n","Current batch: Loss-> 0.9429, Train accuracy->  49.61%\n","Current batch: Loss-> 0.8005, Train accuracy->  49.70%\n","Current batch: Loss-> 0.9643, Train accuracy->  49.78%\n","Current batch: Loss-> 0.8995, Train accuracy->  49.89%\n","Current batch: Loss-> 0.6254, Train accuracy->  49.99%\n","Current batch: Loss-> 1.0220, Train accuracy->  50.09%\n","Current batch: Loss-> 1.0075, Train accuracy->  50.17%\n","Current batch: Loss-> 1.2522, Train accuracy->  50.26%\n","Current batch: Loss-> 1.2493, Train accuracy->  50.35%\n","Current batch: Loss-> 0.7014, Train accuracy->  50.45%\n","Current batch: Loss-> 0.8056, Train accuracy->  50.55%\n","Current batch: Loss-> 0.9184, Train accuracy->  50.64%\n","Current batch: Loss-> 1.0257, Train accuracy->  50.74%\n","Current batch: Loss-> 0.7625, Train accuracy->  50.83%\n","Current batch: Loss-> 0.8424, Train accuracy->  50.92%\n","Current batch: Loss-> 0.8281, Train accuracy->  51.02%\n","Current batch: Loss-> 0.8273, Train accuracy->  51.12%\n","Current batch: Loss-> 0.8662, Train accuracy->  51.21%\n","Current batch: Loss-> 0.7304, Train accuracy->  51.31%\n","Current batch: Loss-> 0.6635, Train accuracy->  51.40%\n","Current batch: Loss-> 0.8991, Train accuracy->  51.49%\n","Current batch: Loss-> 0.8720, Train accuracy->  51.60%\n","Current batch: Loss-> 1.0927, Train accuracy->  51.69%\n","Current batch: Loss-> 0.6668, Train accuracy->  51.79%\n","Current batch: Loss-> 0.6681, Train accuracy->  51.89%\n","Current batch: Loss-> 0.9072, Train accuracy->  52.00%\n","Current batch: Loss-> 0.8514, Train accuracy->  52.11%\n","Current batch: Loss-> 0.4975, Train accuracy->  52.22%\n","Current batch: Loss-> 0.6097, Train accuracy->  52.32%\n","Current batch: Loss-> 0.6674, Train accuracy->  52.42%\n","Current batch: Loss-> 0.6491, Train accuracy->  52.52%\n","Current batch: Loss-> 0.9537, Train accuracy->  52.62%\n","Current batch: Loss-> 0.7906, Train accuracy->  52.73%\n","Current batch: Loss-> 0.8372, Train accuracy->  52.83%\n","Current batch: Loss-> 1.0706, Train accuracy->  52.92%\n","Current batch: Loss-> 1.1167, Train accuracy->  53.01%\n","Current batch: Loss-> 1.1250, Train accuracy->  53.10%\n","Current batch: Loss-> 0.7700, Train accuracy->  53.21%\n","Current batch: Loss-> 0.6449, Train accuracy->  53.32%\n","Current batch: Loss-> 0.6876, Train accuracy->  53.42%\n","Current batch: Loss-> 0.8750, Train accuracy->  53.52%\n","Current batch: Loss-> 0.5162, Train accuracy->  53.63%\n","Current batch: Loss-> 0.9634, Train accuracy->  53.73%\n","Current batch: Loss-> 0.6546, Train accuracy->  53.83%\n","Current batch: Loss-> 0.7361, Train accuracy->  53.93%\n","Current batch: Loss-> 0.7251, Train accuracy->  54.04%\n","Current batch: Loss-> 0.6856, Train accuracy->  54.15%\n","Current batch: Loss-> 0.9161, Train accuracy->  54.25%\n","Current batch: Loss-> 0.5155, Train accuracy->  54.36%\n","Current batch: Loss-> 0.7205, Train accuracy->  54.46%\n","Current batch: Loss-> 0.9146, Train accuracy->  54.57%\n","Current batch: Loss-> 1.0478, Train accuracy->  54.66%\n","Current batch: Loss-> 0.6590, Train accuracy->  54.77%\n","Current batch: Loss-> 0.9100, Train accuracy->  54.87%\n","Current batch: Loss-> 0.9046, Train accuracy->  54.97%\n","Current batch: Loss-> 0.6787, Train accuracy->  55.08%\n","Current batch: Loss-> 0.8279, Train accuracy->  55.18%\n","Current batch: Loss-> 0.6681, Train accuracy->  55.28%\n","Current batch: Loss-> 0.9795, Train accuracy->  55.39%\n","Current batch: Loss-> 0.6461, Train accuracy->  55.50%\n","Current batch: Loss-> 0.6581, Train accuracy->  55.60%\n","Current batch: Loss-> 0.6203, Train accuracy->  55.71%\n","Current batch: Loss-> 0.9157, Train accuracy->  55.80%\n","Current batch: Loss-> 0.8361, Train accuracy->  55.90%\n","Current batch: Loss-> 1.0333, Train accuracy->  55.99%\n","Current batch: Loss-> 0.5830, Train accuracy->  56.10%\n","Current batch: Loss-> 1.1600, Train accuracy->  56.18%\n","Current batch: Loss-> 0.7385, Train accuracy->  56.28%\n","Current batch: Loss-> 1.0470, Train accuracy->  56.36%\n","Current batch: Loss-> 0.9219, Train accuracy->  56.45%\n","Current batch: Loss-> 0.6975, Train accuracy->  56.55%\n","Current batch: Loss-> 1.0030, Train accuracy->  56.64%\n","Current batch: Loss-> 0.6410, Train accuracy->  56.74%\n","Current batch: Loss-> 0.7050, Train accuracy->  56.84%\n","Current batch: Loss-> 0.6533, Train accuracy->  56.95%\n","Current batch: Loss-> 1.1388, Train accuracy->  57.03%\n","Current batch: Loss-> 0.8759, Train accuracy->  57.12%\n","Current batch: Loss-> 1.2166, Train accuracy->  57.20%\n","Current batch: Loss-> 1.1084, Train accuracy->  57.30%\n","Current batch: Loss-> 1.0501, Train accuracy->  57.39%\n","Current batch: Loss-> 0.8726, Train accuracy->  57.49%\n","Current batch: Loss-> 0.7378, Train accuracy->  57.60%\n","Current batch: Loss-> 0.8923, Train accuracy->  57.68%\n","Current batch: Loss-> 0.8329, Train accuracy->  57.78%\n","Current batch: Loss-> 0.7710, Train accuracy->  57.89%\n","Current batch: Loss-> 0.6737, Train accuracy->  57.99%\n","Current batch: Loss-> 0.8047, Train accuracy->  58.09%\n","Current batch: Loss-> 0.7727, Train accuracy->  58.19%\n","Current batch: Loss-> 0.8332, Train accuracy->  58.28%\n","Current batch: Loss-> 0.9096, Train accuracy->  58.38%\n","Current batch: Loss-> 0.7734, Train accuracy->  58.47%\n","Current batch: Loss-> 0.6323, Train accuracy->  58.58%\n","Current batch: Loss-> 0.9493, Train accuracy->  58.68%\n","Current batch: Loss-> 0.7085, Train accuracy->  58.77%\n","Current batch: Loss-> 0.6748, Train accuracy->  58.88%\n","Current batch: Loss-> 0.7850, Train accuracy->  58.99%\n","Current batch: Loss-> 0.8897, Train accuracy->  59.09%\n","Current batch: Loss-> 0.6573, Train accuracy->  59.19%\n","Current batch: Loss-> 0.8551, Train accuracy->  59.29%\n","Current batch: Loss-> 0.7447, Train accuracy->  59.38%\n","Current batch: Loss-> 0.8369, Train accuracy->  59.48%\n","Current batch: Loss-> 0.6237, Train accuracy->  59.59%\n","Current batch: Loss-> 0.9578, Train accuracy->  59.69%\n","Current batch: Loss-> 0.8245, Train accuracy->  59.79%\n","Current batch: Loss-> 0.5475, Train accuracy->  59.91%\n","Current batch: Loss-> 0.6284, Train accuracy->  60.02%\n","Current batch: Loss-> 0.6578, Train accuracy->  60.12%\n","Current batch: Loss-> 0.5525, Train accuracy->  60.23%\n","Current batch: Loss-> 0.8579, Train accuracy->  60.34%\n","Current batch: Loss-> 0.8759, Train accuracy->  60.43%\n","Current batch: Loss-> 1.0818, Train accuracy->  60.52%\n","Current batch: Loss-> 0.6446, Train accuracy->  60.62%\n","Current batch: Loss-> 0.7955, Train accuracy->  60.72%\n","Current batch: Loss-> 0.8967, Train accuracy->  60.82%\n","Current batch: Loss-> 0.9035, Train accuracy->  60.91%\n","Current batch: Loss-> 0.9511, Train accuracy->  61.00%\n","Current batch: Loss-> 0.8194, Train accuracy->  61.10%\n","Current batch: Loss-> 0.8734, Train accuracy->  61.20%\n","Current batch: Loss-> 0.7377, Train accuracy->  61.30%\n","Current batch: Loss-> 0.6696, Train accuracy->  61.41%\n","Current batch: Loss-> 0.9459, Train accuracy->  61.51%\n","Current batch: Loss-> 0.8305, Train accuracy->  61.60%\n","Current batch: Loss-> 0.8418, Train accuracy->  61.70%\n","Current batch: Loss-> 0.8349, Train accuracy->  61.80%\n","Current batch: Loss-> 0.8404, Train accuracy->  61.90%\n","Current batch: Loss-> 0.8323, Train accuracy->  61.99%\n","Current batch: Loss-> 0.8385, Train accuracy->  62.10%\n","Current batch: Loss-> 1.1690, Train accuracy->  62.18%\n","Current batch: Loss-> 0.8380, Train accuracy->  62.29%\n","Current batch: Loss-> 0.7003, Train accuracy->  62.39%\n","Current batch: Loss-> 0.6808, Train accuracy->  62.50%\n","Current batch: Loss-> 0.8520, Train accuracy->  62.61%\n","Current batch: Loss-> 0.7287, Train accuracy->  62.70%\n","Current batch: Loss-> 0.8569, Train accuracy->  62.80%\n","Current batch: Loss-> 0.5567, Train accuracy->  62.91%\n","Current batch: Loss-> 0.7114, Train accuracy->  63.01%\n","Current batch: Loss-> 0.6919, Train accuracy->  63.11%\n","Current batch: Loss-> 0.9335, Train accuracy->  63.20%\n","Current batch: Loss-> 0.9439, Train accuracy->  63.30%\n","Current batch: Loss-> 0.6459, Train accuracy->  63.40%\n","Current batch: Loss-> 0.6608, Train accuracy->  63.50%\n","Current batch: Loss-> 0.6115, Train accuracy->  63.61%\n","Current batch: Loss-> 0.8978, Train accuracy->  63.71%\n","Current batch: Loss-> 0.7763, Train accuracy->  63.81%\n","Current batch: Loss-> 0.8935, Train accuracy->  63.91%\n","Current batch: Loss-> 0.7168, Train accuracy->  64.02%\n","Current batch: Loss-> 0.9361, Train accuracy->  64.11%\n","Current batch: Loss-> 0.7879, Train accuracy->  64.21%\n","Current batch: Loss-> 0.7359, Train accuracy->  64.32%\n","Current batch: Loss-> 0.9576, Train accuracy->  64.42%\n","Current batch: Loss-> 0.5823, Train accuracy->  64.53%\n","Current batch: Loss-> 0.7428, Train accuracy->  64.63%\n","Current batch: Loss-> 1.0972, Train accuracy->  64.72%\n","Current batch: Loss-> 0.7262, Train accuracy->  64.82%\n","Current batch: Loss-> 0.8765, Train accuracy->  64.91%\n","Current batch: Loss-> 0.8762, Train accuracy->  65.00%\n","Current batch: Loss-> 0.6065, Train accuracy->  65.11%\n","Current batch: Loss-> 0.7181, Train accuracy->  65.22%\n","Current batch: Loss-> 0.6093, Train accuracy->  65.33%\n","Current batch: Loss-> 0.6433, Train accuracy->  65.44%\n","Current batch: Loss-> 0.5844, Train accuracy->  65.55%\n","Current batch: Loss-> 0.6485, Train accuracy->  65.67%\n","Current batch: Loss-> 1.0423, Train accuracy->  65.77%\n","Current batch: Loss-> 0.7334, Train accuracy->  65.87%\n","Current batch: Loss-> 0.8934, Train accuracy->  65.95%\n","Current batch: Loss-> 0.7701, Train accuracy->  66.06%\n","Current batch: Loss-> 0.8234, Train accuracy->  66.16%\n","Current batch: Loss-> 0.9937, Train accuracy->  66.25%\n","Current batch: Loss-> 0.7544, Train accuracy->  66.35%\n","Current batch: Loss-> 0.5214, Train accuracy->  66.46%\n","Current batch: Loss-> 1.0205, Train accuracy->  66.55%\n","Current batch: Loss-> 0.6899, Train accuracy->  66.66%\n","Current batch: Loss-> 1.0182, Train accuracy->  66.76%\n","Current batch: Loss-> 0.7003, Train accuracy->  66.86%\n","Current batch: Loss-> 0.6764, Train accuracy->  66.96%\n","Current batch: Loss-> 1.0164, Train accuracy->  67.06%\n","Current batch: Loss-> 0.8877, Train accuracy->  67.15%\n","Current batch: Loss-> 0.7176, Train accuracy->  67.26%\n","Current batch: Loss-> 0.5985, Train accuracy->  67.37%\n","Current batch: Loss-> 1.0588, Train accuracy->  67.46%\n","Current batch: Loss-> 0.5914, Train accuracy->  67.56%\n","Current batch: Loss-> 0.6502, Train accuracy->  67.67%\n","Current batch: Loss-> 0.7953, Train accuracy->  67.78%\n","Current batch: Loss-> 1.0865, Train accuracy->  67.88%\n","Current batch: Loss-> 1.1578, Train accuracy->  67.97%\n","Current batch: Loss-> 0.9836, Train accuracy->  68.07%\n","Current batch: Loss-> 0.6493, Train accuracy->  68.18%\n","Current batch: Loss-> 1.1241, Train accuracy->  68.26%\n","Current batch: Loss-> 0.6658, Train accuracy->  68.38%\n","Current batch: Loss-> 0.6650, Train accuracy->  68.47%\n","Current batch: Loss-> 1.1397, Train accuracy->  68.55%\n","Current batch: Loss-> 0.5936, Train accuracy->  68.66%\n","Current batch: Loss-> 0.5458, Train accuracy->  68.77%\n","Current batch: Loss-> 0.6750, Train accuracy->  68.88%\n","Current batch: Loss-> 0.7707, Train accuracy->  68.99%\n","Current batch: Loss-> 0.6161, Train accuracy->  69.09%\n","Current batch: Loss-> 0.8688, Train accuracy->  69.19%\n","Current batch: Loss-> 1.1139, Train accuracy->  69.28%\n","Current batch: Loss-> 0.9445, Train accuracy->  69.38%\n","Current batch: Loss-> 0.6165, Train accuracy->  69.48%\n","Current batch: Loss-> 1.1386, Train accuracy->  69.56%\n","Current batch: Loss-> 0.9512, Train accuracy->  69.66%\n","Current batch: Loss-> 0.5269, Train accuracy->  69.77%\n","Current batch: Loss-> 0.6956, Train accuracy->  69.88%\n","Current batch: Loss-> 0.7131, Train accuracy->  69.98%\n","Current batch: Loss-> 0.7892, Train accuracy->  70.08%\n","Current batch: Loss-> 0.9833, Train accuracy->  70.17%\n","Current batch: Loss-> 0.7161, Train accuracy->  70.28%\n","Current batch: Loss-> 0.6998, Train accuracy->  70.38%\n","Current batch: Loss-> 0.7226, Train accuracy->  70.49%\n","Current batch: Loss-> 0.9102, Train accuracy->  70.59%\n","Current batch: Loss-> 0.7238, Train accuracy->  70.70%\n","Current batch: Loss-> 0.7068, Train accuracy->  70.80%\n","Current batch: Loss-> 0.7627, Train accuracy->  70.91%\n","Current batch: Loss-> 0.7321, Train accuracy->  71.02%\n","Current batch: Loss-> 0.9238, Train accuracy->  71.12%\n","Current batch: Loss-> 0.8993, Train accuracy->  71.21%\n","Current batch: Loss-> 0.8796, Train accuracy->  71.31%\n","Current batch: Loss-> 0.7735, Train accuracy->  71.40%\n","Current batch: Loss-> 0.8789, Train accuracy->  71.50%\n","Current batch: Loss-> 0.8617, Train accuracy->  71.61%\n","Current batch: Loss-> 0.7553, Train accuracy->  71.71%\n","Current batch: Loss-> 0.6810, Train accuracy->  71.82%\n","Current batch: Loss-> 0.6699, Train accuracy->  71.93%\n","Current batch: Loss-> 0.9051, Train accuracy->  72.02%\n","Current batch: Loss-> 0.6719, Train accuracy->  72.13%\n","Current batch: Loss-> 0.7061, Train accuracy->  72.22%\n","Current batch: Loss-> 0.9365, Train accuracy->  72.32%\n","Current batch: Loss-> 0.7336, Train accuracy->  72.43%\n","Current batch: Loss-> 0.7295, Train accuracy->  72.54%\n","Current batch: Loss-> 0.8378, Train accuracy->  72.64%\n","Current batch: Loss-> 0.9191, Train accuracy->  72.74%\n","Current batch: Loss-> 0.6303, Train accuracy->  72.85%\n","Current batch: Loss-> 0.8093, Train accuracy->  72.95%\n","Current batch: Loss-> 0.5138, Train accuracy->  73.06%\n","Current batch: Loss-> 0.9075, Train accuracy->  73.16%\n","Current batch: Loss-> 0.8806, Train accuracy->  73.26%\n","Current batch: Loss-> 0.6790, Train accuracy->  73.37%\n","Current batch: Loss-> 0.8729, Train accuracy->  73.47%\n","Current batch: Loss-> 0.8340, Train accuracy->  73.57%\n","Current batch: Loss-> 0.9792, Train accuracy->  73.66%\n","Current batch: Loss-> 0.6396, Train accuracy->  73.78%\n","Current batch: Loss-> 0.9023, Train accuracy->  73.88%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 48.53it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 1.2482, Train accuracy->  73.96%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 46.15it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.3383, Accuracy: 5714/12000 (48%)\n","\n","Current batch: Loss-> 1.1516, Train accuracy->   0.08%\n","Current batch: Loss-> 0.7583, Train accuracy->   0.18%\n","Current batch: Loss-> 0.6613, Train accuracy->   0.29%\n","Current batch: Loss-> 0.8100, Train accuracy->   0.38%\n","Current batch: Loss-> 0.8101, Train accuracy->   0.48%\n","Current batch: Loss-> 0.8473, Train accuracy->   0.58%\n","Current batch: Loss-> 0.7412, Train accuracy->   0.68%\n","Current batch: Loss-> 0.7245, Train accuracy->   0.77%\n","Current batch: Loss-> 0.8012, Train accuracy->   0.89%\n","Current batch: Loss-> 0.5831, Train accuracy->   1.00%\n","Current batch: Loss-> 0.6946, Train accuracy->   1.11%\n","Current batch: Loss-> 0.6779, Train accuracy->   1.21%\n","Current batch: Loss-> 0.6712, Train accuracy->   1.31%\n","Current batch: Loss-> 0.8413, Train accuracy->   1.41%\n","Current batch: Loss-> 0.8753, Train accuracy->   1.50%\n","Current batch: Loss-> 1.0175, Train accuracy->   1.60%\n","Current batch: Loss-> 0.7560, Train accuracy->   1.69%\n","Current batch: Loss-> 0.9462, Train accuracy->   1.78%\n","Current batch: Loss-> 0.7436, Train accuracy->   1.89%\n","Current batch: Loss-> 0.8044, Train accuracy->   1.99%\n","Current batch: Loss-> 0.9187, Train accuracy->   2.08%\n","Current batch: Loss-> 0.5327, Train accuracy->   2.19%\n","Current batch: Loss-> 0.7054, Train accuracy->   2.29%\n","Current batch: Loss-> 0.7821, Train accuracy->   2.40%\n","Current batch: Loss-> 0.8249, Train accuracy->   2.50%\n","Current batch: Loss-> 0.7589, Train accuracy->   2.60%\n","Current batch: Loss-> 0.8197, Train accuracy->   2.71%\n","Current batch: Loss-> 0.8296, Train accuracy->   2.81%\n","Current batch: Loss-> 0.8241, Train accuracy->   2.91%\n","Current batch: Loss-> 0.9448, Train accuracy->   3.02%\n","Current batch: Loss-> 0.7943, Train accuracy->   3.12%\n","Current batch: Loss-> 0.7409, Train accuracy->   3.22%\n","Current batch: Loss-> 0.6932, Train accuracy->   3.33%\n","Current batch: Loss-> 0.7299, Train accuracy->   3.43%\n","Current batch: Loss-> 0.7788, Train accuracy->   3.54%\n","Current batch: Loss-> 0.7340, Train accuracy->   3.65%\n","Current batch: Loss-> 0.9534, Train accuracy->   3.73%\n","Current batch: Loss-> 0.8017, Train accuracy->   3.83%\n","Current batch: Loss-> 0.7154, Train accuracy->   3.93%\n","Current batch: Loss-> 0.7420, Train accuracy->   4.04%\n","Current batch: Loss-> 0.7111, Train accuracy->   4.14%\n","Current batch: Loss-> 0.9565, Train accuracy->   4.22%\n","Current batch: Loss-> 0.6259, Train accuracy->   4.33%\n","Current batch: Loss-> 0.9748, Train accuracy->   4.43%\n","Current batch: Loss-> 0.7948, Train accuracy->   4.53%\n","Current batch: Loss-> 0.7783, Train accuracy->   4.62%\n","Current batch: Loss-> 0.7032, Train accuracy->   4.73%\n","Current batch: Loss-> 0.7833, Train accuracy->   4.82%\n","Current batch: Loss-> 0.9724, Train accuracy->   4.91%\n","Current batch: Loss-> 0.5942, Train accuracy->   5.02%\n","Current batch: Loss-> 0.6956, Train accuracy->   5.11%\n","Current batch: Loss-> 0.8906, Train accuracy->   5.21%\n","Current batch: Loss-> 0.9863, Train accuracy->   5.31%\n","Current batch: Loss-> 1.0819, Train accuracy->   5.40%\n","Current batch: Loss-> 0.8155, Train accuracy->   5.50%\n","Current batch: Loss-> 0.7806, Train accuracy->   5.59%\n","Current batch: Loss-> 0.9510, Train accuracy->   5.69%\n","Current batch: Loss-> 0.7215, Train accuracy->   5.79%\n","Current batch: Loss-> 0.7183, Train accuracy->   5.89%\n","Current batch: Loss-> 0.7630, Train accuracy->   5.99%\n","Current batch: Loss-> 0.9613, Train accuracy->   6.09%\n","Current batch: Loss-> 0.6273, Train accuracy->   6.19%\n","Current batch: Loss-> 0.8144, Train accuracy->   6.29%\n","Current batch: Loss-> 1.0284, Train accuracy->   6.38%\n","Current batch: Loss-> 0.9988, Train accuracy->   6.46%\n","Current batch: Loss-> 0.8345, Train accuracy->   6.56%\n","Current batch: Loss-> 1.0791, Train accuracy->   6.65%\n","Current batch: Loss-> 1.0458, Train accuracy->   6.74%\n","Current batch: Loss-> 0.7007, Train accuracy->   6.83%\n","Current batch: Loss-> 0.9079, Train accuracy->   6.92%\n","Current batch: Loss-> 0.8417, Train accuracy->   7.03%\n","Current batch: Loss-> 0.8640, Train accuracy->   7.12%\n","Current batch: Loss-> 0.8447, Train accuracy->   7.21%\n","Current batch: Loss-> 0.8827, Train accuracy->   7.31%\n","Current batch: Loss-> 0.9596, Train accuracy->   7.41%\n","Current batch: Loss-> 0.8009, Train accuracy->   7.51%\n","Current batch: Loss-> 0.8217, Train accuracy->   7.61%\n","Current batch: Loss-> 0.7120, Train accuracy->   7.71%\n","Current batch: Loss-> 1.0533, Train accuracy->   7.81%\n","Current batch: Loss-> 0.7305, Train accuracy->   7.92%\n","Current batch: Loss-> 0.6756, Train accuracy->   8.02%\n","Current batch: Loss-> 0.7252, Train accuracy->   8.13%\n","Current batch: Loss-> 0.7905, Train accuracy->   8.23%\n","Current batch: Loss-> 0.8711, Train accuracy->   8.32%\n","Current batch: Loss-> 0.7746, Train accuracy->   8.43%\n","Current batch: Loss-> 0.8127, Train accuracy->   8.53%\n","Current batch: Loss-> 0.6374, Train accuracy->   8.63%\n","Current batch: Loss-> 0.8192, Train accuracy->   8.74%\n","Current batch: Loss-> 0.7983, Train accuracy->   8.84%\n","Current batch: Loss-> 0.8555, Train accuracy->   8.94%\n","Current batch: Loss-> 0.7756, Train accuracy->   9.04%\n","Current batch: Loss-> 0.6968, Train accuracy->   9.15%\n","Current batch: Loss-> 0.6855, Train accuracy->   9.25%\n","Current batch: Loss-> 0.8008, Train accuracy->   9.36%\n","Current batch: Loss-> 0.9383, Train accuracy->   9.46%\n","Current batch: Loss-> 0.7439, Train accuracy->   9.56%\n","Current batch: Loss-> 0.6913, Train accuracy->   9.68%\n","Current batch: Loss-> 0.7956, Train accuracy->   9.78%\n","Current batch: Loss-> 0.6777, Train accuracy->   9.88%\n","Current batch: Loss-> 0.7452, Train accuracy->   9.99%\n","Current batch: Loss-> 0.7637, Train accuracy->  10.08%\n","Current batch: Loss-> 0.5033, Train accuracy->  10.20%\n","Current batch: Loss-> 0.4391, Train accuracy->  10.31%\n","Current batch: Loss-> 0.7608, Train accuracy->  10.41%\n","Current batch: Loss-> 1.0666, Train accuracy->  10.51%\n","Current batch: Loss-> 0.6779, Train accuracy->  10.62%\n","Current batch: Loss-> 1.1339, Train accuracy->  10.71%\n","Current batch: Loss-> 0.8459, Train accuracy->  10.81%\n","Current batch: Loss-> 0.8425, Train accuracy->  10.91%\n","Current batch: Loss-> 0.7186, Train accuracy->  11.01%\n","Current batch: Loss-> 0.7263, Train accuracy->  11.11%\n","Current batch: Loss-> 0.9357, Train accuracy->  11.22%\n","Current batch: Loss-> 0.6818, Train accuracy->  11.32%\n","Current batch: Loss-> 0.9010, Train accuracy->  11.43%\n","Current batch: Loss-> 0.8698, Train accuracy->  11.52%\n","Current batch: Loss-> 0.6677, Train accuracy->  11.63%\n","Current batch: Loss-> 0.8458, Train accuracy->  11.73%\n","Current batch: Loss-> 0.7131, Train accuracy->  11.82%\n","Current batch: Loss-> 1.0094, Train accuracy->  11.92%\n","Current batch: Loss-> 0.7264, Train accuracy->  12.01%\n","Current batch: Loss-> 0.8843, Train accuracy->  12.11%\n","Current batch: Loss-> 0.7811, Train accuracy->  12.21%\n","Current batch: Loss-> 0.7298, Train accuracy->  12.31%\n","Current batch: Loss-> 0.6456, Train accuracy->  12.41%\n","Current batch: Loss-> 0.6011, Train accuracy->  12.52%\n","Current batch: Loss-> 0.6020, Train accuracy->  12.62%\n","Current batch: Loss-> 0.7530, Train accuracy->  12.73%\n","Current batch: Loss-> 0.7884, Train accuracy->  12.83%\n","Current batch: Loss-> 0.7676, Train accuracy->  12.93%\n","Current batch: Loss-> 0.7967, Train accuracy->  13.03%\n","Current batch: Loss-> 0.8756, Train accuracy->  13.12%\n","Current batch: Loss-> 0.7955, Train accuracy->  13.24%\n","Current batch: Loss-> 0.8239, Train accuracy->  13.34%\n","Current batch: Loss-> 0.9795, Train accuracy->  13.43%\n","Current batch: Loss-> 0.8060, Train accuracy->  13.54%\n","Current batch: Loss-> 0.6789, Train accuracy->  13.64%\n","Current batch: Loss-> 0.5454, Train accuracy->  13.75%\n","Current batch: Loss-> 0.8874, Train accuracy->  13.85%\n","Current batch: Loss-> 0.7491, Train accuracy->  13.95%\n","Current batch: Loss-> 0.6732, Train accuracy->  14.05%\n","Current batch: Loss-> 0.7215, Train accuracy->  14.14%\n","Current batch: Loss-> 0.7360, Train accuracy->  14.24%\n","Current batch: Loss-> 0.7426, Train accuracy->  14.34%\n","Current batch: Loss-> 0.8775, Train accuracy->  14.45%\n","Current batch: Loss-> 0.5932, Train accuracy->  14.56%\n","Current batch: Loss-> 0.9686, Train accuracy->  14.65%\n","Current batch: Loss-> 0.7716, Train accuracy->  14.75%\n","Current batch: Loss-> 0.7329, Train accuracy->  14.86%\n","Current batch: Loss-> 0.7849, Train accuracy->  14.95%\n","Current batch: Loss-> 0.5420, Train accuracy->  15.06%\n","Current batch: Loss-> 0.7189, Train accuracy->  15.16%\n","Current batch: Loss-> 0.6212, Train accuracy->  15.27%\n","Current batch: Loss-> 0.8452, Train accuracy->  15.38%\n","Current batch: Loss-> 0.9125, Train accuracy->  15.48%\n","Current batch: Loss-> 0.6445, Train accuracy->  15.59%\n","Current batch: Loss-> 0.7035, Train accuracy->  15.69%\n","Current batch: Loss-> 0.7447, Train accuracy->  15.79%\n","Current batch: Loss-> 0.7620, Train accuracy->  15.90%\n","Current batch: Loss-> 0.7689, Train accuracy->  16.00%\n","Current batch: Loss-> 1.0653, Train accuracy->  16.10%\n","Current batch: Loss-> 0.6670, Train accuracy->  16.20%\n","Current batch: Loss-> 0.9191, Train accuracy->  16.28%\n","Current batch: Loss-> 0.8900, Train accuracy->  16.39%\n","Current batch: Loss-> 0.5399, Train accuracy->  16.50%\n","Current batch: Loss-> 0.9961, Train accuracy->  16.58%\n","Current batch: Loss-> 0.8823, Train accuracy->  16.68%\n","Current batch: Loss-> 1.0541, Train accuracy->  16.77%\n","Current batch: Loss-> 0.6666, Train accuracy->  16.88%\n","Current batch: Loss-> 1.2780, Train accuracy->  16.97%\n","Current batch: Loss-> 0.6564, Train accuracy->  17.08%\n","Current batch: Loss-> 0.9098, Train accuracy->  17.18%\n","Current batch: Loss-> 1.1407, Train accuracy->  17.27%\n","Current batch: Loss-> 0.9643, Train accuracy->  17.36%\n","Current batch: Loss-> 0.7564, Train accuracy->  17.46%\n","Current batch: Loss-> 0.7452, Train accuracy->  17.56%\n","Current batch: Loss-> 0.7365, Train accuracy->  17.67%\n","Current batch: Loss-> 0.7279, Train accuracy->  17.77%\n","Current batch: Loss-> 0.6215, Train accuracy->  17.87%\n","Current batch: Loss-> 0.8769, Train accuracy->  17.97%\n","Current batch: Loss-> 0.9376, Train accuracy->  18.06%\n","Current batch: Loss-> 0.6727, Train accuracy->  18.16%\n","Current batch: Loss-> 1.0427, Train accuracy->  18.25%\n","Current batch: Loss-> 1.1050, Train accuracy->  18.33%\n","Current batch: Loss-> 0.7868, Train accuracy->  18.43%\n","Current batch: Loss-> 1.2496, Train accuracy->  18.51%\n","Current batch: Loss-> 0.7211, Train accuracy->  18.61%\n","Current batch: Loss-> 1.1366, Train accuracy->  18.70%\n","Current batch: Loss-> 0.8101, Train accuracy->  18.79%\n","Current batch: Loss-> 0.9360, Train accuracy->  18.89%\n","Current batch: Loss-> 1.0021, Train accuracy->  18.97%\n","Current batch: Loss-> 0.9939, Train accuracy->  19.06%\n","Current batch: Loss-> 0.7422, Train accuracy->  19.15%\n","Current batch: Loss-> 0.8501, Train accuracy->  19.25%\n","Current batch: Loss-> 0.6924, Train accuracy->  19.35%\n","Current batch: Loss-> 0.6887, Train accuracy->  19.45%\n","Current batch: Loss-> 0.7897, Train accuracy->  19.56%\n","Current batch: Loss-> 0.8269, Train accuracy->  19.66%\n","Current batch: Loss-> 0.8227, Train accuracy->  19.75%\n","Current batch: Loss-> 0.7617, Train accuracy->  19.85%\n","Current batch: Loss-> 1.0915, Train accuracy->  19.94%\n","Current batch: Loss-> 1.0262, Train accuracy->  20.03%\n","Current batch: Loss-> 0.8204, Train accuracy->  20.14%\n","Current batch: Loss-> 0.6937, Train accuracy->  20.24%\n","Current batch: Loss-> 1.0165, Train accuracy->  20.33%\n","Current batch: Loss-> 0.7964, Train accuracy->  20.43%\n","Current batch: Loss-> 0.9002, Train accuracy->  20.54%\n","Current batch: Loss-> 0.7241, Train accuracy->  20.63%\n","Current batch: Loss-> 0.9143, Train accuracy->  20.73%\n","Current batch: Loss-> 0.8397, Train accuracy->  20.82%\n","Current batch: Loss-> 1.0842, Train accuracy->  20.92%\n","Current batch: Loss-> 0.8019, Train accuracy->  21.01%\n","Current batch: Loss-> 0.8572, Train accuracy->  21.11%\n","Current batch: Loss-> 0.5287, Train accuracy->  21.22%\n","Current batch: Loss-> 0.8922, Train accuracy->  21.32%\n","Current batch: Loss-> 0.5648, Train accuracy->  21.43%\n","Current batch: Loss-> 0.7915, Train accuracy->  21.52%\n","Current batch: Loss-> 0.8335, Train accuracy->  21.62%\n","Current batch: Loss-> 0.5823, Train accuracy->  21.73%\n","Current batch: Loss-> 0.8594, Train accuracy->  21.83%\n","Current batch: Loss-> 0.8552, Train accuracy->  21.93%\n","Current batch: Loss-> 0.7753, Train accuracy->  22.02%\n","Current batch: Loss-> 0.6410, Train accuracy->  22.13%\n","Current batch: Loss-> 0.5208, Train accuracy->  22.24%\n","Current batch: Loss-> 1.0327, Train accuracy->  22.32%\n","Current batch: Loss-> 0.8167, Train accuracy->  22.42%\n","Current batch: Loss-> 0.5960, Train accuracy->  22.54%\n","Current batch: Loss-> 1.0158, Train accuracy->  22.62%\n","Current batch: Loss-> 1.0780, Train accuracy->  22.71%\n","Current batch: Loss-> 0.7169, Train accuracy->  22.82%\n","Current batch: Loss-> 0.5662, Train accuracy->  22.93%\n","Current batch: Loss-> 0.8164, Train accuracy->  23.02%\n","Current batch: Loss-> 0.9237, Train accuracy->  23.11%\n","Current batch: Loss-> 0.8156, Train accuracy->  23.21%\n","Current batch: Loss-> 0.8405, Train accuracy->  23.31%\n","Current batch: Loss-> 0.8788, Train accuracy->  23.41%\n","Current batch: Loss-> 0.6075, Train accuracy->  23.51%\n","Current batch: Loss-> 0.7900, Train accuracy->  23.61%\n","Current batch: Loss-> 0.9404, Train accuracy->  23.71%\n","Current batch: Loss-> 0.7239, Train accuracy->  23.82%\n","Current batch: Loss-> 0.9309, Train accuracy->  23.91%\n","Current batch: Loss-> 0.8216, Train accuracy->  24.01%\n","Current batch: Loss-> 0.8839, Train accuracy->  24.11%\n","Current batch: Loss-> 0.8516, Train accuracy->  24.20%\n","Current batch: Loss-> 1.1372, Train accuracy->  24.30%\n","Current batch: Loss-> 0.8054, Train accuracy->  24.41%\n","Current batch: Loss-> 0.8214, Train accuracy->  24.51%\n","Current batch: Loss-> 0.8104, Train accuracy->  24.61%\n","Current batch: Loss-> 0.7465, Train accuracy->  24.71%\n","Current batch: Loss-> 0.5156, Train accuracy->  24.83%\n","Current batch: Loss-> 0.6781, Train accuracy->  24.93%\n","Current batch: Loss-> 0.9439, Train accuracy->  25.02%\n","Current batch: Loss-> 0.6689, Train accuracy->  25.12%\n","Current batch: Loss-> 0.6162, Train accuracy->  25.22%\n","Current batch: Loss-> 1.0425, Train accuracy->  25.31%\n","Current batch: Loss-> 1.1319, Train accuracy->  25.39%\n","Current batch: Loss-> 0.8245, Train accuracy->  25.49%\n","Current batch: Loss-> 0.8002, Train accuracy->  25.59%\n","Current batch: Loss-> 0.8834, Train accuracy->  25.69%\n","Current batch: Loss-> 0.7013, Train accuracy->  25.78%\n","Current batch: Loss-> 0.5470, Train accuracy->  25.89%\n","Current batch: Loss-> 0.7420, Train accuracy->  26.00%\n","Current batch: Loss-> 0.7849, Train accuracy->  26.09%\n","Current batch: Loss-> 1.0028, Train accuracy->  26.20%\n","Current batch: Loss-> 0.8660, Train accuracy->  26.29%\n","Current batch: Loss-> 0.8816, Train accuracy->  26.39%\n","Current batch: Loss-> 0.6970, Train accuracy->  26.49%\n","Current batch: Loss-> 0.8048, Train accuracy->  26.59%\n","Current batch: Loss-> 0.7859, Train accuracy->  26.69%\n","Current batch: Loss-> 1.0240, Train accuracy->  26.79%\n","Current batch: Loss-> 0.8350, Train accuracy->  26.89%\n","Current batch: Loss-> 0.8777, Train accuracy->  26.98%\n","Current batch: Loss-> 0.7990, Train accuracy->  27.08%\n","Current batch: Loss-> 0.7043, Train accuracy->  27.19%\n","Current batch: Loss-> 0.5013, Train accuracy->  27.30%\n","Current batch: Loss-> 0.6600, Train accuracy->  27.41%\n","Current batch: Loss-> 0.9746, Train accuracy->  27.50%\n","Current batch: Loss-> 0.7422, Train accuracy->  27.60%\n","Current batch: Loss-> 0.6131, Train accuracy->  27.70%\n","Current batch: Loss-> 0.8980, Train accuracy->  27.80%\n","Current batch: Loss-> 0.7070, Train accuracy->  27.89%\n","Current batch: Loss-> 1.0104, Train accuracy->  27.98%\n","Current batch: Loss-> 0.8695, Train accuracy->  28.06%\n","Current batch: Loss-> 0.6276, Train accuracy->  28.17%\n","Current batch: Loss-> 0.6100, Train accuracy->  28.27%\n","Current batch: Loss-> 0.7891, Train accuracy->  28.38%\n","Current batch: Loss-> 0.8414, Train accuracy->  28.48%\n","Current batch: Loss-> 1.0657, Train accuracy->  28.57%\n","Current batch: Loss-> 0.8054, Train accuracy->  28.68%\n","Current batch: Loss-> 1.1522, Train accuracy->  28.77%\n","Current batch: Loss-> 1.1980, Train accuracy->  28.86%\n","Current batch: Loss-> 0.7222, Train accuracy->  28.97%\n","Current batch: Loss-> 0.8984, Train accuracy->  29.06%\n","Current batch: Loss-> 0.9107, Train accuracy->  29.15%\n","Current batch: Loss-> 0.7613, Train accuracy->  29.25%\n","Current batch: Loss-> 0.9159, Train accuracy->  29.34%\n","Current batch: Loss-> 1.0777, Train accuracy->  29.43%\n","Current batch: Loss-> 0.8223, Train accuracy->  29.53%\n","Current batch: Loss-> 0.7897, Train accuracy->  29.62%\n","Current batch: Loss-> 0.6532, Train accuracy->  29.74%\n","Current batch: Loss-> 0.6956, Train accuracy->  29.85%\n","Current batch: Loss-> 0.7157, Train accuracy->  29.95%\n","Current batch: Loss-> 0.6267, Train accuracy->  30.06%\n","Current batch: Loss-> 0.7439, Train accuracy->  30.16%\n","Current batch: Loss-> 0.7907, Train accuracy->  30.26%\n","Current batch: Loss-> 0.8001, Train accuracy->  30.36%\n","Current batch: Loss-> 0.9442, Train accuracy->  30.45%\n","Current batch: Loss-> 0.6704, Train accuracy->  30.55%\n","Current batch: Loss-> 0.9373, Train accuracy->  30.66%\n","Current batch: Loss-> 0.6454, Train accuracy->  30.76%\n","Current batch: Loss-> 0.6732, Train accuracy->  30.87%\n","Current batch: Loss-> 0.6670, Train accuracy->  30.98%\n","Current batch: Loss-> 0.9183, Train accuracy->  31.07%\n","Current batch: Loss-> 0.7574, Train accuracy->  31.18%\n","Current batch: Loss-> 0.8789, Train accuracy->  31.27%\n","Current batch: Loss-> 0.8149, Train accuracy->  31.38%\n","Current batch: Loss-> 0.9908, Train accuracy->  31.47%\n","Current batch: Loss-> 0.9491, Train accuracy->  31.57%\n","Current batch: Loss-> 0.6971, Train accuracy->  31.69%\n","Current batch: Loss-> 0.7518, Train accuracy->  31.79%\n","Current batch: Loss-> 0.9681, Train accuracy->  31.89%\n","Current batch: Loss-> 0.7179, Train accuracy->  31.99%\n","Current batch: Loss-> 0.8458, Train accuracy->  32.09%\n","Current batch: Loss-> 0.9611, Train accuracy->  32.19%\n","Current batch: Loss-> 0.9204, Train accuracy->  32.29%\n","Current batch: Loss-> 0.6395, Train accuracy->  32.40%\n","Current batch: Loss-> 0.7070, Train accuracy->  32.50%\n","Current batch: Loss-> 0.7903, Train accuracy->  32.59%\n","Current batch: Loss-> 0.6929, Train accuracy->  32.70%\n","Current batch: Loss-> 0.7687, Train accuracy->  32.81%\n","Current batch: Loss-> 0.7957, Train accuracy->  32.91%\n","Current batch: Loss-> 0.9894, Train accuracy->  32.99%\n","Current batch: Loss-> 0.7014, Train accuracy->  33.10%\n","Current batch: Loss-> 0.7401, Train accuracy->  33.20%\n","Current batch: Loss-> 0.7056, Train accuracy->  33.30%\n","Current batch: Loss-> 0.7740, Train accuracy->  33.41%\n","Current batch: Loss-> 0.7619, Train accuracy->  33.51%\n","Current batch: Loss-> 0.8709, Train accuracy->  33.60%\n","Current batch: Loss-> 0.8020, Train accuracy->  33.69%\n","Current batch: Loss-> 0.9694, Train accuracy->  33.79%\n","Current batch: Loss-> 0.7347, Train accuracy->  33.90%\n","Current batch: Loss-> 0.9482, Train accuracy->  34.00%\n","Current batch: Loss-> 0.6848, Train accuracy->  34.11%\n","Current batch: Loss-> 0.9677, Train accuracy->  34.20%\n","Current batch: Loss-> 0.9350, Train accuracy->  34.29%\n","Current batch: Loss-> 0.6452, Train accuracy->  34.40%\n","Current batch: Loss-> 1.0321, Train accuracy->  34.48%\n","Current batch: Loss-> 0.7253, Train accuracy->  34.58%\n","Current batch: Loss-> 1.0867, Train accuracy->  34.67%\n","Current batch: Loss-> 0.9070, Train accuracy->  34.76%\n","Current batch: Loss-> 0.9050, Train accuracy->  34.85%\n","Current batch: Loss-> 0.6829, Train accuracy->  34.96%\n","Current batch: Loss-> 0.9323, Train accuracy->  35.05%\n","Current batch: Loss-> 0.8483, Train accuracy->  35.15%\n","Current batch: Loss-> 1.0028, Train accuracy->  35.23%\n","Current batch: Loss-> 1.1790, Train accuracy->  35.31%\n","Current batch: Loss-> 0.5017, Train accuracy->  35.42%\n","Current batch: Loss-> 0.8154, Train accuracy->  35.52%\n","Current batch: Loss-> 0.7287, Train accuracy->  35.62%\n","Current batch: Loss-> 0.7045, Train accuracy->  35.74%\n","Current batch: Loss-> 0.7918, Train accuracy->  35.84%\n","Current batch: Loss-> 0.7014, Train accuracy->  35.94%\n","Current batch: Loss-> 0.7851, Train accuracy->  36.04%\n","Current batch: Loss-> 1.1925, Train accuracy->  36.12%\n","Current batch: Loss-> 1.2073, Train accuracy->  36.21%\n","Current batch: Loss-> 0.7578, Train accuracy->  36.30%\n","Current batch: Loss-> 0.7114, Train accuracy->  36.41%\n","Current batch: Loss-> 0.7363, Train accuracy->  36.52%\n","Current batch: Loss-> 0.8229, Train accuracy->  36.62%\n","Current batch: Loss-> 0.9330, Train accuracy->  36.71%\n","Current batch: Loss-> 0.9344, Train accuracy->  36.80%\n","Current batch: Loss-> 0.8692, Train accuracy->  36.90%\n","Current batch: Loss-> 0.7147, Train accuracy->  36.99%\n","Current batch: Loss-> 0.5927, Train accuracy->  37.11%\n","Current batch: Loss-> 0.5707, Train accuracy->  37.21%\n","Current batch: Loss-> 0.5186, Train accuracy->  37.32%\n","Current batch: Loss-> 0.7378, Train accuracy->  37.42%\n","Current batch: Loss-> 1.0030, Train accuracy->  37.52%\n","Current batch: Loss-> 0.7278, Train accuracy->  37.62%\n","Current batch: Loss-> 0.9235, Train accuracy->  37.71%\n","Current batch: Loss-> 0.8998, Train accuracy->  37.80%\n","Current batch: Loss-> 0.7877, Train accuracy->  37.91%\n","Current batch: Loss-> 0.9678, Train accuracy->  38.00%\n","Current batch: Loss-> 0.9156, Train accuracy->  38.10%\n","Current batch: Loss-> 0.9474, Train accuracy->  38.19%\n","Current batch: Loss-> 0.6604, Train accuracy->  38.30%\n","Current batch: Loss-> 1.0225, Train accuracy->  38.39%\n","Current batch: Loss-> 0.9869, Train accuracy->  38.49%\n","Current batch: Loss-> 0.7221, Train accuracy->  38.59%\n","Current batch: Loss-> 0.7373, Train accuracy->  38.69%\n","Current batch: Loss-> 0.8151, Train accuracy->  38.80%\n","Current batch: Loss-> 0.8126, Train accuracy->  38.88%\n","Current batch: Loss-> 0.9168, Train accuracy->  38.96%\n","Current batch: Loss-> 0.8288, Train accuracy->  39.06%\n","Current batch: Loss-> 0.7519, Train accuracy->  39.17%\n","Current batch: Loss-> 0.7473, Train accuracy->  39.27%\n","Current batch: Loss-> 0.5571, Train accuracy->  39.38%\n","Current batch: Loss-> 0.7518, Train accuracy->  39.48%\n","Current batch: Loss-> 0.6204, Train accuracy->  39.59%\n","Current batch: Loss-> 0.7881, Train accuracy->  39.69%\n","Current batch: Loss-> 0.7495, Train accuracy->  39.79%\n","Current batch: Loss-> 0.7083, Train accuracy->  39.89%\n","Current batch: Loss-> 0.6400, Train accuracy->  39.99%\n","Current batch: Loss-> 0.7603, Train accuracy->  40.10%\n","Current batch: Loss-> 1.0378, Train accuracy->  40.19%\n","Current batch: Loss-> 0.9381, Train accuracy->  40.28%\n","Current batch: Loss-> 0.6517, Train accuracy->  40.38%\n","Current batch: Loss-> 0.6507, Train accuracy->  40.49%\n","Current batch: Loss-> 0.6709, Train accuracy->  40.59%\n","Current batch: Loss-> 0.5884, Train accuracy->  40.70%\n","Current batch: Loss-> 0.6836, Train accuracy->  40.80%\n","Current batch: Loss-> 0.7915, Train accuracy->  40.90%\n","Current batch: Loss-> 0.7055, Train accuracy->  40.99%\n","Current batch: Loss-> 0.8277, Train accuracy->  41.09%\n","Current batch: Loss-> 0.7617, Train accuracy->  41.19%\n","Current batch: Loss-> 0.7597, Train accuracy->  41.29%\n","Current batch: Loss-> 0.9081, Train accuracy->  41.39%\n","Current batch: Loss-> 0.6907, Train accuracy->  41.51%\n","Current batch: Loss-> 0.4974, Train accuracy->  41.62%\n","Current batch: Loss-> 0.5334, Train accuracy->  41.74%\n","Current batch: Loss-> 1.0559, Train accuracy->  41.83%\n","Current batch: Loss-> 0.5776, Train accuracy->  41.94%\n","Current batch: Loss-> 0.7564, Train accuracy->  42.03%\n","Current batch: Loss-> 0.9500, Train accuracy->  42.13%\n","Current batch: Loss-> 0.6781, Train accuracy->  42.24%\n","Current batch: Loss-> 0.6775, Train accuracy->  42.34%\n","Current batch: Loss-> 0.8155, Train accuracy->  42.45%\n","Current batch: Loss-> 0.6445, Train accuracy->  42.56%\n","Current batch: Loss-> 0.6320, Train accuracy->  42.67%\n","Current batch: Loss-> 0.7377, Train accuracy->  42.77%\n","Current batch: Loss-> 0.7704, Train accuracy->  42.87%\n","Current batch: Loss-> 0.6488, Train accuracy->  42.98%\n","Current batch: Loss-> 0.7697, Train accuracy->  43.08%\n","Current batch: Loss-> 0.7162, Train accuracy->  43.18%\n","Current batch: Loss-> 0.8693, Train accuracy->  43.27%\n","Current batch: Loss-> 0.6893, Train accuracy->  43.37%\n","Current batch: Loss-> 0.8080, Train accuracy->  43.47%\n","Current batch: Loss-> 0.7730, Train accuracy->  43.58%\n","Current batch: Loss-> 0.7935, Train accuracy->  43.68%\n","Current batch: Loss-> 0.9213, Train accuracy->  43.78%\n","Current batch: Loss-> 0.6054, Train accuracy->  43.88%\n","Current batch: Loss-> 0.6413, Train accuracy->  43.99%\n","Current batch: Loss-> 1.0187, Train accuracy->  44.09%\n","Current batch: Loss-> 0.9076, Train accuracy->  44.19%\n","Current batch: Loss-> 1.1365, Train accuracy->  44.29%\n","Current batch: Loss-> 0.5878, Train accuracy->  44.39%\n","Current batch: Loss-> 0.7884, Train accuracy->  44.50%\n","Current batch: Loss-> 0.9862, Train accuracy->  44.59%\n","Current batch: Loss-> 1.1395, Train accuracy->  44.68%\n","Current batch: Loss-> 1.0492, Train accuracy->  44.78%\n","Current batch: Loss-> 0.9023, Train accuracy->  44.88%\n","Current batch: Loss-> 1.0883, Train accuracy->  44.96%\n","Current batch: Loss-> 0.7194, Train accuracy->  45.07%\n","Current batch: Loss-> 0.6532, Train accuracy->  45.17%\n","Current batch: Loss-> 0.7740, Train accuracy->  45.27%\n","Current batch: Loss-> 0.8904, Train accuracy->  45.37%\n","Current batch: Loss-> 0.6739, Train accuracy->  45.46%\n","Current batch: Loss-> 1.1120, Train accuracy->  45.56%\n","Current batch: Loss-> 0.5500, Train accuracy->  45.67%\n","Current batch: Loss-> 0.8261, Train accuracy->  45.77%\n","Current batch: Loss-> 1.1319, Train accuracy->  45.85%\n","Current batch: Loss-> 1.0117, Train accuracy->  45.95%\n","Current batch: Loss-> 1.1710, Train accuracy->  46.04%\n","Current batch: Loss-> 0.6561, Train accuracy->  46.14%\n","Current batch: Loss-> 0.7411, Train accuracy->  46.24%\n","Current batch: Loss-> 1.1143, Train accuracy->  46.33%\n","Current batch: Loss-> 0.7691, Train accuracy->  46.43%\n","Current batch: Loss-> 0.6085, Train accuracy->  46.55%\n","Current batch: Loss-> 0.8522, Train accuracy->  46.65%\n","Current batch: Loss-> 0.6243, Train accuracy->  46.76%\n","Current batch: Loss-> 0.8258, Train accuracy->  46.85%\n","Current batch: Loss-> 0.6482, Train accuracy->  46.95%\n","Current batch: Loss-> 0.6154, Train accuracy->  47.06%\n","Current batch: Loss-> 1.0178, Train accuracy->  47.15%\n","Current batch: Loss-> 0.7087, Train accuracy->  47.25%\n","Current batch: Loss-> 0.9857, Train accuracy->  47.34%\n","Current batch: Loss-> 0.6090, Train accuracy->  47.45%\n","Current batch: Loss-> 0.9521, Train accuracy->  47.54%\n","Current batch: Loss-> 0.6519, Train accuracy->  47.64%\n","Current batch: Loss-> 0.7187, Train accuracy->  47.74%\n","Current batch: Loss-> 1.0752, Train accuracy->  47.83%\n","Current batch: Loss-> 0.6439, Train accuracy->  47.94%\n","Current batch: Loss-> 0.9630, Train accuracy->  48.02%\n","Current batch: Loss-> 0.7246, Train accuracy->  48.13%\n","Current batch: Loss-> 0.7249, Train accuracy->  48.23%\n","Current batch: Loss-> 0.7927, Train accuracy->  48.32%\n","Current batch: Loss-> 0.7574, Train accuracy->  48.42%\n","Current batch: Loss-> 0.6709, Train accuracy->  48.52%\n","Current batch: Loss-> 0.7116, Train accuracy->  48.62%\n","Current batch: Loss-> 0.6753, Train accuracy->  48.73%\n","Current batch: Loss-> 0.6721, Train accuracy->  48.83%\n","Current batch: Loss-> 0.7946, Train accuracy->  48.94%\n","Current batch: Loss-> 0.5420, Train accuracy->  49.04%\n","Current batch: Loss-> 0.9228, Train accuracy->  49.14%\n","Current batch: Loss-> 1.1322, Train accuracy->  49.22%\n","Current batch: Loss-> 0.8659, Train accuracy->  49.33%\n","Current batch: Loss-> 0.5767, Train accuracy->  49.44%\n","Current batch: Loss-> 0.8022, Train accuracy->  49.54%\n","Current batch: Loss-> 0.9472, Train accuracy->  49.64%\n","Current batch: Loss-> 0.9639, Train accuracy->  49.73%\n","Current batch: Loss-> 0.8996, Train accuracy->  49.84%\n","Current batch: Loss-> 0.5533, Train accuracy->  49.95%\n","Current batch: Loss-> 0.8869, Train accuracy->  50.06%\n","Current batch: Loss-> 0.8014, Train accuracy->  50.16%\n","Current batch: Loss-> 0.9538, Train accuracy->  50.26%\n","Current batch: Loss-> 0.9595, Train accuracy->  50.35%\n","Current batch: Loss-> 0.8718, Train accuracy->  50.46%\n","Current batch: Loss-> 0.6397, Train accuracy->  50.56%\n","Current batch: Loss-> 1.0195, Train accuracy->  50.66%\n","Current batch: Loss-> 0.7799, Train accuracy->  50.76%\n","Current batch: Loss-> 0.8339, Train accuracy->  50.86%\n","Current batch: Loss-> 0.7330, Train accuracy->  50.95%\n","Current batch: Loss-> 0.7674, Train accuracy->  51.06%\n","Current batch: Loss-> 0.5593, Train accuracy->  51.16%\n","Current batch: Loss-> 0.6478, Train accuracy->  51.26%\n","Current batch: Loss-> 0.8985, Train accuracy->  51.36%\n","Current batch: Loss-> 0.9350, Train accuracy->  51.45%\n","Current batch: Loss-> 0.7473, Train accuracy->  51.54%\n","Current batch: Loss-> 0.7205, Train accuracy->  51.65%\n","Current batch: Loss-> 1.0125, Train accuracy->  51.74%\n","Current batch: Loss-> 0.8176, Train accuracy->  51.84%\n","Current batch: Loss-> 0.8010, Train accuracy->  51.94%\n","Current batch: Loss-> 0.8342, Train accuracy->  52.04%\n","Current batch: Loss-> 1.1352, Train accuracy->  52.12%\n","Current batch: Loss-> 0.7941, Train accuracy->  52.22%\n","Current batch: Loss-> 0.8467, Train accuracy->  52.32%\n","Current batch: Loss-> 0.6715, Train accuracy->  52.43%\n","Current batch: Loss-> 0.9080, Train accuracy->  52.52%\n","Current batch: Loss-> 1.1045, Train accuracy->  52.61%\n","Current batch: Loss-> 0.7028, Train accuracy->  52.71%\n","Current batch: Loss-> 0.7710, Train accuracy->  52.82%\n","Current batch: Loss-> 0.7483, Train accuracy->  52.91%\n","Current batch: Loss-> 0.8762, Train accuracy->  53.01%\n","Current batch: Loss-> 0.8433, Train accuracy->  53.11%\n","Current batch: Loss-> 1.0744, Train accuracy->  53.20%\n","Current batch: Loss-> 0.7600, Train accuracy->  53.31%\n","Current batch: Loss-> 0.7938, Train accuracy->  53.41%\n","Current batch: Loss-> 0.8828, Train accuracy->  53.51%\n","Current batch: Loss-> 0.9441, Train accuracy->  53.60%\n","Current batch: Loss-> 0.9627, Train accuracy->  53.68%\n","Current batch: Loss-> 0.7268, Train accuracy->  53.79%\n","Current batch: Loss-> 0.8315, Train accuracy->  53.89%\n","Current batch: Loss-> 0.9745, Train accuracy->  53.99%\n","Current batch: Loss-> 0.7067, Train accuracy->  54.10%\n","Current batch: Loss-> 0.7393, Train accuracy->  54.21%\n","Current batch: Loss-> 0.7646, Train accuracy->  54.29%\n","Current batch: Loss-> 0.9138, Train accuracy->  54.39%\n","Current batch: Loss-> 0.7221, Train accuracy->  54.48%\n","Current batch: Loss-> 1.0896, Train accuracy->  54.56%\n","Current batch: Loss-> 0.8628, Train accuracy->  54.65%\n","Current batch: Loss-> 0.7064, Train accuracy->  54.75%\n","Current batch: Loss-> 0.9521, Train accuracy->  54.85%\n","Current batch: Loss-> 0.9914, Train accuracy->  54.93%\n","Current batch: Loss-> 0.8980, Train accuracy->  55.02%\n","Current batch: Loss-> 0.7628, Train accuracy->  55.12%\n","Current batch: Loss-> 0.7386, Train accuracy->  55.23%\n","Current batch: Loss-> 0.6383, Train accuracy->  55.34%\n","Current batch: Loss-> 0.8119, Train accuracy->  55.44%\n","Current batch: Loss-> 0.8571, Train accuracy->  55.54%\n","Current batch: Loss-> 0.5952, Train accuracy->  55.65%\n","Current batch: Loss-> 0.8545, Train accuracy->  55.74%\n","Current batch: Loss-> 0.7341, Train accuracy->  55.85%\n","Current batch: Loss-> 0.9732, Train accuracy->  55.96%\n","Current batch: Loss-> 1.1669, Train accuracy->  56.05%\n","Current batch: Loss-> 0.7293, Train accuracy->  56.15%\n","Current batch: Loss-> 0.8490, Train accuracy->  56.26%\n","Current batch: Loss-> 0.8412, Train accuracy->  56.35%\n","Current batch: Loss-> 0.6828, Train accuracy->  56.46%\n","Current batch: Loss-> 0.7646, Train accuracy->  56.57%\n","Current batch: Loss-> 0.6170, Train accuracy->  56.67%\n","Current batch: Loss-> 0.6447, Train accuracy->  56.76%\n","Current batch: Loss-> 0.7557, Train accuracy->  56.87%\n","Current batch: Loss-> 0.6996, Train accuracy->  56.98%\n","Current batch: Loss-> 0.6722, Train accuracy->  57.08%\n","Current batch: Loss-> 0.7187, Train accuracy->  57.18%\n","Current batch: Loss-> 0.5569, Train accuracy->  57.29%\n","Current batch: Loss-> 0.6842, Train accuracy->  57.40%\n","Current batch: Loss-> 0.9925, Train accuracy->  57.49%\n","Current batch: Loss-> 1.0305, Train accuracy->  57.58%\n","Current batch: Loss-> 0.6583, Train accuracy->  57.69%\n","Current batch: Loss-> 1.1146, Train accuracy->  57.77%\n","Current batch: Loss-> 0.7921, Train accuracy->  57.87%\n","Current batch: Loss-> 0.7291, Train accuracy->  57.98%\n","Current batch: Loss-> 1.0620, Train accuracy->  58.06%\n","Current batch: Loss-> 0.6846, Train accuracy->  58.16%\n","Current batch: Loss-> 1.2585, Train accuracy->  58.24%\n","Current batch: Loss-> 0.4188, Train accuracy->  58.36%\n","Current batch: Loss-> 0.5878, Train accuracy->  58.47%\n","Current batch: Loss-> 0.7144, Train accuracy->  58.57%\n","Current batch: Loss-> 0.7068, Train accuracy->  58.68%\n","Current batch: Loss-> 0.6041, Train accuracy->  58.77%\n","Current batch: Loss-> 1.0865, Train accuracy->  58.86%\n","Current batch: Loss-> 0.7653, Train accuracy->  58.97%\n","Current batch: Loss-> 0.6772, Train accuracy->  59.07%\n","Current batch: Loss-> 0.9309, Train accuracy->  59.16%\n","Current batch: Loss-> 1.0525, Train accuracy->  59.26%\n","Current batch: Loss-> 0.9370, Train accuracy->  59.35%\n","Current batch: Loss-> 1.0948, Train accuracy->  59.45%\n","Current batch: Loss-> 1.0319, Train accuracy->  59.55%\n","Current batch: Loss-> 0.7559, Train accuracy->  59.64%\n","Current batch: Loss-> 0.8459, Train accuracy->  59.74%\n","Current batch: Loss-> 0.7342, Train accuracy->  59.85%\n","Current batch: Loss-> 0.9075, Train accuracy->  59.94%\n","Current batch: Loss-> 0.7878, Train accuracy->  60.04%\n","Current batch: Loss-> 0.9934, Train accuracy->  60.14%\n","Current batch: Loss-> 0.8263, Train accuracy->  60.24%\n","Current batch: Loss-> 0.8551, Train accuracy->  60.34%\n","Current batch: Loss-> 0.8734, Train accuracy->  60.43%\n","Current batch: Loss-> 0.9012, Train accuracy->  60.52%\n","Current batch: Loss-> 0.6731, Train accuracy->  60.62%\n","Current batch: Loss-> 1.0611, Train accuracy->  60.71%\n","Current batch: Loss-> 0.8300, Train accuracy->  60.80%\n","Current batch: Loss-> 0.8681, Train accuracy->  60.90%\n","Current batch: Loss-> 0.6899, Train accuracy->  61.01%\n","Current batch: Loss-> 0.7913, Train accuracy->  61.11%\n","Current batch: Loss-> 0.7530, Train accuracy->  61.21%\n","Current batch: Loss-> 0.7948, Train accuracy->  61.31%\n","Current batch: Loss-> 0.8265, Train accuracy->  61.40%\n","Current batch: Loss-> 0.5855, Train accuracy->  61.51%\n","Current batch: Loss-> 0.7732, Train accuracy->  61.61%\n","Current batch: Loss-> 0.9732, Train accuracy->  61.70%\n","Current batch: Loss-> 0.7048, Train accuracy->  61.81%\n","Current batch: Loss-> 0.7391, Train accuracy->  61.91%\n","Current batch: Loss-> 1.0577, Train accuracy->  62.00%\n","Current batch: Loss-> 0.7276, Train accuracy->  62.10%\n","Current batch: Loss-> 0.9814, Train accuracy->  62.20%\n","Current batch: Loss-> 0.5568, Train accuracy->  62.31%\n","Current batch: Loss-> 0.6118, Train accuracy->  62.41%\n","Current batch: Loss-> 0.9152, Train accuracy->  62.50%\n","Current batch: Loss-> 0.8319, Train accuracy->  62.60%\n","Current batch: Loss-> 0.6528, Train accuracy->  62.70%\n","Current batch: Loss-> 0.9932, Train accuracy->  62.80%\n","Current batch: Loss-> 1.0056, Train accuracy->  62.90%\n","Current batch: Loss-> 1.0510, Train accuracy->  63.00%\n","Current batch: Loss-> 0.7102, Train accuracy->  63.10%\n","Current batch: Loss-> 0.7660, Train accuracy->  63.19%\n","Current batch: Loss-> 0.9466, Train accuracy->  63.28%\n","Current batch: Loss-> 0.8840, Train accuracy->  63.38%\n","Current batch: Loss-> 0.5166, Train accuracy->  63.49%\n","Current batch: Loss-> 0.9054, Train accuracy->  63.59%\n","Current batch: Loss-> 0.5511, Train accuracy->  63.69%\n","Current batch: Loss-> 0.7938, Train accuracy->  63.80%\n","Current batch: Loss-> 0.6725, Train accuracy->  63.90%\n","Current batch: Loss-> 0.5213, Train accuracy->  64.00%\n","Current batch: Loss-> 0.6958, Train accuracy->  64.10%\n","Current batch: Loss-> 0.9371, Train accuracy->  64.19%\n","Current batch: Loss-> 0.8736, Train accuracy->  64.29%\n","Current batch: Loss-> 0.5549, Train accuracy->  64.40%\n","Current batch: Loss-> 0.9598, Train accuracy->  64.50%\n","Current batch: Loss-> 0.7125, Train accuracy->  64.61%\n","Current batch: Loss-> 0.9424, Train accuracy->  64.71%\n","Current batch: Loss-> 0.6346, Train accuracy->  64.82%\n","Current batch: Loss-> 0.9335, Train accuracy->  64.91%\n","Current batch: Loss-> 0.8973, Train accuracy->  65.00%\n","Current batch: Loss-> 1.4464, Train accuracy->  65.06%\n","Current batch: Loss-> 0.5611, Train accuracy->  65.18%\n","Current batch: Loss-> 0.6045, Train accuracy->  65.29%\n","Current batch: Loss-> 0.5494, Train accuracy->  65.41%\n","Current batch: Loss-> 0.8786, Train accuracy->  65.50%\n","Current batch: Loss-> 0.7319, Train accuracy->  65.61%\n","Current batch: Loss-> 1.1199, Train accuracy->  65.70%\n","Current batch: Loss-> 0.9253, Train accuracy->  65.79%\n","Current batch: Loss-> 0.7298, Train accuracy->  65.89%\n","Current batch: Loss-> 1.0757, Train accuracy->  65.99%\n","Current batch: Loss-> 1.1071, Train accuracy->  66.08%\n","Current batch: Loss-> 1.1308, Train accuracy->  66.17%\n","Current batch: Loss-> 0.6231, Train accuracy->  66.28%\n","Current batch: Loss-> 0.8179, Train accuracy->  66.37%\n","Current batch: Loss-> 0.9445, Train accuracy->  66.47%\n","Current batch: Loss-> 1.0445, Train accuracy->  66.56%\n","Current batch: Loss-> 0.6985, Train accuracy->  66.67%\n","Current batch: Loss-> 0.8067, Train accuracy->  66.77%\n","Current batch: Loss-> 0.8267, Train accuracy->  66.87%\n","Current batch: Loss-> 0.9700, Train accuracy->  66.97%\n","Current batch: Loss-> 1.0020, Train accuracy->  67.06%\n","Current batch: Loss-> 0.9434, Train accuracy->  67.15%\n","Current batch: Loss-> 0.8549, Train accuracy->  67.24%\n","Current batch: Loss-> 0.6352, Train accuracy->  67.35%\n","Current batch: Loss-> 0.9204, Train accuracy->  67.45%\n","Current batch: Loss-> 0.6414, Train accuracy->  67.55%\n","Current batch: Loss-> 0.7202, Train accuracy->  67.66%\n","Current batch: Loss-> 1.0755, Train accuracy->  67.74%\n","Current batch: Loss-> 0.4369, Train accuracy->  67.86%\n","Current batch: Loss-> 0.8192, Train accuracy->  67.97%\n","Current batch: Loss-> 0.9024, Train accuracy->  68.07%\n","Current batch: Loss-> 0.6133, Train accuracy->  68.18%\n","Current batch: Loss-> 0.6216, Train accuracy->  68.29%\n","Current batch: Loss-> 0.8083, Train accuracy->  68.38%\n","Current batch: Loss-> 0.9021, Train accuracy->  68.47%\n","Current batch: Loss-> 1.0339, Train accuracy->  68.56%\n","Current batch: Loss-> 0.7785, Train accuracy->  68.67%\n","Current batch: Loss-> 0.7551, Train accuracy->  68.77%\n","Current batch: Loss-> 1.0389, Train accuracy->  68.86%\n","Current batch: Loss-> 0.6140, Train accuracy->  68.98%\n","Current batch: Loss-> 0.7756, Train accuracy->  69.08%\n","Current batch: Loss-> 0.5199, Train accuracy->  69.19%\n","Current batch: Loss-> 0.7235, Train accuracy->  69.29%\n","Current batch: Loss-> 0.6175, Train accuracy->  69.40%\n","Current batch: Loss-> 0.7329, Train accuracy->  69.51%\n","Current batch: Loss-> 1.0928, Train accuracy->  69.61%\n","Current batch: Loss-> 0.7005, Train accuracy->  69.70%\n","Current batch: Loss-> 0.6466, Train accuracy->  69.81%\n","Current batch: Loss-> 0.7228, Train accuracy->  69.92%\n","Current batch: Loss-> 0.9018, Train accuracy->  70.01%\n","Current batch: Loss-> 0.7018, Train accuracy->  70.11%\n","Current batch: Loss-> 0.6055, Train accuracy->  70.21%\n","Current batch: Loss-> 0.5970, Train accuracy->  70.32%\n","Current batch: Loss-> 0.4870, Train accuracy->  70.44%\n","Current batch: Loss-> 0.7196, Train accuracy->  70.55%\n","Current batch: Loss-> 0.6379, Train accuracy->  70.66%\n","Current batch: Loss-> 0.6770, Train accuracy->  70.77%\n","Current batch: Loss-> 0.8683, Train accuracy->  70.87%\n","Current batch: Loss-> 0.7304, Train accuracy->  70.97%\n","Current batch: Loss-> 0.5131, Train accuracy->  71.07%\n","Current batch: Loss-> 0.6454, Train accuracy->  71.18%\n","Current batch: Loss-> 0.6967, Train accuracy->  71.28%\n","Current batch: Loss-> 0.5045, Train accuracy->  71.38%\n","Current batch: Loss-> 0.5337, Train accuracy->  71.49%\n","Current batch: Loss-> 0.6115, Train accuracy->  71.60%\n","Current batch: Loss-> 0.9098, Train accuracy->  71.70%\n","Current batch: Loss-> 0.7631, Train accuracy->  71.80%\n","Current batch: Loss-> 0.7121, Train accuracy->  71.91%\n","Current batch: Loss-> 0.6606, Train accuracy->  72.01%\n","Current batch: Loss-> 0.6880, Train accuracy->  72.11%\n","Current batch: Loss-> 0.6431, Train accuracy->  72.22%\n","Current batch: Loss-> 0.8277, Train accuracy->  72.33%\n","Current batch: Loss-> 0.5205, Train accuracy->  72.45%\n","Current batch: Loss-> 0.9069, Train accuracy->  72.55%\n","Current batch: Loss-> 0.6290, Train accuracy->  72.66%\n","Current batch: Loss-> 0.6301, Train accuracy->  72.77%\n","Current batch: Loss-> 0.8004, Train accuracy->  72.87%\n","Current batch: Loss-> 0.7846, Train accuracy->  72.97%\n","Current batch: Loss-> 0.8047, Train accuracy->  73.08%\n","Current batch: Loss-> 0.6052, Train accuracy->  73.19%\n","Current batch: Loss-> 0.5930, Train accuracy->  73.30%\n","Current batch: Loss-> 1.0643, Train accuracy->  73.39%\n","Current batch: Loss-> 0.7409, Train accuracy->  73.50%\n","Current batch: Loss-> 0.8045, Train accuracy->  73.60%\n","Current batch: Loss-> 0.6740, Train accuracy->  73.71%\n","Current batch: Loss-> 0.5612, Train accuracy->  73.81%\n","Current batch: Loss-> 0.7366, Train accuracy->  73.91%\n","Current batch: Loss-> 0.6410, Train accuracy->  74.02%\n","Current batch: Loss-> 0.6410, Train accuracy->  74.13%\n","Current batch: Loss-> 0.7023, Train accuracy->  74.22%\n","Current batch: Loss-> 0.7344, Train accuracy->  74.32%\n","Current batch: Loss-> 0.7600, Train accuracy->  74.43%\n","Current batch: Loss-> 0.6539, Train accuracy->  74.54%\n","Current batch: Loss-> 1.1164, Train accuracy->  74.63%\n","Current batch: Loss-> 0.8466, Train accuracy->  74.73%\n","Current batch: Loss-> 1.1089, Train accuracy->  74.81%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:04, 40.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.8027, Train accuracy->  74.92%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.49it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.5773, Accuracy: 5533/12000 (46%)\n","\n","Current batch: Loss-> 0.8500, Train accuracy->   0.09%\n","Current batch: Loss-> 0.9630, Train accuracy->   0.17%\n","Current batch: Loss-> 0.7471, Train accuracy->   0.27%\n","Current batch: Loss-> 1.2046, Train accuracy->   0.36%\n","Current batch: Loss-> 0.7084, Train accuracy->   0.45%\n","Current batch: Loss-> 0.9077, Train accuracy->   0.55%\n","Current batch: Loss-> 0.6318, Train accuracy->   0.66%\n","Current batch: Loss-> 0.6380, Train accuracy->   0.77%\n","Current batch: Loss-> 0.7431, Train accuracy->   0.88%\n","Current batch: Loss-> 0.7269, Train accuracy->   0.98%\n","Current batch: Loss-> 0.5798, Train accuracy->   1.09%\n","Current batch: Loss-> 0.5887, Train accuracy->   1.21%\n","Current batch: Loss-> 0.7905, Train accuracy->   1.31%\n","Current batch: Loss-> 0.8697, Train accuracy->   1.41%\n","Current batch: Loss-> 0.4269, Train accuracy->   1.54%\n","Current batch: Loss-> 0.9704, Train accuracy->   1.64%\n","Current batch: Loss-> 0.5318, Train accuracy->   1.74%\n","Current batch: Loss-> 0.6928, Train accuracy->   1.86%\n","Current batch: Loss-> 0.7456, Train accuracy->   1.96%\n","Current batch: Loss-> 0.6207, Train accuracy->   2.07%\n","Current batch: Loss-> 0.8983, Train accuracy->   2.17%\n","Current batch: Loss-> 0.5820, Train accuracy->   2.28%\n","Current batch: Loss-> 0.8014, Train accuracy->   2.38%\n","Current batch: Loss-> 0.7101, Train accuracy->   2.49%\n","Current batch: Loss-> 0.5835, Train accuracy->   2.59%\n","Current batch: Loss-> 0.7356, Train accuracy->   2.69%\n","Current batch: Loss-> 0.8836, Train accuracy->   2.79%\n","Current batch: Loss-> 0.8240, Train accuracy->   2.88%\n","Current batch: Loss-> 0.7168, Train accuracy->   2.97%\n","Current batch: Loss-> 0.6831, Train accuracy->   3.08%\n","Current batch: Loss-> 0.8055, Train accuracy->   3.18%\n","Current batch: Loss-> 0.3843, Train accuracy->   3.30%\n","Current batch: Loss-> 0.6065, Train accuracy->   3.41%\n","Current batch: Loss-> 0.5669, Train accuracy->   3.51%\n","Current batch: Loss-> 0.9074, Train accuracy->   3.60%\n","Current batch: Loss-> 0.7548, Train accuracy->   3.70%\n","Current batch: Loss-> 0.8730, Train accuracy->   3.80%\n","Current batch: Loss-> 0.8227, Train accuracy->   3.91%\n","Current batch: Loss-> 0.7120, Train accuracy->   4.01%\n","Current batch: Loss-> 0.6196, Train accuracy->   4.12%\n","Current batch: Loss-> 0.8199, Train accuracy->   4.22%\n","Current batch: Loss-> 0.5582, Train accuracy->   4.34%\n","Current batch: Loss-> 0.8991, Train accuracy->   4.44%\n","Current batch: Loss-> 0.6265, Train accuracy->   4.54%\n","Current batch: Loss-> 1.1323, Train accuracy->   4.63%\n","Current batch: Loss-> 0.7579, Train accuracy->   4.74%\n","Current batch: Loss-> 0.5821, Train accuracy->   4.85%\n","Current batch: Loss-> 0.7936, Train accuracy->   4.95%\n","Current batch: Loss-> 0.9512, Train accuracy->   5.05%\n","Current batch: Loss-> 0.7910, Train accuracy->   5.15%\n","Current batch: Loss-> 0.6826, Train accuracy->   5.26%\n","Current batch: Loss-> 0.8887, Train accuracy->   5.36%\n","Current batch: Loss-> 0.6458, Train accuracy->   5.47%\n","Current batch: Loss-> 0.7374, Train accuracy->   5.57%\n","Current batch: Loss-> 0.6209, Train accuracy->   5.68%\n","Current batch: Loss-> 0.6599, Train accuracy->   5.78%\n","Current batch: Loss-> 0.8001, Train accuracy->   5.88%\n","Current batch: Loss-> 0.7892, Train accuracy->   5.99%\n","Current batch: Loss-> 0.7811, Train accuracy->   6.09%\n","Current batch: Loss-> 0.5532, Train accuracy->   6.20%\n","Current batch: Loss-> 0.6924, Train accuracy->   6.30%\n","Current batch: Loss-> 0.5832, Train accuracy->   6.41%\n","Current batch: Loss-> 0.4963, Train accuracy->   6.53%\n","Current batch: Loss-> 0.7528, Train accuracy->   6.63%\n","Current batch: Loss-> 0.5182, Train accuracy->   6.74%\n","Current batch: Loss-> 0.9320, Train accuracy->   6.83%\n","Current batch: Loss-> 0.8780, Train accuracy->   6.92%\n","Current batch: Loss-> 0.8686, Train accuracy->   7.01%\n","Current batch: Loss-> 0.7632, Train accuracy->   7.11%\n","Current batch: Loss-> 0.6751, Train accuracy->   7.22%\n","Current batch: Loss-> 0.7095, Train accuracy->   7.33%\n","Current batch: Loss-> 0.6625, Train accuracy->   7.43%\n","Current batch: Loss-> 0.6111, Train accuracy->   7.55%\n","Current batch: Loss-> 0.8782, Train accuracy->   7.65%\n","Current batch: Loss-> 0.7851, Train accuracy->   7.75%\n","Current batch: Loss-> 0.4869, Train accuracy->   7.86%\n","Current batch: Loss-> 0.5644, Train accuracy->   7.97%\n","Current batch: Loss-> 0.8389, Train accuracy->   8.07%\n","Current batch: Loss-> 0.5385, Train accuracy->   8.18%\n","Current batch: Loss-> 0.5828, Train accuracy->   8.29%\n","Current batch: Loss-> 0.5512, Train accuracy->   8.40%\n","Current batch: Loss-> 0.7130, Train accuracy->   8.51%\n","Current batch: Loss-> 0.8673, Train accuracy->   8.61%\n","Current batch: Loss-> 0.7300, Train accuracy->   8.71%\n","Current batch: Loss-> 0.9132, Train accuracy->   8.80%\n","Current batch: Loss-> 0.8379, Train accuracy->   8.89%\n","Current batch: Loss-> 0.5963, Train accuracy->   9.01%\n","Current batch: Loss-> 0.5828, Train accuracy->   9.12%\n","Current batch: Loss-> 0.6166, Train accuracy->   9.23%\n","Current batch: Loss-> 0.9748, Train accuracy->   9.32%\n","Current batch: Loss-> 0.8928, Train accuracy->   9.42%\n","Current batch: Loss-> 1.1043, Train accuracy->   9.50%\n","Current batch: Loss-> 0.7920, Train accuracy->   9.59%\n","Current batch: Loss-> 0.8280, Train accuracy->   9.69%\n","Current batch: Loss-> 0.7904, Train accuracy->   9.80%\n","Current batch: Loss-> 0.8826, Train accuracy->   9.89%\n","Current batch: Loss-> 0.8562, Train accuracy->   9.98%\n","Current batch: Loss-> 0.8220, Train accuracy->  10.08%\n","Current batch: Loss-> 1.1659, Train accuracy->  10.16%\n","Current batch: Loss-> 0.8829, Train accuracy->  10.26%\n","Current batch: Loss-> 0.6886, Train accuracy->  10.36%\n","Current batch: Loss-> 0.8354, Train accuracy->  10.46%\n","Current batch: Loss-> 0.9095, Train accuracy->  10.55%\n","Current batch: Loss-> 0.7673, Train accuracy->  10.65%\n","Current batch: Loss-> 0.8177, Train accuracy->  10.75%\n","Current batch: Loss-> 0.5667, Train accuracy->  10.86%\n","Current batch: Loss-> 1.1193, Train accuracy->  10.94%\n","Current batch: Loss-> 0.6015, Train accuracy->  11.05%\n","Current batch: Loss-> 0.6823, Train accuracy->  11.15%\n","Current batch: Loss-> 0.9178, Train accuracy->  11.25%\n","Current batch: Loss-> 0.9015, Train accuracy->  11.35%\n","Current batch: Loss-> 0.8885, Train accuracy->  11.45%\n","Current batch: Loss-> 0.7487, Train accuracy->  11.56%\n","Current batch: Loss-> 1.0821, Train accuracy->  11.64%\n","Current batch: Loss-> 0.7084, Train accuracy->  11.74%\n","Current batch: Loss-> 0.7613, Train accuracy->  11.85%\n","Current batch: Loss-> 0.7840, Train accuracy->  11.94%\n","Current batch: Loss-> 1.0774, Train accuracy->  12.04%\n","Current batch: Loss-> 0.7555, Train accuracy->  12.14%\n","Current batch: Loss-> 0.9624, Train accuracy->  12.22%\n","Current batch: Loss-> 0.6205, Train accuracy->  12.32%\n","Current batch: Loss-> 0.6146, Train accuracy->  12.43%\n","Current batch: Loss-> 0.6710, Train accuracy->  12.52%\n","Current batch: Loss-> 1.1273, Train accuracy->  12.60%\n","Current batch: Loss-> 0.7400, Train accuracy->  12.71%\n","Current batch: Loss-> 0.8094, Train accuracy->  12.81%\n","Current batch: Loss-> 0.9465, Train accuracy->  12.91%\n","Current batch: Loss-> 0.6062, Train accuracy->  13.01%\n","Current batch: Loss-> 0.8266, Train accuracy->  13.11%\n","Current batch: Loss-> 0.5477, Train accuracy->  13.22%\n","Current batch: Loss-> 0.7913, Train accuracy->  13.32%\n","Current batch: Loss-> 0.7180, Train accuracy->  13.43%\n","Current batch: Loss-> 0.7701, Train accuracy->  13.53%\n","Current batch: Loss-> 1.1264, Train accuracy->  13.62%\n","Current batch: Loss-> 0.6573, Train accuracy->  13.74%\n","Current batch: Loss-> 1.0007, Train accuracy->  13.84%\n","Current batch: Loss-> 0.9186, Train accuracy->  13.94%\n","Current batch: Loss-> 0.6731, Train accuracy->  14.05%\n","Current batch: Loss-> 0.7284, Train accuracy->  14.15%\n","Current batch: Loss-> 0.6198, Train accuracy->  14.27%\n","Current batch: Loss-> 0.7844, Train accuracy->  14.36%\n","Current batch: Loss-> 0.7104, Train accuracy->  14.47%\n","Current batch: Loss-> 0.9405, Train accuracy->  14.57%\n","Current batch: Loss-> 0.3945, Train accuracy->  14.69%\n","Current batch: Loss-> 1.0086, Train accuracy->  14.79%\n","Current batch: Loss-> 0.9561, Train accuracy->  14.88%\n","Current batch: Loss-> 0.6302, Train accuracy->  14.99%\n","Current batch: Loss-> 1.0405, Train accuracy->  15.09%\n","Current batch: Loss-> 0.7655, Train accuracy->  15.19%\n","Current batch: Loss-> 0.7449, Train accuracy->  15.30%\n","Current batch: Loss-> 0.7452, Train accuracy->  15.40%\n","Current batch: Loss-> 0.6540, Train accuracy->  15.50%\n","Current batch: Loss-> 0.8221, Train accuracy->  15.60%\n","Current batch: Loss-> 0.7771, Train accuracy->  15.70%\n","Current batch: Loss-> 0.7826, Train accuracy->  15.80%\n","Current batch: Loss-> 0.4744, Train accuracy->  15.91%\n","Current batch: Loss-> 0.6839, Train accuracy->  16.02%\n","Current batch: Loss-> 0.5166, Train accuracy->  16.13%\n","Current batch: Loss-> 0.7937, Train accuracy->  16.24%\n","Current batch: Loss-> 0.7254, Train accuracy->  16.35%\n","Current batch: Loss-> 0.5168, Train accuracy->  16.46%\n","Current batch: Loss-> 0.6611, Train accuracy->  16.56%\n","Current batch: Loss-> 0.6347, Train accuracy->  16.66%\n","Current batch: Loss-> 0.6891, Train accuracy->  16.77%\n","Current batch: Loss-> 0.9412, Train accuracy->  16.87%\n","Current batch: Loss-> 0.8006, Train accuracy->  16.96%\n","Current batch: Loss-> 0.6255, Train accuracy->  17.08%\n","Current batch: Loss-> 0.6398, Train accuracy->  17.19%\n","Current batch: Loss-> 0.7213, Train accuracy->  17.30%\n","Current batch: Loss-> 0.4810, Train accuracy->  17.41%\n","Current batch: Loss-> 0.6349, Train accuracy->  17.52%\n","Current batch: Loss-> 0.7076, Train accuracy->  17.62%\n","Current batch: Loss-> 0.4491, Train accuracy->  17.73%\n","Current batch: Loss-> 0.7645, Train accuracy->  17.84%\n","Current batch: Loss-> 1.0308, Train accuracy->  17.93%\n","Current batch: Loss-> 0.8102, Train accuracy->  18.04%\n","Current batch: Loss-> 0.7263, Train accuracy->  18.14%\n","Current batch: Loss-> 1.0311, Train accuracy->  18.22%\n","Current batch: Loss-> 0.5459, Train accuracy->  18.34%\n","Current batch: Loss-> 1.0849, Train accuracy->  18.43%\n","Current batch: Loss-> 0.6756, Train accuracy->  18.54%\n","Current batch: Loss-> 1.0069, Train accuracy->  18.62%\n","Current batch: Loss-> 0.7857, Train accuracy->  18.73%\n","Current batch: Loss-> 0.8906, Train accuracy->  18.82%\n","Current batch: Loss-> 0.7225, Train accuracy->  18.93%\n","Current batch: Loss-> 0.9249, Train accuracy->  19.02%\n","Current batch: Loss-> 0.7737, Train accuracy->  19.12%\n","Current batch: Loss-> 0.6744, Train accuracy->  19.23%\n","Current batch: Loss-> 0.7048, Train accuracy->  19.33%\n","Current batch: Loss-> 0.9924, Train accuracy->  19.41%\n","Current batch: Loss-> 0.5303, Train accuracy->  19.52%\n","Current batch: Loss-> 0.6660, Train accuracy->  19.63%\n","Current batch: Loss-> 0.7326, Train accuracy->  19.73%\n","Current batch: Loss-> 0.8769, Train accuracy->  19.82%\n","Current batch: Loss-> 0.9934, Train accuracy->  19.91%\n","Current batch: Loss-> 0.7195, Train accuracy->  20.02%\n","Current batch: Loss-> 0.7721, Train accuracy->  20.12%\n","Current batch: Loss-> 0.8522, Train accuracy->  20.22%\n","Current batch: Loss-> 0.8728, Train accuracy->  20.32%\n","Current batch: Loss-> 0.8377, Train accuracy->  20.42%\n","Current batch: Loss-> 0.8485, Train accuracy->  20.50%\n","Current batch: Loss-> 0.6923, Train accuracy->  20.60%\n","Current batch: Loss-> 0.8792, Train accuracy->  20.70%\n","Current batch: Loss-> 0.7502, Train accuracy->  20.79%\n","Current batch: Loss-> 0.7594, Train accuracy->  20.89%\n","Current batch: Loss-> 0.7988, Train accuracy->  20.99%\n","Current batch: Loss-> 0.5343, Train accuracy->  21.09%\n","Current batch: Loss-> 0.7511, Train accuracy->  21.19%\n","Current batch: Loss-> 0.7872, Train accuracy->  21.29%\n","Current batch: Loss-> 1.0973, Train accuracy->  21.38%\n","Current batch: Loss-> 0.7459, Train accuracy->  21.48%\n","Current batch: Loss-> 0.6336, Train accuracy->  21.58%\n","Current batch: Loss-> 0.7192, Train accuracy->  21.69%\n","Current batch: Loss-> 1.1189, Train accuracy->  21.78%\n","Current batch: Loss-> 0.5969, Train accuracy->  21.89%\n","Current batch: Loss-> 0.6854, Train accuracy->  21.99%\n","Current batch: Loss-> 0.8887, Train accuracy->  22.10%\n","Current batch: Loss-> 0.4860, Train accuracy->  22.22%\n","Current batch: Loss-> 0.7062, Train accuracy->  22.32%\n","Current batch: Loss-> 0.8151, Train accuracy->  22.42%\n","Current batch: Loss-> 0.7616, Train accuracy->  22.53%\n","Current batch: Loss-> 0.6667, Train accuracy->  22.63%\n","Current batch: Loss-> 0.6601, Train accuracy->  22.73%\n","Current batch: Loss-> 0.9957, Train accuracy->  22.83%\n","Current batch: Loss-> 0.5219, Train accuracy->  22.94%\n","Current batch: Loss-> 0.8241, Train accuracy->  23.04%\n","Current batch: Loss-> 0.9183, Train accuracy->  23.14%\n","Current batch: Loss-> 0.5560, Train accuracy->  23.24%\n","Current batch: Loss-> 0.5984, Train accuracy->  23.36%\n","Current batch: Loss-> 0.7152, Train accuracy->  23.46%\n","Current batch: Loss-> 1.0299, Train accuracy->  23.55%\n","Current batch: Loss-> 0.7057, Train accuracy->  23.65%\n","Current batch: Loss-> 0.9550, Train accuracy->  23.71%\n","Current batch: Loss-> 1.0282, Train accuracy->  23.79%\n","Current batch: Loss-> 0.7325, Train accuracy->  23.89%\n","Current batch: Loss-> 0.8959, Train accuracy->  23.98%\n","Current batch: Loss-> 0.8931, Train accuracy->  24.08%\n","Current batch: Loss-> 0.7139, Train accuracy->  24.19%\n","Current batch: Loss-> 0.8106, Train accuracy->  24.28%\n","Current batch: Loss-> 0.8323, Train accuracy->  24.38%\n","Current batch: Loss-> 0.8386, Train accuracy->  24.47%\n","Current batch: Loss-> 0.7131, Train accuracy->  24.57%\n","Current batch: Loss-> 0.6718, Train accuracy->  24.67%\n","Current batch: Loss-> 0.4550, Train accuracy->  24.79%\n","Current batch: Loss-> 0.9915, Train accuracy->  24.88%\n","Current batch: Loss-> 0.5661, Train accuracy->  24.99%\n","Current batch: Loss-> 0.6262, Train accuracy->  25.10%\n","Current batch: Loss-> 0.5320, Train accuracy->  25.21%\n","Current batch: Loss-> 0.6188, Train accuracy->  25.32%\n","Current batch: Loss-> 0.6276, Train accuracy->  25.43%\n","Current batch: Loss-> 0.5394, Train accuracy->  25.54%\n","Current batch: Loss-> 0.9020, Train accuracy->  25.64%\n","Current batch: Loss-> 0.9787, Train accuracy->  25.74%\n","Current batch: Loss-> 0.6331, Train accuracy->  25.84%\n","Current batch: Loss-> 0.6155, Train accuracy->  25.95%\n","Current batch: Loss-> 0.6401, Train accuracy->  26.05%\n","Current batch: Loss-> 0.5691, Train accuracy->  26.16%\n","Current batch: Loss-> 0.6458, Train accuracy->  26.27%\n","Current batch: Loss-> 0.6589, Train accuracy->  26.38%\n","Current batch: Loss-> 0.5923, Train accuracy->  26.49%\n","Current batch: Loss-> 0.6033, Train accuracy->  26.60%\n","Current batch: Loss-> 0.7423, Train accuracy->  26.71%\n","Current batch: Loss-> 0.7507, Train accuracy->  26.81%\n","Current batch: Loss-> 0.8445, Train accuracy->  26.92%\n","Current batch: Loss-> 0.7996, Train accuracy->  27.02%\n","Current batch: Loss-> 0.8472, Train accuracy->  27.11%\n","Current batch: Loss-> 0.6862, Train accuracy->  27.22%\n","Current batch: Loss-> 0.5912, Train accuracy->  27.33%\n","Current batch: Loss-> 0.9728, Train accuracy->  27.43%\n","Current batch: Loss-> 1.2195, Train accuracy->  27.50%\n","Current batch: Loss-> 0.9973, Train accuracy->  27.59%\n","Current batch: Loss-> 0.7640, Train accuracy->  27.69%\n","Current batch: Loss-> 0.6403, Train accuracy->  27.79%\n","Current batch: Loss-> 0.7533, Train accuracy->  27.90%\n","Current batch: Loss-> 0.6671, Train accuracy->  28.00%\n","Current batch: Loss-> 0.6919, Train accuracy->  28.10%\n","Current batch: Loss-> 1.0292, Train accuracy->  28.19%\n","Current batch: Loss-> 0.5588, Train accuracy->  28.30%\n","Current batch: Loss-> 0.6016, Train accuracy->  28.40%\n","Current batch: Loss-> 0.6557, Train accuracy->  28.51%\n","Current batch: Loss-> 0.8383, Train accuracy->  28.61%\n","Current batch: Loss-> 0.6975, Train accuracy->  28.71%\n","Current batch: Loss-> 0.7028, Train accuracy->  28.82%\n","Current batch: Loss-> 0.6558, Train accuracy->  28.93%\n","Current batch: Loss-> 0.6881, Train accuracy->  29.03%\n","Current batch: Loss-> 0.7088, Train accuracy->  29.13%\n","Current batch: Loss-> 0.6783, Train accuracy->  29.24%\n","Current batch: Loss-> 0.9275, Train accuracy->  29.33%\n","Current batch: Loss-> 0.8681, Train accuracy->  29.43%\n","Current batch: Loss-> 0.9303, Train accuracy->  29.53%\n","Current batch: Loss-> 0.6354, Train accuracy->  29.63%\n","Current batch: Loss-> 0.6268, Train accuracy->  29.74%\n","Current batch: Loss-> 0.7617, Train accuracy->  29.85%\n","Current batch: Loss-> 0.8426, Train accuracy->  29.95%\n","Current batch: Loss-> 0.6294, Train accuracy->  30.05%\n","Current batch: Loss-> 1.0350, Train accuracy->  30.14%\n","Current batch: Loss-> 0.6881, Train accuracy->  30.25%\n","Current batch: Loss-> 0.7156, Train accuracy->  30.35%\n","Current batch: Loss-> 0.6631, Train accuracy->  30.46%\n","Current batch: Loss-> 0.5920, Train accuracy->  30.57%\n","Current batch: Loss-> 0.4813, Train accuracy->  30.68%\n","Current batch: Loss-> 0.6890, Train accuracy->  30.78%\n","Current batch: Loss-> 0.6478, Train accuracy->  30.89%\n","Current batch: Loss-> 0.7767, Train accuracy->  30.98%\n","Current batch: Loss-> 0.6097, Train accuracy->  31.09%\n","Current batch: Loss-> 0.8477, Train accuracy->  31.19%\n","Current batch: Loss-> 0.7321, Train accuracy->  31.30%\n","Current batch: Loss-> 1.1755, Train accuracy->  31.38%\n","Current batch: Loss-> 0.6042, Train accuracy->  31.49%\n","Current batch: Loss-> 0.5875, Train accuracy->  31.60%\n","Current batch: Loss-> 0.6929, Train accuracy->  31.71%\n","Current batch: Loss-> 1.1217, Train accuracy->  31.80%\n","Current batch: Loss-> 0.7768, Train accuracy->  31.89%\n","Current batch: Loss-> 0.9736, Train accuracy->  31.99%\n","Current batch: Loss-> 0.5794, Train accuracy->  32.09%\n","Current batch: Loss-> 0.4916, Train accuracy->  32.20%\n","Current batch: Loss-> 0.7463, Train accuracy->  32.31%\n","Current batch: Loss-> 1.2105, Train accuracy->  32.39%\n","Current batch: Loss-> 0.7178, Train accuracy->  32.50%\n","Current batch: Loss-> 0.5507, Train accuracy->  32.61%\n","Current batch: Loss-> 0.9991, Train accuracy->  32.71%\n","Current batch: Loss-> 0.4257, Train accuracy->  32.82%\n","Current batch: Loss-> 0.6556, Train accuracy->  32.93%\n","Current batch: Loss-> 0.5319, Train accuracy->  33.04%\n","Current batch: Loss-> 0.6597, Train accuracy->  33.15%\n","Current batch: Loss-> 0.8316, Train accuracy->  33.25%\n","Current batch: Loss-> 0.6889, Train accuracy->  33.36%\n","Current batch: Loss-> 1.0765, Train accuracy->  33.45%\n","Current batch: Loss-> 0.9265, Train accuracy->  33.55%\n","Current batch: Loss-> 0.7791, Train accuracy->  33.65%\n","Current batch: Loss-> 0.8499, Train accuracy->  33.74%\n","Current batch: Loss-> 0.6505, Train accuracy->  33.85%\n","Current batch: Loss-> 0.6842, Train accuracy->  33.96%\n","Current batch: Loss-> 0.7212, Train accuracy->  34.07%\n","Current batch: Loss-> 0.5186, Train accuracy->  34.19%\n","Current batch: Loss-> 0.8813, Train accuracy->  34.29%\n","Current batch: Loss-> 0.8398, Train accuracy->  34.38%\n","Current batch: Loss-> 0.6013, Train accuracy->  34.49%\n","Current batch: Loss-> 0.7290, Train accuracy->  34.59%\n","Current batch: Loss-> 0.6423, Train accuracy->  34.69%\n","Current batch: Loss-> 0.7792, Train accuracy->  34.80%\n","Current batch: Loss-> 0.8062, Train accuracy->  34.90%\n","Current batch: Loss-> 0.5503, Train accuracy->  35.02%\n","Current batch: Loss-> 0.7524, Train accuracy->  35.11%\n","Current batch: Loss-> 0.5905, Train accuracy->  35.22%\n","Current batch: Loss-> 0.5865, Train accuracy->  35.34%\n","Current batch: Loss-> 0.8371, Train accuracy->  35.44%\n","Current batch: Loss-> 0.8646, Train accuracy->  35.54%\n","Current batch: Loss-> 0.4960, Train accuracy->  35.65%\n","Current batch: Loss-> 0.7858, Train accuracy->  35.75%\n","Current batch: Loss-> 0.9450, Train accuracy->  35.84%\n","Current batch: Loss-> 0.6319, Train accuracy->  35.95%\n","Current batch: Loss-> 1.0373, Train accuracy->  36.04%\n","Current batch: Loss-> 0.8808, Train accuracy->  36.14%\n","Current batch: Loss-> 0.8914, Train accuracy->  36.24%\n","Current batch: Loss-> 0.7815, Train accuracy->  36.34%\n","Current batch: Loss-> 0.7279, Train accuracy->  36.45%\n","Current batch: Loss-> 0.7248, Train accuracy->  36.55%\n","Current batch: Loss-> 0.6994, Train accuracy->  36.65%\n","Current batch: Loss-> 0.8115, Train accuracy->  36.76%\n","Current batch: Loss-> 0.6749, Train accuracy->  36.86%\n","Current batch: Loss-> 0.9765, Train accuracy->  36.96%\n","Current batch: Loss-> 0.8715, Train accuracy->  37.05%\n","Current batch: Loss-> 0.6764, Train accuracy->  37.16%\n","Current batch: Loss-> 0.9561, Train accuracy->  37.24%\n","Current batch: Loss-> 0.7534, Train accuracy->  37.35%\n","Current batch: Loss-> 0.6200, Train accuracy->  37.45%\n","Current batch: Loss-> 0.8741, Train accuracy->  37.55%\n","Current batch: Loss-> 0.9370, Train accuracy->  37.64%\n","Current batch: Loss-> 1.0592, Train accuracy->  37.73%\n","Current batch: Loss-> 1.1933, Train accuracy->  37.82%\n","Current batch: Loss-> 1.0071, Train accuracy->  37.91%\n","Current batch: Loss-> 0.7059, Train accuracy->  38.02%\n","Current batch: Loss-> 0.5057, Train accuracy->  38.12%\n","Current batch: Loss-> 0.6369, Train accuracy->  38.23%\n","Current batch: Loss-> 1.0048, Train accuracy->  38.32%\n","Current batch: Loss-> 0.8398, Train accuracy->  38.42%\n","Current batch: Loss-> 0.9863, Train accuracy->  38.51%\n","Current batch: Loss-> 1.2982, Train accuracy->  38.59%\n","Current batch: Loss-> 0.6666, Train accuracy->  38.70%\n","Current batch: Loss-> 1.0000, Train accuracy->  38.80%\n","Current batch: Loss-> 0.8758, Train accuracy->  38.89%\n","Current batch: Loss-> 1.3441, Train accuracy->  38.97%\n","Current batch: Loss-> 1.0761, Train accuracy->  39.06%\n","Current batch: Loss-> 0.7890, Train accuracy->  39.15%\n","Current batch: Loss-> 0.8062, Train accuracy->  39.26%\n","Current batch: Loss-> 0.9212, Train accuracy->  39.35%\n","Current batch: Loss-> 0.6390, Train accuracy->  39.46%\n","Current batch: Loss-> 0.8357, Train accuracy->  39.56%\n","Current batch: Loss-> 0.8108, Train accuracy->  39.65%\n","Current batch: Loss-> 0.5555, Train accuracy->  39.76%\n","Current batch: Loss-> 0.6396, Train accuracy->  39.86%\n","Current batch: Loss-> 0.9092, Train accuracy->  39.96%\n","Current batch: Loss-> 0.8220, Train accuracy->  40.06%\n","Current batch: Loss-> 0.7975, Train accuracy->  40.17%\n","Current batch: Loss-> 0.8259, Train accuracy->  40.26%\n","Current batch: Loss-> 0.6909, Train accuracy->  40.36%\n","Current batch: Loss-> 1.0671, Train accuracy->  40.46%\n","Current batch: Loss-> 0.8055, Train accuracy->  40.55%\n","Current batch: Loss-> 0.6220, Train accuracy->  40.66%\n","Current batch: Loss-> 0.6788, Train accuracy->  40.76%\n","Current batch: Loss-> 0.5970, Train accuracy->  40.88%\n","Current batch: Loss-> 0.6415, Train accuracy->  40.97%\n","Current batch: Loss-> 1.0291, Train accuracy->  41.06%\n","Current batch: Loss-> 0.8559, Train accuracy->  41.16%\n","Current batch: Loss-> 0.8771, Train accuracy->  41.26%\n","Current batch: Loss-> 0.7661, Train accuracy->  41.36%\n","Current batch: Loss-> 0.9921, Train accuracy->  41.45%\n","Current batch: Loss-> 0.9054, Train accuracy->  41.55%\n","Current batch: Loss-> 0.5688, Train accuracy->  41.66%\n","Current batch: Loss-> 0.7895, Train accuracy->  41.77%\n","Current batch: Loss-> 0.6077, Train accuracy->  41.86%\n","Current batch: Loss-> 0.7225, Train accuracy->  41.97%\n","Current batch: Loss-> 0.7693, Train accuracy->  42.06%\n","Current batch: Loss-> 0.7488, Train accuracy->  42.17%\n","Current batch: Loss-> 0.8465, Train accuracy->  42.26%\n","Current batch: Loss-> 0.8470, Train accuracy->  42.37%\n","Current batch: Loss-> 0.4974, Train accuracy->  42.48%\n","Current batch: Loss-> 0.9463, Train accuracy->  42.57%\n","Current batch: Loss-> 0.8102, Train accuracy->  42.66%\n","Current batch: Loss-> 0.6711, Train accuracy->  42.75%\n","Current batch: Loss-> 0.9072, Train accuracy->  42.86%\n","Current batch: Loss-> 0.4746, Train accuracy->  42.97%\n","Current batch: Loss-> 0.7984, Train accuracy->  43.07%\n","Current batch: Loss-> 0.5371, Train accuracy->  43.19%\n","Current batch: Loss-> 0.9443, Train accuracy->  43.29%\n","Current batch: Loss-> 0.7278, Train accuracy->  43.40%\n","Current batch: Loss-> 1.0148, Train accuracy->  43.49%\n","Current batch: Loss-> 0.6796, Train accuracy->  43.59%\n","Current batch: Loss-> 0.6318, Train accuracy->  43.70%\n","Current batch: Loss-> 0.8254, Train accuracy->  43.80%\n","Current batch: Loss-> 0.9298, Train accuracy->  43.89%\n","Current batch: Loss-> 0.7053, Train accuracy->  43.99%\n","Current batch: Loss-> 0.8098, Train accuracy->  44.09%\n","Current batch: Loss-> 0.9776, Train accuracy->  44.18%\n","Current batch: Loss-> 0.4807, Train accuracy->  44.30%\n","Current batch: Loss-> 0.7156, Train accuracy->  44.40%\n","Current batch: Loss-> 0.8133, Train accuracy->  44.51%\n","Current batch: Loss-> 0.8281, Train accuracy->  44.62%\n","Current batch: Loss-> 0.6048, Train accuracy->  44.72%\n","Current batch: Loss-> 1.0420, Train accuracy->  44.82%\n","Current batch: Loss-> 0.7825, Train accuracy->  44.92%\n","Current batch: Loss-> 0.5139, Train accuracy->  45.03%\n","Current batch: Loss-> 0.6514, Train accuracy->  45.13%\n","Current batch: Loss-> 1.0879, Train accuracy->  45.22%\n","Current batch: Loss-> 0.8648, Train accuracy->  45.32%\n","Current batch: Loss-> 0.6990, Train accuracy->  45.42%\n","Current batch: Loss-> 0.6839, Train accuracy->  45.51%\n","Current batch: Loss-> 0.7961, Train accuracy->  45.62%\n","Current batch: Loss-> 0.6829, Train accuracy->  45.72%\n","Current batch: Loss-> 0.4769, Train accuracy->  45.84%\n","Current batch: Loss-> 0.8224, Train accuracy->  45.94%\n","Current batch: Loss-> 0.7563, Train accuracy->  46.04%\n","Current batch: Loss-> 0.6737, Train accuracy->  46.14%\n","Current batch: Loss-> 0.5144, Train accuracy->  46.25%\n","Current batch: Loss-> 0.8415, Train accuracy->  46.35%\n","Current batch: Loss-> 0.7684, Train accuracy->  46.45%\n","Current batch: Loss-> 0.5053, Train accuracy->  46.56%\n","Current batch: Loss-> 0.5394, Train accuracy->  46.68%\n","Current batch: Loss-> 0.5529, Train accuracy->  46.79%\n","Current batch: Loss-> 0.6356, Train accuracy->  46.89%\n","Current batch: Loss-> 1.0254, Train accuracy->  46.99%\n","Current batch: Loss-> 0.5605, Train accuracy->  47.09%\n","Current batch: Loss-> 0.6181, Train accuracy->  47.21%\n","Current batch: Loss-> 0.8238, Train accuracy->  47.31%\n","Current batch: Loss-> 0.8306, Train accuracy->  47.41%\n","Current batch: Loss-> 0.9671, Train accuracy->  47.50%\n","Current batch: Loss-> 0.6084, Train accuracy->  47.61%\n","Current batch: Loss-> 1.0045, Train accuracy->  47.70%\n","Current batch: Loss-> 0.6182, Train accuracy->  47.81%\n","Current batch: Loss-> 0.6197, Train accuracy->  47.92%\n","Current batch: Loss-> 0.6314, Train accuracy->  48.03%\n","Current batch: Loss-> 0.7567, Train accuracy->  48.13%\n","Current batch: Loss-> 0.8323, Train accuracy->  48.24%\n","Current batch: Loss-> 0.7467, Train accuracy->  48.34%\n","Current batch: Loss-> 0.7338, Train accuracy->  48.44%\n","Current batch: Loss-> 0.7498, Train accuracy->  48.54%\n","Current batch: Loss-> 0.7192, Train accuracy->  48.65%\n","Current batch: Loss-> 1.0057, Train accuracy->  48.75%\n","Current batch: Loss-> 0.6937, Train accuracy->  48.86%\n","Current batch: Loss-> 0.6072, Train accuracy->  48.96%\n","Current batch: Loss-> 0.7112, Train accuracy->  49.07%\n","Current batch: Loss-> 0.9102, Train accuracy->  49.16%\n","Current batch: Loss-> 0.9549, Train accuracy->  49.26%\n","Current batch: Loss-> 0.5335, Train accuracy->  49.37%\n","Current batch: Loss-> 0.9475, Train accuracy->  49.47%\n","Current batch: Loss-> 0.7475, Train accuracy->  49.56%\n","Current batch: Loss-> 0.6919, Train accuracy->  49.66%\n","Current batch: Loss-> 0.6094, Train accuracy->  49.76%\n","Current batch: Loss-> 0.7156, Train accuracy->  49.88%\n","Current batch: Loss-> 0.8261, Train accuracy->  49.98%\n","Current batch: Loss-> 0.6116, Train accuracy->  50.08%\n","Current batch: Loss-> 0.7653, Train accuracy->  50.18%\n","Current batch: Loss-> 1.1310, Train accuracy->  50.26%\n","Current batch: Loss-> 0.8130, Train accuracy->  50.36%\n","Current batch: Loss-> 0.7219, Train accuracy->  50.46%\n","Current batch: Loss-> 0.5838, Train accuracy->  50.57%\n","Current batch: Loss-> 0.5674, Train accuracy->  50.68%\n","Current batch: Loss-> 0.6297, Train accuracy->  50.79%\n","Current batch: Loss-> 1.0680, Train accuracy->  50.87%\n","Current batch: Loss-> 0.7288, Train accuracy->  50.97%\n","Current batch: Loss-> 0.7154, Train accuracy->  51.07%\n","Current batch: Loss-> 0.7296, Train accuracy->  51.17%\n","Current batch: Loss-> 0.8396, Train accuracy->  51.27%\n","Current batch: Loss-> 1.0197, Train accuracy->  51.36%\n","Current batch: Loss-> 0.9753, Train accuracy->  51.46%\n","Current batch: Loss-> 0.7593, Train accuracy->  51.56%\n","Current batch: Loss-> 0.7993, Train accuracy->  51.66%\n","Current batch: Loss-> 0.6697, Train accuracy->  51.76%\n","Current batch: Loss-> 0.7819, Train accuracy->  51.86%\n","Current batch: Loss-> 0.6843, Train accuracy->  51.96%\n","Current batch: Loss-> 0.6334, Train accuracy->  52.06%\n","Current batch: Loss-> 0.8471, Train accuracy->  52.16%\n","Current batch: Loss-> 0.8286, Train accuracy->  52.25%\n","Current batch: Loss-> 0.5660, Train accuracy->  52.37%\n","Current batch: Loss-> 0.9142, Train accuracy->  52.46%\n","Current batch: Loss-> 0.6424, Train accuracy->  52.57%\n","Current batch: Loss-> 0.7331, Train accuracy->  52.67%\n","Current batch: Loss-> 0.7700, Train accuracy->  52.77%\n","Current batch: Loss-> 0.7798, Train accuracy->  52.87%\n","Current batch: Loss-> 0.7714, Train accuracy->  52.97%\n","Current batch: Loss-> 0.7361, Train accuracy->  53.08%\n","Current batch: Loss-> 0.6905, Train accuracy->  53.17%\n","Current batch: Loss-> 0.5878, Train accuracy->  53.27%\n","Current batch: Loss-> 0.6514, Train accuracy->  53.38%\n","Current batch: Loss-> 0.7663, Train accuracy->  53.47%\n","Current batch: Loss-> 0.7241, Train accuracy->  53.58%\n","Current batch: Loss-> 0.9933, Train accuracy->  53.68%\n","Current batch: Loss-> 0.7023, Train accuracy->  53.78%\n","Current batch: Loss-> 0.6548, Train accuracy->  53.88%\n","Current batch: Loss-> 0.9916, Train accuracy->  53.99%\n","Current batch: Loss-> 0.5757, Train accuracy->  54.09%\n","Current batch: Loss-> 0.8852, Train accuracy->  54.19%\n","Current batch: Loss-> 0.8681, Train accuracy->  54.29%\n","Current batch: Loss-> 0.6940, Train accuracy->  54.39%\n","Current batch: Loss-> 0.7384, Train accuracy->  54.49%\n","Current batch: Loss-> 0.4712, Train accuracy->  54.60%\n","Current batch: Loss-> 0.7810, Train accuracy->  54.70%\n","Current batch: Loss-> 0.6494, Train accuracy->  54.80%\n","Current batch: Loss-> 0.6251, Train accuracy->  54.91%\n","Current batch: Loss-> 0.7535, Train accuracy->  55.01%\n","Current batch: Loss-> 0.6650, Train accuracy->  55.11%\n","Current batch: Loss-> 1.0452, Train accuracy->  55.20%\n","Current batch: Loss-> 0.6979, Train accuracy->  55.31%\n","Current batch: Loss-> 0.8996, Train accuracy->  55.40%\n","Current batch: Loss-> 0.6378, Train accuracy->  55.50%\n","Current batch: Loss-> 0.8239, Train accuracy->  55.61%\n","Current batch: Loss-> 0.6115, Train accuracy->  55.71%\n","Current batch: Loss-> 0.5682, Train accuracy->  55.82%\n","Current batch: Loss-> 1.0361, Train accuracy->  55.91%\n","Current batch: Loss-> 0.9465, Train accuracy->  56.01%\n","Current batch: Loss-> 0.6467, Train accuracy->  56.11%\n","Current batch: Loss-> 0.8425, Train accuracy->  56.22%\n","Current batch: Loss-> 0.7592, Train accuracy->  56.33%\n","Current batch: Loss-> 1.0404, Train accuracy->  56.43%\n","Current batch: Loss-> 0.6431, Train accuracy->  56.53%\n","Current batch: Loss-> 0.8623, Train accuracy->  56.63%\n","Current batch: Loss-> 0.6475, Train accuracy->  56.73%\n","Current batch: Loss-> 0.6712, Train accuracy->  56.83%\n","Current batch: Loss-> 0.7471, Train accuracy->  56.94%\n","Current batch: Loss-> 0.6069, Train accuracy->  57.04%\n","Current batch: Loss-> 0.7679, Train accuracy->  57.15%\n","Current batch: Loss-> 0.6084, Train accuracy->  57.25%\n","Current batch: Loss-> 0.6308, Train accuracy->  57.35%\n","Current batch: Loss-> 0.8653, Train accuracy->  57.45%\n","Current batch: Loss-> 0.6204, Train accuracy->  57.56%\n","Current batch: Loss-> 0.6968, Train accuracy->  57.67%\n","Current batch: Loss-> 0.7242, Train accuracy->  57.78%\n","Current batch: Loss-> 0.7382, Train accuracy->  57.88%\n","Current batch: Loss-> 1.0184, Train accuracy->  57.97%\n","Current batch: Loss-> 0.8853, Train accuracy->  58.07%\n","Current batch: Loss-> 0.6009, Train accuracy->  58.18%\n","Current batch: Loss-> 0.6828, Train accuracy->  58.29%\n","Current batch: Loss-> 0.7323, Train accuracy->  58.40%\n","Current batch: Loss-> 0.8547, Train accuracy->  58.49%\n","Current batch: Loss-> 1.2864, Train accuracy->  58.57%\n","Current batch: Loss-> 0.6682, Train accuracy->  58.67%\n","Current batch: Loss-> 0.7673, Train accuracy->  58.78%\n","Current batch: Loss-> 0.8169, Train accuracy->  58.87%\n","Current batch: Loss-> 0.5771, Train accuracy->  58.97%\n","Current batch: Loss-> 0.6815, Train accuracy->  59.08%\n","Current batch: Loss-> 0.7446, Train accuracy->  59.17%\n","Current batch: Loss-> 0.6341, Train accuracy->  59.28%\n","Current batch: Loss-> 0.8099, Train accuracy->  59.38%\n","Current batch: Loss-> 0.8328, Train accuracy->  59.48%\n","Current batch: Loss-> 0.6161, Train accuracy->  59.58%\n","Current batch: Loss-> 0.7529, Train accuracy->  59.69%\n","Current batch: Loss-> 0.6740, Train accuracy->  59.79%\n","Current batch: Loss-> 0.6520, Train accuracy->  59.89%\n","Current batch: Loss-> 0.7106, Train accuracy->  59.99%\n","Current batch: Loss-> 0.9223, Train accuracy->  60.09%\n","Current batch: Loss-> 0.8494, Train accuracy->  60.19%\n","Current batch: Loss-> 1.0280, Train accuracy->  60.29%\n","Current batch: Loss-> 0.8104, Train accuracy->  60.39%\n","Current batch: Loss-> 0.7627, Train accuracy->  60.50%\n","Current batch: Loss-> 0.8962, Train accuracy->  60.60%\n","Current batch: Loss-> 0.7857, Train accuracy->  60.71%\n","Current batch: Loss-> 0.9381, Train accuracy->  60.79%\n","Current batch: Loss-> 0.8570, Train accuracy->  60.89%\n","Current batch: Loss-> 0.8742, Train accuracy->  60.99%\n","Current batch: Loss-> 0.7065, Train accuracy->  61.09%\n","Current batch: Loss-> 0.8682, Train accuracy->  61.19%\n","Current batch: Loss-> 0.6859, Train accuracy->  61.29%\n","Current batch: Loss-> 0.6010, Train accuracy->  61.40%\n","Current batch: Loss-> 0.5911, Train accuracy->  61.51%\n","Current batch: Loss-> 0.7764, Train accuracy->  61.60%\n","Current batch: Loss-> 0.6817, Train accuracy->  61.71%\n","Current batch: Loss-> 0.7006, Train accuracy->  61.82%\n","Current batch: Loss-> 0.4760, Train accuracy->  61.94%\n","Current batch: Loss-> 0.5574, Train accuracy->  62.04%\n","Current batch: Loss-> 0.9782, Train accuracy->  62.13%\n","Current batch: Loss-> 0.7713, Train accuracy->  62.23%\n","Current batch: Loss-> 0.7537, Train accuracy->  62.34%\n","Current batch: Loss-> 0.8864, Train accuracy->  62.44%\n","Current batch: Loss-> 1.1106, Train accuracy->  62.53%\n","Current batch: Loss-> 0.8304, Train accuracy->  62.63%\n","Current batch: Loss-> 1.1194, Train accuracy->  62.72%\n","Current batch: Loss-> 1.0426, Train accuracy->  62.82%\n","Current batch: Loss-> 0.6453, Train accuracy->  62.92%\n","Current batch: Loss-> 0.7313, Train accuracy->  63.02%\n","Current batch: Loss-> 0.8186, Train accuracy->  63.12%\n","Current batch: Loss-> 0.7609, Train accuracy->  63.23%\n","Current batch: Loss-> 0.6929, Train accuracy->  63.33%\n","Current batch: Loss-> 0.9696, Train accuracy->  63.42%\n","Current batch: Loss-> 0.8370, Train accuracy->  63.52%\n","Current batch: Loss-> 0.7298, Train accuracy->  63.62%\n","Current batch: Loss-> 0.7936, Train accuracy->  63.73%\n","Current batch: Loss-> 0.7222, Train accuracy->  63.84%\n","Current batch: Loss-> 0.7972, Train accuracy->  63.93%\n","Current batch: Loss-> 0.7437, Train accuracy->  64.02%\n","Current batch: Loss-> 0.8304, Train accuracy->  64.10%\n","Current batch: Loss-> 1.3293, Train accuracy->  64.19%\n","Current batch: Loss-> 0.4738, Train accuracy->  64.30%\n","Current batch: Loss-> 0.8078, Train accuracy->  64.40%\n","Current batch: Loss-> 0.4615, Train accuracy->  64.51%\n","Current batch: Loss-> 0.5559, Train accuracy->  64.62%\n","Current batch: Loss-> 0.6490, Train accuracy->  64.73%\n","Current batch: Loss-> 0.6595, Train accuracy->  64.84%\n","Current batch: Loss-> 0.5061, Train accuracy->  64.94%\n","Current batch: Loss-> 0.5933, Train accuracy->  65.05%\n","Current batch: Loss-> 0.8356, Train accuracy->  65.16%\n","Current batch: Loss-> 0.7487, Train accuracy->  65.26%\n","Current batch: Loss-> 0.5959, Train accuracy->  65.37%\n","Current batch: Loss-> 0.7476, Train accuracy->  65.46%\n","Current batch: Loss-> 0.6062, Train accuracy->  65.57%\n","Current batch: Loss-> 0.5119, Train accuracy->  65.69%\n","Current batch: Loss-> 0.6410, Train accuracy->  65.81%\n","Current batch: Loss-> 0.6747, Train accuracy->  65.91%\n","Current batch: Loss-> 0.5896, Train accuracy->  66.02%\n","Current batch: Loss-> 0.6130, Train accuracy->  66.12%\n","Current batch: Loss-> 0.9218, Train accuracy->  66.22%\n","Current batch: Loss-> 1.3766, Train accuracy->  66.32%\n","Current batch: Loss-> 0.5632, Train accuracy->  66.43%\n","Current batch: Loss-> 0.9470, Train accuracy->  66.53%\n","Current batch: Loss-> 0.6142, Train accuracy->  66.64%\n","Current batch: Loss-> 0.8041, Train accuracy->  66.73%\n","Current batch: Loss-> 0.8391, Train accuracy->  66.82%\n","Current batch: Loss-> 0.6604, Train accuracy->  66.92%\n","Current batch: Loss-> 0.7003, Train accuracy->  67.03%\n","Current batch: Loss-> 0.5174, Train accuracy->  67.14%\n","Current batch: Loss-> 0.6350, Train accuracy->  67.25%\n","Current batch: Loss-> 0.6155, Train accuracy->  67.35%\n","Current batch: Loss-> 0.7637, Train accuracy->  67.45%\n","Current batch: Loss-> 0.4527, Train accuracy->  67.57%\n","Current batch: Loss-> 0.6238, Train accuracy->  67.68%\n","Current batch: Loss-> 0.5807, Train accuracy->  67.78%\n","Current batch: Loss-> 0.5587, Train accuracy->  67.89%\n","Current batch: Loss-> 0.9564, Train accuracy->  67.98%\n","Current batch: Loss-> 0.7074, Train accuracy->  68.08%\n","Current batch: Loss-> 0.6948, Train accuracy->  68.19%\n","Current batch: Loss-> 0.8189, Train accuracy->  68.30%\n","Current batch: Loss-> 0.6221, Train accuracy->  68.41%\n","Current batch: Loss-> 1.2424, Train accuracy->  68.50%\n","Current batch: Loss-> 0.5621, Train accuracy->  68.62%\n","Current batch: Loss-> 0.6704, Train accuracy->  68.72%\n","Current batch: Loss-> 0.9682, Train accuracy->  68.81%\n","Current batch: Loss-> 0.6670, Train accuracy->  68.92%\n","Current batch: Loss-> 0.6049, Train accuracy->  69.02%\n","Current batch: Loss-> 1.0058, Train accuracy->  69.12%\n","Current batch: Loss-> 0.7582, Train accuracy->  69.22%\n","Current batch: Loss-> 0.9657, Train accuracy->  69.30%\n","Current batch: Loss-> 0.7707, Train accuracy->  69.41%\n","Current batch: Loss-> 1.0097, Train accuracy->  69.50%\n","Current batch: Loss-> 0.8547, Train accuracy->  69.60%\n","Current batch: Loss-> 0.7253, Train accuracy->  69.70%\n","Current batch: Loss-> 0.9275, Train accuracy->  69.80%\n","Current batch: Loss-> 0.9432, Train accuracy->  69.90%\n","Current batch: Loss-> 0.8144, Train accuracy->  70.00%\n","Current batch: Loss-> 0.8865, Train accuracy->  70.09%\n","Current batch: Loss-> 0.8111, Train accuracy->  70.19%\n","Current batch: Loss-> 1.1098, Train accuracy->  70.27%\n","Current batch: Loss-> 0.8813, Train accuracy->  70.38%\n","Current batch: Loss-> 0.6686, Train accuracy->  70.48%\n","Current batch: Loss-> 0.7148, Train accuracy->  70.57%\n","Current batch: Loss-> 0.6374, Train accuracy->  70.68%\n","Current batch: Loss-> 0.7089, Train accuracy->  70.78%\n","Current batch: Loss-> 0.6371, Train accuracy->  70.89%\n","Current batch: Loss-> 0.6286, Train accuracy->  70.99%\n","Current batch: Loss-> 0.7980, Train accuracy->  71.08%\n","Current batch: Loss-> 0.8224, Train accuracy->  71.19%\n","Current batch: Loss-> 0.8249, Train accuracy->  71.28%\n","Current batch: Loss-> 0.8864, Train accuracy->  71.38%\n","Current batch: Loss-> 0.5627, Train accuracy->  71.49%\n","Current batch: Loss-> 0.8964, Train accuracy->  71.57%\n","Current batch: Loss-> 0.8176, Train accuracy->  71.68%\n","Current batch: Loss-> 0.7650, Train accuracy->  71.78%\n","Current batch: Loss-> 1.0690, Train accuracy->  71.87%\n","Current batch: Loss-> 0.5934, Train accuracy->  71.97%\n","Current batch: Loss-> 0.7148, Train accuracy->  72.07%\n","Current batch: Loss-> 0.7485, Train accuracy->  72.18%\n","Current batch: Loss-> 0.5410, Train accuracy->  72.30%\n","Current batch: Loss-> 0.6020, Train accuracy->  72.40%\n","Current batch: Loss-> 0.7716, Train accuracy->  72.51%\n","Current batch: Loss-> 0.9958, Train accuracy->  72.61%\n","Current batch: Loss-> 0.9216, Train accuracy->  72.71%\n","Current batch: Loss-> 0.7641, Train accuracy->  72.80%\n","Current batch: Loss-> 0.7954, Train accuracy->  72.90%\n","Current batch: Loss-> 0.6193, Train accuracy->  73.00%\n","Current batch: Loss-> 0.7034, Train accuracy->  73.10%\n","Current batch: Loss-> 0.8741, Train accuracy->  73.20%\n","Current batch: Loss-> 0.8049, Train accuracy->  73.30%\n","Current batch: Loss-> 0.7606, Train accuracy->  73.40%\n","Current batch: Loss-> 1.0911, Train accuracy->  73.49%\n","Current batch: Loss-> 1.0395, Train accuracy->  73.57%\n","Current batch: Loss-> 0.6830, Train accuracy->  73.67%\n","Current batch: Loss-> 0.7752, Train accuracy->  73.77%\n","Current batch: Loss-> 0.6766, Train accuracy->  73.88%\n","Current batch: Loss-> 0.9622, Train accuracy->  73.98%\n","Current batch: Loss-> 0.6659, Train accuracy->  74.09%\n","Current batch: Loss-> 0.8286, Train accuracy->  74.19%\n","Current batch: Loss-> 0.9001, Train accuracy->  74.29%\n","Current batch: Loss-> 0.7023, Train accuracy->  74.40%\n","Current batch: Loss-> 0.7641, Train accuracy->  74.50%\n","Current batch: Loss-> 0.6455, Train accuracy->  74.60%\n","Current batch: Loss-> 0.6862, Train accuracy->  74.71%\n","Current batch: Loss-> 0.9965, Train accuracy->  74.80%\n","Current batch: Loss-> 0.8487, Train accuracy->  74.89%\n","Current batch: Loss-> 0.9972, Train accuracy->  74.98%\n","Current batch: Loss-> 0.6640, Train accuracy->  75.09%\n","Current batch: Loss-> 0.9517, Train accuracy->  75.18%\n","Current batch: Loss-> 0.7448, Train accuracy->  75.29%\n","Current batch: Loss-> 0.6723, Train accuracy->  75.40%\n","Current batch: Loss-> 0.6002, Train accuracy->  75.51%\n","Current batch: Loss-> 0.7765, Train accuracy->  75.61%\n","Current batch: Loss-> 0.5841, Train accuracy->  75.71%\n","Current batch: Loss-> 0.4804, Train accuracy->  75.83%\n","Current batch: Loss-> 0.5921, Train accuracy->  75.95%\n","Current batch: Loss-> 0.6187, Train accuracy->  76.06%\n","Current batch: Loss-> 0.7830, Train accuracy->  76.16%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:04, 45.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.7071, Train accuracy->  76.27%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.91it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.2901, Accuracy: 5208/12000 (43%)\n","\n","Current batch: Loss-> 0.9218, Train accuracy->   0.10%\n","Current batch: Loss-> 0.7001, Train accuracy->   0.21%\n","Current batch: Loss-> 0.6304, Train accuracy->   0.32%\n","Current batch: Loss-> 0.8151, Train accuracy->   0.42%\n","Current batch: Loss-> 0.6061, Train accuracy->   0.53%\n","Current batch: Loss-> 0.6029, Train accuracy->   0.63%\n","Current batch: Loss-> 0.6009, Train accuracy->   0.73%\n","Current batch: Loss-> 0.7871, Train accuracy->   0.83%\n","Current batch: Loss-> 0.5312, Train accuracy->   0.94%\n","Current batch: Loss-> 0.4832, Train accuracy->   1.06%\n","Current batch: Loss-> 0.9516, Train accuracy->   1.14%\n","Current batch: Loss-> 0.8854, Train accuracy->   1.24%\n","Current batch: Loss-> 0.7542, Train accuracy->   1.34%\n","Current batch: Loss-> 0.6452, Train accuracy->   1.45%\n","Current batch: Loss-> 0.6665, Train accuracy->   1.55%\n","Current batch: Loss-> 0.4128, Train accuracy->   1.67%\n","Current batch: Loss-> 0.6581, Train accuracy->   1.77%\n","Current batch: Loss-> 0.5992, Train accuracy->   1.88%\n","Current batch: Loss-> 0.7966, Train accuracy->   1.98%\n","Current batch: Loss-> 0.6476, Train accuracy->   2.08%\n","Current batch: Loss-> 0.8052, Train accuracy->   2.19%\n","Current batch: Loss-> 0.6396, Train accuracy->   2.29%\n","Current batch: Loss-> 0.5596, Train accuracy->   2.41%\n","Current batch: Loss-> 0.7873, Train accuracy->   2.51%\n","Current batch: Loss-> 0.5668, Train accuracy->   2.62%\n","Current batch: Loss-> 0.8277, Train accuracy->   2.71%\n","Current batch: Loss-> 0.6798, Train accuracy->   2.81%\n","Current batch: Loss-> 0.8776, Train accuracy->   2.90%\n","Current batch: Loss-> 0.8933, Train accuracy->   3.00%\n","Current batch: Loss-> 0.8599, Train accuracy->   3.10%\n","Current batch: Loss-> 0.8063, Train accuracy->   3.20%\n","Current batch: Loss-> 0.7932, Train accuracy->   3.30%\n","Current batch: Loss-> 0.5027, Train accuracy->   3.41%\n","Current batch: Loss-> 0.5629, Train accuracy->   3.51%\n","Current batch: Loss-> 0.6661, Train accuracy->   3.61%\n","Current batch: Loss-> 0.5454, Train accuracy->   3.71%\n","Current batch: Loss-> 0.6390, Train accuracy->   3.82%\n","Current batch: Loss-> 0.6285, Train accuracy->   3.94%\n","Current batch: Loss-> 1.0442, Train accuracy->   4.03%\n","Current batch: Loss-> 0.5596, Train accuracy->   4.14%\n","Current batch: Loss-> 0.7404, Train accuracy->   4.25%\n","Current batch: Loss-> 0.5296, Train accuracy->   4.37%\n","Current batch: Loss-> 0.5313, Train accuracy->   4.48%\n","Current batch: Loss-> 0.5284, Train accuracy->   4.58%\n","Current batch: Loss-> 0.8183, Train accuracy->   4.68%\n","Current batch: Loss-> 0.7572, Train accuracy->   4.77%\n","Current batch: Loss-> 0.7156, Train accuracy->   4.88%\n","Current batch: Loss-> 0.8697, Train accuracy->   4.98%\n","Current batch: Loss-> 0.7047, Train accuracy->   5.09%\n","Current batch: Loss-> 1.0244, Train accuracy->   5.19%\n","Current batch: Loss-> 0.8036, Train accuracy->   5.29%\n","Current batch: Loss-> 0.8003, Train accuracy->   5.39%\n","Current batch: Loss-> 0.7542, Train accuracy->   5.49%\n","Current batch: Loss-> 0.8745, Train accuracy->   5.59%\n","Current batch: Loss-> 0.6304, Train accuracy->   5.70%\n","Current batch: Loss-> 1.2284, Train accuracy->   5.78%\n","Current batch: Loss-> 0.8817, Train accuracy->   5.88%\n","Current batch: Loss-> 0.5697, Train accuracy->   5.98%\n","Current batch: Loss-> 1.1791, Train accuracy->   6.05%\n","Current batch: Loss-> 0.8674, Train accuracy->   6.14%\n","Current batch: Loss-> 0.5448, Train accuracy->   6.25%\n","Current batch: Loss-> 0.6752, Train accuracy->   6.36%\n","Current batch: Loss-> 0.4887, Train accuracy->   6.48%\n","Current batch: Loss-> 0.4979, Train accuracy->   6.59%\n","Current batch: Loss-> 0.8287, Train accuracy->   6.69%\n","Current batch: Loss-> 0.7542, Train accuracy->   6.79%\n","Current batch: Loss-> 0.5873, Train accuracy->   6.89%\n","Current batch: Loss-> 0.5813, Train accuracy->   7.00%\n","Current batch: Loss-> 0.7264, Train accuracy->   7.10%\n","Current batch: Loss-> 0.9244, Train accuracy->   7.20%\n","Current batch: Loss-> 0.5491, Train accuracy->   7.30%\n","Current batch: Loss-> 0.6035, Train accuracy->   7.41%\n","Current batch: Loss-> 0.6400, Train accuracy->   7.52%\n","Current batch: Loss-> 0.8448, Train accuracy->   7.62%\n","Current batch: Loss-> 0.8003, Train accuracy->   7.72%\n","Current batch: Loss-> 0.9803, Train accuracy->   7.81%\n","Current batch: Loss-> 0.7931, Train accuracy->   7.90%\n","Current batch: Loss-> 0.5467, Train accuracy->   8.00%\n","Current batch: Loss-> 0.5059, Train accuracy->   8.11%\n","Current batch: Loss-> 0.6094, Train accuracy->   8.23%\n","Current batch: Loss-> 0.6896, Train accuracy->   8.34%\n","Current batch: Loss-> 0.9734, Train accuracy->   8.43%\n","Current batch: Loss-> 0.5937, Train accuracy->   8.54%\n","Current batch: Loss-> 0.7783, Train accuracy->   8.64%\n","Current batch: Loss-> 0.6687, Train accuracy->   8.75%\n","Current batch: Loss-> 0.5862, Train accuracy->   8.85%\n","Current batch: Loss-> 0.7980, Train accuracy->   8.95%\n","Current batch: Loss-> 0.6696, Train accuracy->   9.05%\n","Current batch: Loss-> 1.0458, Train accuracy->   9.13%\n","Current batch: Loss-> 0.7676, Train accuracy->   9.24%\n","Current batch: Loss-> 0.6592, Train accuracy->   9.35%\n","Current batch: Loss-> 0.8166, Train accuracy->   9.45%\n","Current batch: Loss-> 0.7902, Train accuracy->   9.54%\n","Current batch: Loss-> 0.5884, Train accuracy->   9.65%\n","Current batch: Loss-> 0.6739, Train accuracy->   9.76%\n","Current batch: Loss-> 0.5743, Train accuracy->   9.88%\n","Current batch: Loss-> 0.7554, Train accuracy->   9.98%\n","Current batch: Loss-> 0.6046, Train accuracy->  10.08%\n","Current batch: Loss-> 0.5184, Train accuracy->  10.20%\n","Current batch: Loss-> 0.6956, Train accuracy->  10.29%\n","Current batch: Loss-> 0.6767, Train accuracy->  10.40%\n","Current batch: Loss-> 0.7156, Train accuracy->  10.50%\n","Current batch: Loss-> 0.8311, Train accuracy->  10.60%\n","Current batch: Loss-> 0.7022, Train accuracy->  10.71%\n","Current batch: Loss-> 0.6420, Train accuracy->  10.81%\n","Current batch: Loss-> 0.6397, Train accuracy->  10.93%\n","Current batch: Loss-> 0.7371, Train accuracy->  11.03%\n","Current batch: Loss-> 0.6522, Train accuracy->  11.14%\n","Current batch: Loss-> 0.7780, Train accuracy->  11.23%\n","Current batch: Loss-> 0.6661, Train accuracy->  11.34%\n","Current batch: Loss-> 0.6080, Train accuracy->  11.45%\n","Current batch: Loss-> 0.4903, Train accuracy->  11.56%\n","Current batch: Loss-> 0.9786, Train accuracy->  11.64%\n","Current batch: Loss-> 0.5371, Train accuracy->  11.75%\n","Current batch: Loss-> 0.6711, Train accuracy->  11.85%\n","Current batch: Loss-> 0.9815, Train accuracy->  11.95%\n","Current batch: Loss-> 0.5786, Train accuracy->  12.06%\n","Current batch: Loss-> 0.7723, Train accuracy->  12.15%\n","Current batch: Loss-> 0.8026, Train accuracy->  12.25%\n","Current batch: Loss-> 0.7536, Train accuracy->  12.36%\n","Current batch: Loss-> 0.9809, Train accuracy->  12.46%\n","Current batch: Loss-> 0.7896, Train accuracy->  12.56%\n","Current batch: Loss-> 0.9670, Train accuracy->  12.66%\n","Current batch: Loss-> 0.5506, Train accuracy->  12.77%\n","Current batch: Loss-> 0.6683, Train accuracy->  12.87%\n","Current batch: Loss-> 0.6085, Train accuracy->  12.98%\n","Current batch: Loss-> 0.7588, Train accuracy->  13.09%\n","Current batch: Loss-> 0.7198, Train accuracy->  13.19%\n","Current batch: Loss-> 0.7181, Train accuracy->  13.30%\n","Current batch: Loss-> 0.5848, Train accuracy->  13.41%\n","Current batch: Loss-> 0.6960, Train accuracy->  13.51%\n","Current batch: Loss-> 0.5688, Train accuracy->  13.62%\n","Current batch: Loss-> 0.7061, Train accuracy->  13.72%\n","Current batch: Loss-> 0.7075, Train accuracy->  13.83%\n","Current batch: Loss-> 1.0601, Train accuracy->  13.94%\n","Current batch: Loss-> 0.8053, Train accuracy->  14.04%\n","Current batch: Loss-> 0.8923, Train accuracy->  14.13%\n","Current batch: Loss-> 0.8542, Train accuracy->  14.24%\n","Current batch: Loss-> 0.7801, Train accuracy->  14.34%\n","Current batch: Loss-> 0.5416, Train accuracy->  14.44%\n","Current batch: Loss-> 0.8619, Train accuracy->  14.55%\n","Current batch: Loss-> 0.4597, Train accuracy->  14.66%\n","Current batch: Loss-> 0.6331, Train accuracy->  14.76%\n","Current batch: Loss-> 0.6628, Train accuracy->  14.86%\n","Current batch: Loss-> 1.2220, Train accuracy->  14.95%\n","Current batch: Loss-> 0.7345, Train accuracy->  15.05%\n","Current batch: Loss-> 0.6139, Train accuracy->  15.16%\n","Current batch: Loss-> 0.8220, Train accuracy->  15.26%\n","Current batch: Loss-> 0.8841, Train accuracy->  15.36%\n","Current batch: Loss-> 0.6494, Train accuracy->  15.47%\n","Current batch: Loss-> 0.7812, Train accuracy->  15.57%\n","Current batch: Loss-> 0.8002, Train accuracy->  15.67%\n","Current batch: Loss-> 0.8409, Train accuracy->  15.77%\n","Current batch: Loss-> 0.7803, Train accuracy->  15.87%\n","Current batch: Loss-> 0.6221, Train accuracy->  15.99%\n","Current batch: Loss-> 0.5176, Train accuracy->  16.10%\n","Current batch: Loss-> 0.6274, Train accuracy->  16.20%\n","Current batch: Loss-> 0.6713, Train accuracy->  16.31%\n","Current batch: Loss-> 0.7905, Train accuracy->  16.41%\n","Current batch: Loss-> 0.7004, Train accuracy->  16.52%\n","Current batch: Loss-> 0.6269, Train accuracy->  16.62%\n","Current batch: Loss-> 0.9694, Train accuracy->  16.72%\n","Current batch: Loss-> 0.5092, Train accuracy->  16.83%\n","Current batch: Loss-> 0.9395, Train accuracy->  16.93%\n","Current batch: Loss-> 0.8256, Train accuracy->  17.03%\n","Current batch: Loss-> 0.8313, Train accuracy->  17.13%\n","Current batch: Loss-> 0.6414, Train accuracy->  17.23%\n","Current batch: Loss-> 0.4830, Train accuracy->  17.34%\n","Current batch: Loss-> 0.7915, Train accuracy->  17.45%\n","Current batch: Loss-> 0.5775, Train accuracy->  17.56%\n","Current batch: Loss-> 0.5416, Train accuracy->  17.66%\n","Current batch: Loss-> 0.8825, Train accuracy->  17.76%\n","Current batch: Loss-> 0.6327, Train accuracy->  17.87%\n","Current batch: Loss-> 0.6580, Train accuracy->  17.98%\n","Current batch: Loss-> 0.6610, Train accuracy->  18.08%\n","Current batch: Loss-> 0.9893, Train accuracy->  18.17%\n","Current batch: Loss-> 0.4798, Train accuracy->  18.28%\n","Current batch: Loss-> 0.5728, Train accuracy->  18.39%\n","Current batch: Loss-> 0.6111, Train accuracy->  18.50%\n","Current batch: Loss-> 0.7001, Train accuracy->  18.61%\n","Current batch: Loss-> 0.8437, Train accuracy->  18.72%\n","Current batch: Loss-> 0.7047, Train accuracy->  18.82%\n","Current batch: Loss-> 0.6882, Train accuracy->  18.92%\n","Current batch: Loss-> 0.5480, Train accuracy->  19.03%\n","Current batch: Loss-> 0.7041, Train accuracy->  19.13%\n","Current batch: Loss-> 0.6163, Train accuracy->  19.23%\n","Current batch: Loss-> 0.5877, Train accuracy->  19.34%\n","Current batch: Loss-> 0.8859, Train accuracy->  19.44%\n","Current batch: Loss-> 0.5825, Train accuracy->  19.56%\n","Current batch: Loss-> 0.6571, Train accuracy->  19.66%\n","Current batch: Loss-> 0.7363, Train accuracy->  19.77%\n","Current batch: Loss-> 0.6933, Train accuracy->  19.87%\n","Current batch: Loss-> 0.7444, Train accuracy->  19.98%\n","Current batch: Loss-> 0.6790, Train accuracy->  20.09%\n","Current batch: Loss-> 0.6597, Train accuracy->  20.20%\n","Current batch: Loss-> 0.6439, Train accuracy->  20.30%\n","Current batch: Loss-> 0.7008, Train accuracy->  20.40%\n","Current batch: Loss-> 0.7207, Train accuracy->  20.51%\n","Current batch: Loss-> 0.6509, Train accuracy->  20.62%\n","Current batch: Loss-> 0.8550, Train accuracy->  20.71%\n","Current batch: Loss-> 0.7833, Train accuracy->  20.81%\n","Current batch: Loss-> 0.9588, Train accuracy->  20.90%\n","Current batch: Loss-> 0.5908, Train accuracy->  21.01%\n","Current batch: Loss-> 0.8955, Train accuracy->  21.11%\n","Current batch: Loss-> 0.7356, Train accuracy->  21.20%\n","Current batch: Loss-> 0.8195, Train accuracy->  21.31%\n","Current batch: Loss-> 0.7337, Train accuracy->  21.42%\n","Current batch: Loss-> 0.9449, Train accuracy->  21.51%\n","Current batch: Loss-> 0.8905, Train accuracy->  21.61%\n","Current batch: Loss-> 0.5754, Train accuracy->  21.71%\n","Current batch: Loss-> 0.6423, Train accuracy->  21.82%\n","Current batch: Loss-> 0.7124, Train accuracy->  21.93%\n","Current batch: Loss-> 0.6812, Train accuracy->  22.03%\n","Current batch: Loss-> 0.7689, Train accuracy->  22.13%\n","Current batch: Loss-> 0.5277, Train accuracy->  22.24%\n","Current batch: Loss-> 0.7935, Train accuracy->  22.34%\n","Current batch: Loss-> 0.5784, Train accuracy->  22.45%\n","Current batch: Loss-> 0.8337, Train accuracy->  22.54%\n","Current batch: Loss-> 0.7235, Train accuracy->  22.64%\n","Current batch: Loss-> 0.4319, Train accuracy->  22.76%\n","Current batch: Loss-> 0.5717, Train accuracy->  22.87%\n","Current batch: Loss-> 0.7189, Train accuracy->  22.98%\n","Current batch: Loss-> 0.6640, Train accuracy->  23.08%\n","Current batch: Loss-> 0.7683, Train accuracy->  23.19%\n","Current batch: Loss-> 0.9302, Train accuracy->  23.29%\n","Current batch: Loss-> 0.7245, Train accuracy->  23.39%\n","Current batch: Loss-> 0.7416, Train accuracy->  23.49%\n","Current batch: Loss-> 0.6838, Train accuracy->  23.59%\n","Current batch: Loss-> 0.8730, Train accuracy->  23.69%\n","Current batch: Loss-> 0.5818, Train accuracy->  23.79%\n","Current batch: Loss-> 0.5395, Train accuracy->  23.90%\n","Current batch: Loss-> 0.5073, Train accuracy->  24.01%\n","Current batch: Loss-> 0.7588, Train accuracy->  24.12%\n","Current batch: Loss-> 0.9157, Train accuracy->  24.22%\n","Current batch: Loss-> 0.5851, Train accuracy->  24.32%\n","Current batch: Loss-> 0.6497, Train accuracy->  24.44%\n","Current batch: Loss-> 0.8407, Train accuracy->  24.53%\n","Current batch: Loss-> 0.6355, Train accuracy->  24.63%\n","Current batch: Loss-> 1.0279, Train accuracy->  24.71%\n","Current batch: Loss-> 0.6408, Train accuracy->  24.83%\n","Current batch: Loss-> 1.2882, Train accuracy->  24.91%\n","Current batch: Loss-> 0.8435, Train accuracy->  25.00%\n","Current batch: Loss-> 0.6294, Train accuracy->  25.11%\n","Current batch: Loss-> 0.8795, Train accuracy->  25.20%\n","Current batch: Loss-> 0.6041, Train accuracy->  25.31%\n","Current batch: Loss-> 0.6122, Train accuracy->  25.43%\n","Current batch: Loss-> 0.4892, Train accuracy->  25.54%\n","Current batch: Loss-> 0.9873, Train accuracy->  25.64%\n","Current batch: Loss-> 0.8851, Train accuracy->  25.74%\n","Current batch: Loss-> 0.8177, Train accuracy->  25.85%\n","Current batch: Loss-> 0.9708, Train accuracy->  25.94%\n","Current batch: Loss-> 0.7109, Train accuracy->  26.04%\n","Current batch: Loss-> 0.8968, Train accuracy->  26.15%\n","Current batch: Loss-> 0.5844, Train accuracy->  26.26%\n","Current batch: Loss-> 0.6676, Train accuracy->  26.37%\n","Current batch: Loss-> 0.9003, Train accuracy->  26.46%\n","Current batch: Loss-> 0.8567, Train accuracy->  26.56%\n","Current batch: Loss-> 1.2755, Train accuracy->  26.65%\n","Current batch: Loss-> 0.6218, Train accuracy->  26.76%\n","Current batch: Loss-> 0.8392, Train accuracy->  26.86%\n","Current batch: Loss-> 0.5188, Train accuracy->  26.96%\n","Current batch: Loss-> 0.5346, Train accuracy->  27.08%\n","Current batch: Loss-> 0.5696, Train accuracy->  27.19%\n","Current batch: Loss-> 0.7011, Train accuracy->  27.29%\n","Current batch: Loss-> 0.6675, Train accuracy->  27.39%\n","Current batch: Loss-> 0.7046, Train accuracy->  27.49%\n","Current batch: Loss-> 0.6631, Train accuracy->  27.59%\n","Current batch: Loss-> 0.9462, Train accuracy->  27.69%\n","Current batch: Loss-> 0.7452, Train accuracy->  27.78%\n","Current batch: Loss-> 0.4860, Train accuracy->  27.90%\n","Current batch: Loss-> 0.5925, Train accuracy->  28.00%\n","Current batch: Loss-> 0.6314, Train accuracy->  28.11%\n","Current batch: Loss-> 0.4894, Train accuracy->  28.22%\n","Current batch: Loss-> 0.3698, Train accuracy->  28.35%\n","Current batch: Loss-> 0.7058, Train accuracy->  28.46%\n","Current batch: Loss-> 1.0652, Train accuracy->  28.55%\n","Current batch: Loss-> 0.5167, Train accuracy->  28.66%\n","Current batch: Loss-> 0.6500, Train accuracy->  28.76%\n","Current batch: Loss-> 0.5573, Train accuracy->  28.86%\n","Current batch: Loss-> 0.3833, Train accuracy->  28.98%\n","Current batch: Loss-> 0.5535, Train accuracy->  29.09%\n","Current batch: Loss-> 0.7487, Train accuracy->  29.19%\n","Current batch: Loss-> 0.4003, Train accuracy->  29.30%\n","Current batch: Loss-> 0.7107, Train accuracy->  29.41%\n","Current batch: Loss-> 0.4894, Train accuracy->  29.53%\n","Current batch: Loss-> 0.7708, Train accuracy->  29.63%\n","Current batch: Loss-> 0.6134, Train accuracy->  29.74%\n","Current batch: Loss-> 0.7082, Train accuracy->  29.84%\n","Current batch: Loss-> 0.6361, Train accuracy->  29.95%\n","Current batch: Loss-> 0.9473, Train accuracy->  30.05%\n","Current batch: Loss-> 0.6350, Train accuracy->  30.16%\n","Current batch: Loss-> 0.5295, Train accuracy->  30.27%\n","Current batch: Loss-> 0.6430, Train accuracy->  30.39%\n","Current batch: Loss-> 0.8587, Train accuracy->  30.49%\n","Current batch: Loss-> 0.9343, Train accuracy->  30.59%\n","Current batch: Loss-> 0.7727, Train accuracy->  30.69%\n","Current batch: Loss-> 0.6330, Train accuracy->  30.80%\n","Current batch: Loss-> 0.5832, Train accuracy->  30.91%\n","Current batch: Loss-> 0.4536, Train accuracy->  31.03%\n","Current batch: Loss-> 0.5667, Train accuracy->  31.13%\n","Current batch: Loss-> 0.6631, Train accuracy->  31.24%\n","Current batch: Loss-> 0.8478, Train accuracy->  31.33%\n","Current batch: Loss-> 0.6270, Train accuracy->  31.45%\n","Current batch: Loss-> 0.4178, Train accuracy->  31.56%\n","Current batch: Loss-> 0.6692, Train accuracy->  31.67%\n","Current batch: Loss-> 0.6473, Train accuracy->  31.78%\n","Current batch: Loss-> 0.5222, Train accuracy->  31.89%\n","Current batch: Loss-> 0.5075, Train accuracy->  31.99%\n","Current batch: Loss-> 0.7723, Train accuracy->  32.09%\n","Current batch: Loss-> 0.7831, Train accuracy->  32.19%\n","Current batch: Loss-> 0.3618, Train accuracy->  32.31%\n","Current batch: Loss-> 1.0267, Train accuracy->  32.40%\n","Current batch: Loss-> 0.4346, Train accuracy->  32.51%\n","Current batch: Loss-> 0.6657, Train accuracy->  32.62%\n","Current batch: Loss-> 0.5192, Train accuracy->  32.72%\n","Current batch: Loss-> 0.5818, Train accuracy->  32.84%\n","Current batch: Loss-> 0.5428, Train accuracy->  32.95%\n","Current batch: Loss-> 0.7148, Train accuracy->  33.05%\n","Current batch: Loss-> 0.4744, Train accuracy->  33.16%\n","Current batch: Loss-> 0.6927, Train accuracy->  33.26%\n","Current batch: Loss-> 0.6818, Train accuracy->  33.36%\n","Current batch: Loss-> 0.7882, Train accuracy->  33.46%\n","Current batch: Loss-> 0.5250, Train accuracy->  33.57%\n","Current batch: Loss-> 0.5330, Train accuracy->  33.69%\n","Current batch: Loss-> 0.5698, Train accuracy->  33.80%\n","Current batch: Loss-> 0.8795, Train accuracy->  33.91%\n","Current batch: Loss-> 0.8549, Train accuracy->  34.01%\n","Current batch: Loss-> 0.6278, Train accuracy->  34.11%\n","Current batch: Loss-> 0.7387, Train accuracy->  34.21%\n","Current batch: Loss-> 0.9422, Train accuracy->  34.31%\n","Current batch: Loss-> 0.6407, Train accuracy->  34.42%\n","Current batch: Loss-> 0.9793, Train accuracy->  34.51%\n","Current batch: Loss-> 0.5351, Train accuracy->  34.63%\n","Current batch: Loss-> 1.2649, Train accuracy->  34.72%\n","Current batch: Loss-> 0.5482, Train accuracy->  34.83%\n","Current batch: Loss-> 0.6830, Train accuracy->  34.94%\n","Current batch: Loss-> 0.7271, Train accuracy->  35.04%\n","Current batch: Loss-> 0.8658, Train accuracy->  35.13%\n","Current batch: Loss-> 0.6580, Train accuracy->  35.24%\n","Current batch: Loss-> 0.9278, Train accuracy->  35.34%\n","Current batch: Loss-> 0.7715, Train accuracy->  35.44%\n","Current batch: Loss-> 0.8199, Train accuracy->  35.54%\n","Current batch: Loss-> 0.7979, Train accuracy->  35.64%\n","Current batch: Loss-> 0.7752, Train accuracy->  35.74%\n","Current batch: Loss-> 0.8585, Train accuracy->  35.83%\n","Current batch: Loss-> 0.5935, Train accuracy->  35.94%\n","Current batch: Loss-> 0.9082, Train accuracy->  36.04%\n","Current batch: Loss-> 0.5698, Train accuracy->  36.16%\n","Current batch: Loss-> 0.8302, Train accuracy->  36.27%\n","Current batch: Loss-> 0.5663, Train accuracy->  36.38%\n","Current batch: Loss-> 0.4959, Train accuracy->  36.49%\n","Current batch: Loss-> 0.4421, Train accuracy->  36.60%\n","Current batch: Loss-> 0.8306, Train accuracy->  36.70%\n","Current batch: Loss-> 0.7230, Train accuracy->  36.82%\n","Current batch: Loss-> 0.7178, Train accuracy->  36.92%\n","Current batch: Loss-> 1.0614, Train accuracy->  37.01%\n","Current batch: Loss-> 0.8216, Train accuracy->  37.09%\n","Current batch: Loss-> 0.5139, Train accuracy->  37.20%\n","Current batch: Loss-> 0.7296, Train accuracy->  37.30%\n","Current batch: Loss-> 1.0497, Train accuracy->  37.39%\n","Current batch: Loss-> 0.8821, Train accuracy->  37.48%\n","Current batch: Loss-> 1.0349, Train accuracy->  37.58%\n","Current batch: Loss-> 0.8360, Train accuracy->  37.67%\n","Current batch: Loss-> 0.4912, Train accuracy->  37.78%\n","Current batch: Loss-> 0.5668, Train accuracy->  37.89%\n","Current batch: Loss-> 0.6758, Train accuracy->  37.99%\n","Current batch: Loss-> 1.0140, Train accuracy->  38.09%\n","Current batch: Loss-> 0.7824, Train accuracy->  38.19%\n","Current batch: Loss-> 0.9155, Train accuracy->  38.29%\n","Current batch: Loss-> 0.7980, Train accuracy->  38.38%\n","Current batch: Loss-> 0.7496, Train accuracy->  38.49%\n","Current batch: Loss-> 0.7818, Train accuracy->  38.58%\n","Current batch: Loss-> 0.8135, Train accuracy->  38.69%\n","Current batch: Loss-> 0.6046, Train accuracy->  38.80%\n","Current batch: Loss-> 0.6107, Train accuracy->  38.91%\n","Current batch: Loss-> 0.7034, Train accuracy->  39.02%\n","Current batch: Loss-> 0.7003, Train accuracy->  39.12%\n","Current batch: Loss-> 0.5061, Train accuracy->  39.23%\n","Current batch: Loss-> 0.5894, Train accuracy->  39.33%\n","Current batch: Loss-> 0.7537, Train accuracy->  39.43%\n","Current batch: Loss-> 0.5010, Train accuracy->  39.54%\n","Current batch: Loss-> 1.0174, Train accuracy->  39.63%\n","Current batch: Loss-> 0.7685, Train accuracy->  39.74%\n","Current batch: Loss-> 0.6912, Train accuracy->  39.84%\n","Current batch: Loss-> 0.6825, Train accuracy->  39.94%\n","Current batch: Loss-> 0.7401, Train accuracy->  40.04%\n","Current batch: Loss-> 0.5530, Train accuracy->  40.15%\n","Current batch: Loss-> 0.7855, Train accuracy->  40.25%\n","Current batch: Loss-> 0.5811, Train accuracy->  40.36%\n","Current batch: Loss-> 0.6422, Train accuracy->  40.47%\n","Current batch: Loss-> 0.8971, Train accuracy->  40.58%\n","Current batch: Loss-> 0.7211, Train accuracy->  40.67%\n","Current batch: Loss-> 0.7627, Train accuracy->  40.77%\n","Current batch: Loss-> 0.8118, Train accuracy->  40.86%\n","Current batch: Loss-> 0.7710, Train accuracy->  40.96%\n","Current batch: Loss-> 0.7487, Train accuracy->  41.05%\n","Current batch: Loss-> 0.9285, Train accuracy->  41.16%\n","Current batch: Loss-> 0.7678, Train accuracy->  41.26%\n","Current batch: Loss-> 0.7531, Train accuracy->  41.35%\n","Current batch: Loss-> 0.6960, Train accuracy->  41.45%\n","Current batch: Loss-> 0.8545, Train accuracy->  41.55%\n","Current batch: Loss-> 0.8465, Train accuracy->  41.65%\n","Current batch: Loss-> 0.9002, Train accuracy->  41.75%\n","Current batch: Loss-> 0.6475, Train accuracy->  41.86%\n","Current batch: Loss-> 0.7333, Train accuracy->  41.97%\n","Current batch: Loss-> 0.7779, Train accuracy->  42.06%\n","Current batch: Loss-> 0.8687, Train accuracy->  42.16%\n","Current batch: Loss-> 0.6777, Train accuracy->  42.27%\n","Current batch: Loss-> 0.8672, Train accuracy->  42.36%\n","Current batch: Loss-> 0.6572, Train accuracy->  42.47%\n","Current batch: Loss-> 0.7563, Train accuracy->  42.57%\n","Current batch: Loss-> 0.8337, Train accuracy->  42.66%\n","Current batch: Loss-> 0.4962, Train accuracy->  42.77%\n","Current batch: Loss-> 0.7380, Train accuracy->  42.86%\n","Current batch: Loss-> 1.2025, Train accuracy->  42.96%\n","Current batch: Loss-> 1.0106, Train accuracy->  43.06%\n","Current batch: Loss-> 0.7156, Train accuracy->  43.17%\n","Current batch: Loss-> 0.5859, Train accuracy->  43.28%\n","Current batch: Loss-> 0.8581, Train accuracy->  43.38%\n","Current batch: Loss-> 0.6216, Train accuracy->  43.49%\n","Current batch: Loss-> 0.7917, Train accuracy->  43.58%\n","Current batch: Loss-> 0.9501, Train accuracy->  43.67%\n","Current batch: Loss-> 0.6671, Train accuracy->  43.78%\n","Current batch: Loss-> 0.6020, Train accuracy->  43.89%\n","Current batch: Loss-> 0.6467, Train accuracy->  44.00%\n","Current batch: Loss-> 0.5990, Train accuracy->  44.11%\n","Current batch: Loss-> 0.8143, Train accuracy->  44.20%\n","Current batch: Loss-> 0.7341, Train accuracy->  44.31%\n","Current batch: Loss-> 0.4959, Train accuracy->  44.42%\n","Current batch: Loss-> 0.4573, Train accuracy->  44.53%\n","Current batch: Loss-> 0.5162, Train accuracy->  44.65%\n","Current batch: Loss-> 0.6790, Train accuracy->  44.75%\n","Current batch: Loss-> 0.8012, Train accuracy->  44.86%\n","Current batch: Loss-> 0.6775, Train accuracy->  44.96%\n","Current batch: Loss-> 0.5857, Train accuracy->  45.07%\n","Current batch: Loss-> 0.7693, Train accuracy->  45.17%\n","Current batch: Loss-> 0.7712, Train accuracy->  45.27%\n","Current batch: Loss-> 0.6735, Train accuracy->  45.37%\n","Current batch: Loss-> 0.6174, Train accuracy->  45.49%\n","Current batch: Loss-> 0.8959, Train accuracy->  45.59%\n","Current batch: Loss-> 0.6314, Train accuracy->  45.70%\n","Current batch: Loss-> 0.8454, Train accuracy->  45.79%\n","Current batch: Loss-> 0.4650, Train accuracy->  45.91%\n","Current batch: Loss-> 0.8080, Train accuracy->  46.01%\n","Current batch: Loss-> 0.5169, Train accuracy->  46.12%\n","Current batch: Loss-> 0.5203, Train accuracy->  46.23%\n","Current batch: Loss-> 0.6788, Train accuracy->  46.34%\n","Current batch: Loss-> 0.7593, Train accuracy->  46.44%\n","Current batch: Loss-> 0.5605, Train accuracy->  46.55%\n","Current batch: Loss-> 0.8345, Train accuracy->  46.65%\n","Current batch: Loss-> 0.7768, Train accuracy->  46.76%\n","Current batch: Loss-> 0.7607, Train accuracy->  46.86%\n","Current batch: Loss-> 0.8811, Train accuracy->  46.97%\n","Current batch: Loss-> 0.6222, Train accuracy->  47.08%\n","Current batch: Loss-> 0.7832, Train accuracy->  47.18%\n","Current batch: Loss-> 1.0213, Train accuracy->  47.28%\n","Current batch: Loss-> 0.5032, Train accuracy->  47.40%\n","Current batch: Loss-> 0.7199, Train accuracy->  47.51%\n","Current batch: Loss-> 0.6659, Train accuracy->  47.61%\n","Current batch: Loss-> 0.9653, Train accuracy->  47.70%\n","Current batch: Loss-> 0.8722, Train accuracy->  47.80%\n","Current batch: Loss-> 0.6832, Train accuracy->  47.91%\n","Current batch: Loss-> 0.7211, Train accuracy->  48.02%\n","Current batch: Loss-> 0.7037, Train accuracy->  48.13%\n","Current batch: Loss-> 1.0104, Train accuracy->  48.21%\n","Current batch: Loss-> 0.7053, Train accuracy->  48.31%\n","Current batch: Loss-> 0.7013, Train accuracy->  48.41%\n","Current batch: Loss-> 0.8601, Train accuracy->  48.51%\n","Current batch: Loss-> 0.6740, Train accuracy->  48.61%\n","Current batch: Loss-> 0.5401, Train accuracy->  48.72%\n","Current batch: Loss-> 1.0205, Train accuracy->  48.81%\n","Current batch: Loss-> 1.0394, Train accuracy->  48.90%\n","Current batch: Loss-> 0.6551, Train accuracy->  49.00%\n","Current batch: Loss-> 0.7122, Train accuracy->  49.10%\n","Current batch: Loss-> 1.1591, Train accuracy->  49.20%\n","Current batch: Loss-> 1.0011, Train accuracy->  49.28%\n","Current batch: Loss-> 0.8119, Train accuracy->  49.39%\n","Current batch: Loss-> 0.6973, Train accuracy->  49.49%\n","Current batch: Loss-> 0.9303, Train accuracy->  49.59%\n","Current batch: Loss-> 0.5409, Train accuracy->  49.70%\n","Current batch: Loss-> 0.7401, Train accuracy->  49.81%\n","Current batch: Loss-> 1.0652, Train accuracy->  49.89%\n","Current batch: Loss-> 0.5257, Train accuracy->  50.00%\n","Current batch: Loss-> 0.7169, Train accuracy->  50.11%\n","Current batch: Loss-> 0.7929, Train accuracy->  50.22%\n","Current batch: Loss-> 0.7921, Train accuracy->  50.33%\n","Current batch: Loss-> 0.7437, Train accuracy->  50.43%\n","Current batch: Loss-> 0.5488, Train accuracy->  50.54%\n","Current batch: Loss-> 0.8173, Train accuracy->  50.64%\n","Current batch: Loss-> 0.7610, Train accuracy->  50.74%\n","Current batch: Loss-> 0.9462, Train accuracy->  50.84%\n","Current batch: Loss-> 0.6496, Train accuracy->  50.95%\n","Current batch: Loss-> 0.5915, Train accuracy->  51.05%\n","Current batch: Loss-> 0.7042, Train accuracy->  51.16%\n","Current batch: Loss-> 0.6141, Train accuracy->  51.27%\n","Current batch: Loss-> 0.7817, Train accuracy->  51.37%\n","Current batch: Loss-> 0.7976, Train accuracy->  51.46%\n","Current batch: Loss-> 0.6980, Train accuracy->  51.57%\n","Current batch: Loss-> 0.6281, Train accuracy->  51.67%\n","Current batch: Loss-> 0.6897, Train accuracy->  51.78%\n","Current batch: Loss-> 0.6954, Train accuracy->  51.87%\n","Current batch: Loss-> 0.8104, Train accuracy->  51.97%\n","Current batch: Loss-> 0.5339, Train accuracy->  52.09%\n","Current batch: Loss-> 0.7772, Train accuracy->  52.19%\n","Current batch: Loss-> 0.7392, Train accuracy->  52.30%\n","Current batch: Loss-> 0.8241, Train accuracy->  52.39%\n","Current batch: Loss-> 0.9210, Train accuracy->  52.49%\n","Current batch: Loss-> 0.7095, Train accuracy->  52.59%\n","Current batch: Loss-> 0.6688, Train accuracy->  52.69%\n","Current batch: Loss-> 0.7126, Train accuracy->  52.80%\n","Current batch: Loss-> 0.6752, Train accuracy->  52.90%\n","Current batch: Loss-> 0.6025, Train accuracy->  52.99%\n","Current batch: Loss-> 0.4384, Train accuracy->  53.11%\n","Current batch: Loss-> 0.5036, Train accuracy->  53.21%\n","Current batch: Loss-> 0.6104, Train accuracy->  53.32%\n","Current batch: Loss-> 0.9177, Train accuracy->  53.42%\n","Current batch: Loss-> 0.7347, Train accuracy->  53.52%\n","Current batch: Loss-> 0.4625, Train accuracy->  53.63%\n","Current batch: Loss-> 0.7089, Train accuracy->  53.74%\n","Current batch: Loss-> 0.8306, Train accuracy->  53.84%\n","Current batch: Loss-> 0.7690, Train accuracy->  53.95%\n","Current batch: Loss-> 0.9953, Train accuracy->  54.05%\n","Current batch: Loss-> 0.7680, Train accuracy->  54.15%\n","Current batch: Loss-> 0.5459, Train accuracy->  54.26%\n","Current batch: Loss-> 0.6729, Train accuracy->  54.36%\n","Current batch: Loss-> 0.5943, Train accuracy->  54.47%\n","Current batch: Loss-> 0.8949, Train accuracy->  54.57%\n","Current batch: Loss-> 0.5278, Train accuracy->  54.68%\n","Current batch: Loss-> 0.8002, Train accuracy->  54.78%\n","Current batch: Loss-> 0.3861, Train accuracy->  54.90%\n","Current batch: Loss-> 0.7001, Train accuracy->  55.01%\n","Current batch: Loss-> 0.5098, Train accuracy->  55.11%\n","Current batch: Loss-> 0.8314, Train accuracy->  55.22%\n","Current batch: Loss-> 0.6426, Train accuracy->  55.33%\n","Current batch: Loss-> 0.5926, Train accuracy->  55.44%\n","Current batch: Loss-> 0.4922, Train accuracy->  55.55%\n","Current batch: Loss-> 0.6462, Train accuracy->  55.66%\n","Current batch: Loss-> 0.7624, Train accuracy->  55.76%\n","Current batch: Loss-> 0.7226, Train accuracy->  55.86%\n","Current batch: Loss-> 1.0440, Train accuracy->  55.95%\n","Current batch: Loss-> 0.4814, Train accuracy->  56.07%\n","Current batch: Loss-> 0.8453, Train accuracy->  56.17%\n","Current batch: Loss-> 0.6028, Train accuracy->  56.27%\n","Current batch: Loss-> 0.7219, Train accuracy->  56.39%\n","Current batch: Loss-> 0.5775, Train accuracy->  56.50%\n","Current batch: Loss-> 0.4838, Train accuracy->  56.61%\n","Current batch: Loss-> 1.0518, Train accuracy->  56.70%\n","Current batch: Loss-> 0.7341, Train accuracy->  56.80%\n","Current batch: Loss-> 0.7489, Train accuracy->  56.89%\n","Current batch: Loss-> 0.6146, Train accuracy->  57.00%\n","Current batch: Loss-> 0.6941, Train accuracy->  57.11%\n","Current batch: Loss-> 1.0148, Train accuracy->  57.20%\n","Current batch: Loss-> 0.7175, Train accuracy->  57.30%\n","Current batch: Loss-> 0.9244, Train accuracy->  57.39%\n","Current batch: Loss-> 0.7873, Train accuracy->  57.50%\n","Current batch: Loss-> 0.6166, Train accuracy->  57.61%\n","Current batch: Loss-> 0.7403, Train accuracy->  57.70%\n","Current batch: Loss-> 0.6018, Train accuracy->  57.81%\n","Current batch: Loss-> 0.9009, Train accuracy->  57.90%\n","Current batch: Loss-> 0.6083, Train accuracy->  58.01%\n","Current batch: Loss-> 0.9525, Train accuracy->  58.11%\n","Current batch: Loss-> 1.0146, Train accuracy->  58.20%\n","Current batch: Loss-> 1.0297, Train accuracy->  58.31%\n","Current batch: Loss-> 0.5489, Train accuracy->  58.43%\n","Current batch: Loss-> 1.1674, Train accuracy->  58.54%\n","Current batch: Loss-> 0.6251, Train accuracy->  58.64%\n","Current batch: Loss-> 0.6308, Train accuracy->  58.74%\n","Current batch: Loss-> 0.6233, Train accuracy->  58.85%\n","Current batch: Loss-> 0.6514, Train accuracy->  58.95%\n","Current batch: Loss-> 0.6348, Train accuracy->  59.06%\n","Current batch: Loss-> 0.8734, Train accuracy->  59.16%\n","Current batch: Loss-> 0.6860, Train accuracy->  59.26%\n","Current batch: Loss-> 0.5283, Train accuracy->  59.37%\n","Current batch: Loss-> 0.6424, Train accuracy->  59.48%\n","Current batch: Loss-> 0.6289, Train accuracy->  59.59%\n","Current batch: Loss-> 0.8277, Train accuracy->  59.69%\n","Current batch: Loss-> 0.6366, Train accuracy->  59.79%\n","Current batch: Loss-> 0.8085, Train accuracy->  59.89%\n","Current batch: Loss-> 0.7706, Train accuracy->  59.99%\n","Current batch: Loss-> 0.9100, Train accuracy->  60.09%\n","Current batch: Loss-> 0.8066, Train accuracy->  60.20%\n","Current batch: Loss-> 0.6731, Train accuracy->  60.30%\n","Current batch: Loss-> 0.8261, Train accuracy->  60.39%\n","Current batch: Loss-> 0.7662, Train accuracy->  60.49%\n","Current batch: Loss-> 0.8164, Train accuracy->  60.59%\n","Current batch: Loss-> 0.8242, Train accuracy->  60.69%\n","Current batch: Loss-> 0.7402, Train accuracy->  60.80%\n","Current batch: Loss-> 0.4903, Train accuracy->  60.91%\n","Current batch: Loss-> 0.8428, Train accuracy->  61.00%\n","Current batch: Loss-> 0.5478, Train accuracy->  61.11%\n","Current batch: Loss-> 0.6946, Train accuracy->  61.21%\n","Current batch: Loss-> 0.6221, Train accuracy->  61.31%\n","Current batch: Loss-> 0.8770, Train accuracy->  61.41%\n","Current batch: Loss-> 0.9389, Train accuracy->  61.51%\n","Current batch: Loss-> 0.5362, Train accuracy->  61.62%\n","Current batch: Loss-> 0.6002, Train accuracy->  61.73%\n","Current batch: Loss-> 0.5400, Train accuracy->  61.84%\n","Current batch: Loss-> 0.9584, Train accuracy->  61.94%\n","Current batch: Loss-> 0.7459, Train accuracy->  62.04%\n","Current batch: Loss-> 0.6051, Train accuracy->  62.14%\n","Current batch: Loss-> 0.4401, Train accuracy->  62.25%\n","Current batch: Loss-> 0.6642, Train accuracy->  62.35%\n","Current batch: Loss-> 0.8356, Train accuracy->  62.45%\n","Current batch: Loss-> 0.7977, Train accuracy->  62.56%\n","Current batch: Loss-> 0.9019, Train accuracy->  62.66%\n","Current batch: Loss-> 0.8091, Train accuracy->  62.75%\n","Current batch: Loss-> 0.6541, Train accuracy->  62.86%\n","Current batch: Loss-> 0.9810, Train accuracy->  62.96%\n","Current batch: Loss-> 0.7091, Train accuracy->  63.06%\n","Current batch: Loss-> 0.6558, Train accuracy->  63.17%\n","Current batch: Loss-> 0.6296, Train accuracy->  63.27%\n","Current batch: Loss-> 0.7827, Train accuracy->  63.38%\n","Current batch: Loss-> 0.6942, Train accuracy->  63.48%\n","Current batch: Loss-> 0.5544, Train accuracy->  63.59%\n","Current batch: Loss-> 0.7846, Train accuracy->  63.69%\n","Current batch: Loss-> 0.6777, Train accuracy->  63.80%\n","Current batch: Loss-> 0.6976, Train accuracy->  63.90%\n","Current batch: Loss-> 0.7379, Train accuracy->  64.00%\n","Current batch: Loss-> 0.9333, Train accuracy->  64.10%\n","Current batch: Loss-> 0.8356, Train accuracy->  64.20%\n","Current batch: Loss-> 0.6656, Train accuracy->  64.29%\n","Current batch: Loss-> 0.6761, Train accuracy->  64.40%\n","Current batch: Loss-> 0.4526, Train accuracy->  64.51%\n","Current batch: Loss-> 0.7323, Train accuracy->  64.61%\n","Current batch: Loss-> 0.6255, Train accuracy->  64.72%\n","Current batch: Loss-> 0.7259, Train accuracy->  64.82%\n","Current batch: Loss-> 0.7192, Train accuracy->  64.92%\n","Current batch: Loss-> 0.9315, Train accuracy->  65.00%\n","Current batch: Loss-> 0.7261, Train accuracy->  65.10%\n","Current batch: Loss-> 0.8203, Train accuracy->  65.21%\n","Current batch: Loss-> 0.7592, Train accuracy->  65.31%\n","Current batch: Loss-> 0.5943, Train accuracy->  65.41%\n","Current batch: Loss-> 0.5660, Train accuracy->  65.52%\n","Current batch: Loss-> 0.8712, Train accuracy->  65.62%\n","Current batch: Loss-> 0.7807, Train accuracy->  65.71%\n","Current batch: Loss-> 0.5957, Train accuracy->  65.82%\n","Current batch: Loss-> 0.6231, Train accuracy->  65.93%\n","Current batch: Loss-> 0.6091, Train accuracy->  66.03%\n","Current batch: Loss-> 0.7445, Train accuracy->  66.14%\n","Current batch: Loss-> 0.7378, Train accuracy->  66.24%\n","Current batch: Loss-> 0.4123, Train accuracy->  66.36%\n","Current batch: Loss-> 0.4772, Train accuracy->  66.48%\n","Current batch: Loss-> 0.5989, Train accuracy->  66.59%\n","Current batch: Loss-> 0.9060, Train accuracy->  66.69%\n","Current batch: Loss-> 0.8058, Train accuracy->  66.79%\n","Current batch: Loss-> 0.7884, Train accuracy->  66.90%\n","Current batch: Loss-> 0.4256, Train accuracy->  67.01%\n","Current batch: Loss-> 0.6160, Train accuracy->  67.12%\n","Current batch: Loss-> 0.5885, Train accuracy->  67.22%\n","Current batch: Loss-> 0.9472, Train accuracy->  67.32%\n","Current batch: Loss-> 0.7537, Train accuracy->  67.43%\n","Current batch: Loss-> 0.6659, Train accuracy->  67.52%\n","Current batch: Loss-> 1.0048, Train accuracy->  67.62%\n","Current batch: Loss-> 0.8752, Train accuracy->  67.72%\n","Current batch: Loss-> 0.8827, Train accuracy->  67.82%\n","Current batch: Loss-> 0.6709, Train accuracy->  67.94%\n","Current batch: Loss-> 0.6630, Train accuracy->  68.04%\n","Current batch: Loss-> 0.8673, Train accuracy->  68.12%\n","Current batch: Loss-> 0.4741, Train accuracy->  68.23%\n","Current batch: Loss-> 0.7347, Train accuracy->  68.33%\n","Current batch: Loss-> 0.9467, Train accuracy->  68.43%\n","Current batch: Loss-> 0.6168, Train accuracy->  68.54%\n","Current batch: Loss-> 0.6992, Train accuracy->  68.63%\n","Current batch: Loss-> 0.5365, Train accuracy->  68.74%\n","Current batch: Loss-> 0.5834, Train accuracy->  68.85%\n","Current batch: Loss-> 0.9628, Train accuracy->  68.94%\n","Current batch: Loss-> 0.6833, Train accuracy->  69.05%\n","Current batch: Loss-> 0.5804, Train accuracy->  69.16%\n","Current batch: Loss-> 0.6091, Train accuracy->  69.26%\n","Current batch: Loss-> 0.6633, Train accuracy->  69.37%\n","Current batch: Loss-> 0.5457, Train accuracy->  69.47%\n","Current batch: Loss-> 0.7018, Train accuracy->  69.58%\n","Current batch: Loss-> 0.6428, Train accuracy->  69.68%\n","Current batch: Loss-> 0.6395, Train accuracy->  69.79%\n","Current batch: Loss-> 0.5936, Train accuracy->  69.90%\n","Current batch: Loss-> 0.6023, Train accuracy->  70.01%\n","Current batch: Loss-> 0.8400, Train accuracy->  70.10%\n","Current batch: Loss-> 0.6819, Train accuracy->  70.20%\n","Current batch: Loss-> 1.0022, Train accuracy->  70.29%\n","Current batch: Loss-> 0.9542, Train accuracy->  70.40%\n","Current batch: Loss-> 0.7553, Train accuracy->  70.49%\n","Current batch: Loss-> 0.7995, Train accuracy->  70.59%\n","Current batch: Loss-> 0.6558, Train accuracy->  70.71%\n","Current batch: Loss-> 0.7273, Train accuracy->  70.81%\n","Current batch: Loss-> 0.6566, Train accuracy->  70.91%\n","Current batch: Loss-> 0.9416, Train accuracy->  70.98%\n","Current batch: Loss-> 0.7221, Train accuracy->  71.09%\n","Current batch: Loss-> 0.8524, Train accuracy->  71.18%\n","Current batch: Loss-> 0.7769, Train accuracy->  71.28%\n","Current batch: Loss-> 0.6851, Train accuracy->  71.38%\n","Current batch: Loss-> 0.6543, Train accuracy->  71.48%\n","Current batch: Loss-> 0.7542, Train accuracy->  71.57%\n","Current batch: Loss-> 0.8343, Train accuracy->  71.67%\n","Current batch: Loss-> 0.8939, Train accuracy->  71.78%\n","Current batch: Loss-> 0.5283, Train accuracy->  71.89%\n","Current batch: Loss-> 0.7279, Train accuracy->  71.99%\n","Current batch: Loss-> 0.7291, Train accuracy->  72.09%\n","Current batch: Loss-> 0.7990, Train accuracy->  72.20%\n","Current batch: Loss-> 0.7448, Train accuracy->  72.30%\n","Current batch: Loss-> 0.9897, Train accuracy->  72.40%\n","Current batch: Loss-> 0.7289, Train accuracy->  72.51%\n","Current batch: Loss-> 0.6241, Train accuracy->  72.62%\n","Current batch: Loss-> 0.7268, Train accuracy->  72.72%\n","Current batch: Loss-> 0.8634, Train accuracy->  72.80%\n","Current batch: Loss-> 1.0372, Train accuracy->  72.89%\n","Current batch: Loss-> 0.9138, Train accuracy->  72.98%\n","Current batch: Loss-> 1.0546, Train accuracy->  73.07%\n","Current batch: Loss-> 0.7451, Train accuracy->  73.17%\n","Current batch: Loss-> 0.6761, Train accuracy->  73.27%\n","Current batch: Loss-> 0.9673, Train accuracy->  73.38%\n","Current batch: Loss-> 0.9442, Train accuracy->  73.47%\n","Current batch: Loss-> 0.8782, Train accuracy->  73.57%\n","Current batch: Loss-> 0.6879, Train accuracy->  73.68%\n","Current batch: Loss-> 0.7123, Train accuracy->  73.79%\n","Current batch: Loss-> 0.5577, Train accuracy->  73.90%\n","Current batch: Loss-> 0.8644, Train accuracy->  73.99%\n","Current batch: Loss-> 0.5908, Train accuracy->  74.09%\n","Current batch: Loss-> 1.1933, Train accuracy->  74.17%\n","Current batch: Loss-> 0.8881, Train accuracy->  74.27%\n","Current batch: Loss-> 0.5627, Train accuracy->  74.38%\n","Current batch: Loss-> 0.9015, Train accuracy->  74.47%\n","Current batch: Loss-> 0.6664, Train accuracy->  74.58%\n","Current batch: Loss-> 0.5801, Train accuracy->  74.69%\n","Current batch: Loss-> 0.6179, Train accuracy->  74.79%\n","Current batch: Loss-> 0.7493, Train accuracy->  74.90%\n","Current batch: Loss-> 0.8412, Train accuracy->  75.00%\n","Current batch: Loss-> 0.9062, Train accuracy->  75.10%\n","Current batch: Loss-> 0.7535, Train accuracy->  75.20%\n","Current batch: Loss-> 0.8815, Train accuracy->  75.31%\n","Current batch: Loss-> 1.1411, Train accuracy->  75.40%\n","Current batch: Loss-> 0.6657, Train accuracy->  75.50%\n","Current batch: Loss-> 0.8701, Train accuracy->  75.60%\n","Current batch: Loss-> 0.8357, Train accuracy->  75.70%\n","Current batch: Loss-> 0.7098, Train accuracy->  75.80%\n","Current batch: Loss-> 0.9068, Train accuracy->  75.91%\n","Current batch: Loss-> 0.6689, Train accuracy->  76.02%\n","Current batch: Loss-> 0.7143, Train accuracy->  76.12%\n","Current batch: Loss-> 0.6484, Train accuracy->  76.23%\n","Current batch: Loss-> 0.6897, Train accuracy->  76.33%\n","Current batch: Loss-> 0.8214, Train accuracy->  76.44%\n","Current batch: Loss-> 0.5530, Train accuracy->  76.55%\n","Current batch: Loss-> 0.6693, Train accuracy->  76.65%\n","Current batch: Loss-> 0.5985, Train accuracy->  76.75%\n","Current batch: Loss-> 0.7590, Train accuracy->  76.85%\n","Current batch: Loss-> 0.4678, Train accuracy->  76.96%\n","Current batch: Loss-> 0.7758, Train accuracy->  77.05%\n","Current batch: Loss-> 0.8184, Train accuracy->  77.15%\n","Current batch: Loss-> 0.5536, Train accuracy->  77.26%\n","Current batch: Loss-> 0.5747, Train accuracy->  77.38%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 48.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.7841, Train accuracy->  77.47%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.95it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.7863, Accuracy: 5346/12000 (45%)\n","\n","Current batch: Loss-> 0.9746, Train accuracy->   0.10%\n","Current batch: Loss-> 0.7234, Train accuracy->   0.20%\n","Current batch: Loss-> 0.6976, Train accuracy->   0.31%\n","Current batch: Loss-> 0.7358, Train accuracy->   0.42%\n","Current batch: Loss-> 0.4372, Train accuracy->   0.54%\n","Current batch: Loss-> 0.5187, Train accuracy->   0.64%\n","Current batch: Loss-> 0.6673, Train accuracy->   0.74%\n","Current batch: Loss-> 0.7504, Train accuracy->   0.84%\n","Current batch: Loss-> 0.8388, Train accuracy->   0.95%\n","Current batch: Loss-> 0.9034, Train accuracy->   1.05%\n","Current batch: Loss-> 0.6273, Train accuracy->   1.16%\n","Current batch: Loss-> 0.4626, Train accuracy->   1.27%\n","Current batch: Loss-> 0.6651, Train accuracy->   1.37%\n","Current batch: Loss-> 0.5417, Train accuracy->   1.49%\n","Current batch: Loss-> 0.9945, Train accuracy->   1.58%\n","Current batch: Loss-> 0.6202, Train accuracy->   1.67%\n","Current batch: Loss-> 0.6904, Train accuracy->   1.77%\n","Current batch: Loss-> 0.6095, Train accuracy->   1.88%\n","Current batch: Loss-> 0.5183, Train accuracy->   2.00%\n","Current batch: Loss-> 0.6944, Train accuracy->   2.11%\n","Current batch: Loss-> 0.7084, Train accuracy->   2.21%\n","Current batch: Loss-> 0.5901, Train accuracy->   2.32%\n","Current batch: Loss-> 0.6137, Train accuracy->   2.43%\n","Current batch: Loss-> 0.7396, Train accuracy->   2.53%\n","Current batch: Loss-> 0.8864, Train accuracy->   2.64%\n","Current batch: Loss-> 0.6797, Train accuracy->   2.74%\n","Current batch: Loss-> 0.5627, Train accuracy->   2.85%\n","Current batch: Loss-> 0.6512, Train accuracy->   2.96%\n","Current batch: Loss-> 0.6743, Train accuracy->   3.05%\n","Current batch: Loss-> 0.6248, Train accuracy->   3.15%\n","Current batch: Loss-> 0.5730, Train accuracy->   3.27%\n","Current batch: Loss-> 0.7406, Train accuracy->   3.37%\n","Current batch: Loss-> 0.9461, Train accuracy->   3.47%\n","Current batch: Loss-> 0.8527, Train accuracy->   3.56%\n","Current batch: Loss-> 0.4651, Train accuracy->   3.67%\n","Current batch: Loss-> 0.8442, Train accuracy->   3.77%\n","Current batch: Loss-> 0.6701, Train accuracy->   3.88%\n","Current batch: Loss-> 0.6552, Train accuracy->   3.98%\n","Current batch: Loss-> 0.6835, Train accuracy->   4.08%\n","Current batch: Loss-> 0.3883, Train accuracy->   4.19%\n","Current batch: Loss-> 0.6164, Train accuracy->   4.31%\n","Current batch: Loss-> 0.9049, Train accuracy->   4.41%\n","Current batch: Loss-> 0.9013, Train accuracy->   4.51%\n","Current batch: Loss-> 0.7365, Train accuracy->   4.62%\n","Current batch: Loss-> 0.4333, Train accuracy->   4.73%\n","Current batch: Loss-> 0.5090, Train accuracy->   4.84%\n","Current batch: Loss-> 0.5076, Train accuracy->   4.95%\n","Current batch: Loss-> 0.4782, Train accuracy->   5.06%\n","Current batch: Loss-> 0.6048, Train accuracy->   5.17%\n","Current batch: Loss-> 0.5472, Train accuracy->   5.28%\n","Current batch: Loss-> 0.7720, Train accuracy->   5.38%\n","Current batch: Loss-> 0.6538, Train accuracy->   5.50%\n","Current batch: Loss-> 0.6877, Train accuracy->   5.60%\n","Current batch: Loss-> 0.5020, Train accuracy->   5.71%\n","Current batch: Loss-> 0.4549, Train accuracy->   5.83%\n","Current batch: Loss-> 0.7751, Train accuracy->   5.93%\n","Current batch: Loss-> 0.7292, Train accuracy->   6.03%\n","Current batch: Loss-> 0.5414, Train accuracy->   6.14%\n","Current batch: Loss-> 0.8164, Train accuracy->   6.23%\n","Current batch: Loss-> 0.5179, Train accuracy->   6.34%\n","Current batch: Loss-> 0.6567, Train accuracy->   6.44%\n","Current batch: Loss-> 0.8455, Train accuracy->   6.53%\n","Current batch: Loss-> 0.6046, Train accuracy->   6.65%\n","Current batch: Loss-> 0.6919, Train accuracy->   6.75%\n","Current batch: Loss-> 0.9335, Train accuracy->   6.86%\n","Current batch: Loss-> 0.6328, Train accuracy->   6.97%\n","Current batch: Loss-> 0.8206, Train accuracy->   7.07%\n","Current batch: Loss-> 0.8670, Train accuracy->   7.17%\n","Current batch: Loss-> 0.6899, Train accuracy->   7.28%\n","Current batch: Loss-> 0.5026, Train accuracy->   7.39%\n","Current batch: Loss-> 0.5924, Train accuracy->   7.50%\n","Current batch: Loss-> 0.9971, Train accuracy->   7.58%\n","Current batch: Loss-> 0.5099, Train accuracy->   7.70%\n","Current batch: Loss-> 0.4475, Train accuracy->   7.81%\n","Current batch: Loss-> 0.5400, Train accuracy->   7.92%\n","Current batch: Loss-> 0.8633, Train accuracy->   8.03%\n","Current batch: Loss-> 0.5116, Train accuracy->   8.14%\n","Current batch: Loss-> 0.8499, Train accuracy->   8.25%\n","Current batch: Loss-> 0.4618, Train accuracy->   8.36%\n","Current batch: Loss-> 0.8291, Train accuracy->   8.46%\n","Current batch: Loss-> 0.6772, Train accuracy->   8.56%\n","Current batch: Loss-> 0.7707, Train accuracy->   8.65%\n","Current batch: Loss-> 0.7518, Train accuracy->   8.75%\n","Current batch: Loss-> 0.6466, Train accuracy->   8.86%\n","Current batch: Loss-> 0.6364, Train accuracy->   8.96%\n","Current batch: Loss-> 0.8092, Train accuracy->   9.05%\n","Current batch: Loss-> 0.8000, Train accuracy->   9.16%\n","Current batch: Loss-> 0.9971, Train accuracy->   9.25%\n","Current batch: Loss-> 0.5341, Train accuracy->   9.36%\n","Current batch: Loss-> 1.0846, Train accuracy->   9.47%\n","Current batch: Loss-> 0.5904, Train accuracy->   9.59%\n","Current batch: Loss-> 0.4782, Train accuracy->   9.70%\n","Current batch: Loss-> 0.7086, Train accuracy->   9.81%\n","Current batch: Loss-> 0.7525, Train accuracy->   9.91%\n","Current batch: Loss-> 1.0560, Train accuracy->  10.01%\n","Current batch: Loss-> 0.7153, Train accuracy->  10.12%\n","Current batch: Loss-> 0.6501, Train accuracy->  10.24%\n","Current batch: Loss-> 0.5665, Train accuracy->  10.34%\n","Current batch: Loss-> 0.6886, Train accuracy->  10.45%\n","Current batch: Loss-> 0.8050, Train accuracy->  10.54%\n","Current batch: Loss-> 0.5035, Train accuracy->  10.65%\n","Current batch: Loss-> 0.7313, Train accuracy->  10.75%\n","Current batch: Loss-> 0.6802, Train accuracy->  10.85%\n","Current batch: Loss-> 0.6882, Train accuracy->  10.95%\n","Current batch: Loss-> 0.6204, Train accuracy->  11.05%\n","Current batch: Loss-> 0.9865, Train accuracy->  11.15%\n","Current batch: Loss-> 0.7153, Train accuracy->  11.26%\n","Current batch: Loss-> 0.6857, Train accuracy->  11.37%\n","Current batch: Loss-> 1.0931, Train accuracy->  11.46%\n","Current batch: Loss-> 0.6779, Train accuracy->  11.57%\n","Current batch: Loss-> 0.9280, Train accuracy->  11.66%\n","Current batch: Loss-> 1.2068, Train accuracy->  11.76%\n","Current batch: Loss-> 0.5513, Train accuracy->  11.87%\n","Current batch: Loss-> 0.6338, Train accuracy->  11.98%\n","Current batch: Loss-> 0.9820, Train accuracy->  12.07%\n","Current batch: Loss-> 0.6359, Train accuracy->  12.18%\n","Current batch: Loss-> 0.6495, Train accuracy->  12.29%\n","Current batch: Loss-> 0.6576, Train accuracy->  12.40%\n","Current batch: Loss-> 0.5051, Train accuracy->  12.50%\n","Current batch: Loss-> 0.4695, Train accuracy->  12.62%\n","Current batch: Loss-> 0.9407, Train accuracy->  12.72%\n","Current batch: Loss-> 0.7015, Train accuracy->  12.81%\n","Current batch: Loss-> 0.8517, Train accuracy->  12.92%\n","Current batch: Loss-> 0.4533, Train accuracy->  13.03%\n","Current batch: Loss-> 0.8318, Train accuracy->  13.12%\n","Current batch: Loss-> 0.5434, Train accuracy->  13.23%\n","Current batch: Loss-> 0.5452, Train accuracy->  13.34%\n","Current batch: Loss-> 0.8299, Train accuracy->  13.45%\n","Current batch: Loss-> 0.4509, Train accuracy->  13.56%\n","Current batch: Loss-> 0.4950, Train accuracy->  13.68%\n","Current batch: Loss-> 0.9869, Train accuracy->  13.77%\n","Current batch: Loss-> 0.6012, Train accuracy->  13.88%\n","Current batch: Loss-> 1.3086, Train accuracy->  13.96%\n","Current batch: Loss-> 0.5912, Train accuracy->  14.07%\n","Current batch: Loss-> 1.0666, Train accuracy->  14.17%\n","Current batch: Loss-> 0.5702, Train accuracy->  14.29%\n","Current batch: Loss-> 0.9043, Train accuracy->  14.38%\n","Current batch: Loss-> 0.7943, Train accuracy->  14.48%\n","Current batch: Loss-> 0.6560, Train accuracy->  14.59%\n","Current batch: Loss-> 0.6643, Train accuracy->  14.70%\n","Current batch: Loss-> 0.5074, Train accuracy->  14.81%\n","Current batch: Loss-> 0.5155, Train accuracy->  14.92%\n","Current batch: Loss-> 0.8338, Train accuracy->  15.02%\n","Current batch: Loss-> 0.3815, Train accuracy->  15.14%\n","Current batch: Loss-> 0.5118, Train accuracy->  15.24%\n","Current batch: Loss-> 0.6506, Train accuracy->  15.34%\n","Current batch: Loss-> 0.5307, Train accuracy->  15.45%\n","Current batch: Loss-> 0.6032, Train accuracy->  15.56%\n","Current batch: Loss-> 0.7709, Train accuracy->  15.65%\n","Current batch: Loss-> 0.5832, Train accuracy->  15.76%\n","Current batch: Loss-> 0.5373, Train accuracy->  15.87%\n","Current batch: Loss-> 0.7664, Train accuracy->  15.97%\n","Current batch: Loss-> 0.5321, Train accuracy->  16.08%\n","Current batch: Loss-> 1.0483, Train accuracy->  16.19%\n","Current batch: Loss-> 0.5644, Train accuracy->  16.29%\n","Current batch: Loss-> 0.6142, Train accuracy->  16.40%\n","Current batch: Loss-> 0.8635, Train accuracy->  16.51%\n","Current batch: Loss-> 0.8427, Train accuracy->  16.60%\n","Current batch: Loss-> 0.4776, Train accuracy->  16.72%\n","Current batch: Loss-> 0.7391, Train accuracy->  16.82%\n","Current batch: Loss-> 0.4525, Train accuracy->  16.93%\n","Current batch: Loss-> 0.5721, Train accuracy->  17.04%\n","Current batch: Loss-> 0.4594, Train accuracy->  17.15%\n","Current batch: Loss-> 0.5806, Train accuracy->  17.27%\n","Current batch: Loss-> 0.6088, Train accuracy->  17.38%\n","Current batch: Loss-> 0.5750, Train accuracy->  17.49%\n","Current batch: Loss-> 0.7775, Train accuracy->  17.58%\n","Current batch: Loss-> 0.6540, Train accuracy->  17.68%\n","Current batch: Loss-> 0.6551, Train accuracy->  17.78%\n","Current batch: Loss-> 0.5637, Train accuracy->  17.89%\n","Current batch: Loss-> 0.7934, Train accuracy->  17.99%\n","Current batch: Loss-> 1.0824, Train accuracy->  18.09%\n","Current batch: Loss-> 0.7251, Train accuracy->  18.19%\n","Current batch: Loss-> 0.6717, Train accuracy->  18.30%\n","Current batch: Loss-> 0.5041, Train accuracy->  18.41%\n","Current batch: Loss-> 0.5623, Train accuracy->  18.51%\n","Current batch: Loss-> 0.9909, Train accuracy->  18.61%\n","Current batch: Loss-> 0.8212, Train accuracy->  18.71%\n","Current batch: Loss-> 0.9014, Train accuracy->  18.81%\n","Current batch: Loss-> 0.8101, Train accuracy->  18.90%\n","Current batch: Loss-> 0.9184, Train accuracy->  18.99%\n","Current batch: Loss-> 0.7340, Train accuracy->  19.10%\n","Current batch: Loss-> 0.7745, Train accuracy->  19.20%\n","Current batch: Loss-> 0.7611, Train accuracy->  19.30%\n","Current batch: Loss-> 0.6831, Train accuracy->  19.41%\n","Current batch: Loss-> 0.6081, Train accuracy->  19.52%\n","Current batch: Loss-> 0.5246, Train accuracy->  19.63%\n","Current batch: Loss-> 0.5604, Train accuracy->  19.74%\n","Current batch: Loss-> 0.7930, Train accuracy->  19.84%\n","Current batch: Loss-> 0.6888, Train accuracy->  19.95%\n","Current batch: Loss-> 0.5617, Train accuracy->  20.05%\n","Current batch: Loss-> 0.6398, Train accuracy->  20.16%\n","Current batch: Loss-> 0.5954, Train accuracy->  20.26%\n","Current batch: Loss-> 0.6671, Train accuracy->  20.38%\n","Current batch: Loss-> 0.6661, Train accuracy->  20.49%\n","Current batch: Loss-> 0.5857, Train accuracy->  20.60%\n","Current batch: Loss-> 0.5870, Train accuracy->  20.71%\n","Current batch: Loss-> 0.7372, Train accuracy->  20.81%\n","Current batch: Loss-> 0.6622, Train accuracy->  20.92%\n","Current batch: Loss-> 0.7190, Train accuracy->  21.03%\n","Current batch: Loss-> 0.6903, Train accuracy->  21.14%\n","Current batch: Loss-> 0.6267, Train accuracy->  21.24%\n","Current batch: Loss-> 0.5414, Train accuracy->  21.35%\n","Current batch: Loss-> 0.7232, Train accuracy->  21.45%\n","Current batch: Loss-> 0.6722, Train accuracy->  21.56%\n","Current batch: Loss-> 1.0357, Train accuracy->  21.65%\n","Current batch: Loss-> 0.9020, Train accuracy->  21.76%\n","Current batch: Loss-> 0.5820, Train accuracy->  21.87%\n","Current batch: Loss-> 0.5717, Train accuracy->  21.98%\n","Current batch: Loss-> 0.9653, Train accuracy->  22.07%\n","Current batch: Loss-> 0.8062, Train accuracy->  22.18%\n","Current batch: Loss-> 0.5823, Train accuracy->  22.29%\n","Current batch: Loss-> 0.8598, Train accuracy->  22.39%\n","Current batch: Loss-> 0.8794, Train accuracy->  22.50%\n","Current batch: Loss-> 0.7861, Train accuracy->  22.59%\n","Current batch: Loss-> 0.6315, Train accuracy->  22.70%\n","Current batch: Loss-> 0.8072, Train accuracy->  22.80%\n","Current batch: Loss-> 0.8069, Train accuracy->  22.90%\n","Current batch: Loss-> 0.6467, Train accuracy->  23.01%\n","Current batch: Loss-> 0.7100, Train accuracy->  23.11%\n","Current batch: Loss-> 0.5779, Train accuracy->  23.22%\n","Current batch: Loss-> 0.7897, Train accuracy->  23.32%\n","Current batch: Loss-> 0.8290, Train accuracy->  23.43%\n","Current batch: Loss-> 1.0211, Train accuracy->  23.53%\n","Current batch: Loss-> 0.6426, Train accuracy->  23.64%\n","Current batch: Loss-> 0.6256, Train accuracy->  23.75%\n","Current batch: Loss-> 0.6438, Train accuracy->  23.84%\n","Current batch: Loss-> 0.6118, Train accuracy->  23.95%\n","Current batch: Loss-> 0.5102, Train accuracy->  24.06%\n","Current batch: Loss-> 0.3885, Train accuracy->  24.18%\n","Current batch: Loss-> 0.4956, Train accuracy->  24.29%\n","Current batch: Loss-> 0.5861, Train accuracy->  24.40%\n","Current batch: Loss-> 0.7948, Train accuracy->  24.50%\n","Current batch: Loss-> 0.7354, Train accuracy->  24.61%\n","Current batch: Loss-> 0.7392, Train accuracy->  24.72%\n","Current batch: Loss-> 0.7372, Train accuracy->  24.81%\n","Current batch: Loss-> 0.6194, Train accuracy->  24.91%\n","Current batch: Loss-> 0.6274, Train accuracy->  25.02%\n","Current batch: Loss-> 0.9451, Train accuracy->  25.12%\n","Current batch: Loss-> 0.7742, Train accuracy->  25.22%\n","Current batch: Loss-> 0.5305, Train accuracy->  25.32%\n","Current batch: Loss-> 1.0334, Train accuracy->  25.42%\n","Current batch: Loss-> 0.7946, Train accuracy->  25.52%\n","Current batch: Loss-> 0.7597, Train accuracy->  25.62%\n","Current batch: Loss-> 0.5797, Train accuracy->  25.74%\n","Current batch: Loss-> 0.5286, Train accuracy->  25.85%\n","Current batch: Loss-> 0.9249, Train accuracy->  25.95%\n","Current batch: Loss-> 0.5690, Train accuracy->  26.06%\n","Current batch: Loss-> 0.6140, Train accuracy->  26.17%\n","Current batch: Loss-> 0.6746, Train accuracy->  26.28%\n","Current batch: Loss-> 1.1483, Train accuracy->  26.37%\n","Current batch: Loss-> 0.6980, Train accuracy->  26.48%\n","Current batch: Loss-> 1.1821, Train accuracy->  26.56%\n","Current batch: Loss-> 0.4551, Train accuracy->  26.68%\n","Current batch: Loss-> 0.6369, Train accuracy->  26.79%\n","Current batch: Loss-> 0.6794, Train accuracy->  26.90%\n","Current batch: Loss-> 0.6625, Train accuracy->  27.01%\n","Current batch: Loss-> 0.6001, Train accuracy->  27.12%\n","Current batch: Loss-> 0.5505, Train accuracy->  27.23%\n","Current batch: Loss-> 0.4547, Train accuracy->  27.35%\n","Current batch: Loss-> 0.6802, Train accuracy->  27.45%\n","Current batch: Loss-> 0.5975, Train accuracy->  27.56%\n","Current batch: Loss-> 0.4793, Train accuracy->  27.67%\n","Current batch: Loss-> 0.5530, Train accuracy->  27.78%\n","Current batch: Loss-> 0.7487, Train accuracy->  27.89%\n","Current batch: Loss-> 0.7114, Train accuracy->  27.99%\n","Current batch: Loss-> 0.7309, Train accuracy->  28.09%\n","Current batch: Loss-> 0.7100, Train accuracy->  28.19%\n","Current batch: Loss-> 0.5766, Train accuracy->  28.30%\n","Current batch: Loss-> 0.7226, Train accuracy->  28.41%\n","Current batch: Loss-> 0.6127, Train accuracy->  28.52%\n","Current batch: Loss-> 0.7417, Train accuracy->  28.62%\n","Current batch: Loss-> 0.4966, Train accuracy->  28.74%\n","Current batch: Loss-> 0.6623, Train accuracy->  28.85%\n","Current batch: Loss-> 0.7644, Train accuracy->  28.95%\n","Current batch: Loss-> 0.7104, Train accuracy->  29.05%\n","Current batch: Loss-> 0.7598, Train accuracy->  29.16%\n","Current batch: Loss-> 0.5188, Train accuracy->  29.27%\n","Current batch: Loss-> 0.6181, Train accuracy->  29.38%\n","Current batch: Loss-> 0.5769, Train accuracy->  29.49%\n","Current batch: Loss-> 0.7153, Train accuracy->  29.59%\n","Current batch: Loss-> 0.6079, Train accuracy->  29.70%\n","Current batch: Loss-> 0.6344, Train accuracy->  29.82%\n","Current batch: Loss-> 0.6004, Train accuracy->  29.93%\n","Current batch: Loss-> 0.6665, Train accuracy->  30.04%\n","Current batch: Loss-> 0.7602, Train accuracy->  30.14%\n","Current batch: Loss-> 0.6974, Train accuracy->  30.24%\n","Current batch: Loss-> 0.6603, Train accuracy->  30.34%\n","Current batch: Loss-> 0.6936, Train accuracy->  30.45%\n","Current batch: Loss-> 0.4392, Train accuracy->  30.56%\n","Current batch: Loss-> 0.7749, Train accuracy->  30.66%\n","Current batch: Loss-> 0.5563, Train accuracy->  30.77%\n","Current batch: Loss-> 0.7725, Train accuracy->  30.87%\n","Current batch: Loss-> 0.6977, Train accuracy->  30.98%\n","Current batch: Loss-> 0.7257, Train accuracy->  31.08%\n","Current batch: Loss-> 0.6993, Train accuracy->  31.19%\n","Current batch: Loss-> 0.6167, Train accuracy->  31.30%\n","Current batch: Loss-> 0.4992, Train accuracy->  31.42%\n","Current batch: Loss-> 0.7271, Train accuracy->  31.52%\n","Current batch: Loss-> 0.8408, Train accuracy->  31.63%\n","Current batch: Loss-> 0.5883, Train accuracy->  31.73%\n","Current batch: Loss-> 0.6172, Train accuracy->  31.85%\n","Current batch: Loss-> 0.5099, Train accuracy->  31.96%\n","Current batch: Loss-> 0.6078, Train accuracy->  32.07%\n","Current batch: Loss-> 0.5157, Train accuracy->  32.18%\n","Current batch: Loss-> 0.7061, Train accuracy->  32.29%\n","Current batch: Loss-> 0.5188, Train accuracy->  32.40%\n","Current batch: Loss-> 0.5830, Train accuracy->  32.50%\n","Current batch: Loss-> 0.7424, Train accuracy->  32.61%\n","Current batch: Loss-> 0.7256, Train accuracy->  32.71%\n","Current batch: Loss-> 0.5832, Train accuracy->  32.82%\n","Current batch: Loss-> 0.7711, Train accuracy->  32.92%\n","Current batch: Loss-> 0.7953, Train accuracy->  33.01%\n","Current batch: Loss-> 0.6266, Train accuracy->  33.12%\n","Current batch: Loss-> 0.6689, Train accuracy->  33.22%\n","Current batch: Loss-> 0.6452, Train accuracy->  33.33%\n","Current batch: Loss-> 0.6569, Train accuracy->  33.44%\n","Current batch: Loss-> 0.5137, Train accuracy->  33.55%\n","Current batch: Loss-> 0.7623, Train accuracy->  33.66%\n","Current batch: Loss-> 0.9859, Train accuracy->  33.74%\n","Current batch: Loss-> 0.4896, Train accuracy->  33.86%\n","Current batch: Loss-> 0.6231, Train accuracy->  33.96%\n","Current batch: Loss-> 0.5109, Train accuracy->  34.08%\n","Current batch: Loss-> 1.0108, Train accuracy->  34.17%\n","Current batch: Loss-> 0.5791, Train accuracy->  34.29%\n","Current batch: Loss-> 0.5577, Train accuracy->  34.40%\n","Current batch: Loss-> 0.7198, Train accuracy->  34.51%\n","Current batch: Loss-> 0.8148, Train accuracy->  34.61%\n","Current batch: Loss-> 0.5585, Train accuracy->  34.72%\n","Current batch: Loss-> 0.7214, Train accuracy->  34.82%\n","Current batch: Loss-> 0.5411, Train accuracy->  34.93%\n","Current batch: Loss-> 0.8314, Train accuracy->  35.02%\n","Current batch: Loss-> 0.7372, Train accuracy->  35.13%\n","Current batch: Loss-> 0.7543, Train accuracy->  35.23%\n","Current batch: Loss-> 0.5398, Train accuracy->  35.34%\n","Current batch: Loss-> 0.6353, Train accuracy->  35.44%\n","Current batch: Loss-> 0.6100, Train accuracy->  35.55%\n","Current batch: Loss-> 0.6463, Train accuracy->  35.66%\n","Current batch: Loss-> 0.5749, Train accuracy->  35.77%\n","Current batch: Loss-> 0.6682, Train accuracy->  35.87%\n","Current batch: Loss-> 0.7833, Train accuracy->  35.98%\n","Current batch: Loss-> 0.6466, Train accuracy->  36.09%\n","Current batch: Loss-> 0.7289, Train accuracy->  36.19%\n","Current batch: Loss-> 0.7072, Train accuracy->  36.28%\n","Current batch: Loss-> 0.6443, Train accuracy->  36.39%\n","Current batch: Loss-> 0.5572, Train accuracy->  36.50%\n","Current batch: Loss-> 0.4961, Train accuracy->  36.61%\n","Current batch: Loss-> 0.7223, Train accuracy->  36.71%\n","Current batch: Loss-> 1.2493, Train accuracy->  36.79%\n","Current batch: Loss-> 0.6071, Train accuracy->  36.90%\n","Current batch: Loss-> 0.6881, Train accuracy->  37.00%\n","Current batch: Loss-> 1.1685, Train accuracy->  37.09%\n","Current batch: Loss-> 0.6853, Train accuracy->  37.20%\n","Current batch: Loss-> 0.5350, Train accuracy->  37.31%\n","Current batch: Loss-> 0.7150, Train accuracy->  37.41%\n","Current batch: Loss-> 0.9566, Train accuracy->  37.51%\n","Current batch: Loss-> 0.8663, Train accuracy->  37.61%\n","Current batch: Loss-> 1.0132, Train accuracy->  37.71%\n","Current batch: Loss-> 0.6916, Train accuracy->  37.80%\n","Current batch: Loss-> 0.8259, Train accuracy->  37.90%\n","Current batch: Loss-> 0.5773, Train accuracy->  38.01%\n","Current batch: Loss-> 0.6991, Train accuracy->  38.12%\n","Current batch: Loss-> 0.9517, Train accuracy->  38.22%\n","Current batch: Loss-> 0.7198, Train accuracy->  38.32%\n","Current batch: Loss-> 0.7479, Train accuracy->  38.42%\n","Current batch: Loss-> 0.6376, Train accuracy->  38.53%\n","Current batch: Loss-> 0.8883, Train accuracy->  38.61%\n","Current batch: Loss-> 0.7714, Train accuracy->  38.71%\n","Current batch: Loss-> 1.0803, Train accuracy->  38.80%\n","Current batch: Loss-> 0.5911, Train accuracy->  38.91%\n","Current batch: Loss-> 0.7348, Train accuracy->  39.01%\n","Current batch: Loss-> 0.7035, Train accuracy->  39.11%\n","Current batch: Loss-> 0.7289, Train accuracy->  39.22%\n","Current batch: Loss-> 0.8818, Train accuracy->  39.31%\n","Current batch: Loss-> 0.7096, Train accuracy->  39.41%\n","Current batch: Loss-> 0.6530, Train accuracy->  39.52%\n","Current batch: Loss-> 0.6226, Train accuracy->  39.64%\n","Current batch: Loss-> 0.7069, Train accuracy->  39.74%\n","Current batch: Loss-> 0.7420, Train accuracy->  39.85%\n","Current batch: Loss-> 0.4008, Train accuracy->  39.96%\n","Current batch: Loss-> 0.5313, Train accuracy->  40.08%\n","Current batch: Loss-> 0.8567, Train accuracy->  40.18%\n","Current batch: Loss-> 0.7757, Train accuracy->  40.29%\n","Current batch: Loss-> 0.6979, Train accuracy->  40.39%\n","Current batch: Loss-> 0.7878, Train accuracy->  40.49%\n","Current batch: Loss-> 0.6949, Train accuracy->  40.60%\n","Current batch: Loss-> 0.8514, Train accuracy->  40.69%\n","Current batch: Loss-> 0.8678, Train accuracy->  40.79%\n","Current batch: Loss-> 0.5826, Train accuracy->  40.90%\n","Current batch: Loss-> 1.0076, Train accuracy->  40.99%\n","Current batch: Loss-> 0.6332, Train accuracy->  41.09%\n","Current batch: Loss-> 0.7751, Train accuracy->  41.19%\n","Current batch: Loss-> 0.5709, Train accuracy->  41.30%\n","Current batch: Loss-> 0.7744, Train accuracy->  41.40%\n","Current batch: Loss-> 0.7690, Train accuracy->  41.51%\n","Current batch: Loss-> 0.7809, Train accuracy->  41.61%\n","Current batch: Loss-> 0.7962, Train accuracy->  41.71%\n","Current batch: Loss-> 0.5724, Train accuracy->  41.82%\n","Current batch: Loss-> 0.8025, Train accuracy->  41.92%\n","Current batch: Loss-> 0.7213, Train accuracy->  42.01%\n","Current batch: Loss-> 0.5612, Train accuracy->  42.12%\n","Current batch: Loss-> 0.7123, Train accuracy->  42.21%\n","Current batch: Loss-> 0.9283, Train accuracy->  42.31%\n","Current batch: Loss-> 0.7044, Train accuracy->  42.41%\n","Current batch: Loss-> 0.8481, Train accuracy->  42.52%\n","Current batch: Loss-> 0.5259, Train accuracy->  42.63%\n","Current batch: Loss-> 0.7599, Train accuracy->  42.73%\n","Current batch: Loss-> 0.6146, Train accuracy->  42.84%\n","Current batch: Loss-> 0.8701, Train accuracy->  42.94%\n","Current batch: Loss-> 0.7351, Train accuracy->  43.03%\n","Current batch: Loss-> 0.8083, Train accuracy->  43.14%\n","Current batch: Loss-> 0.6322, Train accuracy->  43.24%\n","Current batch: Loss-> 0.8909, Train accuracy->  43.34%\n","Current batch: Loss-> 0.7826, Train accuracy->  43.44%\n","Current batch: Loss-> 0.6581, Train accuracy->  43.55%\n","Current batch: Loss-> 0.6962, Train accuracy->  43.65%\n","Current batch: Loss-> 0.8094, Train accuracy->  43.75%\n","Current batch: Loss-> 0.7179, Train accuracy->  43.85%\n","Current batch: Loss-> 0.9259, Train accuracy->  43.95%\n","Current batch: Loss-> 0.7519, Train accuracy->  44.05%\n","Current batch: Loss-> 0.8035, Train accuracy->  44.16%\n","Current batch: Loss-> 0.7450, Train accuracy->  44.27%\n","Current batch: Loss-> 1.0204, Train accuracy->  44.36%\n","Current batch: Loss-> 0.7253, Train accuracy->  44.46%\n","Current batch: Loss-> 0.8108, Train accuracy->  44.56%\n","Current batch: Loss-> 0.8513, Train accuracy->  44.67%\n","Current batch: Loss-> 0.5990, Train accuracy->  44.78%\n","Current batch: Loss-> 0.7801, Train accuracy->  44.88%\n","Current batch: Loss-> 0.6232, Train accuracy->  44.97%\n","Current batch: Loss-> 0.7383, Train accuracy->  45.08%\n","Current batch: Loss-> 0.7755, Train accuracy->  45.17%\n","Current batch: Loss-> 0.6575, Train accuracy->  45.29%\n","Current batch: Loss-> 0.7712, Train accuracy->  45.39%\n","Current batch: Loss-> 0.6074, Train accuracy->  45.49%\n","Current batch: Loss-> 0.5263, Train accuracy->  45.61%\n","Current batch: Loss-> 0.4455, Train accuracy->  45.72%\n","Current batch: Loss-> 0.5497, Train accuracy->  45.83%\n","Current batch: Loss-> 0.8557, Train accuracy->  45.93%\n","Current batch: Loss-> 0.8404, Train accuracy->  46.03%\n","Current batch: Loss-> 0.6033, Train accuracy->  46.14%\n","Current batch: Loss-> 0.9433, Train accuracy->  46.23%\n","Current batch: Loss-> 0.6556, Train accuracy->  46.34%\n","Current batch: Loss-> 0.7940, Train accuracy->  46.44%\n","Current batch: Loss-> 0.3390, Train accuracy->  46.56%\n","Current batch: Loss-> 0.6596, Train accuracy->  46.67%\n","Current batch: Loss-> 0.4863, Train accuracy->  46.78%\n","Current batch: Loss-> 0.5432, Train accuracy->  46.89%\n","Current batch: Loss-> 0.6263, Train accuracy->  47.00%\n","Current batch: Loss-> 0.5607, Train accuracy->  47.11%\n","Current batch: Loss-> 1.1892, Train accuracy->  47.20%\n","Current batch: Loss-> 0.6617, Train accuracy->  47.30%\n","Current batch: Loss-> 0.8934, Train accuracy->  47.40%\n","Current batch: Loss-> 0.4814, Train accuracy->  47.51%\n","Current batch: Loss-> 0.6061, Train accuracy->  47.62%\n","Current batch: Loss-> 0.7147, Train accuracy->  47.73%\n","Current batch: Loss-> 1.0272, Train accuracy->  47.82%\n","Current batch: Loss-> 0.7259, Train accuracy->  47.92%\n","Current batch: Loss-> 0.5749, Train accuracy->  48.03%\n","Current batch: Loss-> 0.6023, Train accuracy->  48.14%\n","Current batch: Loss-> 0.6495, Train accuracy->  48.24%\n","Current batch: Loss-> 0.5106, Train accuracy->  48.35%\n","Current batch: Loss-> 0.5991, Train accuracy->  48.46%\n","Current batch: Loss-> 0.6932, Train accuracy->  48.56%\n","Current batch: Loss-> 0.7541, Train accuracy->  48.66%\n","Current batch: Loss-> 0.8834, Train accuracy->  48.77%\n","Current batch: Loss-> 0.8359, Train accuracy->  48.87%\n","Current batch: Loss-> 0.7145, Train accuracy->  48.97%\n","Current batch: Loss-> 0.5693, Train accuracy->  49.08%\n","Current batch: Loss-> 0.6179, Train accuracy->  49.18%\n","Current batch: Loss-> 0.7643, Train accuracy->  49.28%\n","Current batch: Loss-> 0.6872, Train accuracy->  49.38%\n","Current batch: Loss-> 0.5255, Train accuracy->  49.50%\n","Current batch: Loss-> 0.5445, Train accuracy->  49.61%\n","Current batch: Loss-> 0.7753, Train accuracy->  49.72%\n","Current batch: Loss-> 0.7864, Train accuracy->  49.81%\n","Current batch: Loss-> 0.5628, Train accuracy->  49.93%\n","Current batch: Loss-> 0.6645, Train accuracy->  50.04%\n","Current batch: Loss-> 0.8035, Train accuracy->  50.14%\n","Current batch: Loss-> 0.4390, Train accuracy->  50.26%\n","Current batch: Loss-> 0.5207, Train accuracy->  50.38%\n","Current batch: Loss-> 0.7244, Train accuracy->  50.48%\n","Current batch: Loss-> 0.6133, Train accuracy->  50.59%\n","Current batch: Loss-> 0.7340, Train accuracy->  50.69%\n","Current batch: Loss-> 0.4407, Train accuracy->  50.81%\n","Current batch: Loss-> 0.5920, Train accuracy->  50.92%\n","Current batch: Loss-> 0.7415, Train accuracy->  51.02%\n","Current batch: Loss-> 0.9193, Train accuracy->  51.12%\n","Current batch: Loss-> 0.5395, Train accuracy->  51.24%\n","Current batch: Loss-> 0.6476, Train accuracy->  51.34%\n","Current batch: Loss-> 0.5789, Train accuracy->  51.45%\n","Current batch: Loss-> 0.5152, Train accuracy->  51.56%\n","Current batch: Loss-> 0.6268, Train accuracy->  51.67%\n","Current batch: Loss-> 0.5679, Train accuracy->  51.78%\n","Current batch: Loss-> 0.4945, Train accuracy->  51.90%\n","Current batch: Loss-> 0.5961, Train accuracy->  52.01%\n","Current batch: Loss-> 0.6692, Train accuracy->  52.12%\n","Current batch: Loss-> 0.6750, Train accuracy->  52.22%\n","Current batch: Loss-> 0.5939, Train accuracy->  52.32%\n","Current batch: Loss-> 1.0614, Train accuracy->  52.41%\n","Current batch: Loss-> 0.8300, Train accuracy->  52.51%\n","Current batch: Loss-> 0.5741, Train accuracy->  52.62%\n","Current batch: Loss-> 0.5824, Train accuracy->  52.73%\n","Current batch: Loss-> 0.6159, Train accuracy->  52.83%\n","Current batch: Loss-> 0.9170, Train accuracy->  52.92%\n","Current batch: Loss-> 0.6045, Train accuracy->  53.03%\n","Current batch: Loss-> 0.8383, Train accuracy->  53.13%\n","Current batch: Loss-> 0.5739, Train accuracy->  53.24%\n","Current batch: Loss-> 0.6736, Train accuracy->  53.34%\n","Current batch: Loss-> 0.4700, Train accuracy->  53.46%\n","Current batch: Loss-> 0.6620, Train accuracy->  53.56%\n","Current batch: Loss-> 0.7351, Train accuracy->  53.66%\n","Current batch: Loss-> 0.7873, Train accuracy->  53.77%\n","Current batch: Loss-> 0.6993, Train accuracy->  53.87%\n","Current batch: Loss-> 0.7880, Train accuracy->  53.97%\n","Current batch: Loss-> 0.6124, Train accuracy->  54.07%\n","Current batch: Loss-> 0.6715, Train accuracy->  54.17%\n","Current batch: Loss-> 0.6461, Train accuracy->  54.28%\n","Current batch: Loss-> 0.6648, Train accuracy->  54.38%\n","Current batch: Loss-> 0.6164, Train accuracy->  54.50%\n","Current batch: Loss-> 0.6278, Train accuracy->  54.60%\n","Current batch: Loss-> 0.5726, Train accuracy->  54.71%\n","Current batch: Loss-> 0.6689, Train accuracy->  54.81%\n","Current batch: Loss-> 0.4716, Train accuracy->  54.92%\n","Current batch: Loss-> 0.5210, Train accuracy->  55.04%\n","Current batch: Loss-> 0.5631, Train accuracy->  55.15%\n","Current batch: Loss-> 0.4255, Train accuracy->  55.26%\n","Current batch: Loss-> 0.6383, Train accuracy->  55.36%\n","Current batch: Loss-> 0.9585, Train accuracy->  55.46%\n","Current batch: Loss-> 0.5157, Train accuracy->  55.58%\n","Current batch: Loss-> 0.7370, Train accuracy->  55.67%\n","Current batch: Loss-> 0.6578, Train accuracy->  55.79%\n","Current batch: Loss-> 0.6416, Train accuracy->  55.89%\n","Current batch: Loss-> 0.8783, Train accuracy->  55.99%\n","Current batch: Loss-> 0.5434, Train accuracy->  56.10%\n","Current batch: Loss-> 0.7404, Train accuracy->  56.20%\n","Current batch: Loss-> 0.9947, Train accuracy->  56.31%\n","Current batch: Loss-> 0.5294, Train accuracy->  56.42%\n","Current batch: Loss-> 0.9874, Train accuracy->  56.51%\n","Current batch: Loss-> 0.5321, Train accuracy->  56.62%\n","Current batch: Loss-> 0.7216, Train accuracy->  56.74%\n","Current batch: Loss-> 0.4164, Train accuracy->  56.86%\n","Current batch: Loss-> 0.5812, Train accuracy->  56.97%\n","Current batch: Loss-> 0.6173, Train accuracy->  57.08%\n","Current batch: Loss-> 1.1949, Train accuracy->  57.16%\n","Current batch: Loss-> 1.1775, Train accuracy->  57.26%\n","Current batch: Loss-> 0.9046, Train accuracy->  57.35%\n","Current batch: Loss-> 0.7434, Train accuracy->  57.45%\n","Current batch: Loss-> 0.8547, Train accuracy->  57.56%\n","Current batch: Loss-> 0.7812, Train accuracy->  57.66%\n","Current batch: Loss-> 0.9260, Train accuracy->  57.75%\n","Current batch: Loss-> 0.7418, Train accuracy->  57.86%\n","Current batch: Loss-> 0.9018, Train accuracy->  57.95%\n","Current batch: Loss-> 0.9430, Train accuracy->  58.05%\n","Current batch: Loss-> 0.5137, Train accuracy->  58.16%\n","Current batch: Loss-> 0.6810, Train accuracy->  58.26%\n","Current batch: Loss-> 0.6081, Train accuracy->  58.38%\n","Current batch: Loss-> 0.6925, Train accuracy->  58.48%\n","Current batch: Loss-> 0.5361, Train accuracy->  58.59%\n","Current batch: Loss-> 0.7335, Train accuracy->  58.70%\n","Current batch: Loss-> 0.6446, Train accuracy->  58.80%\n","Current batch: Loss-> 0.8700, Train accuracy->  58.90%\n","Current batch: Loss-> 0.6053, Train accuracy->  59.00%\n","Current batch: Loss-> 1.0184, Train accuracy->  59.10%\n","Current batch: Loss-> 0.6921, Train accuracy->  59.20%\n","Current batch: Loss-> 0.9777, Train accuracy->  59.30%\n","Current batch: Loss-> 0.6438, Train accuracy->  59.41%\n","Current batch: Loss-> 0.7514, Train accuracy->  59.51%\n","Current batch: Loss-> 0.7187, Train accuracy->  59.61%\n","Current batch: Loss-> 0.7503, Train accuracy->  59.70%\n","Current batch: Loss-> 0.5111, Train accuracy->  59.81%\n","Current batch: Loss-> 0.8486, Train accuracy->  59.92%\n","Current batch: Loss-> 0.6911, Train accuracy->  60.03%\n","Current batch: Loss-> 0.7667, Train accuracy->  60.12%\n","Current batch: Loss-> 0.7761, Train accuracy->  60.22%\n","Current batch: Loss-> 0.5257, Train accuracy->  60.33%\n","Current batch: Loss-> 0.6753, Train accuracy->  60.43%\n","Current batch: Loss-> 0.6112, Train accuracy->  60.54%\n","Current batch: Loss-> 0.4407, Train accuracy->  60.66%\n","Current batch: Loss-> 0.6206, Train accuracy->  60.76%\n","Current batch: Loss-> 0.7343, Train accuracy->  60.86%\n","Current batch: Loss-> 0.6252, Train accuracy->  60.96%\n","Current batch: Loss-> 0.4635, Train accuracy->  61.07%\n","Current batch: Loss-> 0.6535, Train accuracy->  61.18%\n","Current batch: Loss-> 0.6635, Train accuracy->  61.29%\n","Current batch: Loss-> 0.6821, Train accuracy->  61.39%\n","Current batch: Loss-> 0.6926, Train accuracy->  61.51%\n","Current batch: Loss-> 0.9646, Train accuracy->  61.59%\n","Current batch: Loss-> 0.7743, Train accuracy->  61.68%\n","Current batch: Loss-> 0.5239, Train accuracy->  61.79%\n","Current batch: Loss-> 0.7522, Train accuracy->  61.90%\n","Current batch: Loss-> 0.4854, Train accuracy->  62.01%\n","Current batch: Loss-> 0.7007, Train accuracy->  62.12%\n","Current batch: Loss-> 0.7404, Train accuracy->  62.23%\n","Current batch: Loss-> 0.9362, Train accuracy->  62.33%\n","Current batch: Loss-> 0.6558, Train accuracy->  62.44%\n","Current batch: Loss-> 0.6074, Train accuracy->  62.54%\n","Current batch: Loss-> 0.7093, Train accuracy->  62.64%\n","Current batch: Loss-> 0.6021, Train accuracy->  62.75%\n","Current batch: Loss-> 0.3867, Train accuracy->  62.87%\n","Current batch: Loss-> 0.9650, Train accuracy->  62.96%\n","Current batch: Loss-> 0.6392, Train accuracy->  63.08%\n","Current batch: Loss-> 0.4028, Train accuracy->  63.19%\n","Current batch: Loss-> 0.6720, Train accuracy->  63.29%\n","Current batch: Loss-> 0.5983, Train accuracy->  63.39%\n","Current batch: Loss-> 1.1721, Train accuracy->  63.49%\n","Current batch: Loss-> 0.4690, Train accuracy->  63.60%\n","Current batch: Loss-> 0.7704, Train accuracy->  63.70%\n","Current batch: Loss-> 0.5357, Train accuracy->  63.81%\n","Current batch: Loss-> 0.8095, Train accuracy->  63.91%\n","Current batch: Loss-> 0.7747, Train accuracy->  64.01%\n","Current batch: Loss-> 1.1828, Train accuracy->  64.10%\n","Current batch: Loss-> 0.7682, Train accuracy->  64.20%\n","Current batch: Loss-> 0.7178, Train accuracy->  64.30%\n","Current batch: Loss-> 0.8525, Train accuracy->  64.40%\n","Current batch: Loss-> 0.6012, Train accuracy->  64.50%\n","Current batch: Loss-> 0.8096, Train accuracy->  64.60%\n","Current batch: Loss-> 0.9498, Train accuracy->  64.71%\n","Current batch: Loss-> 0.5789, Train accuracy->  64.81%\n","Current batch: Loss-> 0.7184, Train accuracy->  64.92%\n","Current batch: Loss-> 0.7448, Train accuracy->  65.02%\n","Current batch: Loss-> 0.5550, Train accuracy->  65.12%\n","Current batch: Loss-> 0.6012, Train accuracy->  65.22%\n","Current batch: Loss-> 0.7204, Train accuracy->  65.33%\n","Current batch: Loss-> 0.7338, Train accuracy->  65.43%\n","Current batch: Loss-> 1.0505, Train accuracy->  65.52%\n","Current batch: Loss-> 0.6736, Train accuracy->  65.62%\n","Current batch: Loss-> 0.9892, Train accuracy->  65.70%\n","Current batch: Loss-> 0.5379, Train accuracy->  65.82%\n","Current batch: Loss-> 0.5473, Train accuracy->  65.93%\n","Current batch: Loss-> 0.8587, Train accuracy->  66.03%\n","Current batch: Loss-> 0.8216, Train accuracy->  66.14%\n","Current batch: Loss-> 0.5442, Train accuracy->  66.25%\n","Current batch: Loss-> 0.8036, Train accuracy->  66.35%\n","Current batch: Loss-> 0.7084, Train accuracy->  66.45%\n","Current batch: Loss-> 0.7425, Train accuracy->  66.56%\n","Current batch: Loss-> 0.4161, Train accuracy->  66.68%\n","Current batch: Loss-> 0.4821, Train accuracy->  66.78%\n","Current batch: Loss-> 0.7136, Train accuracy->  66.88%\n","Current batch: Loss-> 0.9400, Train accuracy->  66.97%\n","Current batch: Loss-> 0.6811, Train accuracy->  67.08%\n","Current batch: Loss-> 0.6257, Train accuracy->  67.19%\n","Current batch: Loss-> 0.6867, Train accuracy->  67.29%\n","Current batch: Loss-> 0.5736, Train accuracy->  67.40%\n","Current batch: Loss-> 0.8554, Train accuracy->  67.50%\n","Current batch: Loss-> 0.5259, Train accuracy->  67.61%\n","Current batch: Loss-> 0.7293, Train accuracy->  67.72%\n","Current batch: Loss-> 0.8406, Train accuracy->  67.82%\n","Current batch: Loss-> 0.5503, Train accuracy->  67.92%\n","Current batch: Loss-> 0.5574, Train accuracy->  68.03%\n","Current batch: Loss-> 0.6750, Train accuracy->  68.14%\n","Current batch: Loss-> 0.3907, Train accuracy->  68.26%\n","Current batch: Loss-> 0.4859, Train accuracy->  68.38%\n","Current batch: Loss-> 0.8200, Train accuracy->  68.47%\n","Current batch: Loss-> 0.8165, Train accuracy->  68.58%\n","Current batch: Loss-> 0.7978, Train accuracy->  68.68%\n","Current batch: Loss-> 0.7937, Train accuracy->  68.78%\n","Current batch: Loss-> 0.5054, Train accuracy->  68.90%\n","Current batch: Loss-> 0.4274, Train accuracy->  69.01%\n","Current batch: Loss-> 0.4694, Train accuracy->  69.12%\n","Current batch: Loss-> 0.7030, Train accuracy->  69.22%\n","Current batch: Loss-> 0.7007, Train accuracy->  69.34%\n","Current batch: Loss-> 0.6520, Train accuracy->  69.45%\n","Current batch: Loss-> 0.9473, Train accuracy->  69.54%\n","Current batch: Loss-> 0.8161, Train accuracy->  69.65%\n","Current batch: Loss-> 0.4526, Train accuracy->  69.77%\n","Current batch: Loss-> 0.6224, Train accuracy->  69.87%\n","Current batch: Loss-> 0.5220, Train accuracy->  69.99%\n","Current batch: Loss-> 0.6387, Train accuracy->  70.10%\n","Current batch: Loss-> 0.4730, Train accuracy->  70.21%\n","Current batch: Loss-> 0.5848, Train accuracy->  70.33%\n","Current batch: Loss-> 0.6578, Train accuracy->  70.44%\n","Current batch: Loss-> 0.5965, Train accuracy->  70.54%\n","Current batch: Loss-> 0.8295, Train accuracy->  70.64%\n","Current batch: Loss-> 0.4109, Train accuracy->  70.75%\n","Current batch: Loss-> 0.5253, Train accuracy->  70.85%\n","Current batch: Loss-> 0.8010, Train accuracy->  70.95%\n","Current batch: Loss-> 0.6031, Train accuracy->  71.06%\n","Current batch: Loss-> 0.7272, Train accuracy->  71.16%\n","Current batch: Loss-> 0.9227, Train accuracy->  71.26%\n","Current batch: Loss-> 0.7329, Train accuracy->  71.37%\n","Current batch: Loss-> 0.8521, Train accuracy->  71.47%\n","Current batch: Loss-> 0.9021, Train accuracy->  71.57%\n","Current batch: Loss-> 0.5535, Train accuracy->  71.67%\n","Current batch: Loss-> 0.5305, Train accuracy->  71.79%\n","Current batch: Loss-> 0.8074, Train accuracy->  71.88%\n","Current batch: Loss-> 0.5844, Train accuracy->  72.00%\n","Current batch: Loss-> 0.6022, Train accuracy->  72.10%\n","Current batch: Loss-> 0.8768, Train accuracy->  72.19%\n","Current batch: Loss-> 0.9827, Train accuracy->  72.29%\n","Current batch: Loss-> 0.7366, Train accuracy->  72.39%\n","Current batch: Loss-> 0.6366, Train accuracy->  72.49%\n","Current batch: Loss-> 1.2491, Train accuracy->  72.58%\n","Current batch: Loss-> 0.6486, Train accuracy->  72.69%\n","Current batch: Loss-> 0.7881, Train accuracy->  72.79%\n","Current batch: Loss-> 0.7703, Train accuracy->  72.89%\n","Current batch: Loss-> 0.5357, Train accuracy->  73.00%\n","Current batch: Loss-> 0.8701, Train accuracy->  73.10%\n","Current batch: Loss-> 0.6421, Train accuracy->  73.20%\n","Current batch: Loss-> 0.4989, Train accuracy->  73.31%\n","Current batch: Loss-> 0.6261, Train accuracy->  73.42%\n","Current batch: Loss-> 0.7530, Train accuracy->  73.53%\n","Current batch: Loss-> 0.4843, Train accuracy->  73.64%\n","Current batch: Loss-> 0.6770, Train accuracy->  73.74%\n","Current batch: Loss-> 0.7813, Train accuracy->  73.84%\n","Current batch: Loss-> 0.6512, Train accuracy->  73.94%\n","Current batch: Loss-> 0.8345, Train accuracy->  74.03%\n","Current batch: Loss-> 0.7039, Train accuracy->  74.14%\n","Current batch: Loss-> 0.7384, Train accuracy->  74.25%\n","Current batch: Loss-> 0.6686, Train accuracy->  74.35%\n","Current batch: Loss-> 0.6952, Train accuracy->  74.45%\n","Current batch: Loss-> 0.5715, Train accuracy->  74.55%\n","Current batch: Loss-> 0.5548, Train accuracy->  74.66%\n","Current batch: Loss-> 0.9326, Train accuracy->  74.77%\n","Current batch: Loss-> 0.7470, Train accuracy->  74.88%\n","Current batch: Loss-> 0.4943, Train accuracy->  75.00%\n","Current batch: Loss-> 0.5710, Train accuracy->  75.10%\n","Current batch: Loss-> 0.5280, Train accuracy->  75.21%\n","Current batch: Loss-> 0.4843, Train accuracy->  75.33%\n","Current batch: Loss-> 0.5937, Train accuracy->  75.43%\n","Current batch: Loss-> 0.4623, Train accuracy->  75.55%\n","Current batch: Loss-> 0.5518, Train accuracy->  75.66%\n","Current batch: Loss-> 0.6445, Train accuracy->  75.76%\n","Current batch: Loss-> 0.5791, Train accuracy->  75.87%\n","Current batch: Loss-> 0.7767, Train accuracy->  75.97%\n","Current batch: Loss-> 0.5804, Train accuracy->  76.08%\n","Current batch: Loss-> 0.5336, Train accuracy->  76.19%\n","Current batch: Loss-> 0.8721, Train accuracy->  76.29%\n","Current batch: Loss-> 0.4646, Train accuracy->  76.40%\n","Current batch: Loss-> 0.5658, Train accuracy->  76.51%\n","Current batch: Loss-> 0.5429, Train accuracy->  76.62%\n","Current batch: Loss-> 1.1671, Train accuracy->  76.72%\n","Current batch: Loss-> 0.7882, Train accuracy->  76.83%\n","Current batch: Loss-> 0.4196, Train accuracy->  76.94%\n","Current batch: Loss-> 0.4570, Train accuracy->  77.06%\n","Current batch: Loss-> 0.5170, Train accuracy->  77.17%\n","Current batch: Loss-> 0.6004, Train accuracy->  77.28%\n","Current batch: Loss-> 0.5146, Train accuracy->  77.39%\n","Current batch: Loss-> 0.7292, Train accuracy->  77.49%\n","Current batch: Loss-> 0.7944, Train accuracy->  77.60%\n","Current batch: Loss-> 0.7615, Train accuracy->  77.70%\n","Current batch: Loss-> 0.5170, Train accuracy->  77.81%\n","Current batch: Loss-> 0.4589, Train accuracy->  77.93%\n","Current batch: Loss-> 0.7590, Train accuracy->  78.04%\n","Current batch: Loss-> 0.7652, Train accuracy->  78.14%\n","Current batch: Loss-> 0.9558, Train accuracy->  78.25%\n","Current batch: Loss-> 0.7779, Train accuracy->  78.34%\n","Current batch: Loss-> 0.6583, Train accuracy->  78.45%\n","Current batch: Loss-> 0.7858, Train accuracy->  78.56%\n","Current batch: Loss-> 0.6872, Train accuracy->  78.66%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 47.79it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.5170, Train accuracy->  78.77%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 45.03it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.6503, Accuracy: 5631/12000 (47%)\n","\n","Current batch: Loss-> 0.6467, Train accuracy->   0.11%\n","Current batch: Loss-> 0.7748, Train accuracy->   0.22%\n","Current batch: Loss-> 0.6253, Train accuracy->   0.33%\n","Current batch: Loss-> 0.5555, Train accuracy->   0.44%\n","Current batch: Loss-> 0.5910, Train accuracy->   0.55%\n","Current batch: Loss-> 0.4383, Train accuracy->   0.67%\n","Current batch: Loss-> 0.5897, Train accuracy->   0.78%\n","Current batch: Loss-> 0.4786, Train accuracy->   0.90%\n","Current batch: Loss-> 0.4856, Train accuracy->   1.01%\n","Current batch: Loss-> 0.6631, Train accuracy->   1.12%\n","Current batch: Loss-> 0.6773, Train accuracy->   1.23%\n","Current batch: Loss-> 0.7604, Train accuracy->   1.34%\n","Current batch: Loss-> 0.5429, Train accuracy->   1.44%\n","Current batch: Loss-> 0.6795, Train accuracy->   1.55%\n","Current batch: Loss-> 0.5312, Train accuracy->   1.65%\n","Current batch: Loss-> 0.7292, Train accuracy->   1.73%\n","Current batch: Loss-> 0.3503, Train accuracy->   1.86%\n","Current batch: Loss-> 0.6072, Train accuracy->   1.96%\n","Current batch: Loss-> 0.7028, Train accuracy->   2.06%\n","Current batch: Loss-> 0.7929, Train accuracy->   2.17%\n","Current batch: Loss-> 0.6752, Train accuracy->   2.28%\n","Current batch: Loss-> 0.3244, Train accuracy->   2.40%\n","Current batch: Loss-> 0.6813, Train accuracy->   2.51%\n","Current batch: Loss-> 0.6457, Train accuracy->   2.62%\n","Current batch: Loss-> 0.4812, Train accuracy->   2.73%\n","Current batch: Loss-> 0.6230, Train accuracy->   2.83%\n","Current batch: Loss-> 0.6390, Train accuracy->   2.94%\n","Current batch: Loss-> 0.6637, Train accuracy->   3.05%\n","Current batch: Loss-> 0.6868, Train accuracy->   3.15%\n","Current batch: Loss-> 0.8192, Train accuracy->   3.24%\n","Current batch: Loss-> 0.5876, Train accuracy->   3.35%\n","Current batch: Loss-> 0.6937, Train accuracy->   3.46%\n","Current batch: Loss-> 0.4727, Train accuracy->   3.58%\n","Current batch: Loss-> 0.6503, Train accuracy->   3.68%\n","Current batch: Loss-> 0.8083, Train accuracy->   3.78%\n","Current batch: Loss-> 0.5699, Train accuracy->   3.89%\n","Current batch: Loss-> 0.7765, Train accuracy->   4.00%\n","Current batch: Loss-> 0.3701, Train accuracy->   4.12%\n","Current batch: Loss-> 0.5549, Train accuracy->   4.22%\n","Current batch: Loss-> 0.6174, Train accuracy->   4.34%\n","Current batch: Loss-> 0.5798, Train accuracy->   4.45%\n","Current batch: Loss-> 0.5175, Train accuracy->   4.56%\n","Current batch: Loss-> 0.5388, Train accuracy->   4.67%\n","Current batch: Loss-> 0.6105, Train accuracy->   4.78%\n","Current batch: Loss-> 0.6555, Train accuracy->   4.88%\n","Current batch: Loss-> 0.8314, Train accuracy->   4.99%\n","Current batch: Loss-> 0.8810, Train accuracy->   5.09%\n","Current batch: Loss-> 0.4740, Train accuracy->   5.20%\n","Current batch: Loss-> 0.8401, Train accuracy->   5.32%\n","Current batch: Loss-> 0.6438, Train accuracy->   5.42%\n","Current batch: Loss-> 0.7752, Train accuracy->   5.53%\n","Current batch: Loss-> 0.7018, Train accuracy->   5.63%\n","Current batch: Loss-> 0.5900, Train accuracy->   5.73%\n","Current batch: Loss-> 0.7837, Train accuracy->   5.83%\n","Current batch: Loss-> 0.4886, Train accuracy->   5.94%\n","Current batch: Loss-> 0.7035, Train accuracy->   6.05%\n","Current batch: Loss-> 0.5978, Train accuracy->   6.14%\n","Current batch: Loss-> 0.3932, Train accuracy->   6.27%\n","Current batch: Loss-> 0.5243, Train accuracy->   6.37%\n","Current batch: Loss-> 1.0158, Train accuracy->   6.46%\n","Current batch: Loss-> 0.5350, Train accuracy->   6.58%\n","Current batch: Loss-> 0.4538, Train accuracy->   6.69%\n","Current batch: Loss-> 0.5029, Train accuracy->   6.80%\n","Current batch: Loss-> 0.6181, Train accuracy->   6.91%\n","Current batch: Loss-> 0.6336, Train accuracy->   7.01%\n","Current batch: Loss-> 0.4293, Train accuracy->   7.12%\n","Current batch: Loss-> 0.7753, Train accuracy->   7.23%\n","Current batch: Loss-> 0.6760, Train accuracy->   7.34%\n","Current batch: Loss-> 0.6302, Train accuracy->   7.45%\n","Current batch: Loss-> 0.7184, Train accuracy->   7.55%\n","Current batch: Loss-> 0.7670, Train accuracy->   7.66%\n","Current batch: Loss-> 0.6916, Train accuracy->   7.77%\n","Current batch: Loss-> 0.4431, Train accuracy->   7.88%\n","Current batch: Loss-> 0.7168, Train accuracy->   7.99%\n","Current batch: Loss-> 0.6793, Train accuracy->   8.09%\n","Current batch: Loss-> 0.8288, Train accuracy->   8.19%\n","Current batch: Loss-> 0.4537, Train accuracy->   8.31%\n","Current batch: Loss-> 0.6275, Train accuracy->   8.42%\n","Current batch: Loss-> 0.6341, Train accuracy->   8.52%\n","Current batch: Loss-> 0.7294, Train accuracy->   8.63%\n","Current batch: Loss-> 0.4874, Train accuracy->   8.74%\n","Current batch: Loss-> 0.4411, Train accuracy->   8.85%\n","Current batch: Loss-> 0.5740, Train accuracy->   8.96%\n","Current batch: Loss-> 0.6362, Train accuracy->   9.07%\n","Current batch: Loss-> 0.4915, Train accuracy->   9.19%\n","Current batch: Loss-> 0.5030, Train accuracy->   9.30%\n","Current batch: Loss-> 0.5892, Train accuracy->   9.41%\n","Current batch: Loss-> 0.6396, Train accuracy->   9.51%\n","Current batch: Loss-> 0.7815, Train accuracy->   9.62%\n","Current batch: Loss-> 0.3605, Train accuracy->   9.73%\n","Current batch: Loss-> 0.7117, Train accuracy->   9.84%\n","Current batch: Loss-> 0.8498, Train accuracy->   9.94%\n","Current batch: Loss-> 0.7184, Train accuracy->  10.04%\n","Current batch: Loss-> 0.5597, Train accuracy->  10.15%\n","Current batch: Loss-> 0.7176, Train accuracy->  10.25%\n","Current batch: Loss-> 0.5235, Train accuracy->  10.36%\n","Current batch: Loss-> 0.8495, Train accuracy->  10.45%\n","Current batch: Loss-> 0.4054, Train accuracy->  10.57%\n","Current batch: Loss-> 0.9223, Train accuracy->  10.66%\n","Current batch: Loss-> 0.7746, Train accuracy->  10.76%\n","Current batch: Loss-> 0.5200, Train accuracy->  10.87%\n","Current batch: Loss-> 0.7124, Train accuracy->  10.97%\n","Current batch: Loss-> 0.4611, Train accuracy->  11.09%\n","Current batch: Loss-> 0.6195, Train accuracy->  11.19%\n","Current batch: Loss-> 0.8206, Train accuracy->  11.30%\n","Current batch: Loss-> 0.6784, Train accuracy->  11.40%\n","Current batch: Loss-> 0.6124, Train accuracy->  11.51%\n","Current batch: Loss-> 0.8818, Train accuracy->  11.60%\n","Current batch: Loss-> 0.7474, Train accuracy->  11.70%\n","Current batch: Loss-> 0.6614, Train accuracy->  11.81%\n","Current batch: Loss-> 0.4860, Train accuracy->  11.93%\n","Current batch: Loss-> 0.7376, Train accuracy->  12.04%\n","Current batch: Loss-> 0.5401, Train accuracy->  12.15%\n","Current batch: Loss-> 0.5800, Train accuracy->  12.26%\n","Current batch: Loss-> 0.7550, Train accuracy->  12.37%\n","Current batch: Loss-> 0.6194, Train accuracy->  12.48%\n","Current batch: Loss-> 0.7690, Train accuracy->  12.59%\n","Current batch: Loss-> 0.4855, Train accuracy->  12.70%\n","Current batch: Loss-> 0.3732, Train accuracy->  12.82%\n","Current batch: Loss-> 0.9699, Train accuracy->  12.92%\n","Current batch: Loss-> 0.8848, Train accuracy->  13.03%\n","Current batch: Loss-> 0.6471, Train accuracy->  13.14%\n","Current batch: Loss-> 0.5981, Train accuracy->  13.25%\n","Current batch: Loss-> 0.8065, Train accuracy->  13.36%\n","Current batch: Loss-> 0.5550, Train accuracy->  13.47%\n","Current batch: Loss-> 0.6627, Train accuracy->  13.57%\n","Current batch: Loss-> 0.5671, Train accuracy->  13.69%\n","Current batch: Loss-> 0.4642, Train accuracy->  13.80%\n","Current batch: Loss-> 0.6729, Train accuracy->  13.90%\n","Current batch: Loss-> 0.4765, Train accuracy->  14.01%\n","Current batch: Loss-> 0.5990, Train accuracy->  14.12%\n","Current batch: Loss-> 0.6981, Train accuracy->  14.23%\n","Current batch: Loss-> 0.5874, Train accuracy->  14.34%\n","Current batch: Loss-> 0.6248, Train accuracy->  14.44%\n","Current batch: Loss-> 0.6988, Train accuracy->  14.55%\n","Current batch: Loss-> 0.5719, Train accuracy->  14.66%\n","Current batch: Loss-> 0.7286, Train accuracy->  14.76%\n","Current batch: Loss-> 0.7682, Train accuracy->  14.86%\n","Current batch: Loss-> 0.6759, Train accuracy->  14.96%\n","Current batch: Loss-> 0.3581, Train accuracy->  15.07%\n","Current batch: Loss-> 0.5990, Train accuracy->  15.19%\n","Current batch: Loss-> 0.5685, Train accuracy->  15.30%\n","Current batch: Loss-> 0.3811, Train accuracy->  15.42%\n","Current batch: Loss-> 0.5540, Train accuracy->  15.52%\n","Current batch: Loss-> 1.1013, Train accuracy->  15.61%\n","Current batch: Loss-> 0.6363, Train accuracy->  15.71%\n","Current batch: Loss-> 0.6574, Train accuracy->  15.81%\n","Current batch: Loss-> 0.8839, Train accuracy->  15.90%\n","Current batch: Loss-> 0.4915, Train accuracy->  16.01%\n","Current batch: Loss-> 0.5890, Train accuracy->  16.11%\n","Current batch: Loss-> 0.5574, Train accuracy->  16.22%\n","Current batch: Loss-> 0.3690, Train accuracy->  16.34%\n","Current batch: Loss-> 0.6046, Train accuracy->  16.44%\n","Current batch: Loss-> 0.7761, Train accuracy->  16.55%\n","Current batch: Loss-> 0.4866, Train accuracy->  16.66%\n","Current batch: Loss-> 0.5755, Train accuracy->  16.76%\n","Current batch: Loss-> 0.6118, Train accuracy->  16.86%\n","Current batch: Loss-> 0.7335, Train accuracy->  16.97%\n","Current batch: Loss-> 0.6815, Train accuracy->  17.08%\n","Current batch: Loss-> 0.4724, Train accuracy->  17.19%\n","Current batch: Loss-> 0.9206, Train accuracy->  17.30%\n","Current batch: Loss-> 0.8041, Train accuracy->  17.40%\n","Current batch: Loss-> 0.7463, Train accuracy->  17.51%\n","Current batch: Loss-> 0.8628, Train accuracy->  17.61%\n","Current batch: Loss-> 0.7037, Train accuracy->  17.71%\n","Current batch: Loss-> 0.9020, Train accuracy->  17.81%\n","Current batch: Loss-> 0.6820, Train accuracy->  17.91%\n","Current batch: Loss-> 0.7131, Train accuracy->  18.01%\n","Current batch: Loss-> 0.7976, Train accuracy->  18.11%\n","Current batch: Loss-> 0.7094, Train accuracy->  18.22%\n","Current batch: Loss-> 0.5575, Train accuracy->  18.34%\n","Current batch: Loss-> 0.6288, Train accuracy->  18.45%\n","Current batch: Loss-> 0.5227, Train accuracy->  18.56%\n","Current batch: Loss-> 0.7337, Train accuracy->  18.66%\n","Current batch: Loss-> 0.5660, Train accuracy->  18.77%\n","Current batch: Loss-> 0.5098, Train accuracy->  18.88%\n","Current batch: Loss-> 0.5981, Train accuracy->  18.99%\n","Current batch: Loss-> 1.2912, Train accuracy->  19.08%\n","Current batch: Loss-> 0.4372, Train accuracy->  19.20%\n","Current batch: Loss-> 0.8183, Train accuracy->  19.30%\n","Current batch: Loss-> 0.7534, Train accuracy->  19.40%\n","Current batch: Loss-> 0.5934, Train accuracy->  19.50%\n","Current batch: Loss-> 0.9050, Train accuracy->  19.60%\n","Current batch: Loss-> 0.7211, Train accuracy->  19.70%\n","Current batch: Loss-> 0.8325, Train accuracy->  19.81%\n","Current batch: Loss-> 0.9263, Train accuracy->  19.90%\n","Current batch: Loss-> 0.5208, Train accuracy->  20.01%\n","Current batch: Loss-> 0.7476, Train accuracy->  20.11%\n","Current batch: Loss-> 0.6873, Train accuracy->  20.21%\n","Current batch: Loss-> 0.5143, Train accuracy->  20.32%\n","Current batch: Loss-> 0.5488, Train accuracy->  20.44%\n","Current batch: Loss-> 0.7078, Train accuracy->  20.54%\n","Current batch: Loss-> 1.0139, Train accuracy->  20.64%\n","Current batch: Loss-> 0.5437, Train accuracy->  20.76%\n","Current batch: Loss-> 0.5645, Train accuracy->  20.88%\n","Current batch: Loss-> 0.4805, Train accuracy->  20.99%\n","Current batch: Loss-> 0.4712, Train accuracy->  21.10%\n","Current batch: Loss-> 0.6042, Train accuracy->  21.21%\n","Current batch: Loss-> 0.7730, Train accuracy->  21.32%\n","Current batch: Loss-> 0.7044, Train accuracy->  21.43%\n","Current batch: Loss-> 0.6994, Train accuracy->  21.54%\n","Current batch: Loss-> 0.5910, Train accuracy->  21.66%\n","Current batch: Loss-> 0.6126, Train accuracy->  21.76%\n","Current batch: Loss-> 0.6542, Train accuracy->  21.87%\n","Current batch: Loss-> 0.6432, Train accuracy->  21.98%\n","Current batch: Loss-> 0.4411, Train accuracy->  22.09%\n","Current batch: Loss-> 0.5632, Train accuracy->  22.20%\n","Current batch: Loss-> 0.5089, Train accuracy->  22.31%\n","Current batch: Loss-> 0.7451, Train accuracy->  22.41%\n","Current batch: Loss-> 0.6893, Train accuracy->  22.52%\n","Current batch: Loss-> 0.8142, Train accuracy->  22.61%\n","Current batch: Loss-> 0.4228, Train accuracy->  22.73%\n","Current batch: Loss-> 0.6759, Train accuracy->  22.84%\n","Current batch: Loss-> 0.7029, Train accuracy->  22.95%\n","Current batch: Loss-> 0.4064, Train accuracy->  23.06%\n","Current batch: Loss-> 0.4851, Train accuracy->  23.18%\n","Current batch: Loss-> 0.6523, Train accuracy->  23.28%\n","Current batch: Loss-> 0.7453, Train accuracy->  23.39%\n","Current batch: Loss-> 0.6102, Train accuracy->  23.50%\n","Current batch: Loss-> 0.7848, Train accuracy->  23.61%\n","Current batch: Loss-> 0.9964, Train accuracy->  23.71%\n","Current batch: Loss-> 0.6777, Train accuracy->  23.82%\n","Current batch: Loss-> 0.8817, Train accuracy->  23.91%\n","Current batch: Loss-> 0.4859, Train accuracy->  24.02%\n","Current batch: Loss-> 0.9519, Train accuracy->  24.12%\n","Current batch: Loss-> 0.5588, Train accuracy->  24.23%\n","Current batch: Loss-> 0.5415, Train accuracy->  24.34%\n","Current batch: Loss-> 0.6383, Train accuracy->  24.44%\n","Current batch: Loss-> 0.4604, Train accuracy->  24.55%\n","Current batch: Loss-> 0.7858, Train accuracy->  24.66%\n","Current batch: Loss-> 0.4802, Train accuracy->  24.77%\n","Current batch: Loss-> 0.5629, Train accuracy->  24.88%\n","Current batch: Loss-> 0.6921, Train accuracy->  24.99%\n","Current batch: Loss-> 0.7735, Train accuracy->  25.09%\n","Current batch: Loss-> 0.8427, Train accuracy->  25.20%\n","Current batch: Loss-> 0.6635, Train accuracy->  25.30%\n","Current batch: Loss-> 0.7530, Train accuracy->  25.39%\n","Current batch: Loss-> 0.4160, Train accuracy->  25.51%\n","Current batch: Loss-> 0.8282, Train accuracy->  25.61%\n","Current batch: Loss-> 0.6164, Train accuracy->  25.73%\n","Current batch: Loss-> 0.7837, Train accuracy->  25.82%\n","Current batch: Loss-> 0.7268, Train accuracy->  25.93%\n","Current batch: Loss-> 0.6626, Train accuracy->  26.04%\n","Current batch: Loss-> 0.7459, Train accuracy->  26.13%\n","Current batch: Loss-> 0.6495, Train accuracy->  26.25%\n","Current batch: Loss-> 0.5727, Train accuracy->  26.35%\n","Current batch: Loss-> 0.4895, Train accuracy->  26.47%\n","Current batch: Loss-> 0.8211, Train accuracy->  26.57%\n","Current batch: Loss-> 1.1262, Train accuracy->  26.67%\n","Current batch: Loss-> 0.4466, Train accuracy->  26.78%\n","Current batch: Loss-> 0.5130, Train accuracy->  26.89%\n","Current batch: Loss-> 0.8283, Train accuracy->  26.99%\n","Current batch: Loss-> 0.9832, Train accuracy->  27.07%\n","Current batch: Loss-> 0.8984, Train accuracy->  27.17%\n","Current batch: Loss-> 0.8285, Train accuracy->  27.27%\n","Current batch: Loss-> 0.5744, Train accuracy->  27.38%\n","Current batch: Loss-> 0.4625, Train accuracy->  27.50%\n","Current batch: Loss-> 0.6139, Train accuracy->  27.61%\n","Current batch: Loss-> 0.6552, Train accuracy->  27.71%\n","Current batch: Loss-> 0.7887, Train accuracy->  27.82%\n","Current batch: Loss-> 0.6618, Train accuracy->  27.94%\n","Current batch: Loss-> 0.7272, Train accuracy->  28.04%\n","Current batch: Loss-> 0.7971, Train accuracy->  28.14%\n","Current batch: Loss-> 0.8316, Train accuracy->  28.25%\n","Current batch: Loss-> 0.5967, Train accuracy->  28.34%\n","Current batch: Loss-> 1.0569, Train accuracy->  28.44%\n","Current batch: Loss-> 0.6479, Train accuracy->  28.55%\n","Current batch: Loss-> 0.6076, Train accuracy->  28.65%\n","Current batch: Loss-> 0.6275, Train accuracy->  28.75%\n","Current batch: Loss-> 0.5986, Train accuracy->  28.86%\n","Current batch: Loss-> 0.6185, Train accuracy->  28.97%\n","Current batch: Loss-> 0.7785, Train accuracy->  29.07%\n","Current batch: Loss-> 0.6792, Train accuracy->  29.17%\n","Current batch: Loss-> 0.5391, Train accuracy->  29.28%\n","Current batch: Loss-> 0.9594, Train accuracy->  29.39%\n","Current batch: Loss-> 0.7480, Train accuracy->  29.49%\n","Current batch: Loss-> 0.7188, Train accuracy->  29.60%\n","Current batch: Loss-> 0.4351, Train accuracy->  29.71%\n","Current batch: Loss-> 0.5824, Train accuracy->  29.81%\n","Current batch: Loss-> 0.5800, Train accuracy->  29.92%\n","Current batch: Loss-> 0.5774, Train accuracy->  30.04%\n","Current batch: Loss-> 0.7564, Train accuracy->  30.14%\n","Current batch: Loss-> 0.6300, Train accuracy->  30.25%\n","Current batch: Loss-> 0.6809, Train accuracy->  30.37%\n","Current batch: Loss-> 0.8560, Train accuracy->  30.47%\n","Current batch: Loss-> 0.4808, Train accuracy->  30.57%\n","Current batch: Loss-> 0.6284, Train accuracy->  30.68%\n","Current batch: Loss-> 0.6360, Train accuracy->  30.79%\n","Current batch: Loss-> 0.8807, Train accuracy->  30.89%\n","Current batch: Loss-> 0.6058, Train accuracy->  31.00%\n","Current batch: Loss-> 0.6610, Train accuracy->  31.11%\n","Current batch: Loss-> 0.7529, Train accuracy->  31.22%\n","Current batch: Loss-> 0.6032, Train accuracy->  31.33%\n","Current batch: Loss-> 0.9489, Train accuracy->  31.42%\n","Current batch: Loss-> 0.7155, Train accuracy->  31.52%\n","Current batch: Loss-> 0.5111, Train accuracy->  31.63%\n","Current batch: Loss-> 0.6624, Train accuracy->  31.74%\n","Current batch: Loss-> 0.5960, Train accuracy->  31.84%\n","Current batch: Loss-> 0.8562, Train accuracy->  31.94%\n","Current batch: Loss-> 0.7657, Train accuracy->  32.04%\n","Current batch: Loss-> 0.5373, Train accuracy->  32.16%\n","Current batch: Loss-> 0.5049, Train accuracy->  32.27%\n","Current batch: Loss-> 0.6735, Train accuracy->  32.38%\n","Current batch: Loss-> 0.7582, Train accuracy->  32.49%\n","Current batch: Loss-> 0.4858, Train accuracy->  32.60%\n","Current batch: Loss-> 1.0443, Train accuracy->  32.69%\n","Current batch: Loss-> 0.5843, Train accuracy->  32.79%\n","Current batch: Loss-> 0.5138, Train accuracy->  32.90%\n","Current batch: Loss-> 0.8061, Train accuracy->  33.00%\n","Current batch: Loss-> 0.7795, Train accuracy->  33.10%\n","Current batch: Loss-> 0.5559, Train accuracy->  33.20%\n","Current batch: Loss-> 0.8887, Train accuracy->  33.30%\n","Current batch: Loss-> 0.7387, Train accuracy->  33.40%\n","Current batch: Loss-> 0.4791, Train accuracy->  33.51%\n","Current batch: Loss-> 0.5360, Train accuracy->  33.62%\n","Current batch: Loss-> 0.6516, Train accuracy->  33.72%\n","Current batch: Loss-> 0.6864, Train accuracy->  33.83%\n","Current batch: Loss-> 0.5052, Train accuracy->  33.95%\n","Current batch: Loss-> 0.5989, Train accuracy->  34.06%\n","Current batch: Loss-> 0.7074, Train accuracy->  34.16%\n","Current batch: Loss-> 0.8374, Train accuracy->  34.27%\n","Current batch: Loss-> 0.6517, Train accuracy->  34.38%\n","Current batch: Loss-> 0.3585, Train accuracy->  34.50%\n","Current batch: Loss-> 0.7364, Train accuracy->  34.61%\n","Current batch: Loss-> 0.4890, Train accuracy->  34.72%\n","Current batch: Loss-> 0.5934, Train accuracy->  34.83%\n","Current batch: Loss-> 0.6513, Train accuracy->  34.94%\n","Current batch: Loss-> 0.5141, Train accuracy->  35.05%\n","Current batch: Loss-> 0.5188, Train accuracy->  35.16%\n","Current batch: Loss-> 0.4141, Train accuracy->  35.28%\n","Current batch: Loss-> 0.5951, Train accuracy->  35.39%\n","Current batch: Loss-> 0.7038, Train accuracy->  35.50%\n","Current batch: Loss-> 0.5798, Train accuracy->  35.61%\n","Current batch: Loss-> 0.6772, Train accuracy->  35.71%\n","Current batch: Loss-> 0.3746, Train accuracy->  35.83%\n","Current batch: Loss-> 0.9229, Train accuracy->  35.93%\n","Current batch: Loss-> 0.5333, Train accuracy->  36.04%\n","Current batch: Loss-> 0.6086, Train accuracy->  36.15%\n","Current batch: Loss-> 0.4344, Train accuracy->  36.26%\n","Current batch: Loss-> 0.6417, Train accuracy->  36.36%\n","Current batch: Loss-> 0.7797, Train accuracy->  36.47%\n","Current batch: Loss-> 0.5740, Train accuracy->  36.59%\n","Current batch: Loss-> 0.6298, Train accuracy->  36.69%\n","Current batch: Loss-> 0.8784, Train accuracy->  36.79%\n","Current batch: Loss-> 0.3968, Train accuracy->  36.91%\n","Current batch: Loss-> 0.7190, Train accuracy->  37.00%\n","Current batch: Loss-> 0.5366, Train accuracy->  37.11%\n","Current batch: Loss-> 0.7060, Train accuracy->  37.22%\n","Current batch: Loss-> 0.9280, Train accuracy->  37.33%\n","Current batch: Loss-> 0.7387, Train accuracy->  37.44%\n","Current batch: Loss-> 0.8281, Train accuracy->  37.54%\n","Current batch: Loss-> 0.6209, Train accuracy->  37.65%\n","Current batch: Loss-> 0.7800, Train accuracy->  37.76%\n","Current batch: Loss-> 0.4326, Train accuracy->  37.87%\n","Current batch: Loss-> 0.7041, Train accuracy->  37.97%\n","Current batch: Loss-> 0.5083, Train accuracy->  38.09%\n","Current batch: Loss-> 0.8479, Train accuracy->  38.18%\n","Current batch: Loss-> 0.6554, Train accuracy->  38.29%\n","Current batch: Loss-> 0.6265, Train accuracy->  38.40%\n","Current batch: Loss-> 0.4568, Train accuracy->  38.51%\n","Current batch: Loss-> 0.5805, Train accuracy->  38.62%\n","Current batch: Loss-> 0.7420, Train accuracy->  38.72%\n","Current batch: Loss-> 0.7405, Train accuracy->  38.82%\n","Current batch: Loss-> 0.7732, Train accuracy->  38.93%\n","Current batch: Loss-> 0.7952, Train accuracy->  39.04%\n","Current batch: Loss-> 0.8406, Train accuracy->  39.15%\n","Current batch: Loss-> 0.6945, Train accuracy->  39.26%\n","Current batch: Loss-> 0.5844, Train accuracy->  39.36%\n","Current batch: Loss-> 0.7942, Train accuracy->  39.46%\n","Current batch: Loss-> 0.8257, Train accuracy->  39.56%\n","Current batch: Loss-> 0.7210, Train accuracy->  39.66%\n","Current batch: Loss-> 0.5500, Train accuracy->  39.77%\n","Current batch: Loss-> 0.5752, Train accuracy->  39.88%\n","Current batch: Loss-> 0.7872, Train accuracy->  39.98%\n","Current batch: Loss-> 0.6077, Train accuracy->  40.09%\n","Current batch: Loss-> 0.7023, Train accuracy->  40.19%\n","Current batch: Loss-> 0.9524, Train accuracy->  40.28%\n","Current batch: Loss-> 0.6379, Train accuracy->  40.38%\n","Current batch: Loss-> 0.7439, Train accuracy->  40.48%\n","Current batch: Loss-> 0.6897, Train accuracy->  40.58%\n","Current batch: Loss-> 0.8286, Train accuracy->  40.68%\n","Current batch: Loss-> 1.0238, Train accuracy->  40.77%\n","Current batch: Loss-> 0.9812, Train accuracy->  40.86%\n","Current batch: Loss-> 0.6465, Train accuracy->  40.96%\n","Current batch: Loss-> 0.4736, Train accuracy->  41.07%\n","Current batch: Loss-> 0.5989, Train accuracy->  41.17%\n","Current batch: Loss-> 0.9079, Train accuracy->  41.28%\n","Current batch: Loss-> 0.6833, Train accuracy->  41.39%\n","Current batch: Loss-> 0.6136, Train accuracy->  41.49%\n","Current batch: Loss-> 0.5044, Train accuracy->  41.61%\n","Current batch: Loss-> 0.6174, Train accuracy->  41.71%\n","Current batch: Loss-> 0.5440, Train accuracy->  41.82%\n","Current batch: Loss-> 1.1469, Train accuracy->  41.91%\n","Current batch: Loss-> 0.8486, Train accuracy->  42.01%\n","Current batch: Loss-> 0.5417, Train accuracy->  42.11%\n","Current batch: Loss-> 0.6297, Train accuracy->  42.21%\n","Current batch: Loss-> 0.7984, Train accuracy->  42.32%\n","Current batch: Loss-> 0.5034, Train accuracy->  42.42%\n","Current batch: Loss-> 0.4788, Train accuracy->  42.53%\n","Current batch: Loss-> 0.4766, Train accuracy->  42.64%\n","Current batch: Loss-> 0.6532, Train accuracy->  42.75%\n","Current batch: Loss-> 0.4016, Train accuracy->  42.86%\n","Current batch: Loss-> 0.7034, Train accuracy->  42.97%\n","Current batch: Loss-> 0.6411, Train accuracy->  43.06%\n","Current batch: Loss-> 0.8101, Train accuracy->  43.16%\n","Current batch: Loss-> 0.6235, Train accuracy->  43.26%\n","Current batch: Loss-> 0.6480, Train accuracy->  43.36%\n","Current batch: Loss-> 0.7233, Train accuracy->  43.47%\n","Current batch: Loss-> 0.7231, Train accuracy->  43.58%\n","Current batch: Loss-> 0.7276, Train accuracy->  43.67%\n","Current batch: Loss-> 0.6208, Train accuracy->  43.78%\n","Current batch: Loss-> 0.7698, Train accuracy->  43.88%\n","Current batch: Loss-> 0.7005, Train accuracy->  43.98%\n","Current batch: Loss-> 0.5635, Train accuracy->  44.09%\n","Current batch: Loss-> 0.4708, Train accuracy->  44.21%\n","Current batch: Loss-> 0.8122, Train accuracy->  44.32%\n","Current batch: Loss-> 0.6864, Train accuracy->  44.42%\n","Current batch: Loss-> 0.6512, Train accuracy->  44.53%\n","Current batch: Loss-> 0.5430, Train accuracy->  44.64%\n","Current batch: Loss-> 0.6940, Train accuracy->  44.74%\n","Current batch: Loss-> 0.7049, Train accuracy->  44.84%\n","Current batch: Loss-> 0.6143, Train accuracy->  44.96%\n","Current batch: Loss-> 0.6653, Train accuracy->  45.06%\n","Current batch: Loss-> 0.5219, Train accuracy->  45.18%\n","Current batch: Loss-> 0.6372, Train accuracy->  45.28%\n","Current batch: Loss-> 0.5460, Train accuracy->  45.39%\n","Current batch: Loss-> 0.8604, Train accuracy->  45.50%\n","Current batch: Loss-> 0.8148, Train accuracy->  45.60%\n","Current batch: Loss-> 0.5339, Train accuracy->  45.71%\n","Current batch: Loss-> 0.7651, Train accuracy->  45.80%\n","Current batch: Loss-> 0.8248, Train accuracy->  45.90%\n","Current batch: Loss-> 0.7299, Train accuracy->  46.01%\n","Current batch: Loss-> 0.3323, Train accuracy->  46.12%\n","Current batch: Loss-> 0.4541, Train accuracy->  46.24%\n","Current batch: Loss-> 0.7368, Train accuracy->  46.35%\n","Current batch: Loss-> 0.7235, Train accuracy->  46.45%\n","Current batch: Loss-> 0.6865, Train accuracy->  46.56%\n","Current batch: Loss-> 0.5791, Train accuracy->  46.67%\n","Current batch: Loss-> 0.6538, Train accuracy->  46.77%\n","Current batch: Loss-> 0.5538, Train accuracy->  46.88%\n","Current batch: Loss-> 0.5015, Train accuracy->  47.00%\n","Current batch: Loss-> 0.8236, Train accuracy->  47.09%\n","Current batch: Loss-> 0.5210, Train accuracy->  47.20%\n","Current batch: Loss-> 0.5472, Train accuracy->  47.31%\n","Current batch: Loss-> 0.5506, Train accuracy->  47.42%\n","Current batch: Loss-> 0.4702, Train accuracy->  47.54%\n","Current batch: Loss-> 0.5802, Train accuracy->  47.65%\n","Current batch: Loss-> 0.6793, Train accuracy->  47.75%\n","Current batch: Loss-> 0.6072, Train accuracy->  47.87%\n","Current batch: Loss-> 0.7635, Train accuracy->  47.97%\n","Current batch: Loss-> 1.0053, Train accuracy->  48.06%\n","Current batch: Loss-> 0.9574, Train accuracy->  48.15%\n","Current batch: Loss-> 0.4809, Train accuracy->  48.26%\n","Current batch: Loss-> 0.8134, Train accuracy->  48.37%\n","Current batch: Loss-> 0.6726, Train accuracy->  48.48%\n","Current batch: Loss-> 0.5201, Train accuracy->  48.59%\n","Current batch: Loss-> 0.5721, Train accuracy->  48.70%\n","Current batch: Loss-> 0.9671, Train accuracy->  48.80%\n","Current batch: Loss-> 0.8559, Train accuracy->  48.89%\n","Current batch: Loss-> 0.4453, Train accuracy->  49.00%\n","Current batch: Loss-> 0.4571, Train accuracy->  49.11%\n","Current batch: Loss-> 0.5731, Train accuracy->  49.22%\n","Current batch: Loss-> 0.5615, Train accuracy->  49.33%\n","Current batch: Loss-> 0.6835, Train accuracy->  49.43%\n","Current batch: Loss-> 0.3660, Train accuracy->  49.55%\n","Current batch: Loss-> 0.6623, Train accuracy->  49.65%\n","Current batch: Loss-> 0.5059, Train accuracy->  49.76%\n","Current batch: Loss-> 0.6256, Train accuracy->  49.87%\n","Current batch: Loss-> 0.5412, Train accuracy->  49.98%\n","Current batch: Loss-> 0.7479, Train accuracy->  50.09%\n","Current batch: Loss-> 0.5496, Train accuracy->  50.20%\n","Current batch: Loss-> 0.6112, Train accuracy->  50.31%\n","Current batch: Loss-> 0.5943, Train accuracy->  50.42%\n","Current batch: Loss-> 0.8342, Train accuracy->  50.52%\n","Current batch: Loss-> 0.7348, Train accuracy->  50.63%\n","Current batch: Loss-> 0.4472, Train accuracy->  50.74%\n","Current batch: Loss-> 0.7126, Train accuracy->  50.86%\n","Current batch: Loss-> 0.6368, Train accuracy->  50.97%\n","Current batch: Loss-> 0.6138, Train accuracy->  51.08%\n","Current batch: Loss-> 0.5835, Train accuracy->  51.18%\n","Current batch: Loss-> 0.4445, Train accuracy->  51.30%\n","Current batch: Loss-> 0.5475, Train accuracy->  51.42%\n","Current batch: Loss-> 0.4422, Train accuracy->  51.54%\n","Current batch: Loss-> 0.4390, Train accuracy->  51.65%\n","Current batch: Loss-> 0.6973, Train accuracy->  51.76%\n","Current batch: Loss-> 0.6174, Train accuracy->  51.87%\n","Current batch: Loss-> 0.5520, Train accuracy->  51.98%\n","Current batch: Loss-> 0.6997, Train accuracy->  52.07%\n","Current batch: Loss-> 0.5379, Train accuracy->  52.18%\n","Current batch: Loss-> 0.6659, Train accuracy->  52.29%\n","Current batch: Loss-> 0.3958, Train accuracy->  52.41%\n","Current batch: Loss-> 0.5321, Train accuracy->  52.53%\n","Current batch: Loss-> 0.7301, Train accuracy->  52.62%\n","Current batch: Loss-> 0.5563, Train accuracy->  52.74%\n","Current batch: Loss-> 0.8551, Train accuracy->  52.84%\n","Current batch: Loss-> 0.7863, Train accuracy->  52.94%\n","Current batch: Loss-> 0.6603, Train accuracy->  53.05%\n","Current batch: Loss-> 0.4487, Train accuracy->  53.16%\n","Current batch: Loss-> 0.8805, Train accuracy->  53.26%\n","Current batch: Loss-> 0.8985, Train accuracy->  53.36%\n","Current batch: Loss-> 1.0354, Train accuracy->  53.46%\n","Current batch: Loss-> 0.6333, Train accuracy->  53.57%\n","Current batch: Loss-> 0.4583, Train accuracy->  53.69%\n","Current batch: Loss-> 0.6937, Train accuracy->  53.80%\n","Current batch: Loss-> 0.4221, Train accuracy->  53.91%\n","Current batch: Loss-> 1.1139, Train accuracy->  54.01%\n","Current batch: Loss-> 0.5015, Train accuracy->  54.12%\n","Current batch: Loss-> 0.7600, Train accuracy->  54.22%\n","Current batch: Loss-> 0.7643, Train accuracy->  54.32%\n","Current batch: Loss-> 0.5032, Train accuracy->  54.43%\n","Current batch: Loss-> 0.7078, Train accuracy->  54.52%\n","Current batch: Loss-> 0.5297, Train accuracy->  54.63%\n","Current batch: Loss-> 0.5463, Train accuracy->  54.74%\n","Current batch: Loss-> 0.7674, Train accuracy->  54.85%\n","Current batch: Loss-> 0.7621, Train accuracy->  54.94%\n","Current batch: Loss-> 0.6446, Train accuracy->  55.04%\n","Current batch: Loss-> 0.5176, Train accuracy->  55.15%\n","Current batch: Loss-> 0.6148, Train accuracy->  55.25%\n","Current batch: Loss-> 0.6497, Train accuracy->  55.35%\n","Current batch: Loss-> 0.8924, Train accuracy->  55.44%\n","Current batch: Loss-> 0.6193, Train accuracy->  55.55%\n","Current batch: Loss-> 0.7716, Train accuracy->  55.65%\n","Current batch: Loss-> 0.7837, Train accuracy->  55.75%\n","Current batch: Loss-> 0.6952, Train accuracy->  55.85%\n","Current batch: Loss-> 0.4544, Train accuracy->  55.95%\n","Current batch: Loss-> 0.9815, Train accuracy->  56.05%\n","Current batch: Loss-> 0.5902, Train accuracy->  56.16%\n","Current batch: Loss-> 0.6179, Train accuracy->  56.27%\n","Current batch: Loss-> 0.5387, Train accuracy->  56.38%\n","Current batch: Loss-> 0.8312, Train accuracy->  56.47%\n","Current batch: Loss-> 0.8328, Train accuracy->  56.58%\n","Current batch: Loss-> 0.7297, Train accuracy->  56.69%\n","Current batch: Loss-> 0.9547, Train accuracy->  56.79%\n","Current batch: Loss-> 0.6072, Train accuracy->  56.90%\n","Current batch: Loss-> 0.7331, Train accuracy->  57.00%\n","Current batch: Loss-> 0.6276, Train accuracy->  57.10%\n","Current batch: Loss-> 0.8793, Train accuracy->  57.20%\n","Current batch: Loss-> 0.7586, Train accuracy->  57.30%\n","Current batch: Loss-> 0.6224, Train accuracy->  57.40%\n","Current batch: Loss-> 0.7366, Train accuracy->  57.50%\n","Current batch: Loss-> 0.5158, Train accuracy->  57.61%\n","Current batch: Loss-> 0.6897, Train accuracy->  57.72%\n","Current batch: Loss-> 0.6107, Train accuracy->  57.83%\n","Current batch: Loss-> 0.5741, Train accuracy->  57.93%\n","Current batch: Loss-> 0.6039, Train accuracy->  58.05%\n","Current batch: Loss-> 0.6679, Train accuracy->  58.15%\n","Current batch: Loss-> 0.6355, Train accuracy->  58.25%\n","Current batch: Loss-> 0.8316, Train accuracy->  58.34%\n","Current batch: Loss-> 0.7541, Train accuracy->  58.45%\n","Current batch: Loss-> 0.7701, Train accuracy->  58.55%\n","Current batch: Loss-> 0.8640, Train accuracy->  58.65%\n","Current batch: Loss-> 0.5054, Train accuracy->  58.76%\n","Current batch: Loss-> 0.7077, Train accuracy->  58.87%\n","Current batch: Loss-> 0.7317, Train accuracy->  58.98%\n","Current batch: Loss-> 0.6038, Train accuracy->  59.09%\n","Current batch: Loss-> 0.7686, Train accuracy->  59.19%\n","Current batch: Loss-> 0.8566, Train accuracy->  59.29%\n","Current batch: Loss-> 0.8365, Train accuracy->  59.40%\n","Current batch: Loss-> 0.7328, Train accuracy->  59.50%\n","Current batch: Loss-> 0.7051, Train accuracy->  59.59%\n","Current batch: Loss-> 0.5609, Train accuracy->  59.69%\n","Current batch: Loss-> 0.6893, Train accuracy->  59.80%\n","Current batch: Loss-> 0.7393, Train accuracy->  59.91%\n","Current batch: Loss-> 0.5378, Train accuracy->  60.02%\n","Current batch: Loss-> 0.9315, Train accuracy->  60.12%\n","Current batch: Loss-> 0.7155, Train accuracy->  60.22%\n","Current batch: Loss-> 0.5295, Train accuracy->  60.34%\n","Current batch: Loss-> 0.5963, Train accuracy->  60.44%\n","Current batch: Loss-> 0.7066, Train accuracy->  60.55%\n","Current batch: Loss-> 0.6891, Train accuracy->  60.65%\n","Current batch: Loss-> 1.0093, Train accuracy->  60.75%\n","Current batch: Loss-> 0.6331, Train accuracy->  60.85%\n","Current batch: Loss-> 0.6484, Train accuracy->  60.96%\n","Current batch: Loss-> 0.4698, Train accuracy->  61.07%\n","Current batch: Loss-> 0.6656, Train accuracy->  61.17%\n","Current batch: Loss-> 0.5058, Train accuracy->  61.29%\n","Current batch: Loss-> 0.6299, Train accuracy->  61.39%\n","Current batch: Loss-> 0.7117, Train accuracy->  61.50%\n","Current batch: Loss-> 0.8599, Train accuracy->  61.60%\n","Current batch: Loss-> 0.5871, Train accuracy->  61.70%\n","Current batch: Loss-> 0.5429, Train accuracy->  61.80%\n","Current batch: Loss-> 0.6068, Train accuracy->  61.91%\n","Current batch: Loss-> 0.6576, Train accuracy->  62.02%\n","Current batch: Loss-> 0.7801, Train accuracy->  62.13%\n","Current batch: Loss-> 0.7410, Train accuracy->  62.23%\n","Current batch: Loss-> 0.7742, Train accuracy->  62.34%\n","Current batch: Loss-> 0.6385, Train accuracy->  62.45%\n","Current batch: Loss-> 0.7549, Train accuracy->  62.55%\n","Current batch: Loss-> 0.8482, Train accuracy->  62.65%\n","Current batch: Loss-> 0.6639, Train accuracy->  62.75%\n","Current batch: Loss-> 0.4579, Train accuracy->  62.86%\n","Current batch: Loss-> 0.4025, Train accuracy->  62.98%\n","Current batch: Loss-> 1.0009, Train accuracy->  63.08%\n","Current batch: Loss-> 0.6626, Train accuracy->  63.18%\n","Current batch: Loss-> 0.5240, Train accuracy->  63.29%\n","Current batch: Loss-> 0.9971, Train accuracy->  63.39%\n","Current batch: Loss-> 0.4331, Train accuracy->  63.51%\n","Current batch: Loss-> 0.5803, Train accuracy->  63.61%\n","Current batch: Loss-> 0.7811, Train accuracy->  63.72%\n","Current batch: Loss-> 0.5826, Train accuracy->  63.84%\n","Current batch: Loss-> 1.0873, Train accuracy->  63.93%\n","Current batch: Loss-> 0.8905, Train accuracy->  64.02%\n","Current batch: Loss-> 1.0112, Train accuracy->  64.11%\n","Current batch: Loss-> 0.8037, Train accuracy->  64.21%\n","Current batch: Loss-> 0.7510, Train accuracy->  64.31%\n","Current batch: Loss-> 0.5104, Train accuracy->  64.43%\n","Current batch: Loss-> 0.9262, Train accuracy->  64.53%\n","Current batch: Loss-> 0.8058, Train accuracy->  64.64%\n","Current batch: Loss-> 0.6776, Train accuracy->  64.74%\n","Current batch: Loss-> 0.9317, Train accuracy->  64.85%\n","Current batch: Loss-> 0.4939, Train accuracy->  64.97%\n","Current batch: Loss-> 0.6263, Train accuracy->  65.07%\n","Current batch: Loss-> 0.5272, Train accuracy->  65.18%\n","Current batch: Loss-> 0.6312, Train accuracy->  65.29%\n","Current batch: Loss-> 0.7255, Train accuracy->  65.39%\n","Current batch: Loss-> 0.4452, Train accuracy->  65.51%\n","Current batch: Loss-> 0.6591, Train accuracy->  65.61%\n","Current batch: Loss-> 0.5619, Train accuracy->  65.72%\n","Current batch: Loss-> 0.7381, Train accuracy->  65.83%\n","Current batch: Loss-> 0.5636, Train accuracy->  65.94%\n","Current batch: Loss-> 0.6746, Train accuracy->  66.05%\n","Current batch: Loss-> 0.7360, Train accuracy->  66.14%\n","Current batch: Loss-> 0.6515, Train accuracy->  66.24%\n","Current batch: Loss-> 0.8370, Train accuracy->  66.35%\n","Current batch: Loss-> 0.5939, Train accuracy->  66.46%\n","Current batch: Loss-> 0.8759, Train accuracy->  66.56%\n","Current batch: Loss-> 0.6661, Train accuracy->  66.66%\n","Current batch: Loss-> 0.5461, Train accuracy->  66.78%\n","Current batch: Loss-> 0.5422, Train accuracy->  66.89%\n","Current batch: Loss-> 0.5774, Train accuracy->  67.00%\n","Current batch: Loss-> 0.7856, Train accuracy->  67.11%\n","Current batch: Loss-> 0.8076, Train accuracy->  67.22%\n","Current batch: Loss-> 0.5854, Train accuracy->  67.32%\n","Current batch: Loss-> 0.5570, Train accuracy->  67.44%\n","Current batch: Loss-> 0.6653, Train accuracy->  67.55%\n","Current batch: Loss-> 0.8687, Train accuracy->  67.64%\n","Current batch: Loss-> 0.5177, Train accuracy->  67.75%\n","Current batch: Loss-> 0.6138, Train accuracy->  67.85%\n","Current batch: Loss-> 0.5220, Train accuracy->  67.96%\n","Current batch: Loss-> 0.3905, Train accuracy->  68.08%\n","Current batch: Loss-> 0.4895, Train accuracy->  68.18%\n","Current batch: Loss-> 0.5578, Train accuracy->  68.30%\n","Current batch: Loss-> 0.7101, Train accuracy->  68.41%\n","Current batch: Loss-> 0.5674, Train accuracy->  68.52%\n","Current batch: Loss-> 0.7935, Train accuracy->  68.62%\n","Current batch: Loss-> 0.4654, Train accuracy->  68.73%\n","Current batch: Loss-> 0.6477, Train accuracy->  68.85%\n","Current batch: Loss-> 0.5531, Train accuracy->  68.96%\n","Current batch: Loss-> 0.5036, Train accuracy->  69.08%\n","Current batch: Loss-> 0.5153, Train accuracy->  69.20%\n","Current batch: Loss-> 0.9003, Train accuracy->  69.29%\n","Current batch: Loss-> 0.6753, Train accuracy->  69.40%\n","Current batch: Loss-> 0.9409, Train accuracy->  69.50%\n","Current batch: Loss-> 0.7765, Train accuracy->  69.60%\n","Current batch: Loss-> 0.7105, Train accuracy->  69.71%\n","Current batch: Loss-> 0.6855, Train accuracy->  69.82%\n","Current batch: Loss-> 0.4066, Train accuracy->  69.94%\n","Current batch: Loss-> 0.3615, Train accuracy->  70.05%\n","Current batch: Loss-> 0.4820, Train accuracy->  70.16%\n","Current batch: Loss-> 0.6169, Train accuracy->  70.26%\n","Current batch: Loss-> 0.5580, Train accuracy->  70.37%\n","Current batch: Loss-> 0.8208, Train accuracy->  70.47%\n","Current batch: Loss-> 0.5195, Train accuracy->  70.58%\n","Current batch: Loss-> 0.6947, Train accuracy->  70.69%\n","Current batch: Loss-> 0.8085, Train accuracy->  70.80%\n","Current batch: Loss-> 0.7667, Train accuracy->  70.90%\n","Current batch: Loss-> 0.5009, Train accuracy->  71.02%\n","Current batch: Loss-> 0.7982, Train accuracy->  71.11%\n","Current batch: Loss-> 0.4561, Train accuracy->  71.23%\n","Current batch: Loss-> 0.8819, Train accuracy->  71.33%\n","Current batch: Loss-> 0.5847, Train accuracy->  71.44%\n","Current batch: Loss-> 0.5957, Train accuracy->  71.55%\n","Current batch: Loss-> 0.8656, Train accuracy->  71.65%\n","Current batch: Loss-> 0.4284, Train accuracy->  71.77%\n","Current batch: Loss-> 0.6383, Train accuracy->  71.88%\n","Current batch: Loss-> 0.5975, Train accuracy->  71.98%\n","Current batch: Loss-> 0.4462, Train accuracy->  72.10%\n","Current batch: Loss-> 0.6293, Train accuracy->  72.21%\n","Current batch: Loss-> 0.5696, Train accuracy->  72.32%\n","Current batch: Loss-> 0.5975, Train accuracy->  72.42%\n","Current batch: Loss-> 0.3879, Train accuracy->  72.54%\n","Current batch: Loss-> 0.8007, Train accuracy->  72.65%\n","Current batch: Loss-> 0.5131, Train accuracy->  72.76%\n","Current batch: Loss-> 0.6569, Train accuracy->  72.87%\n","Current batch: Loss-> 0.6392, Train accuracy->  72.98%\n","Current batch: Loss-> 0.5527, Train accuracy->  73.09%\n","Current batch: Loss-> 0.6631, Train accuracy->  73.19%\n","Current batch: Loss-> 0.3975, Train accuracy->  73.31%\n","Current batch: Loss-> 0.6997, Train accuracy->  73.41%\n","Current batch: Loss-> 0.7608, Train accuracy->  73.51%\n","Current batch: Loss-> 0.6110, Train accuracy->  73.62%\n","Current batch: Loss-> 0.5284, Train accuracy->  73.73%\n","Current batch: Loss-> 0.6211, Train accuracy->  73.85%\n","Current batch: Loss-> 0.9663, Train accuracy->  73.95%\n","Current batch: Loss-> 0.6499, Train accuracy->  74.06%\n","Current batch: Loss-> 0.7204, Train accuracy->  74.15%\n","Current batch: Loss-> 0.7204, Train accuracy->  74.26%\n","Current batch: Loss-> 0.7750, Train accuracy->  74.36%\n","Current batch: Loss-> 0.7023, Train accuracy->  74.46%\n","Current batch: Loss-> 0.3813, Train accuracy->  74.58%\n","Current batch: Loss-> 0.6637, Train accuracy->  74.68%\n","Current batch: Loss-> 0.5816, Train accuracy->  74.79%\n","Current batch: Loss-> 0.6817, Train accuracy->  74.90%\n","Current batch: Loss-> 0.7263, Train accuracy->  75.00%\n","Current batch: Loss-> 1.1576, Train accuracy->  75.10%\n","Current batch: Loss-> 0.7146, Train accuracy->  75.21%\n","Current batch: Loss-> 0.7554, Train accuracy->  75.32%\n","Current batch: Loss-> 0.6006, Train accuracy->  75.43%\n","Current batch: Loss-> 0.7328, Train accuracy->  75.54%\n","Current batch: Loss-> 0.7071, Train accuracy->  75.65%\n","Current batch: Loss-> 1.0584, Train accuracy->  75.74%\n","Current batch: Loss-> 0.8706, Train accuracy->  75.84%\n","Current batch: Loss-> 0.6096, Train accuracy->  75.94%\n","Current batch: Loss-> 0.4994, Train accuracy->  76.05%\n","Current batch: Loss-> 0.4067, Train accuracy->  76.17%\n","Current batch: Loss-> 0.7397, Train accuracy->  76.26%\n","Current batch: Loss-> 0.5972, Train accuracy->  76.37%\n","Current batch: Loss-> 0.4976, Train accuracy->  76.49%\n","Current batch: Loss-> 0.6598, Train accuracy->  76.59%\n","Current batch: Loss-> 0.5061, Train accuracy->  76.70%\n","Current batch: Loss-> 0.6091, Train accuracy->  76.80%\n","Current batch: Loss-> 0.4448, Train accuracy->  76.92%\n","Current batch: Loss-> 0.4213, Train accuracy->  77.03%\n","Current batch: Loss-> 0.6514, Train accuracy->  77.14%\n","Current batch: Loss-> 0.6063, Train accuracy->  77.24%\n","Current batch: Loss-> 0.5668, Train accuracy->  77.35%\n","Current batch: Loss-> 0.5051, Train accuracy->  77.47%\n","Current batch: Loss-> 0.6566, Train accuracy->  77.56%\n","Current batch: Loss-> 0.4869, Train accuracy->  77.68%\n","Current batch: Loss-> 0.3834, Train accuracy->  77.80%\n","Current batch: Loss-> 0.6027, Train accuracy->  77.90%\n","Current batch: Loss-> 0.6497, Train accuracy->  78.01%\n","Current batch: Loss-> 0.5678, Train accuracy->  78.12%\n","Current batch: Loss-> 0.6849, Train accuracy->  78.23%\n","Current batch: Loss-> 0.5344, Train accuracy->  78.34%\n","Current batch: Loss-> 0.4479, Train accuracy->  78.45%\n","Current batch: Loss-> 0.3266, Train accuracy->  78.57%\n","Current batch: Loss-> 0.5798, Train accuracy->  78.68%\n","Current batch: Loss-> 0.3981, Train accuracy->  78.80%\n","Current batch: Loss-> 0.6551, Train accuracy->  78.90%\n","Current batch: Loss-> 0.6292, Train accuracy->  79.01%\n","Current batch: Loss-> 0.4213, Train accuracy->  79.12%\n","Current batch: Loss-> 0.5752, Train accuracy->  79.24%\n","Current batch: Loss-> 0.5972, Train accuracy->  79.34%\n","Current batch: Loss-> 0.6777, Train accuracy->  79.44%\n","Current batch: Loss-> 0.8136, Train accuracy->  79.54%\n","Current batch: Loss-> 0.4535, Train accuracy->  79.64%\n","Current batch: Loss-> 0.8214, Train accuracy->  79.74%\n","Current batch: Loss-> 0.6339, Train accuracy->  79.85%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 47.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.5255, Train accuracy->  79.96%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.90it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.5964, Accuracy: 5459/12000 (45%)\n","\n","Current batch: Loss-> 0.5087, Train accuracy->   0.10%\n","Current batch: Loss-> 1.1118, Train accuracy->   0.20%\n","Current batch: Loss-> 0.8064, Train accuracy->   0.30%\n","Current batch: Loss-> 0.9917, Train accuracy->   0.40%\n","Current batch: Loss-> 0.3712, Train accuracy->   0.51%\n","Current batch: Loss-> 0.5021, Train accuracy->   0.63%\n","Current batch: Loss-> 0.6232, Train accuracy->   0.73%\n","Current batch: Loss-> 0.8854, Train accuracy->   0.84%\n","Current batch: Loss-> 0.5669, Train accuracy->   0.95%\n","Current batch: Loss-> 0.6782, Train accuracy->   1.05%\n","Current batch: Loss-> 0.6919, Train accuracy->   1.16%\n","Current batch: Loss-> 0.7489, Train accuracy->   1.27%\n","Current batch: Loss-> 0.6912, Train accuracy->   1.37%\n","Current batch: Loss-> 0.8422, Train accuracy->   1.47%\n","Current batch: Loss-> 0.4690, Train accuracy->   1.59%\n","Current batch: Loss-> 0.6636, Train accuracy->   1.69%\n","Current batch: Loss-> 0.6981, Train accuracy->   1.80%\n","Current batch: Loss-> 0.8843, Train accuracy->   1.90%\n","Current batch: Loss-> 0.7366, Train accuracy->   1.99%\n","Current batch: Loss-> 0.4274, Train accuracy->   2.10%\n","Current batch: Loss-> 0.7996, Train accuracy->   2.20%\n","Current batch: Loss-> 0.6210, Train accuracy->   2.31%\n","Current batch: Loss-> 0.7460, Train accuracy->   2.41%\n","Current batch: Loss-> 0.5003, Train accuracy->   2.53%\n","Current batch: Loss-> 0.6283, Train accuracy->   2.64%\n","Current batch: Loss-> 0.7579, Train accuracy->   2.75%\n","Current batch: Loss-> 0.5378, Train accuracy->   2.87%\n","Current batch: Loss-> 0.7637, Train accuracy->   2.96%\n","Current batch: Loss-> 0.4533, Train accuracy->   3.07%\n","Current batch: Loss-> 0.7885, Train accuracy->   3.17%\n","Current batch: Loss-> 0.3383, Train accuracy->   3.29%\n","Current batch: Loss-> 0.7276, Train accuracy->   3.39%\n","Current batch: Loss-> 0.7773, Train accuracy->   3.49%\n","Current batch: Loss-> 0.6760, Train accuracy->   3.60%\n","Current batch: Loss-> 0.4545, Train accuracy->   3.71%\n","Current batch: Loss-> 0.5092, Train accuracy->   3.82%\n","Current batch: Loss-> 0.6879, Train accuracy->   3.93%\n","Current batch: Loss-> 0.4971, Train accuracy->   4.03%\n","Current batch: Loss-> 0.6665, Train accuracy->   4.14%\n","Current batch: Loss-> 0.6054, Train accuracy->   4.25%\n","Current batch: Loss-> 0.4713, Train accuracy->   4.37%\n","Current batch: Loss-> 0.6890, Train accuracy->   4.47%\n","Current batch: Loss-> 0.6026, Train accuracy->   4.58%\n","Current batch: Loss-> 0.5246, Train accuracy->   4.70%\n","Current batch: Loss-> 0.6333, Train accuracy->   4.80%\n","Current batch: Loss-> 0.6250, Train accuracy->   4.91%\n","Current batch: Loss-> 0.7613, Train accuracy->   5.01%\n","Current batch: Loss-> 0.8848, Train accuracy->   5.11%\n","Current batch: Loss-> 0.4546, Train accuracy->   5.23%\n","Current batch: Loss-> 0.6708, Train accuracy->   5.33%\n","Current batch: Loss-> 0.5922, Train accuracy->   5.44%\n","Current batch: Loss-> 0.3850, Train accuracy->   5.55%\n","Current batch: Loss-> 0.6337, Train accuracy->   5.66%\n","Current batch: Loss-> 0.5311, Train accuracy->   5.77%\n","Current batch: Loss-> 0.5442, Train accuracy->   5.89%\n","Current batch: Loss-> 0.6445, Train accuracy->   6.00%\n","Current batch: Loss-> 0.5851, Train accuracy->   6.11%\n","Current batch: Loss-> 0.4253, Train accuracy->   6.22%\n","Current batch: Loss-> 0.6337, Train accuracy->   6.33%\n","Current batch: Loss-> 0.8016, Train accuracy->   6.44%\n","Current batch: Loss-> 0.5636, Train accuracy->   6.54%\n","Current batch: Loss-> 0.8758, Train accuracy->   6.65%\n","Current batch: Loss-> 0.4231, Train accuracy->   6.77%\n","Current batch: Loss-> 0.6741, Train accuracy->   6.87%\n","Current batch: Loss-> 1.0126, Train accuracy->   6.97%\n","Current batch: Loss-> 0.5457, Train accuracy->   7.09%\n","Current batch: Loss-> 0.4582, Train accuracy->   7.20%\n","Current batch: Loss-> 0.6583, Train accuracy->   7.31%\n","Current batch: Loss-> 0.8036, Train accuracy->   7.41%\n","Current batch: Loss-> 0.4427, Train accuracy->   7.53%\n","Current batch: Loss-> 0.5753, Train accuracy->   7.63%\n","Current batch: Loss-> 0.7421, Train accuracy->   7.74%\n","Current batch: Loss-> 0.7378, Train accuracy->   7.85%\n","Current batch: Loss-> 0.5309, Train accuracy->   7.96%\n","Current batch: Loss-> 0.4447, Train accuracy->   8.07%\n","Current batch: Loss-> 0.4918, Train accuracy->   8.18%\n","Current batch: Loss-> 0.5534, Train accuracy->   8.29%\n","Current batch: Loss-> 0.7100, Train accuracy->   8.39%\n","Current batch: Loss-> 0.4809, Train accuracy->   8.50%\n","Current batch: Loss-> 0.3081, Train accuracy->   8.62%\n","Current batch: Loss-> 0.7344, Train accuracy->   8.73%\n","Current batch: Loss-> 0.6015, Train accuracy->   8.83%\n","Current batch: Loss-> 0.7524, Train accuracy->   8.94%\n","Current batch: Loss-> 0.5957, Train accuracy->   9.05%\n","Current batch: Loss-> 0.5852, Train accuracy->   9.16%\n","Current batch: Loss-> 0.5181, Train accuracy->   9.26%\n","Current batch: Loss-> 0.9158, Train accuracy->   9.36%\n","Current batch: Loss-> 0.8150, Train accuracy->   9.47%\n","Current batch: Loss-> 0.5683, Train accuracy->   9.58%\n","Current batch: Loss-> 0.7715, Train accuracy->   9.69%\n","Current batch: Loss-> 0.6706, Train accuracy->   9.79%\n","Current batch: Loss-> 1.0609, Train accuracy->   9.88%\n","Current batch: Loss-> 0.5716, Train accuracy->   9.99%\n","Current batch: Loss-> 0.8146, Train accuracy->  10.08%\n","Current batch: Loss-> 0.6837, Train accuracy->  10.18%\n","Current batch: Loss-> 0.7144, Train accuracy->  10.29%\n","Current batch: Loss-> 0.8502, Train accuracy->  10.40%\n","Current batch: Loss-> 0.9801, Train accuracy->  10.49%\n","Current batch: Loss-> 0.5765, Train accuracy->  10.61%\n","Current batch: Loss-> 0.6972, Train accuracy->  10.71%\n","Current batch: Loss-> 0.5807, Train accuracy->  10.81%\n","Current batch: Loss-> 0.6447, Train accuracy->  10.91%\n","Current batch: Loss-> 0.8241, Train accuracy->  11.01%\n","Current batch: Loss-> 0.6247, Train accuracy->  11.12%\n","Current batch: Loss-> 0.7915, Train accuracy->  11.22%\n","Current batch: Loss-> 0.9008, Train accuracy->  11.30%\n","Current batch: Loss-> 0.4771, Train accuracy->  11.43%\n","Current batch: Loss-> 0.7737, Train accuracy->  11.52%\n","Current batch: Loss-> 0.5594, Train accuracy->  11.64%\n","Current batch: Loss-> 0.5093, Train accuracy->  11.75%\n","Current batch: Loss-> 0.4516, Train accuracy->  11.87%\n","Current batch: Loss-> 0.6367, Train accuracy->  11.97%\n","Current batch: Loss-> 0.6081, Train accuracy->  12.08%\n","Current batch: Loss-> 0.6909, Train accuracy->  12.18%\n","Current batch: Loss-> 0.7392, Train accuracy->  12.28%\n","Current batch: Loss-> 0.5944, Train accuracy->  12.38%\n","Current batch: Loss-> 0.5555, Train accuracy->  12.50%\n","Current batch: Loss-> 0.3918, Train accuracy->  12.61%\n","Current batch: Loss-> 0.5602, Train accuracy->  12.71%\n","Current batch: Loss-> 0.7631, Train accuracy->  12.82%\n","Current batch: Loss-> 0.7497, Train accuracy->  12.91%\n","Current batch: Loss-> 0.6677, Train accuracy->  13.02%\n","Current batch: Loss-> 0.6558, Train accuracy->  13.13%\n","Current batch: Loss-> 0.6411, Train accuracy->  13.23%\n","Current batch: Loss-> 0.7520, Train accuracy->  13.33%\n","Current batch: Loss-> 0.5513, Train accuracy->  13.44%\n","Current batch: Loss-> 0.5213, Train accuracy->  13.55%\n","Current batch: Loss-> 0.9393, Train accuracy->  13.64%\n","Current batch: Loss-> 0.5493, Train accuracy->  13.75%\n","Current batch: Loss-> 0.3588, Train accuracy->  13.87%\n","Current batch: Loss-> 0.6576, Train accuracy->  13.96%\n","Current batch: Loss-> 0.8466, Train accuracy->  14.07%\n","Current batch: Loss-> 0.6380, Train accuracy->  14.17%\n","Current batch: Loss-> 0.7077, Train accuracy->  14.27%\n","Current batch: Loss-> 0.6648, Train accuracy->  14.39%\n","Current batch: Loss-> 0.5427, Train accuracy->  14.50%\n","Current batch: Loss-> 0.7228, Train accuracy->  14.60%\n","Current batch: Loss-> 0.4153, Train accuracy->  14.71%\n","Current batch: Loss-> 0.6437, Train accuracy->  14.82%\n","Current batch: Loss-> 0.4301, Train accuracy->  14.93%\n","Current batch: Loss-> 0.6752, Train accuracy->  15.03%\n","Current batch: Loss-> 0.7835, Train accuracy->  15.13%\n","Current batch: Loss-> 0.3833, Train accuracy->  15.25%\n","Current batch: Loss-> 0.6149, Train accuracy->  15.37%\n","Current batch: Loss-> 0.5435, Train accuracy->  15.48%\n","Current batch: Loss-> 0.6679, Train accuracy->  15.59%\n","Current batch: Loss-> 0.6998, Train accuracy->  15.68%\n","Current batch: Loss-> 0.4926, Train accuracy->  15.78%\n","Current batch: Loss-> 0.9275, Train accuracy->  15.88%\n","Current batch: Loss-> 0.4842, Train accuracy->  16.00%\n","Current batch: Loss-> 0.3807, Train accuracy->  16.12%\n","Current batch: Loss-> 0.7107, Train accuracy->  16.22%\n","Current batch: Loss-> 0.5093, Train accuracy->  16.33%\n","Current batch: Loss-> 0.7243, Train accuracy->  16.43%\n","Current batch: Loss-> 0.5189, Train accuracy->  16.54%\n","Current batch: Loss-> 0.5663, Train accuracy->  16.66%\n","Current batch: Loss-> 0.4811, Train accuracy->  16.77%\n","Current batch: Loss-> 0.6225, Train accuracy->  16.86%\n","Current batch: Loss-> 0.4286, Train accuracy->  16.98%\n","Current batch: Loss-> 0.6635, Train accuracy->  17.09%\n","Current batch: Loss-> 0.3758, Train accuracy->  17.20%\n","Current batch: Loss-> 0.3605, Train accuracy->  17.32%\n","Current batch: Loss-> 0.4617, Train accuracy->  17.43%\n","Current batch: Loss-> 0.7315, Train accuracy->  17.54%\n","Current batch: Loss-> 0.7950, Train accuracy->  17.65%\n","Current batch: Loss-> 0.7534, Train accuracy->  17.75%\n","Current batch: Loss-> 0.4534, Train accuracy->  17.87%\n","Current batch: Loss-> 0.4876, Train accuracy->  17.98%\n","Current batch: Loss-> 0.4498, Train accuracy->  18.10%\n","Current batch: Loss-> 0.7317, Train accuracy->  18.21%\n","Current batch: Loss-> 0.8322, Train accuracy->  18.32%\n","Current batch: Loss-> 0.5993, Train accuracy->  18.43%\n","Current batch: Loss-> 0.6536, Train accuracy->  18.54%\n","Current batch: Loss-> 0.6787, Train accuracy->  18.65%\n","Current batch: Loss-> 0.6245, Train accuracy->  18.76%\n","Current batch: Loss-> 0.5168, Train accuracy->  18.87%\n","Current batch: Loss-> 0.6159, Train accuracy->  18.98%\n","Current batch: Loss-> 0.6585, Train accuracy->  19.09%\n","Current batch: Loss-> 0.6855, Train accuracy->  19.19%\n","Current batch: Loss-> 0.6985, Train accuracy->  19.29%\n","Current batch: Loss-> 0.7212, Train accuracy->  19.40%\n","Current batch: Loss-> 0.6572, Train accuracy->  19.51%\n","Current batch: Loss-> 0.5679, Train accuracy->  19.62%\n","Current batch: Loss-> 0.5583, Train accuracy->  19.73%\n","Current batch: Loss-> 0.5147, Train accuracy->  19.83%\n","Current batch: Loss-> 0.5738, Train accuracy->  19.94%\n","Current batch: Loss-> 0.8571, Train accuracy->  20.05%\n","Current batch: Loss-> 0.8827, Train accuracy->  20.15%\n","Current batch: Loss-> 0.6043, Train accuracy->  20.25%\n","Current batch: Loss-> 0.5692, Train accuracy->  20.36%\n","Current batch: Loss-> 0.5669, Train accuracy->  20.46%\n","Current batch: Loss-> 0.5176, Train accuracy->  20.57%\n","Current batch: Loss-> 0.8086, Train accuracy->  20.66%\n","Current batch: Loss-> 0.5495, Train accuracy->  20.78%\n","Current batch: Loss-> 0.5908, Train accuracy->  20.88%\n","Current batch: Loss-> 0.6199, Train accuracy->  21.00%\n","Current batch: Loss-> 0.5673, Train accuracy->  21.10%\n","Current batch: Loss-> 0.6682, Train accuracy->  21.20%\n","Current batch: Loss-> 0.7044, Train accuracy->  21.31%\n","Current batch: Loss-> 0.5127, Train accuracy->  21.41%\n","Current batch: Loss-> 0.9094, Train accuracy->  21.51%\n","Current batch: Loss-> 0.4555, Train accuracy->  21.63%\n","Current batch: Loss-> 0.6952, Train accuracy->  21.74%\n","Current batch: Loss-> 0.5092, Train accuracy->  21.85%\n","Current batch: Loss-> 0.5669, Train accuracy->  21.96%\n","Current batch: Loss-> 0.8041, Train accuracy->  22.07%\n","Current batch: Loss-> 0.4589, Train accuracy->  22.18%\n","Current batch: Loss-> 0.7565, Train accuracy->  22.28%\n","Current batch: Loss-> 0.5981, Train accuracy->  22.39%\n","Current batch: Loss-> 0.5295, Train accuracy->  22.51%\n","Current batch: Loss-> 0.6562, Train accuracy->  22.62%\n","Current batch: Loss-> 0.8081, Train accuracy->  22.72%\n","Current batch: Loss-> 0.4455, Train accuracy->  22.83%\n","Current batch: Loss-> 0.5720, Train accuracy->  22.94%\n","Current batch: Loss-> 0.5154, Train accuracy->  23.05%\n","Current batch: Loss-> 0.7003, Train accuracy->  23.16%\n","Current batch: Loss-> 0.6452, Train accuracy->  23.25%\n","Current batch: Loss-> 0.7431, Train accuracy->  23.36%\n","Current batch: Loss-> 0.5648, Train accuracy->  23.47%\n","Current batch: Loss-> 0.3856, Train accuracy->  23.59%\n","Current batch: Loss-> 0.5546, Train accuracy->  23.70%\n","Current batch: Loss-> 0.5673, Train accuracy->  23.81%\n","Current batch: Loss-> 0.6587, Train accuracy->  23.92%\n","Current batch: Loss-> 0.7034, Train accuracy->  24.03%\n","Current batch: Loss-> 0.4431, Train accuracy->  24.14%\n","Current batch: Loss-> 0.4333, Train accuracy->  24.25%\n","Current batch: Loss-> 0.9452, Train accuracy->  24.34%\n","Current batch: Loss-> 0.7610, Train accuracy->  24.45%\n","Current batch: Loss-> 0.7607, Train accuracy->  24.55%\n","Current batch: Loss-> 0.7443, Train accuracy->  24.65%\n","Current batch: Loss-> 0.8352, Train accuracy->  24.75%\n","Current batch: Loss-> 0.6429, Train accuracy->  24.86%\n","Current batch: Loss-> 0.7743, Train accuracy->  24.97%\n","Current batch: Loss-> 0.9847, Train accuracy->  25.07%\n","Current batch: Loss-> 0.3244, Train accuracy->  25.19%\n","Current batch: Loss-> 0.7894, Train accuracy->  25.29%\n","Current batch: Loss-> 0.5413, Train accuracy->  25.39%\n","Current batch: Loss-> 0.6688, Train accuracy->  25.50%\n","Current batch: Loss-> 0.5463, Train accuracy->  25.61%\n","Current batch: Loss-> 0.7948, Train accuracy->  25.71%\n","Current batch: Loss-> 0.5761, Train accuracy->  25.82%\n","Current batch: Loss-> 0.8875, Train accuracy->  25.92%\n","Current batch: Loss-> 0.5078, Train accuracy->  26.04%\n","Current batch: Loss-> 0.5900, Train accuracy->  26.15%\n","Current batch: Loss-> 0.4753, Train accuracy->  26.27%\n","Current batch: Loss-> 0.5219, Train accuracy->  26.38%\n","Current batch: Loss-> 1.1070, Train accuracy->  26.47%\n","Current batch: Loss-> 0.5241, Train accuracy->  26.58%\n","Current batch: Loss-> 0.5669, Train accuracy->  26.69%\n","Current batch: Loss-> 0.7181, Train accuracy->  26.79%\n","Current batch: Loss-> 0.5786, Train accuracy->  26.90%\n","Current batch: Loss-> 0.5290, Train accuracy->  27.00%\n","Current batch: Loss-> 0.6129, Train accuracy->  27.11%\n","Current batch: Loss-> 0.6634, Train accuracy->  27.21%\n","Current batch: Loss-> 0.5369, Train accuracy->  27.31%\n","Current batch: Loss-> 0.6350, Train accuracy->  27.41%\n","Current batch: Loss-> 0.4435, Train accuracy->  27.53%\n","Current batch: Loss-> 0.6352, Train accuracy->  27.63%\n","Current batch: Loss-> 0.8187, Train accuracy->  27.74%\n","Current batch: Loss-> 0.7686, Train accuracy->  27.85%\n","Current batch: Loss-> 0.4710, Train accuracy->  27.96%\n","Current batch: Loss-> 0.9097, Train accuracy->  28.06%\n","Current batch: Loss-> 0.4497, Train accuracy->  28.16%\n","Current batch: Loss-> 0.4192, Train accuracy->  28.27%\n","Current batch: Loss-> 0.3958, Train accuracy->  28.39%\n","Current batch: Loss-> 0.4824, Train accuracy->  28.50%\n","Current batch: Loss-> 0.5016, Train accuracy->  28.62%\n","Current batch: Loss-> 0.4435, Train accuracy->  28.74%\n","Current batch: Loss-> 0.7271, Train accuracy->  28.83%\n","Current batch: Loss-> 0.5713, Train accuracy->  28.93%\n","Current batch: Loss-> 0.8032, Train accuracy->  29.04%\n","Current batch: Loss-> 0.3455, Train accuracy->  29.16%\n","Current batch: Loss-> 1.0528, Train accuracy->  29.25%\n","Current batch: Loss-> 0.6786, Train accuracy->  29.35%\n","Current batch: Loss-> 0.6115, Train accuracy->  29.47%\n","Current batch: Loss-> 0.5569, Train accuracy->  29.58%\n","Current batch: Loss-> 0.8228, Train accuracy->  29.69%\n","Current batch: Loss-> 0.4120, Train accuracy->  29.80%\n","Current batch: Loss-> 0.7671, Train accuracy->  29.91%\n","Current batch: Loss-> 0.4771, Train accuracy->  30.03%\n","Current batch: Loss-> 0.6263, Train accuracy->  30.13%\n","Current batch: Loss-> 0.7084, Train accuracy->  30.24%\n","Current batch: Loss-> 0.4627, Train accuracy->  30.34%\n","Current batch: Loss-> 0.9123, Train accuracy->  30.44%\n","Current batch: Loss-> 0.8440, Train accuracy->  30.55%\n","Current batch: Loss-> 0.8252, Train accuracy->  30.64%\n","Current batch: Loss-> 0.7087, Train accuracy->  30.75%\n","Current batch: Loss-> 0.8392, Train accuracy->  30.85%\n","Current batch: Loss-> 0.6911, Train accuracy->  30.96%\n","Current batch: Loss-> 0.7241, Train accuracy->  31.05%\n","Current batch: Loss-> 0.8482, Train accuracy->  31.16%\n","Current batch: Loss-> 0.4635, Train accuracy->  31.27%\n","Current batch: Loss-> 0.5884, Train accuracy->  31.38%\n","Current batch: Loss-> 0.9115, Train accuracy->  31.47%\n","Current batch: Loss-> 0.6033, Train accuracy->  31.57%\n","Current batch: Loss-> 0.5573, Train accuracy->  31.68%\n","Current batch: Loss-> 0.6382, Train accuracy->  31.79%\n","Current batch: Loss-> 0.6767, Train accuracy->  31.90%\n","Current batch: Loss-> 0.5871, Train accuracy->  32.02%\n","Current batch: Loss-> 0.4925, Train accuracy->  32.13%\n","Current batch: Loss-> 0.4560, Train accuracy->  32.24%\n","Current batch: Loss-> 0.4762, Train accuracy->  32.36%\n","Current batch: Loss-> 0.7265, Train accuracy->  32.47%\n","Current batch: Loss-> 0.6432, Train accuracy->  32.58%\n","Current batch: Loss-> 0.5946, Train accuracy->  32.69%\n","Current batch: Loss-> 0.6838, Train accuracy->  32.80%\n","Current batch: Loss-> 0.5806, Train accuracy->  32.90%\n","Current batch: Loss-> 0.5481, Train accuracy->  33.01%\n","Current batch: Loss-> 0.7457, Train accuracy->  33.12%\n","Current batch: Loss-> 0.4294, Train accuracy->  33.24%\n","Current batch: Loss-> 0.7188, Train accuracy->  33.35%\n","Current batch: Loss-> 0.8547, Train accuracy->  33.45%\n","Current batch: Loss-> 0.6797, Train accuracy->  33.56%\n","Current batch: Loss-> 0.7996, Train accuracy->  33.65%\n","Current batch: Loss-> 0.4469, Train accuracy->  33.77%\n","Current batch: Loss-> 0.9959, Train accuracy->  33.86%\n","Current batch: Loss-> 0.6265, Train accuracy->  33.97%\n","Current batch: Loss-> 0.5247, Train accuracy->  34.08%\n","Current batch: Loss-> 0.5653, Train accuracy->  34.19%\n","Current batch: Loss-> 0.7081, Train accuracy->  34.30%\n","Current batch: Loss-> 0.5536, Train accuracy->  34.40%\n","Current batch: Loss-> 0.8987, Train accuracy->  34.51%\n","Current batch: Loss-> 0.6730, Train accuracy->  34.61%\n","Current batch: Loss-> 0.6107, Train accuracy->  34.72%\n","Current batch: Loss-> 0.4540, Train accuracy->  34.84%\n","Current batch: Loss-> 0.6592, Train accuracy->  34.94%\n","Current batch: Loss-> 0.4402, Train accuracy->  35.05%\n","Current batch: Loss-> 0.6504, Train accuracy->  35.16%\n","Current batch: Loss-> 0.5285, Train accuracy->  35.28%\n","Current batch: Loss-> 0.6472, Train accuracy->  35.39%\n","Current batch: Loss-> 0.6236, Train accuracy->  35.49%\n","Current batch: Loss-> 0.5663, Train accuracy->  35.59%\n","Current batch: Loss-> 0.7328, Train accuracy->  35.71%\n","Current batch: Loss-> 0.4808, Train accuracy->  35.82%\n","Current batch: Loss-> 0.4731, Train accuracy->  35.93%\n","Current batch: Loss-> 0.6823, Train accuracy->  36.04%\n","Current batch: Loss-> 0.5949, Train accuracy->  36.14%\n","Current batch: Loss-> 0.6857, Train accuracy->  36.24%\n","Current batch: Loss-> 0.5301, Train accuracy->  36.35%\n","Current batch: Loss-> 0.7868, Train accuracy->  36.46%\n","Current batch: Loss-> 0.4789, Train accuracy->  36.58%\n","Current batch: Loss-> 0.4913, Train accuracy->  36.69%\n","Current batch: Loss-> 0.4557, Train accuracy->  36.79%\n","Current batch: Loss-> 0.4575, Train accuracy->  36.90%\n","Current batch: Loss-> 0.4357, Train accuracy->  37.01%\n","Current batch: Loss-> 0.7152, Train accuracy->  37.11%\n","Current batch: Loss-> 0.5008, Train accuracy->  37.22%\n","Current batch: Loss-> 0.7564, Train accuracy->  37.33%\n","Current batch: Loss-> 0.8058, Train accuracy->  37.42%\n","Current batch: Loss-> 0.5987, Train accuracy->  37.54%\n","Current batch: Loss-> 0.7667, Train accuracy->  37.64%\n","Current batch: Loss-> 0.8351, Train accuracy->  37.73%\n","Current batch: Loss-> 0.8622, Train accuracy->  37.83%\n","Current batch: Loss-> 0.8293, Train accuracy->  37.93%\n","Current batch: Loss-> 0.3416, Train accuracy->  38.05%\n","Current batch: Loss-> 0.5893, Train accuracy->  38.16%\n","Current batch: Loss-> 0.5390, Train accuracy->  38.26%\n","Current batch: Loss-> 0.8905, Train accuracy->  38.38%\n","Current batch: Loss-> 0.4748, Train accuracy->  38.49%\n","Current batch: Loss-> 0.6926, Train accuracy->  38.60%\n","Current batch: Loss-> 0.5695, Train accuracy->  38.71%\n","Current batch: Loss-> 0.6664, Train accuracy->  38.81%\n","Current batch: Loss-> 0.6222, Train accuracy->  38.92%\n","Current batch: Loss-> 0.7406, Train accuracy->  39.02%\n","Current batch: Loss-> 0.3582, Train accuracy->  39.14%\n","Current batch: Loss-> 0.5995, Train accuracy->  39.25%\n","Current batch: Loss-> 0.4759, Train accuracy->  39.36%\n","Current batch: Loss-> 0.5906, Train accuracy->  39.47%\n","Current batch: Loss-> 0.6382, Train accuracy->  39.58%\n","Current batch: Loss-> 0.4842, Train accuracy->  39.69%\n","Current batch: Loss-> 0.6466, Train accuracy->  39.79%\n","Current batch: Loss-> 0.4068, Train accuracy->  39.91%\n","Current batch: Loss-> 0.7644, Train accuracy->  40.00%\n","Current batch: Loss-> 0.5808, Train accuracy->  40.11%\n","Current batch: Loss-> 0.4466, Train accuracy->  40.23%\n","Current batch: Loss-> 0.5665, Train accuracy->  40.34%\n","Current batch: Loss-> 0.6036, Train accuracy->  40.45%\n","Current batch: Loss-> 0.7016, Train accuracy->  40.55%\n","Current batch: Loss-> 0.5985, Train accuracy->  40.66%\n","Current batch: Loss-> 0.3489, Train accuracy->  40.78%\n","Current batch: Loss-> 0.5595, Train accuracy->  40.89%\n","Current batch: Loss-> 0.5466, Train accuracy->  41.00%\n","Current batch: Loss-> 0.8348, Train accuracy->  41.10%\n","Current batch: Loss-> 0.5121, Train accuracy->  41.21%\n","Current batch: Loss-> 0.5942, Train accuracy->  41.31%\n","Current batch: Loss-> 0.3604, Train accuracy->  41.43%\n","Current batch: Loss-> 0.6561, Train accuracy->  41.54%\n","Current batch: Loss-> 0.4078, Train accuracy->  41.66%\n","Current batch: Loss-> 0.4327, Train accuracy->  41.77%\n","Current batch: Loss-> 0.4921, Train accuracy->  41.89%\n","Current batch: Loss-> 0.4408, Train accuracy->  42.01%\n","Current batch: Loss-> 0.6544, Train accuracy->  42.11%\n","Current batch: Loss-> 0.4541, Train accuracy->  42.23%\n","Current batch: Loss-> 0.6211, Train accuracy->  42.34%\n","Current batch: Loss-> 0.4970, Train accuracy->  42.45%\n","Current batch: Loss-> 0.7473, Train accuracy->  42.54%\n","Current batch: Loss-> 0.4830, Train accuracy->  42.65%\n","Current batch: Loss-> 0.4957, Train accuracy->  42.76%\n","Current batch: Loss-> 0.7368, Train accuracy->  42.87%\n","Current batch: Loss-> 0.8443, Train accuracy->  42.98%\n","Current batch: Loss-> 0.8902, Train accuracy->  43.07%\n","Current batch: Loss-> 0.7737, Train accuracy->  43.17%\n","Current batch: Loss-> 0.5170, Train accuracy->  43.29%\n","Current batch: Loss-> 0.3697, Train accuracy->  43.40%\n","Current batch: Loss-> 0.6900, Train accuracy->  43.51%\n","Current batch: Loss-> 0.4996, Train accuracy->  43.62%\n","Current batch: Loss-> 0.9567, Train accuracy->  43.72%\n","Current batch: Loss-> 0.6696, Train accuracy->  43.83%\n","Current batch: Loss-> 0.8180, Train accuracy->  43.94%\n","Current batch: Loss-> 0.6821, Train accuracy->  44.04%\n","Current batch: Loss-> 0.7091, Train accuracy->  44.14%\n","Current batch: Loss-> 0.6025, Train accuracy->  44.25%\n","Current batch: Loss-> 0.5418, Train accuracy->  44.36%\n","Current batch: Loss-> 1.1088, Train accuracy->  44.45%\n","Current batch: Loss-> 0.7628, Train accuracy->  44.56%\n","Current batch: Loss-> 0.3760, Train accuracy->  44.67%\n","Current batch: Loss-> 0.5089, Train accuracy->  44.78%\n","Current batch: Loss-> 0.6627, Train accuracy->  44.89%\n","Current batch: Loss-> 0.7490, Train accuracy->  45.00%\n","Current batch: Loss-> 0.3441, Train accuracy->  45.12%\n","Current batch: Loss-> 0.5755, Train accuracy->  45.23%\n","Current batch: Loss-> 0.6502, Train accuracy->  45.34%\n","Current batch: Loss-> 0.5480, Train accuracy->  45.44%\n","Current batch: Loss-> 0.7417, Train accuracy->  45.54%\n","Current batch: Loss-> 0.7597, Train accuracy->  45.66%\n","Current batch: Loss-> 0.9125, Train accuracy->  45.76%\n","Current batch: Loss-> 0.5359, Train accuracy->  45.86%\n","Current batch: Loss-> 0.6094, Train accuracy->  45.97%\n","Current batch: Loss-> 0.6257, Train accuracy->  46.08%\n","Current batch: Loss-> 0.4166, Train accuracy->  46.20%\n","Current batch: Loss-> 0.5905, Train accuracy->  46.31%\n","Current batch: Loss-> 0.4561, Train accuracy->  46.42%\n","Current batch: Loss-> 0.4514, Train accuracy->  46.54%\n","Current batch: Loss-> 0.3324, Train accuracy->  46.66%\n","Current batch: Loss-> 0.8220, Train accuracy->  46.76%\n","Current batch: Loss-> 0.7540, Train accuracy->  46.86%\n","Current batch: Loss-> 0.6940, Train accuracy->  46.97%\n","Current batch: Loss-> 0.3652, Train accuracy->  47.08%\n","Current batch: Loss-> 0.9063, Train accuracy->  47.18%\n","Current batch: Loss-> 0.8118, Train accuracy->  47.28%\n","Current batch: Loss-> 0.5007, Train accuracy->  47.39%\n","Current batch: Loss-> 0.7537, Train accuracy->  47.47%\n","Current batch: Loss-> 0.6100, Train accuracy->  47.59%\n","Current batch: Loss-> 0.6080, Train accuracy->  47.70%\n","Current batch: Loss-> 0.5359, Train accuracy->  47.81%\n","Current batch: Loss-> 0.6206, Train accuracy->  47.92%\n","Current batch: Loss-> 0.5479, Train accuracy->  48.04%\n","Current batch: Loss-> 0.8509, Train accuracy->  48.12%\n","Current batch: Loss-> 0.5083, Train accuracy->  48.24%\n","Current batch: Loss-> 0.5312, Train accuracy->  48.36%\n","Current batch: Loss-> 0.5664, Train accuracy->  48.47%\n","Current batch: Loss-> 0.6453, Train accuracy->  48.58%\n","Current batch: Loss-> 0.6334, Train accuracy->  48.68%\n","Current batch: Loss-> 0.7096, Train accuracy->  48.79%\n","Current batch: Loss-> 0.7439, Train accuracy->  48.88%\n","Current batch: Loss-> 0.6566, Train accuracy->  48.98%\n","Current batch: Loss-> 0.5371, Train accuracy->  49.10%\n","Current batch: Loss-> 0.9776, Train accuracy->  49.19%\n","Current batch: Loss-> 0.6345, Train accuracy->  49.30%\n","Current batch: Loss-> 0.5670, Train accuracy->  49.41%\n","Current batch: Loss-> 0.6667, Train accuracy->  49.52%\n","Current batch: Loss-> 0.6650, Train accuracy->  49.63%\n","Current batch: Loss-> 0.5389, Train accuracy->  49.73%\n","Current batch: Loss-> 0.5845, Train accuracy->  49.84%\n","Current batch: Loss-> 0.4584, Train accuracy->  49.96%\n","Current batch: Loss-> 0.5169, Train accuracy->  50.07%\n","Current batch: Loss-> 0.7942, Train accuracy->  50.17%\n","Current batch: Loss-> 0.4331, Train accuracy->  50.28%\n","Current batch: Loss-> 0.6965, Train accuracy->  50.38%\n","Current batch: Loss-> 0.5362, Train accuracy->  50.49%\n","Current batch: Loss-> 0.6416, Train accuracy->  50.60%\n","Current batch: Loss-> 0.5944, Train accuracy->  50.70%\n","Current batch: Loss-> 0.9423, Train accuracy->  50.81%\n","Current batch: Loss-> 0.6510, Train accuracy->  50.92%\n","Current batch: Loss-> 0.9091, Train accuracy->  51.01%\n","Current batch: Loss-> 0.7041, Train accuracy->  51.11%\n","Current batch: Loss-> 0.8137, Train accuracy->  51.21%\n","Current batch: Loss-> 0.9217, Train accuracy->  51.31%\n","Current batch: Loss-> 0.4375, Train accuracy->  51.42%\n","Current batch: Loss-> 0.6882, Train accuracy->  51.52%\n","Current batch: Loss-> 0.8830, Train accuracy->  51.62%\n","Current batch: Loss-> 0.7583, Train accuracy->  51.73%\n","Current batch: Loss-> 0.6279, Train accuracy->  51.84%\n","Current batch: Loss-> 0.9982, Train accuracy->  51.94%\n","Current batch: Loss-> 0.6652, Train accuracy->  52.05%\n","Current batch: Loss-> 0.5999, Train accuracy->  52.17%\n","Current batch: Loss-> 0.6985, Train accuracy->  52.28%\n","Current batch: Loss-> 0.7423, Train accuracy->  52.37%\n","Current batch: Loss-> 0.5829, Train accuracy->  52.48%\n","Current batch: Loss-> 0.6336, Train accuracy->  52.59%\n","Current batch: Loss-> 0.5474, Train accuracy->  52.70%\n","Current batch: Loss-> 0.9063, Train accuracy->  52.80%\n","Current batch: Loss-> 0.5302, Train accuracy->  52.91%\n","Current batch: Loss-> 0.7260, Train accuracy->  53.01%\n","Current batch: Loss-> 0.5283, Train accuracy->  53.11%\n","Current batch: Loss-> 0.6394, Train accuracy->  53.22%\n","Current batch: Loss-> 0.5886, Train accuracy->  53.33%\n","Current batch: Loss-> 0.6902, Train accuracy->  53.44%\n","Current batch: Loss-> 0.5958, Train accuracy->  53.54%\n","Current batch: Loss-> 0.6942, Train accuracy->  53.65%\n","Current batch: Loss-> 0.6033, Train accuracy->  53.75%\n","Current batch: Loss-> 0.5196, Train accuracy->  53.86%\n","Current batch: Loss-> 0.5260, Train accuracy->  53.98%\n","Current batch: Loss-> 0.4652, Train accuracy->  54.09%\n","Current batch: Loss-> 0.5348, Train accuracy->  54.21%\n","Current batch: Loss-> 0.5897, Train accuracy->  54.32%\n","Current batch: Loss-> 0.6385, Train accuracy->  54.43%\n","Current batch: Loss-> 0.5611, Train accuracy->  54.54%\n","Current batch: Loss-> 0.6249, Train accuracy->  54.64%\n","Current batch: Loss-> 0.3660, Train accuracy->  54.76%\n","Current batch: Loss-> 0.7302, Train accuracy->  54.87%\n","Current batch: Loss-> 0.3979, Train accuracy->  54.98%\n","Current batch: Loss-> 0.9562, Train accuracy->  55.08%\n","Current batch: Loss-> 0.8804, Train accuracy->  55.18%\n","Current batch: Loss-> 0.5100, Train accuracy->  55.29%\n","Current batch: Loss-> 0.4879, Train accuracy->  55.40%\n","Current batch: Loss-> 0.6633, Train accuracy->  55.51%\n","Current batch: Loss-> 0.4618, Train accuracy->  55.62%\n","Current batch: Loss-> 0.3810, Train accuracy->  55.74%\n","Current batch: Loss-> 1.2164, Train accuracy->  55.82%\n","Current batch: Loss-> 0.3850, Train accuracy->  55.94%\n","Current batch: Loss-> 0.6866, Train accuracy->  56.04%\n","Current batch: Loss-> 0.5244, Train accuracy->  56.16%\n","Current batch: Loss-> 0.6377, Train accuracy->  56.27%\n","Current batch: Loss-> 0.9563, Train accuracy->  56.37%\n","Current batch: Loss-> 0.5119, Train accuracy->  56.48%\n","Current batch: Loss-> 0.5084, Train accuracy->  56.59%\n","Current batch: Loss-> 0.5651, Train accuracy->  56.70%\n","Current batch: Loss-> 0.7154, Train accuracy->  56.81%\n","Current batch: Loss-> 0.8847, Train accuracy->  56.92%\n","Current batch: Loss-> 0.6128, Train accuracy->  57.03%\n","Current batch: Loss-> 0.4484, Train accuracy->  57.14%\n","Current batch: Loss-> 0.3618, Train accuracy->  57.26%\n","Current batch: Loss-> 0.4105, Train accuracy->  57.38%\n","Current batch: Loss-> 0.5982, Train accuracy->  57.48%\n","Current batch: Loss-> 0.6235, Train accuracy->  57.59%\n","Current batch: Loss-> 0.7906, Train accuracy->  57.69%\n","Current batch: Loss-> 0.4932, Train accuracy->  57.81%\n","Current batch: Loss-> 0.7735, Train accuracy->  57.91%\n","Current batch: Loss-> 0.7895, Train accuracy->  58.01%\n","Current batch: Loss-> 0.5179, Train accuracy->  58.12%\n","Current batch: Loss-> 1.1792, Train accuracy->  58.22%\n","Current batch: Loss-> 0.7057, Train accuracy->  58.34%\n","Current batch: Loss-> 0.9257, Train accuracy->  58.43%\n","Current batch: Loss-> 0.4621, Train accuracy->  58.55%\n","Current batch: Loss-> 0.6387, Train accuracy->  58.66%\n","Current batch: Loss-> 0.5112, Train accuracy->  58.77%\n","Current batch: Loss-> 0.5970, Train accuracy->  58.87%\n","Current batch: Loss-> 0.5877, Train accuracy->  58.98%\n","Current batch: Loss-> 0.4702, Train accuracy->  59.10%\n","Current batch: Loss-> 0.6769, Train accuracy->  59.20%\n","Current batch: Loss-> 0.7400, Train accuracy->  59.31%\n","Current batch: Loss-> 0.5361, Train accuracy->  59.41%\n","Current batch: Loss-> 0.7044, Train accuracy->  59.51%\n","Current batch: Loss-> 0.7064, Train accuracy->  59.62%\n","Current batch: Loss-> 0.7079, Train accuracy->  59.71%\n","Current batch: Loss-> 0.6699, Train accuracy->  59.82%\n","Current batch: Loss-> 0.7289, Train accuracy->  59.93%\n","Current batch: Loss-> 0.6204, Train accuracy->  60.04%\n","Current batch: Loss-> 1.0581, Train accuracy->  60.14%\n","Current batch: Loss-> 0.7280, Train accuracy->  60.25%\n","Current batch: Loss-> 0.4046, Train accuracy->  60.37%\n","Current batch: Loss-> 0.5703, Train accuracy->  60.48%\n","Current batch: Loss-> 0.6746, Train accuracy->  60.59%\n","Current batch: Loss-> 0.6390, Train accuracy->  60.69%\n","Current batch: Loss-> 0.5959, Train accuracy->  60.80%\n","Current batch: Loss-> 0.7147, Train accuracy->  60.91%\n","Current batch: Loss-> 0.5940, Train accuracy->  61.02%\n","Current batch: Loss-> 0.4136, Train accuracy->  61.14%\n","Current batch: Loss-> 0.8352, Train accuracy->  61.24%\n","Current batch: Loss-> 0.8707, Train accuracy->  61.33%\n","Current batch: Loss-> 0.4596, Train accuracy->  61.44%\n","Current batch: Loss-> 0.6395, Train accuracy->  61.55%\n","Current batch: Loss-> 0.5903, Train accuracy->  61.66%\n","Current batch: Loss-> 0.3577, Train accuracy->  61.78%\n","Current batch: Loss-> 0.9318, Train accuracy->  61.87%\n","Current batch: Loss-> 0.5529, Train accuracy->  61.98%\n","Current batch: Loss-> 1.1809, Train accuracy->  62.07%\n","Current batch: Loss-> 0.7074, Train accuracy->  62.18%\n","Current batch: Loss-> 0.6392, Train accuracy->  62.29%\n","Current batch: Loss-> 0.4940, Train accuracy->  62.40%\n","Current batch: Loss-> 0.8665, Train accuracy->  62.50%\n","Current batch: Loss-> 0.7315, Train accuracy->  62.60%\n","Current batch: Loss-> 0.4298, Train accuracy->  62.72%\n","Current batch: Loss-> 0.7552, Train accuracy->  62.82%\n","Current batch: Loss-> 0.8178, Train accuracy->  62.91%\n","Current batch: Loss-> 0.6579, Train accuracy->  63.02%\n","Current batch: Loss-> 0.5248, Train accuracy->  63.13%\n","Current batch: Loss-> 0.8158, Train accuracy->  63.24%\n","Current batch: Loss-> 0.7092, Train accuracy->  63.34%\n","Current batch: Loss-> 0.7548, Train accuracy->  63.42%\n","Current batch: Loss-> 0.5499, Train accuracy->  63.54%\n","Current batch: Loss-> 0.5079, Train accuracy->  63.65%\n","Current batch: Loss-> 0.6517, Train accuracy->  63.76%\n","Current batch: Loss-> 0.3430, Train accuracy->  63.87%\n","Current batch: Loss-> 0.6574, Train accuracy->  63.98%\n","Current batch: Loss-> 0.7709, Train accuracy->  64.08%\n","Current batch: Loss-> 0.4634, Train accuracy->  64.19%\n","Current batch: Loss-> 0.4478, Train accuracy->  64.31%\n","Current batch: Loss-> 0.8339, Train accuracy->  64.41%\n","Current batch: Loss-> 0.3934, Train accuracy->  64.52%\n","Current batch: Loss-> 0.8124, Train accuracy->  64.63%\n","Current batch: Loss-> 0.4830, Train accuracy->  64.74%\n","Current batch: Loss-> 0.8086, Train accuracy->  64.84%\n","Current batch: Loss-> 0.4116, Train accuracy->  64.96%\n","Current batch: Loss-> 1.0162, Train accuracy->  65.06%\n","Current batch: Loss-> 0.5824, Train accuracy->  65.17%\n","Current batch: Loss-> 0.5171, Train accuracy->  65.28%\n","Current batch: Loss-> 0.3777, Train accuracy->  65.39%\n","Current batch: Loss-> 0.6514, Train accuracy->  65.50%\n","Current batch: Loss-> 0.7408, Train accuracy->  65.60%\n","Current batch: Loss-> 0.4195, Train accuracy->  65.72%\n","Current batch: Loss-> 0.6806, Train accuracy->  65.82%\n","Current batch: Loss-> 0.6789, Train accuracy->  65.93%\n","Current batch: Loss-> 0.5326, Train accuracy->  66.05%\n","Current batch: Loss-> 0.5912, Train accuracy->  66.15%\n","Current batch: Loss-> 0.8663, Train accuracy->  66.26%\n","Current batch: Loss-> 0.5391, Train accuracy->  66.37%\n","Current batch: Loss-> 0.6647, Train accuracy->  66.48%\n","Current batch: Loss-> 0.9302, Train accuracy->  66.58%\n","Current batch: Loss-> 0.6367, Train accuracy->  66.69%\n","Current batch: Loss-> 0.7352, Train accuracy->  66.80%\n","Current batch: Loss-> 0.6103, Train accuracy->  66.91%\n","Current batch: Loss-> 0.9179, Train accuracy->  67.00%\n","Current batch: Loss-> 0.4680, Train accuracy->  67.12%\n","Current batch: Loss-> 0.3936, Train accuracy->  67.24%\n","Current batch: Loss-> 0.5553, Train accuracy->  67.34%\n","Current batch: Loss-> 0.7929, Train accuracy->  67.44%\n","Current batch: Loss-> 0.8776, Train accuracy->  67.55%\n","Current batch: Loss-> 0.7623, Train accuracy->  67.64%\n","Current batch: Loss-> 0.3168, Train accuracy->  67.76%\n","Current batch: Loss-> 0.6790, Train accuracy->  67.87%\n","Current batch: Loss-> 0.5177, Train accuracy->  67.98%\n","Current batch: Loss-> 0.7673, Train accuracy->  68.07%\n","Current batch: Loss-> 0.6039, Train accuracy->  68.19%\n","Current batch: Loss-> 0.6147, Train accuracy->  68.30%\n","Current batch: Loss-> 0.6990, Train accuracy->  68.40%\n","Current batch: Loss-> 1.2481, Train accuracy->  68.48%\n","Current batch: Loss-> 0.4270, Train accuracy->  68.60%\n","Current batch: Loss-> 0.7913, Train accuracy->  68.71%\n","Current batch: Loss-> 0.6845, Train accuracy->  68.81%\n","Current batch: Loss-> 0.7828, Train accuracy->  68.91%\n","Current batch: Loss-> 0.8389, Train accuracy->  69.01%\n","Current batch: Loss-> 0.5839, Train accuracy->  69.11%\n","Current batch: Loss-> 0.8400, Train accuracy->  69.21%\n","Current batch: Loss-> 0.4955, Train accuracy->  69.32%\n","Current batch: Loss-> 0.8859, Train accuracy->  69.42%\n","Current batch: Loss-> 0.7265, Train accuracy->  69.51%\n","Current batch: Loss-> 0.8263, Train accuracy->  69.62%\n","Current batch: Loss-> 0.6609, Train accuracy->  69.72%\n","Current batch: Loss-> 0.6645, Train accuracy->  69.82%\n","Current batch: Loss-> 0.2853, Train accuracy->  69.94%\n","Current batch: Loss-> 0.8811, Train accuracy->  70.04%\n","Current batch: Loss-> 0.6554, Train accuracy->  70.15%\n","Current batch: Loss-> 0.6456, Train accuracy->  70.26%\n","Current batch: Loss-> 0.5513, Train accuracy->  70.37%\n","Current batch: Loss-> 0.5442, Train accuracy->  70.48%\n","Current batch: Loss-> 0.8181, Train accuracy->  70.58%\n","Current batch: Loss-> 0.6057, Train accuracy->  70.68%\n","Current batch: Loss-> 0.9160, Train accuracy->  70.78%\n","Current batch: Loss-> 0.5211, Train accuracy->  70.89%\n","Current batch: Loss-> 0.6778, Train accuracy->  70.99%\n","Current batch: Loss-> 0.6141, Train accuracy->  71.10%\n","Current batch: Loss-> 0.4775, Train accuracy->  71.21%\n","Current batch: Loss-> 0.9195, Train accuracy->  71.31%\n","Current batch: Loss-> 0.8010, Train accuracy->  71.41%\n","Current batch: Loss-> 0.6766, Train accuracy->  71.51%\n","Current batch: Loss-> 0.6846, Train accuracy->  71.62%\n","Current batch: Loss-> 0.6552, Train accuracy->  71.72%\n","Current batch: Loss-> 0.5969, Train accuracy->  71.83%\n","Current batch: Loss-> 1.0631, Train accuracy->  71.92%\n","Current batch: Loss-> 1.0405, Train accuracy->  72.01%\n","Current batch: Loss-> 0.9106, Train accuracy->  72.10%\n","Current batch: Loss-> 0.7606, Train accuracy->  72.20%\n","Current batch: Loss-> 0.3540, Train accuracy->  72.32%\n","Current batch: Loss-> 0.5847, Train accuracy->  72.41%\n","Current batch: Loss-> 0.5754, Train accuracy->  72.53%\n","Current batch: Loss-> 0.7658, Train accuracy->  72.62%\n","Current batch: Loss-> 0.6258, Train accuracy->  72.72%\n","Current batch: Loss-> 0.8621, Train accuracy->  72.83%\n","Current batch: Loss-> 0.6929, Train accuracy->  72.93%\n","Current batch: Loss-> 0.4861, Train accuracy->  73.05%\n","Current batch: Loss-> 0.5592, Train accuracy->  73.16%\n","Current batch: Loss-> 0.5878, Train accuracy->  73.27%\n","Current batch: Loss-> 0.8333, Train accuracy->  73.38%\n","Current batch: Loss-> 1.0873, Train accuracy->  73.46%\n","Current batch: Loss-> 0.6116, Train accuracy->  73.57%\n","Current batch: Loss-> 0.7349, Train accuracy->  73.67%\n","Current batch: Loss-> 0.7480, Train accuracy->  73.79%\n","Current batch: Loss-> 0.7987, Train accuracy->  73.88%\n","Current batch: Loss-> 0.4941, Train accuracy->  73.99%\n","Current batch: Loss-> 0.7403, Train accuracy->  74.10%\n","Current batch: Loss-> 0.4788, Train accuracy->  74.21%\n","Current batch: Loss-> 0.5906, Train accuracy->  74.31%\n","Current batch: Loss-> 0.7986, Train accuracy->  74.42%\n","Current batch: Loss-> 0.3421, Train accuracy->  74.54%\n","Current batch: Loss-> 0.6995, Train accuracy->  74.65%\n","Current batch: Loss-> 0.4413, Train accuracy->  74.76%\n","Current batch: Loss-> 0.7151, Train accuracy->  74.87%\n","Current batch: Loss-> 0.6633, Train accuracy->  74.98%\n","Current batch: Loss-> 0.7620, Train accuracy->  75.08%\n","Current batch: Loss-> 0.6235, Train accuracy->  75.19%\n","Current batch: Loss-> 0.5082, Train accuracy->  75.30%\n","Current batch: Loss-> 0.4968, Train accuracy->  75.41%\n","Current batch: Loss-> 0.5360, Train accuracy->  75.52%\n","Current batch: Loss-> 0.6627, Train accuracy->  75.62%\n","Current batch: Loss-> 0.7728, Train accuracy->  75.73%\n","Current batch: Loss-> 0.9820, Train accuracy->  75.84%\n","Current batch: Loss-> 0.6312, Train accuracy->  75.94%\n","Current batch: Loss-> 0.8114, Train accuracy->  76.04%\n","Current batch: Loss-> 0.4938, Train accuracy->  76.16%\n","Current batch: Loss-> 0.7968, Train accuracy->  76.26%\n","Current batch: Loss-> 0.5440, Train accuracy->  76.37%\n","Current batch: Loss-> 0.6839, Train accuracy->  76.46%\n","Current batch: Loss-> 0.5400, Train accuracy->  76.58%\n","Current batch: Loss-> 0.6911, Train accuracy->  76.68%\n","Current batch: Loss-> 0.5101, Train accuracy->  76.79%\n","Current batch: Loss-> 0.5504, Train accuracy->  76.89%\n","Current batch: Loss-> 0.6210, Train accuracy->  77.00%\n","Current batch: Loss-> 0.9942, Train accuracy->  77.10%\n","Current batch: Loss-> 0.6203, Train accuracy->  77.21%\n","Current batch: Loss-> 0.8677, Train accuracy->  77.32%\n","Current batch: Loss-> 0.6637, Train accuracy->  77.42%\n","Current batch: Loss-> 0.6765, Train accuracy->  77.52%\n","Current batch: Loss-> 0.8911, Train accuracy->  77.62%\n","Current batch: Loss-> 0.4323, Train accuracy->  77.74%\n","Current batch: Loss-> 0.6003, Train accuracy->  77.85%\n","Current batch: Loss-> 0.6614, Train accuracy->  77.95%\n","Current batch: Loss-> 0.5282, Train accuracy->  78.06%\n","Current batch: Loss-> 0.3962, Train accuracy->  78.18%\n","Current batch: Loss-> 0.6599, Train accuracy->  78.28%\n","Current batch: Loss-> 0.6808, Train accuracy->  78.39%\n","Current batch: Loss-> 0.5868, Train accuracy->  78.50%\n","Current batch: Loss-> 0.6674, Train accuracy->  78.60%\n","Current batch: Loss-> 0.8081, Train accuracy->  78.70%\n","Current batch: Loss-> 0.6373, Train accuracy->  78.80%\n","Current batch: Loss-> 0.4610, Train accuracy->  78.91%\n","Current batch: Loss-> 0.6724, Train accuracy->  79.02%\n","Current batch: Loss-> 0.5644, Train accuracy->  79.14%\n","Current batch: Loss-> 0.6229, Train accuracy->  79.24%\n","Current batch: Loss-> 0.6743, Train accuracy->  79.34%\n","Current batch: Loss-> 0.5271, Train accuracy->  79.46%\n","Current batch: Loss-> 0.4752, Train accuracy->  79.57%\n","Current batch: Loss-> 0.8641, Train accuracy->  79.67%\n","Current batch: Loss-> 0.9632, Train accuracy->  79.77%\n","Current batch: Loss-> 0.4503, Train accuracy->  79.89%\n","Current batch: Loss-> 0.5905, Train accuracy->  80.00%\n","Current batch: Loss-> 0.6955, Train accuracy->  80.09%\n","Current batch: Loss-> 0.4641, Train accuracy->  80.21%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 46.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.5802, Train accuracy->  80.32%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.35it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.0622, Accuracy: 5112/12000 (43%)\n","\n","Current batch: Loss-> 0.7409, Train accuracy->   0.10%\n","Current batch: Loss-> 0.5298, Train accuracy->   0.22%\n","Current batch: Loss-> 0.4253, Train accuracy->   0.34%\n","Current batch: Loss-> 0.6614, Train accuracy->   0.44%\n","Current batch: Loss-> 0.6230, Train accuracy->   0.54%\n","Current batch: Loss-> 0.5239, Train accuracy->   0.65%\n","Current batch: Loss-> 0.4923, Train accuracy->   0.76%\n","Current batch: Loss-> 0.5111, Train accuracy->   0.88%\n","Current batch: Loss-> 0.7242, Train accuracy->   0.98%\n","Current batch: Loss-> 0.7812, Train accuracy->   1.10%\n","Current batch: Loss-> 0.5923, Train accuracy->   1.21%\n","Current batch: Loss-> 0.6225, Train accuracy->   1.32%\n","Current batch: Loss-> 0.5496, Train accuracy->   1.45%\n","Current batch: Loss-> 0.4822, Train accuracy->   1.56%\n","Current batch: Loss-> 0.5234, Train accuracy->   1.67%\n","Current batch: Loss-> 0.7894, Train accuracy->   1.76%\n","Current batch: Loss-> 0.4965, Train accuracy->   1.88%\n","Current batch: Loss-> 0.6444, Train accuracy->   1.98%\n","Current batch: Loss-> 0.4677, Train accuracy->   2.10%\n","Current batch: Loss-> 0.6264, Train accuracy->   2.21%\n","Current batch: Loss-> 0.5792, Train accuracy->   2.30%\n","Current batch: Loss-> 0.6171, Train accuracy->   2.39%\n","Current batch: Loss-> 0.5314, Train accuracy->   2.50%\n","Current batch: Loss-> 0.4703, Train accuracy->   2.61%\n","Current batch: Loss-> 0.7043, Train accuracy->   2.72%\n","Current batch: Loss-> 0.7832, Train accuracy->   2.82%\n","Current batch: Loss-> 0.8342, Train accuracy->   2.91%\n","Current batch: Loss-> 0.8238, Train accuracy->   3.00%\n","Current batch: Loss-> 0.5117, Train accuracy->   3.11%\n","Current batch: Loss-> 0.6085, Train accuracy->   3.23%\n","Current batch: Loss-> 0.5644, Train accuracy->   3.34%\n","Current batch: Loss-> 0.7828, Train accuracy->   3.44%\n","Current batch: Loss-> 0.6695, Train accuracy->   3.55%\n","Current batch: Loss-> 0.3486, Train accuracy->   3.67%\n","Current batch: Loss-> 0.6475, Train accuracy->   3.78%\n","Current batch: Loss-> 0.9028, Train accuracy->   3.88%\n","Current batch: Loss-> 0.7804, Train accuracy->   3.98%\n","Current batch: Loss-> 0.5642, Train accuracy->   4.09%\n","Current batch: Loss-> 0.5526, Train accuracy->   4.20%\n","Current batch: Loss-> 0.6479, Train accuracy->   4.31%\n","Current batch: Loss-> 0.5784, Train accuracy->   4.42%\n","Current batch: Loss-> 0.6337, Train accuracy->   4.52%\n","Current batch: Loss-> 0.5681, Train accuracy->   4.64%\n","Current batch: Loss-> 0.3377, Train accuracy->   4.76%\n","Current batch: Loss-> 0.5183, Train accuracy->   4.86%\n","Current batch: Loss-> 0.3972, Train accuracy->   4.98%\n","Current batch: Loss-> 0.7942, Train accuracy->   5.08%\n","Current batch: Loss-> 0.6639, Train accuracy->   5.18%\n","Current batch: Loss-> 0.5668, Train accuracy->   5.29%\n","Current batch: Loss-> 0.4874, Train accuracy->   5.41%\n","Current batch: Loss-> 0.5070, Train accuracy->   5.52%\n","Current batch: Loss-> 0.5867, Train accuracy->   5.63%\n","Current batch: Loss-> 0.4488, Train accuracy->   5.75%\n","Current batch: Loss-> 0.5069, Train accuracy->   5.86%\n","Current batch: Loss-> 0.4958, Train accuracy->   5.96%\n","Current batch: Loss-> 0.5566, Train accuracy->   6.07%\n","Current batch: Loss-> 0.6238, Train accuracy->   6.17%\n","Current batch: Loss-> 0.5761, Train accuracy->   6.28%\n","Current batch: Loss-> 0.3222, Train accuracy->   6.39%\n","Current batch: Loss-> 0.7522, Train accuracy->   6.49%\n","Current batch: Loss-> 0.5417, Train accuracy->   6.60%\n","Current batch: Loss-> 0.6915, Train accuracy->   6.71%\n","Current batch: Loss-> 0.6979, Train accuracy->   6.82%\n","Current batch: Loss-> 0.7363, Train accuracy->   6.92%\n","Current batch: Loss-> 0.4296, Train accuracy->   7.03%\n","Current batch: Loss-> 0.6942, Train accuracy->   7.14%\n","Current batch: Loss-> 0.7664, Train accuracy->   7.24%\n","Current batch: Loss-> 0.6905, Train accuracy->   7.33%\n","Current batch: Loss-> 0.6912, Train accuracy->   7.44%\n","Current batch: Loss-> 0.5220, Train accuracy->   7.54%\n","Current batch: Loss-> 0.8293, Train accuracy->   7.65%\n","Current batch: Loss-> 0.6546, Train accuracy->   7.76%\n","Current batch: Loss-> 0.7942, Train accuracy->   7.86%\n","Current batch: Loss-> 0.5479, Train accuracy->   7.97%\n","Current batch: Loss-> 0.7926, Train accuracy->   8.07%\n","Current batch: Loss-> 0.5350, Train accuracy->   8.19%\n","Current batch: Loss-> 0.5788, Train accuracy->   8.30%\n","Current batch: Loss-> 0.7364, Train accuracy->   8.41%\n","Current batch: Loss-> 0.4571, Train accuracy->   8.52%\n","Current batch: Loss-> 0.4995, Train accuracy->   8.63%\n","Current batch: Loss-> 0.4827, Train accuracy->   8.74%\n","Current batch: Loss-> 0.5355, Train accuracy->   8.86%\n","Current batch: Loss-> 0.7040, Train accuracy->   8.96%\n","Current batch: Loss-> 0.7438, Train accuracy->   9.06%\n","Current batch: Loss-> 0.6290, Train accuracy->   9.18%\n","Current batch: Loss-> 0.5851, Train accuracy->   9.28%\n","Current batch: Loss-> 0.5355, Train accuracy->   9.39%\n","Current batch: Loss-> 0.4971, Train accuracy->   9.51%\n","Current batch: Loss-> 0.5900, Train accuracy->   9.63%\n","Current batch: Loss-> 0.3914, Train accuracy->   9.74%\n","Current batch: Loss-> 0.5066, Train accuracy->   9.85%\n","Current batch: Loss-> 0.6120, Train accuracy->   9.96%\n","Current batch: Loss-> 0.6020, Train accuracy->  10.07%\n","Current batch: Loss-> 0.8316, Train accuracy->  10.18%\n","Current batch: Loss-> 0.8173, Train accuracy->  10.28%\n","Current batch: Loss-> 0.5736, Train accuracy->  10.40%\n","Current batch: Loss-> 0.7567, Train accuracy->  10.50%\n","Current batch: Loss-> 0.4313, Train accuracy->  10.62%\n","Current batch: Loss-> 0.7042, Train accuracy->  10.72%\n","Current batch: Loss-> 0.4925, Train accuracy->  10.83%\n","Current batch: Loss-> 0.5205, Train accuracy->  10.94%\n","Current batch: Loss-> 0.4625, Train accuracy->  11.06%\n","Current batch: Loss-> 0.4325, Train accuracy->  11.18%\n","Current batch: Loss-> 0.9693, Train accuracy->  11.29%\n","Current batch: Loss-> 0.4145, Train accuracy->  11.41%\n","Current batch: Loss-> 0.6069, Train accuracy->  11.51%\n","Current batch: Loss-> 0.3692, Train accuracy->  11.63%\n","Current batch: Loss-> 0.6225, Train accuracy->  11.74%\n","Current batch: Loss-> 0.4595, Train accuracy->  11.86%\n","Current batch: Loss-> 0.6604, Train accuracy->  11.96%\n","Current batch: Loss-> 0.5122, Train accuracy->  12.07%\n","Current batch: Loss-> 0.6455, Train accuracy->  12.18%\n","Current batch: Loss-> 0.5954, Train accuracy->  12.30%\n","Current batch: Loss-> 0.5766, Train accuracy->  12.39%\n","Current batch: Loss-> 0.6730, Train accuracy->  12.50%\n","Current batch: Loss-> 0.7409, Train accuracy->  12.61%\n","Current batch: Loss-> 0.6040, Train accuracy->  12.71%\n","Current batch: Loss-> 0.5056, Train accuracy->  12.82%\n","Current batch: Loss-> 0.5821, Train accuracy->  12.93%\n","Current batch: Loss-> 0.6657, Train accuracy->  13.04%\n","Current batch: Loss-> 0.6838, Train accuracy->  13.15%\n","Current batch: Loss-> 0.7987, Train accuracy->  13.26%\n","Current batch: Loss-> 0.7327, Train accuracy->  13.37%\n","Current batch: Loss-> 0.7050, Train accuracy->  13.47%\n","Current batch: Loss-> 0.8644, Train accuracy->  13.57%\n","Current batch: Loss-> 0.5803, Train accuracy->  13.68%\n","Current batch: Loss-> 0.5771, Train accuracy->  13.78%\n","Current batch: Loss-> 0.5268, Train accuracy->  13.90%\n","Current batch: Loss-> 0.9048, Train accuracy->  13.99%\n","Current batch: Loss-> 0.4698, Train accuracy->  14.10%\n","Current batch: Loss-> 0.4788, Train accuracy->  14.22%\n","Current batch: Loss-> 0.5440, Train accuracy->  14.33%\n","Current batch: Loss-> 0.6836, Train accuracy->  14.42%\n","Current batch: Loss-> 0.7308, Train accuracy->  14.53%\n","Current batch: Loss-> 0.4209, Train accuracy->  14.64%\n","Current batch: Loss-> 0.5934, Train accuracy->  14.75%\n","Current batch: Loss-> 0.5044, Train accuracy->  14.86%\n","Current batch: Loss-> 0.4613, Train accuracy->  14.97%\n","Current batch: Loss-> 0.6591, Train accuracy->  15.07%\n","Current batch: Loss-> 0.5747, Train accuracy->  15.18%\n","Current batch: Loss-> 0.4382, Train accuracy->  15.30%\n","Current batch: Loss-> 0.6110, Train accuracy->  15.41%\n","Current batch: Loss-> 0.3945, Train accuracy->  15.52%\n","Current batch: Loss-> 0.7661, Train accuracy->  15.62%\n","Current batch: Loss-> 0.5812, Train accuracy->  15.74%\n","Current batch: Loss-> 0.8229, Train accuracy->  15.82%\n","Current batch: Loss-> 0.5496, Train accuracy->  15.94%\n","Current batch: Loss-> 0.6615, Train accuracy->  16.04%\n","Current batch: Loss-> 0.3122, Train accuracy->  16.17%\n","Current batch: Loss-> 0.3549, Train accuracy->  16.28%\n","Current batch: Loss-> 0.4446, Train accuracy->  16.39%\n","Current batch: Loss-> 0.5621, Train accuracy->  16.50%\n","Current batch: Loss-> 0.5082, Train accuracy->  16.61%\n","Current batch: Loss-> 0.4955, Train accuracy->  16.73%\n","Current batch: Loss-> 0.5892, Train accuracy->  16.83%\n","Current batch: Loss-> 0.6514, Train accuracy->  16.94%\n","Current batch: Loss-> 0.4221, Train accuracy->  17.06%\n","Current batch: Loss-> 0.6002, Train accuracy->  17.16%\n","Current batch: Loss-> 0.4869, Train accuracy->  17.27%\n","Current batch: Loss-> 0.4298, Train accuracy->  17.38%\n","Current batch: Loss-> 0.4030, Train accuracy->  17.49%\n","Current batch: Loss-> 0.4318, Train accuracy->  17.61%\n","Current batch: Loss-> 0.7286, Train accuracy->  17.71%\n","Current batch: Loss-> 0.8715, Train accuracy->  17.82%\n","Current batch: Loss-> 0.5432, Train accuracy->  17.93%\n","Current batch: Loss-> 0.4520, Train accuracy->  18.04%\n","Current batch: Loss-> 0.5286, Train accuracy->  18.15%\n","Current batch: Loss-> 0.4921, Train accuracy->  18.26%\n","Current batch: Loss-> 0.6025, Train accuracy->  18.38%\n","Current batch: Loss-> 0.5154, Train accuracy->  18.49%\n","Current batch: Loss-> 0.6020, Train accuracy->  18.60%\n","Current batch: Loss-> 0.7576, Train accuracy->  18.71%\n","Current batch: Loss-> 0.6962, Train accuracy->  18.81%\n","Current batch: Loss-> 0.5451, Train accuracy->  18.92%\n","Current batch: Loss-> 0.7494, Train accuracy->  19.03%\n","Current batch: Loss-> 0.6540, Train accuracy->  19.14%\n","Current batch: Loss-> 0.7858, Train accuracy->  19.24%\n","Current batch: Loss-> 0.5293, Train accuracy->  19.34%\n","Current batch: Loss-> 0.5982, Train accuracy->  19.45%\n","Current batch: Loss-> 0.5300, Train accuracy->  19.56%\n","Current batch: Loss-> 0.5677, Train accuracy->  19.67%\n","Current batch: Loss-> 0.5180, Train accuracy->  19.78%\n","Current batch: Loss-> 0.6773, Train accuracy->  19.89%\n","Current batch: Loss-> 0.4738, Train accuracy->  20.01%\n","Current batch: Loss-> 0.3084, Train accuracy->  20.13%\n","Current batch: Loss-> 0.9739, Train accuracy->  20.23%\n","Current batch: Loss-> 0.8029, Train accuracy->  20.33%\n","Current batch: Loss-> 0.6002, Train accuracy->  20.44%\n","Current batch: Loss-> 0.4547, Train accuracy->  20.55%\n","Current batch: Loss-> 0.6898, Train accuracy->  20.65%\n","Current batch: Loss-> 0.6586, Train accuracy->  20.76%\n","Current batch: Loss-> 0.8376, Train accuracy->  20.86%\n","Current batch: Loss-> 0.4905, Train accuracy->  20.98%\n","Current batch: Loss-> 0.9913, Train accuracy->  21.08%\n","Current batch: Loss-> 0.7084, Train accuracy->  21.19%\n","Current batch: Loss-> 0.7647, Train accuracy->  21.29%\n","Current batch: Loss-> 0.6024, Train accuracy->  21.40%\n","Current batch: Loss-> 0.5328, Train accuracy->  21.51%\n","Current batch: Loss-> 0.4048, Train accuracy->  21.62%\n","Current batch: Loss-> 0.5378, Train accuracy->  21.73%\n","Current batch: Loss-> 0.4675, Train accuracy->  21.85%\n","Current batch: Loss-> 0.8486, Train accuracy->  21.95%\n","Current batch: Loss-> 0.4853, Train accuracy->  22.05%\n","Current batch: Loss-> 0.6185, Train accuracy->  22.16%\n","Current batch: Loss-> 0.5679, Train accuracy->  22.27%\n","Current batch: Loss-> 0.5037, Train accuracy->  22.38%\n","Current batch: Loss-> 0.6092, Train accuracy->  22.49%\n","Current batch: Loss-> 0.4866, Train accuracy->  22.60%\n","Current batch: Loss-> 0.7692, Train accuracy->  22.71%\n","Current batch: Loss-> 0.8579, Train accuracy->  22.80%\n","Current batch: Loss-> 0.5765, Train accuracy->  22.91%\n","Current batch: Loss-> 0.6168, Train accuracy->  23.02%\n","Current batch: Loss-> 0.6202, Train accuracy->  23.13%\n","Current batch: Loss-> 0.5948, Train accuracy->  23.24%\n","Current batch: Loss-> 0.5586, Train accuracy->  23.35%\n","Current batch: Loss-> 0.6072, Train accuracy->  23.46%\n","Current batch: Loss-> 0.6288, Train accuracy->  23.57%\n","Current batch: Loss-> 0.8049, Train accuracy->  23.66%\n","Current batch: Loss-> 0.4974, Train accuracy->  23.77%\n","Current batch: Loss-> 0.6335, Train accuracy->  23.88%\n","Current batch: Loss-> 0.4484, Train accuracy->  23.98%\n","Current batch: Loss-> 0.5460, Train accuracy->  24.10%\n","Current batch: Loss-> 0.8801, Train accuracy->  24.19%\n","Current batch: Loss-> 0.5896, Train accuracy->  24.30%\n","Current batch: Loss-> 0.6633, Train accuracy->  24.41%\n","Current batch: Loss-> 0.3420, Train accuracy->  24.53%\n","Current batch: Loss-> 0.8790, Train accuracy->  24.64%\n","Current batch: Loss-> 0.8816, Train accuracy->  24.74%\n","Current batch: Loss-> 0.7164, Train accuracy->  24.85%\n","Current batch: Loss-> 0.7055, Train accuracy->  24.95%\n","Current batch: Loss-> 0.6462, Train accuracy->  25.06%\n","Current batch: Loss-> 0.3974, Train accuracy->  25.17%\n","Current batch: Loss-> 0.5422, Train accuracy->  25.28%\n","Current batch: Loss-> 0.5355, Train accuracy->  25.39%\n","Current batch: Loss-> 0.9052, Train accuracy->  25.50%\n","Current batch: Loss-> 0.7663, Train accuracy->  25.60%\n","Current batch: Loss-> 0.6670, Train accuracy->  25.71%\n","Current batch: Loss-> 0.6437, Train accuracy->  25.81%\n","Current batch: Loss-> 0.4551, Train accuracy->  25.92%\n","Current batch: Loss-> 0.4886, Train accuracy->  26.04%\n","Current batch: Loss-> 0.6617, Train accuracy->  26.14%\n","Current batch: Loss-> 0.4817, Train accuracy->  26.26%\n","Current batch: Loss-> 0.5307, Train accuracy->  26.38%\n","Current batch: Loss-> 0.7959, Train accuracy->  26.48%\n","Current batch: Loss-> 0.4902, Train accuracy->  26.59%\n","Current batch: Loss-> 0.6294, Train accuracy->  26.70%\n","Current batch: Loss-> 0.5381, Train accuracy->  26.82%\n","Current batch: Loss-> 0.5736, Train accuracy->  26.93%\n","Current batch: Loss-> 0.3475, Train accuracy->  27.05%\n","Current batch: Loss-> 0.4481, Train accuracy->  27.17%\n","Current batch: Loss-> 0.5514, Train accuracy->  27.28%\n","Current batch: Loss-> 0.5869, Train accuracy->  27.39%\n","Current batch: Loss-> 0.5755, Train accuracy->  27.50%\n","Current batch: Loss-> 0.4416, Train accuracy->  27.61%\n","Current batch: Loss-> 0.4970, Train accuracy->  27.73%\n","Current batch: Loss-> 0.5201, Train accuracy->  27.84%\n","Current batch: Loss-> 0.6040, Train accuracy->  27.94%\n","Current batch: Loss-> 0.4043, Train accuracy->  28.05%\n","Current batch: Loss-> 0.7683, Train accuracy->  28.16%\n","Current batch: Loss-> 0.6099, Train accuracy->  28.28%\n","Current batch: Loss-> 0.4354, Train accuracy->  28.39%\n","Current batch: Loss-> 0.6676, Train accuracy->  28.49%\n","Current batch: Loss-> 0.5647, Train accuracy->  28.61%\n","Current batch: Loss-> 0.4367, Train accuracy->  28.72%\n","Current batch: Loss-> 0.8286, Train accuracy->  28.82%\n","Current batch: Loss-> 0.7996, Train accuracy->  28.93%\n","Current batch: Loss-> 0.5511, Train accuracy->  29.04%\n","Current batch: Loss-> 0.5414, Train accuracy->  29.15%\n","Current batch: Loss-> 0.6567, Train accuracy->  29.26%\n","Current batch: Loss-> 0.4548, Train accuracy->  29.38%\n","Current batch: Loss-> 0.9223, Train accuracy->  29.47%\n","Current batch: Loss-> 0.4393, Train accuracy->  29.59%\n","Current batch: Loss-> 0.3596, Train accuracy->  29.71%\n","Current batch: Loss-> 0.9110, Train accuracy->  29.81%\n","Current batch: Loss-> 0.4027, Train accuracy->  29.92%\n","Current batch: Loss-> 0.7404, Train accuracy->  30.03%\n","Current batch: Loss-> 0.3927, Train accuracy->  30.15%\n","Current batch: Loss-> 0.6267, Train accuracy->  30.27%\n","Current batch: Loss-> 0.5346, Train accuracy->  30.38%\n","Current batch: Loss-> 0.7444, Train accuracy->  30.48%\n","Current batch: Loss-> 0.5476, Train accuracy->  30.59%\n","Current batch: Loss-> 0.5827, Train accuracy->  30.70%\n","Current batch: Loss-> 0.6450, Train accuracy->  30.80%\n","Current batch: Loss-> 0.4855, Train accuracy->  30.91%\n","Current batch: Loss-> 0.3139, Train accuracy->  31.02%\n","Current batch: Loss-> 0.7308, Train accuracy->  31.13%\n","Current batch: Loss-> 0.5876, Train accuracy->  31.24%\n","Current batch: Loss-> 0.6207, Train accuracy->  31.35%\n","Current batch: Loss-> 0.7744, Train accuracy->  31.45%\n","Current batch: Loss-> 0.5925, Train accuracy->  31.55%\n","Current batch: Loss-> 0.4967, Train accuracy->  31.66%\n","Current batch: Loss-> 0.4999, Train accuracy->  31.77%\n","Current batch: Loss-> 0.4754, Train accuracy->  31.89%\n","Current batch: Loss-> 0.5364, Train accuracy->  32.00%\n","Current batch: Loss-> 0.2690, Train accuracy->  32.12%\n","Current batch: Loss-> 0.6139, Train accuracy->  32.22%\n","Current batch: Loss-> 0.6528, Train accuracy->  32.33%\n","Current batch: Loss-> 0.8147, Train accuracy->  32.42%\n","Current batch: Loss-> 0.3607, Train accuracy->  32.55%\n","Current batch: Loss-> 0.9823, Train accuracy->  32.64%\n","Current batch: Loss-> 0.7190, Train accuracy->  32.74%\n","Current batch: Loss-> 0.7109, Train accuracy->  32.85%\n","Current batch: Loss-> 0.7095, Train accuracy->  32.96%\n","Current batch: Loss-> 0.6960, Train accuracy->  33.06%\n","Current batch: Loss-> 0.8348, Train accuracy->  33.16%\n","Current batch: Loss-> 0.5886, Train accuracy->  33.26%\n","Current batch: Loss-> 0.4833, Train accuracy->  33.38%\n","Current batch: Loss-> 0.7294, Train accuracy->  33.47%\n","Current batch: Loss-> 0.6169, Train accuracy->  33.58%\n","Current batch: Loss-> 0.3381, Train accuracy->  33.70%\n","Current batch: Loss-> 0.5648, Train accuracy->  33.82%\n","Current batch: Loss-> 0.4676, Train accuracy->  33.93%\n","Current batch: Loss-> 0.6253, Train accuracy->  34.03%\n","Current batch: Loss-> 0.3884, Train accuracy->  34.14%\n","Current batch: Loss-> 0.8748, Train accuracy->  34.24%\n","Current batch: Loss-> 0.6977, Train accuracy->  34.36%\n","Current batch: Loss-> 0.4790, Train accuracy->  34.47%\n","Current batch: Loss-> 0.5958, Train accuracy->  34.58%\n","Current batch: Loss-> 0.3667, Train accuracy->  34.69%\n","Current batch: Loss-> 0.7775, Train accuracy->  34.79%\n","Current batch: Loss-> 0.7214, Train accuracy->  34.90%\n","Current batch: Loss-> 0.5996, Train accuracy->  35.00%\n","Current batch: Loss-> 0.6156, Train accuracy->  35.10%\n","Current batch: Loss-> 0.5146, Train accuracy->  35.22%\n","Current batch: Loss-> 0.7293, Train accuracy->  35.33%\n","Current batch: Loss-> 0.5256, Train accuracy->  35.44%\n","Current batch: Loss-> 0.6992, Train accuracy->  35.54%\n","Current batch: Loss-> 0.5714, Train accuracy->  35.65%\n","Current batch: Loss-> 0.5055, Train accuracy->  35.75%\n","Current batch: Loss-> 0.6355, Train accuracy->  35.86%\n","Current batch: Loss-> 0.3676, Train accuracy->  35.97%\n","Current batch: Loss-> 0.5618, Train accuracy->  36.09%\n","Current batch: Loss-> 0.8018, Train accuracy->  36.19%\n","Current batch: Loss-> 0.3823, Train accuracy->  36.31%\n","Current batch: Loss-> 0.5656, Train accuracy->  36.42%\n","Current batch: Loss-> 0.6015, Train accuracy->  36.53%\n","Current batch: Loss-> 0.4526, Train accuracy->  36.65%\n","Current batch: Loss-> 0.4766, Train accuracy->  36.77%\n","Current batch: Loss-> 0.9027, Train accuracy->  36.88%\n","Current batch: Loss-> 0.7076, Train accuracy->  36.98%\n","Current batch: Loss-> 0.7216, Train accuracy->  37.10%\n","Current batch: Loss-> 0.7376, Train accuracy->  37.20%\n","Current batch: Loss-> 0.6906, Train accuracy->  37.30%\n","Current batch: Loss-> 0.4319, Train accuracy->  37.42%\n","Current batch: Loss-> 0.6164, Train accuracy->  37.53%\n","Current batch: Loss-> 0.5088, Train accuracy->  37.63%\n","Current batch: Loss-> 0.5404, Train accuracy->  37.74%\n","Current batch: Loss-> 0.6824, Train accuracy->  37.84%\n","Current batch: Loss-> 0.4461, Train accuracy->  37.96%\n","Current batch: Loss-> 0.8340, Train accuracy->  38.06%\n","Current batch: Loss-> 1.2851, Train accuracy->  38.16%\n","Current batch: Loss-> 0.5835, Train accuracy->  38.26%\n","Current batch: Loss-> 0.7604, Train accuracy->  38.36%\n","Current batch: Loss-> 0.6109, Train accuracy->  38.47%\n","Current batch: Loss-> 0.5904, Train accuracy->  38.58%\n","Current batch: Loss-> 0.4312, Train accuracy->  38.70%\n","Current batch: Loss-> 0.6202, Train accuracy->  38.80%\n","Current batch: Loss-> 0.5132, Train accuracy->  38.91%\n","Current batch: Loss-> 0.3662, Train accuracy->  39.03%\n","Current batch: Loss-> 0.6000, Train accuracy->  39.13%\n","Current batch: Loss-> 0.6620, Train accuracy->  39.24%\n","Current batch: Loss-> 0.7267, Train accuracy->  39.35%\n","Current batch: Loss-> 0.7589, Train accuracy->  39.45%\n","Current batch: Loss-> 0.7413, Train accuracy->  39.56%\n","Current batch: Loss-> 0.7966, Train accuracy->  39.67%\n","Current batch: Loss-> 0.6363, Train accuracy->  39.77%\n","Current batch: Loss-> 0.5504, Train accuracy->  39.88%\n","Current batch: Loss-> 0.5925, Train accuracy->  39.99%\n","Current batch: Loss-> 0.5011, Train accuracy->  40.10%\n","Current batch: Loss-> 0.6924, Train accuracy->  40.21%\n","Current batch: Loss-> 0.4662, Train accuracy->  40.33%\n","Current batch: Loss-> 0.5813, Train accuracy->  40.44%\n","Current batch: Loss-> 0.6200, Train accuracy->  40.54%\n","Current batch: Loss-> 0.5166, Train accuracy->  40.64%\n","Current batch: Loss-> 0.5761, Train accuracy->  40.75%\n","Current batch: Loss-> 0.4253, Train accuracy->  40.87%\n","Current batch: Loss-> 0.5107, Train accuracy->  40.99%\n","Current batch: Loss-> 0.7674, Train accuracy->  41.09%\n","Current batch: Loss-> 0.4397, Train accuracy->  41.20%\n","Current batch: Loss-> 0.6510, Train accuracy->  41.31%\n","Current batch: Loss-> 0.4815, Train accuracy->  41.42%\n","Current batch: Loss-> 0.7041, Train accuracy->  41.52%\n","Current batch: Loss-> 0.5110, Train accuracy->  41.63%\n","Current batch: Loss-> 0.7404, Train accuracy->  41.74%\n","Current batch: Loss-> 0.5938, Train accuracy->  41.84%\n","Current batch: Loss-> 0.4648, Train accuracy->  41.95%\n","Current batch: Loss-> 0.7026, Train accuracy->  42.05%\n","Current batch: Loss-> 0.7341, Train accuracy->  42.15%\n","Current batch: Loss-> 0.7844, Train accuracy->  42.26%\n","Current batch: Loss-> 0.7941, Train accuracy->  42.37%\n","Current batch: Loss-> 0.3989, Train accuracy->  42.49%\n","Current batch: Loss-> 0.3861, Train accuracy->  42.60%\n","Current batch: Loss-> 0.5891, Train accuracy->  42.71%\n","Current batch: Loss-> 0.5547, Train accuracy->  42.82%\n","Current batch: Loss-> 0.6306, Train accuracy->  42.93%\n","Current batch: Loss-> 0.7227, Train accuracy->  43.03%\n","Current batch: Loss-> 0.6542, Train accuracy->  43.13%\n","Current batch: Loss-> 0.5289, Train accuracy->  43.25%\n","Current batch: Loss-> 0.5199, Train accuracy->  43.36%\n","Current batch: Loss-> 0.6146, Train accuracy->  43.48%\n","Current batch: Loss-> 0.4369, Train accuracy->  43.59%\n","Current batch: Loss-> 0.3572, Train accuracy->  43.70%\n","Current batch: Loss-> 0.8263, Train accuracy->  43.81%\n","Current batch: Loss-> 0.7019, Train accuracy->  43.91%\n","Current batch: Loss-> 0.6939, Train accuracy->  44.01%\n","Current batch: Loss-> 0.8304, Train accuracy->  44.11%\n","Current batch: Loss-> 0.4533, Train accuracy->  44.22%\n","Current batch: Loss-> 0.9502, Train accuracy->  44.32%\n","Current batch: Loss-> 0.5262, Train accuracy->  44.43%\n","Current batch: Loss-> 0.4866, Train accuracy->  44.54%\n","Current batch: Loss-> 0.4753, Train accuracy->  44.65%\n","Current batch: Loss-> 0.8911, Train accuracy->  44.76%\n","Current batch: Loss-> 0.7958, Train accuracy->  44.86%\n","Current batch: Loss-> 0.8418, Train accuracy->  44.95%\n","Current batch: Loss-> 0.4749, Train accuracy->  45.07%\n","Current batch: Loss-> 0.5064, Train accuracy->  45.18%\n","Current batch: Loss-> 0.4944, Train accuracy->  45.29%\n","Current batch: Loss-> 0.4768, Train accuracy->  45.41%\n","Current batch: Loss-> 0.6525, Train accuracy->  45.51%\n","Current batch: Loss-> 0.4944, Train accuracy->  45.62%\n","Current batch: Loss-> 0.4170, Train accuracy->  45.74%\n","Current batch: Loss-> 0.4637, Train accuracy->  45.86%\n","Current batch: Loss-> 0.7527, Train accuracy->  45.96%\n","Current batch: Loss-> 0.5948, Train accuracy->  46.06%\n","Current batch: Loss-> 0.5407, Train accuracy->  46.17%\n","Current batch: Loss-> 0.3683, Train accuracy->  46.29%\n","Current batch: Loss-> 0.7413, Train accuracy->  46.39%\n","Current batch: Loss-> 0.7878, Train accuracy->  46.49%\n","Current batch: Loss-> 0.5106, Train accuracy->  46.59%\n","Current batch: Loss-> 0.5147, Train accuracy->  46.69%\n","Current batch: Loss-> 0.4545, Train accuracy->  46.80%\n","Current batch: Loss-> 0.3319, Train accuracy->  46.92%\n","Current batch: Loss-> 0.5061, Train accuracy->  47.04%\n","Current batch: Loss-> 0.8029, Train accuracy->  47.14%\n","Current batch: Loss-> 0.6778, Train accuracy->  47.24%\n","Current batch: Loss-> 0.7970, Train accuracy->  47.35%\n","Current batch: Loss-> 0.7425, Train accuracy->  47.45%\n","Current batch: Loss-> 0.6277, Train accuracy->  47.56%\n","Current batch: Loss-> 0.4812, Train accuracy->  47.67%\n","Current batch: Loss-> 0.7098, Train accuracy->  47.77%\n","Current batch: Loss-> 0.4650, Train accuracy->  47.89%\n","Current batch: Loss-> 0.6117, Train accuracy->  48.00%\n","Current batch: Loss-> 0.5127, Train accuracy->  48.11%\n","Current batch: Loss-> 0.5004, Train accuracy->  48.23%\n","Current batch: Loss-> 0.5077, Train accuracy->  48.34%\n","Current batch: Loss-> 0.6245, Train accuracy->  48.45%\n","Current batch: Loss-> 0.5150, Train accuracy->  48.55%\n","Current batch: Loss-> 0.4045, Train accuracy->  48.66%\n","Current batch: Loss-> 0.6000, Train accuracy->  48.78%\n","Current batch: Loss-> 0.6240, Train accuracy->  48.90%\n","Current batch: Loss-> 0.6187, Train accuracy->  49.01%\n","Current batch: Loss-> 0.5345, Train accuracy->  49.11%\n","Current batch: Loss-> 0.5198, Train accuracy->  49.23%\n","Current batch: Loss-> 0.3251, Train accuracy->  49.35%\n","Current batch: Loss-> 0.7748, Train accuracy->  49.46%\n","Current batch: Loss-> 0.6057, Train accuracy->  49.57%\n","Current batch: Loss-> 0.5548, Train accuracy->  49.68%\n","Current batch: Loss-> 0.3927, Train accuracy->  49.80%\n","Current batch: Loss-> 0.6349, Train accuracy->  49.91%\n","Current batch: Loss-> 0.6026, Train accuracy->  50.03%\n","Current batch: Loss-> 0.4417, Train accuracy->  50.14%\n","Current batch: Loss-> 0.6479, Train accuracy->  50.25%\n","Current batch: Loss-> 0.4871, Train accuracy->  50.36%\n","Current batch: Loss-> 0.8281, Train accuracy->  50.48%\n","Current batch: Loss-> 0.9464, Train accuracy->  50.58%\n","Current batch: Loss-> 0.7860, Train accuracy->  50.69%\n","Current batch: Loss-> 0.5833, Train accuracy->  50.79%\n","Current batch: Loss-> 0.4176, Train accuracy->  50.91%\n","Current batch: Loss-> 0.7090, Train accuracy->  51.01%\n","Current batch: Loss-> 0.5093, Train accuracy->  51.12%\n","Current batch: Loss-> 0.5265, Train accuracy->  51.23%\n","Current batch: Loss-> 0.5396, Train accuracy->  51.34%\n","Current batch: Loss-> 0.3337, Train accuracy->  51.45%\n","Current batch: Loss-> 0.5704, Train accuracy->  51.56%\n","Current batch: Loss-> 0.2739, Train accuracy->  51.68%\n","Current batch: Loss-> 0.6710, Train accuracy->  51.79%\n","Current batch: Loss-> 0.5904, Train accuracy->  51.90%\n","Current batch: Loss-> 0.2638, Train accuracy->  52.02%\n","Current batch: Loss-> 0.6621, Train accuracy->  52.12%\n","Current batch: Loss-> 0.3398, Train accuracy->  52.24%\n","Current batch: Loss-> 0.3806, Train accuracy->  52.35%\n","Current batch: Loss-> 0.4715, Train accuracy->  52.47%\n","Current batch: Loss-> 0.5185, Train accuracy->  52.58%\n","Current batch: Loss-> 0.3500, Train accuracy->  52.70%\n","Current batch: Loss-> 0.5447, Train accuracy->  52.81%\n","Current batch: Loss-> 0.6951, Train accuracy->  52.92%\n","Current batch: Loss-> 0.7705, Train accuracy->  53.02%\n","Current batch: Loss-> 0.7185, Train accuracy->  53.13%\n","Current batch: Loss-> 1.1410, Train accuracy->  53.24%\n","Current batch: Loss-> 0.5478, Train accuracy->  53.35%\n","Current batch: Loss-> 0.6189, Train accuracy->  53.46%\n","Current batch: Loss-> 0.5807, Train accuracy->  53.57%\n","Current batch: Loss-> 1.0776, Train accuracy->  53.67%\n","Current batch: Loss-> 0.9151, Train accuracy->  53.77%\n","Current batch: Loss-> 0.6372, Train accuracy->  53.88%\n","Current batch: Loss-> 0.5510, Train accuracy->  53.99%\n","Current batch: Loss-> 0.5391, Train accuracy->  54.09%\n","Current batch: Loss-> 0.4740, Train accuracy->  54.20%\n","Current batch: Loss-> 0.6902, Train accuracy->  54.31%\n","Current batch: Loss-> 0.6426, Train accuracy->  54.42%\n","Current batch: Loss-> 0.6179, Train accuracy->  54.53%\n","Current batch: Loss-> 0.6411, Train accuracy->  54.63%\n","Current batch: Loss-> 0.7625, Train accuracy->  54.74%\n","Current batch: Loss-> 0.4263, Train accuracy->  54.86%\n","Current batch: Loss-> 0.5901, Train accuracy->  54.97%\n","Current batch: Loss-> 0.4612, Train accuracy->  55.08%\n","Current batch: Loss-> 0.5721, Train accuracy->  55.18%\n","Current batch: Loss-> 0.8123, Train accuracy->  55.29%\n","Current batch: Loss-> 0.6473, Train accuracy->  55.39%\n","Current batch: Loss-> 0.5846, Train accuracy->  55.50%\n","Current batch: Loss-> 0.5124, Train accuracy->  55.61%\n","Current batch: Loss-> 0.5469, Train accuracy->  55.72%\n","Current batch: Loss-> 0.5583, Train accuracy->  55.83%\n","Current batch: Loss-> 0.7219, Train accuracy->  55.93%\n","Current batch: Loss-> 0.4846, Train accuracy->  56.05%\n","Current batch: Loss-> 0.7053, Train accuracy->  56.14%\n","Current batch: Loss-> 1.0173, Train accuracy->  56.24%\n","Current batch: Loss-> 0.5894, Train accuracy->  56.35%\n","Current batch: Loss-> 0.2784, Train accuracy->  56.48%\n","Current batch: Loss-> 0.4672, Train accuracy->  56.60%\n","Current batch: Loss-> 0.4748, Train accuracy->  56.70%\n","Current batch: Loss-> 0.7869, Train accuracy->  56.80%\n","Current batch: Loss-> 0.4048, Train accuracy->  56.92%\n","Current batch: Loss-> 0.8982, Train accuracy->  57.01%\n","Current batch: Loss-> 0.7381, Train accuracy->  57.11%\n","Current batch: Loss-> 0.7032, Train accuracy->  57.22%\n","Current batch: Loss-> 0.6622, Train accuracy->  57.33%\n","Current batch: Loss-> 0.9120, Train accuracy->  57.43%\n","Current batch: Loss-> 0.4703, Train accuracy->  57.54%\n","Current batch: Loss-> 0.6069, Train accuracy->  57.66%\n","Current batch: Loss-> 0.5719, Train accuracy->  57.77%\n","Current batch: Loss-> 0.7296, Train accuracy->  57.87%\n","Current batch: Loss-> 0.6820, Train accuracy->  57.98%\n","Current batch: Loss-> 0.6305, Train accuracy->  58.08%\n","Current batch: Loss-> 0.6144, Train accuracy->  58.18%\n","Current batch: Loss-> 0.6954, Train accuracy->  58.29%\n","Current batch: Loss-> 0.5682, Train accuracy->  58.39%\n","Current batch: Loss-> 0.8746, Train accuracy->  58.49%\n","Current batch: Loss-> 0.5859, Train accuracy->  58.59%\n","Current batch: Loss-> 0.8693, Train accuracy->  58.70%\n","Current batch: Loss-> 0.4244, Train accuracy->  58.80%\n","Current batch: Loss-> 0.9907, Train accuracy->  58.90%\n","Current batch: Loss-> 0.6769, Train accuracy->  59.01%\n","Current batch: Loss-> 0.9074, Train accuracy->  59.12%\n","Current batch: Loss-> 0.4614, Train accuracy->  59.23%\n","Current batch: Loss-> 0.6140, Train accuracy->  59.33%\n","Current batch: Loss-> 0.3785, Train accuracy->  59.45%\n","Current batch: Loss-> 0.4342, Train accuracy->  59.56%\n","Current batch: Loss-> 0.8422, Train accuracy->  59.66%\n","Current batch: Loss-> 0.6636, Train accuracy->  59.76%\n","Current batch: Loss-> 0.7707, Train accuracy->  59.87%\n","Current batch: Loss-> 0.7264, Train accuracy->  59.98%\n","Current batch: Loss-> 0.7570, Train accuracy->  60.09%\n","Current batch: Loss-> 0.5067, Train accuracy->  60.20%\n","Current batch: Loss-> 0.5026, Train accuracy->  60.32%\n","Current batch: Loss-> 0.6179, Train accuracy->  60.43%\n","Current batch: Loss-> 0.8483, Train accuracy->  60.52%\n","Current batch: Loss-> 0.6772, Train accuracy->  60.63%\n","Current batch: Loss-> 0.7216, Train accuracy->  60.74%\n","Current batch: Loss-> 0.4923, Train accuracy->  60.85%\n","Current batch: Loss-> 0.5326, Train accuracy->  60.97%\n","Current batch: Loss-> 0.3604, Train accuracy->  61.09%\n","Current batch: Loss-> 0.6028, Train accuracy->  61.20%\n","Current batch: Loss-> 0.6747, Train accuracy->  61.31%\n","Current batch: Loss-> 0.7444, Train accuracy->  61.41%\n","Current batch: Loss-> 0.5907, Train accuracy->  61.52%\n","Current batch: Loss-> 0.5806, Train accuracy->  61.63%\n","Current batch: Loss-> 0.8476, Train accuracy->  61.73%\n","Current batch: Loss-> 0.5832, Train accuracy->  61.83%\n","Current batch: Loss-> 0.7727, Train accuracy->  61.94%\n","Current batch: Loss-> 0.7837, Train accuracy->  62.04%\n","Current batch: Loss-> 0.4622, Train accuracy->  62.15%\n","Current batch: Loss-> 0.5609, Train accuracy->  62.25%\n","Current batch: Loss-> 0.5498, Train accuracy->  62.36%\n","Current batch: Loss-> 0.4643, Train accuracy->  62.47%\n","Current batch: Loss-> 0.7010, Train accuracy->  62.58%\n","Current batch: Loss-> 0.5889, Train accuracy->  62.70%\n","Current batch: Loss-> 0.5291, Train accuracy->  62.81%\n","Current batch: Loss-> 0.5388, Train accuracy->  62.92%\n","Current batch: Loss-> 0.3887, Train accuracy->  63.04%\n","Current batch: Loss-> 0.5003, Train accuracy->  63.15%\n","Current batch: Loss-> 0.5165, Train accuracy->  63.25%\n","Current batch: Loss-> 0.6288, Train accuracy->  63.36%\n","Current batch: Loss-> 0.6867, Train accuracy->  63.46%\n","Current batch: Loss-> 0.5047, Train accuracy->  63.58%\n","Current batch: Loss-> 0.6001, Train accuracy->  63.69%\n","Current batch: Loss-> 0.7252, Train accuracy->  63.80%\n","Current batch: Loss-> 0.7775, Train accuracy->  63.91%\n","Current batch: Loss-> 0.4636, Train accuracy->  64.03%\n","Current batch: Loss-> 0.6155, Train accuracy->  64.13%\n","Current batch: Loss-> 0.4024, Train accuracy->  64.24%\n","Current batch: Loss-> 0.8716, Train accuracy->  64.34%\n","Current batch: Loss-> 0.7454, Train accuracy->  64.44%\n","Current batch: Loss-> 0.5927, Train accuracy->  64.55%\n","Current batch: Loss-> 0.7889, Train accuracy->  64.65%\n","Current batch: Loss-> 0.6176, Train accuracy->  64.76%\n","Current batch: Loss-> 0.4124, Train accuracy->  64.88%\n","Current batch: Loss-> 0.6668, Train accuracy->  64.99%\n","Current batch: Loss-> 0.5458, Train accuracy->  65.09%\n","Current batch: Loss-> 0.4858, Train accuracy->  65.20%\n","Current batch: Loss-> 0.5716, Train accuracy->  65.32%\n","Current batch: Loss-> 0.5617, Train accuracy->  65.42%\n","Current batch: Loss-> 0.8505, Train accuracy->  65.52%\n","Current batch: Loss-> 0.7045, Train accuracy->  65.64%\n","Current batch: Loss-> 0.5148, Train accuracy->  65.74%\n","Current batch: Loss-> 0.7804, Train accuracy->  65.84%\n","Current batch: Loss-> 0.4483, Train accuracy->  65.95%\n","Current batch: Loss-> 0.5841, Train accuracy->  66.06%\n","Current batch: Loss-> 0.5587, Train accuracy->  66.17%\n","Current batch: Loss-> 0.7648, Train accuracy->  66.28%\n","Current batch: Loss-> 0.5056, Train accuracy->  66.38%\n","Current batch: Loss-> 0.5223, Train accuracy->  66.50%\n","Current batch: Loss-> 0.6127, Train accuracy->  66.60%\n","Current batch: Loss-> 0.7897, Train accuracy->  66.70%\n","Current batch: Loss-> 0.4763, Train accuracy->  66.82%\n","Current batch: Loss-> 0.5893, Train accuracy->  66.93%\n","Current batch: Loss-> 0.4356, Train accuracy->  67.04%\n","Current batch: Loss-> 0.5186, Train accuracy->  67.15%\n","Current batch: Loss-> 0.8086, Train accuracy->  67.25%\n","Current batch: Loss-> 0.5611, Train accuracy->  67.37%\n","Current batch: Loss-> 0.6488, Train accuracy->  67.47%\n","Current batch: Loss-> 0.4244, Train accuracy->  67.60%\n","Current batch: Loss-> 0.6179, Train accuracy->  67.71%\n","Current batch: Loss-> 0.4664, Train accuracy->  67.82%\n","Current batch: Loss-> 0.3350, Train accuracy->  67.94%\n","Current batch: Loss-> 0.5109, Train accuracy->  68.05%\n","Current batch: Loss-> 0.5824, Train accuracy->  68.16%\n","Current batch: Loss-> 0.5017, Train accuracy->  68.27%\n","Current batch: Loss-> 0.5838, Train accuracy->  68.38%\n","Current batch: Loss-> 0.6061, Train accuracy->  68.48%\n","Current batch: Loss-> 0.6068, Train accuracy->  68.60%\n","Current batch: Loss-> 0.5603, Train accuracy->  68.71%\n","Current batch: Loss-> 0.6131, Train accuracy->  68.81%\n","Current batch: Loss-> 0.4488, Train accuracy->  68.93%\n","Current batch: Loss-> 0.5141, Train accuracy->  69.05%\n","Current batch: Loss-> 0.6445, Train accuracy->  69.16%\n","Current batch: Loss-> 0.8750, Train accuracy->  69.26%\n","Current batch: Loss-> 0.4067, Train accuracy->  69.37%\n","Current batch: Loss-> 0.3551, Train accuracy->  69.49%\n","Current batch: Loss-> 0.4934, Train accuracy->  69.60%\n","Current batch: Loss-> 0.3815, Train accuracy->  69.72%\n","Current batch: Loss-> 0.5706, Train accuracy->  69.83%\n","Current batch: Loss-> 0.6554, Train accuracy->  69.94%\n","Current batch: Loss-> 0.4314, Train accuracy->  70.05%\n","Current batch: Loss-> 0.8334, Train accuracy->  70.15%\n","Current batch: Loss-> 0.8267, Train accuracy->  70.26%\n","Current batch: Loss-> 0.5683, Train accuracy->  70.38%\n","Current batch: Loss-> 0.6108, Train accuracy->  70.49%\n","Current batch: Loss-> 0.7366, Train accuracy->  70.59%\n","Current batch: Loss-> 0.5019, Train accuracy->  70.70%\n","Current batch: Loss-> 0.7482, Train accuracy->  70.80%\n","Current batch: Loss-> 0.5607, Train accuracy->  70.91%\n","Current batch: Loss-> 0.8585, Train accuracy->  71.01%\n","Current batch: Loss-> 0.6667, Train accuracy->  71.12%\n","Current batch: Loss-> 0.7803, Train accuracy->  71.22%\n","Current batch: Loss-> 0.5674, Train accuracy->  71.33%\n","Current batch: Loss-> 0.6015, Train accuracy->  71.43%\n","Current batch: Loss-> 0.8789, Train accuracy->  71.54%\n","Current batch: Loss-> 0.4294, Train accuracy->  71.66%\n","Current batch: Loss-> 0.9331, Train accuracy->  71.75%\n","Current batch: Loss-> 0.6300, Train accuracy->  71.86%\n","Current batch: Loss-> 0.6705, Train accuracy->  71.96%\n","Current batch: Loss-> 0.7831, Train accuracy->  72.05%\n","Current batch: Loss-> 0.6754, Train accuracy->  72.15%\n","Current batch: Loss-> 0.6485, Train accuracy->  72.26%\n","Current batch: Loss-> 0.6069, Train accuracy->  72.36%\n","Current batch: Loss-> 0.7047, Train accuracy->  72.47%\n","Current batch: Loss-> 0.7480, Train accuracy->  72.57%\n","Current batch: Loss-> 0.6550, Train accuracy->  72.67%\n","Current batch: Loss-> 0.8550, Train accuracy->  72.77%\n","Current batch: Loss-> 0.5295, Train accuracy->  72.88%\n","Current batch: Loss-> 0.7690, Train accuracy->  72.99%\n","Current batch: Loss-> 0.6349, Train accuracy->  73.09%\n","Current batch: Loss-> 0.4559, Train accuracy->  73.21%\n","Current batch: Loss-> 0.7705, Train accuracy->  73.31%\n","Current batch: Loss-> 0.6950, Train accuracy->  73.41%\n","Current batch: Loss-> 0.5849, Train accuracy->  73.52%\n","Current batch: Loss-> 0.9229, Train accuracy->  73.62%\n","Current batch: Loss-> 0.6283, Train accuracy->  73.73%\n","Current batch: Loss-> 0.5547, Train accuracy->  73.84%\n","Current batch: Loss-> 0.7395, Train accuracy->  73.94%\n","Current batch: Loss-> 0.8589, Train accuracy->  74.04%\n","Current batch: Loss-> 0.7263, Train accuracy->  74.15%\n","Current batch: Loss-> 0.5685, Train accuracy->  74.27%\n","Current batch: Loss-> 0.5132, Train accuracy->  74.38%\n","Current batch: Loss-> 0.7662, Train accuracy->  74.49%\n","Current batch: Loss-> 0.2740, Train accuracy->  74.61%\n","Current batch: Loss-> 0.6322, Train accuracy->  74.72%\n","Current batch: Loss-> 0.5219, Train accuracy->  74.84%\n","Current batch: Loss-> 0.3949, Train accuracy->  74.95%\n","Current batch: Loss-> 0.6074, Train accuracy->  75.06%\n","Current batch: Loss-> 0.7874, Train accuracy->  75.17%\n","Current batch: Loss-> 0.6943, Train accuracy->  75.27%\n","Current batch: Loss-> 0.2584, Train accuracy->  75.40%\n","Current batch: Loss-> 0.5950, Train accuracy->  75.51%\n","Current batch: Loss-> 0.6035, Train accuracy->  75.62%\n","Current batch: Loss-> 0.6368, Train accuracy->  75.72%\n","Current batch: Loss-> 0.6607, Train accuracy->  75.83%\n","Current batch: Loss-> 0.3404, Train accuracy->  75.95%\n","Current batch: Loss-> 0.3981, Train accuracy->  76.07%\n","Current batch: Loss-> 0.5734, Train accuracy->  76.17%\n","Current batch: Loss-> 0.6357, Train accuracy->  76.28%\n","Current batch: Loss-> 0.7561, Train accuracy->  76.39%\n","Current batch: Loss-> 0.6937, Train accuracy->  76.49%\n","Current batch: Loss-> 0.5624, Train accuracy->  76.60%\n","Current batch: Loss-> 0.7029, Train accuracy->  76.71%\n","Current batch: Loss-> 0.4644, Train accuracy->  76.83%\n","Current batch: Loss-> 0.5621, Train accuracy->  76.95%\n","Current batch: Loss-> 0.8196, Train accuracy->  77.05%\n","Current batch: Loss-> 0.5492, Train accuracy->  77.16%\n","Current batch: Loss-> 0.2990, Train accuracy->  77.28%\n","Current batch: Loss-> 0.8488, Train accuracy->  77.37%\n","Current batch: Loss-> 0.6555, Train accuracy->  77.47%\n","Current batch: Loss-> 0.5363, Train accuracy->  77.58%\n","Current batch: Loss-> 0.3820, Train accuracy->  77.70%\n","Current batch: Loss-> 0.4429, Train accuracy->  77.82%\n","Current batch: Loss-> 0.8005, Train accuracy->  77.92%\n","Current batch: Loss-> 1.0426, Train accuracy->  78.02%\n","Current batch: Loss-> 0.3023, Train accuracy->  78.14%\n","Current batch: Loss-> 0.7324, Train accuracy->  78.25%\n","Current batch: Loss-> 0.4733, Train accuracy->  78.37%\n","Current batch: Loss-> 0.5052, Train accuracy->  78.48%\n","Current batch: Loss-> 0.3517, Train accuracy->  78.60%\n","Current batch: Loss-> 0.8089, Train accuracy->  78.69%\n","Current batch: Loss-> 0.5387, Train accuracy->  78.80%\n","Current batch: Loss-> 0.8266, Train accuracy->  78.90%\n","Current batch: Loss-> 0.5968, Train accuracy->  79.01%\n","Current batch: Loss-> 0.8122, Train accuracy->  79.11%\n","Current batch: Loss-> 0.5098, Train accuracy->  79.22%\n","Current batch: Loss-> 0.4933, Train accuracy->  79.34%\n","Current batch: Loss-> 1.0234, Train accuracy->  79.43%\n","Current batch: Loss-> 0.6637, Train accuracy->  79.54%\n","Current batch: Loss-> 0.6222, Train accuracy->  79.64%\n","Current batch: Loss-> 0.8883, Train accuracy->  79.73%\n","Current batch: Loss-> 0.4882, Train accuracy->  79.85%\n","Current batch: Loss-> 0.4836, Train accuracy->  79.96%\n","Current batch: Loss-> 0.5575, Train accuracy->  80.07%\n","Current batch: Loss-> 0.4714, Train accuracy->  80.20%\n","Current batch: Loss-> 1.0910, Train accuracy->  80.29%\n","Current batch: Loss-> 0.4423, Train accuracy->  80.41%\n","Current batch: Loss-> 0.6695, Train accuracy->  80.51%\n","Current batch: Loss-> 0.5958, Train accuracy->  80.62%\n","Current batch: Loss-> 0.4063, Train accuracy->  80.73%\n","Current batch: Loss-> 0.5275, Train accuracy->  80.85%\n","Current batch: Loss-> 0.8039, Train accuracy->  80.95%\n","Current batch: Loss-> 0.6776, Train accuracy->  81.06%\n","Current batch: Loss-> 0.5231, Train accuracy->  81.16%\n","Current batch: Loss-> 0.4682, Train accuracy->  81.27%\n","Current batch: Loss-> 0.4083, Train accuracy->  81.39%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:04, 44.65it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.5699, Train accuracy->  81.50%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.47it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.5855, Accuracy: 5637/12000 (47%)\n","\n","Current batch: Loss-> 0.5987, Train accuracy->   0.11%\n","Current batch: Loss-> 0.6537, Train accuracy->   0.22%\n","Current batch: Loss-> 0.7912, Train accuracy->   0.33%\n","Current batch: Loss-> 0.4706, Train accuracy->   0.45%\n","Current batch: Loss-> 0.5546, Train accuracy->   0.56%\n","Current batch: Loss-> 0.8815, Train accuracy->   0.66%\n","Current batch: Loss-> 0.6120, Train accuracy->   0.77%\n","Current batch: Loss-> 0.5102, Train accuracy->   0.88%\n","Current batch: Loss-> 0.3480, Train accuracy->   0.99%\n","Current batch: Loss-> 0.9092, Train accuracy->   1.10%\n","Current batch: Loss-> 0.4143, Train accuracy->   1.21%\n","Current batch: Loss-> 0.5364, Train accuracy->   1.32%\n","Current batch: Loss-> 0.9434, Train accuracy->   1.42%\n","Current batch: Loss-> 0.6756, Train accuracy->   1.53%\n","Current batch: Loss-> 0.5857, Train accuracy->   1.63%\n","Current batch: Loss-> 0.4143, Train accuracy->   1.75%\n","Current batch: Loss-> 0.3667, Train accuracy->   1.87%\n","Current batch: Loss-> 0.5701, Train accuracy->   1.98%\n","Current batch: Loss-> 0.5608, Train accuracy->   2.10%\n","Current batch: Loss-> 0.5883, Train accuracy->   2.20%\n","Current batch: Loss-> 0.6324, Train accuracy->   2.30%\n","Current batch: Loss-> 0.6552, Train accuracy->   2.41%\n","Current batch: Loss-> 0.4777, Train accuracy->   2.53%\n","Current batch: Loss-> 0.7626, Train accuracy->   2.63%\n","Current batch: Loss-> 0.5640, Train accuracy->   2.74%\n","Current batch: Loss-> 0.8365, Train accuracy->   2.84%\n","Current batch: Loss-> 0.5693, Train accuracy->   2.95%\n","Current batch: Loss-> 0.3864, Train accuracy->   3.06%\n","Current batch: Loss-> 0.5049, Train accuracy->   3.17%\n","Current batch: Loss-> 0.5108, Train accuracy->   3.29%\n","Current batch: Loss-> 0.8230, Train accuracy->   3.39%\n","Current batch: Loss-> 0.8594, Train accuracy->   3.50%\n","Current batch: Loss-> 0.4991, Train accuracy->   3.61%\n","Current batch: Loss-> 0.5211, Train accuracy->   3.72%\n","Current batch: Loss-> 0.5502, Train accuracy->   3.83%\n","Current batch: Loss-> 0.5689, Train accuracy->   3.93%\n","Current batch: Loss-> 0.7754, Train accuracy->   4.03%\n","Current batch: Loss-> 0.4693, Train accuracy->   4.14%\n","Current batch: Loss-> 0.3643, Train accuracy->   4.27%\n","Current batch: Loss-> 0.7247, Train accuracy->   4.36%\n","Current batch: Loss-> 0.7327, Train accuracy->   4.45%\n","Current batch: Loss-> 0.6894, Train accuracy->   4.56%\n","Current batch: Loss-> 0.6997, Train accuracy->   4.67%\n","Current batch: Loss-> 0.4680, Train accuracy->   4.78%\n","Current batch: Loss-> 0.6510, Train accuracy->   4.89%\n","Current batch: Loss-> 0.6025, Train accuracy->   5.00%\n","Current batch: Loss-> 0.7876, Train accuracy->   5.10%\n","Current batch: Loss-> 0.3796, Train accuracy->   5.22%\n","Current batch: Loss-> 0.6320, Train accuracy->   5.33%\n","Current batch: Loss-> 0.5779, Train accuracy->   5.44%\n","Current batch: Loss-> 0.5483, Train accuracy->   5.55%\n","Current batch: Loss-> 0.5381, Train accuracy->   5.66%\n","Current batch: Loss-> 0.6633, Train accuracy->   5.76%\n","Current batch: Loss-> 0.5784, Train accuracy->   5.87%\n","Current batch: Loss-> 0.3685, Train accuracy->   6.00%\n","Current batch: Loss-> 0.6423, Train accuracy->   6.10%\n","Current batch: Loss-> 0.5554, Train accuracy->   6.21%\n","Current batch: Loss-> 0.4862, Train accuracy->   6.33%\n","Current batch: Loss-> 0.6358, Train accuracy->   6.44%\n","Current batch: Loss-> 0.5718, Train accuracy->   6.55%\n","Current batch: Loss-> 1.1166, Train accuracy->   6.64%\n","Current batch: Loss-> 0.5481, Train accuracy->   6.75%\n","Current batch: Loss-> 0.5740, Train accuracy->   6.85%\n","Current batch: Loss-> 0.6096, Train accuracy->   6.97%\n","Current batch: Loss-> 0.4502, Train accuracy->   7.08%\n","Current batch: Loss-> 1.1862, Train accuracy->   7.18%\n","Current batch: Loss-> 0.5654, Train accuracy->   7.29%\n","Current batch: Loss-> 0.5689, Train accuracy->   7.39%\n","Current batch: Loss-> 0.6346, Train accuracy->   7.50%\n","Current batch: Loss-> 0.5294, Train accuracy->   7.61%\n","Current batch: Loss-> 0.4485, Train accuracy->   7.73%\n","Current batch: Loss-> 0.7210, Train accuracy->   7.84%\n","Current batch: Loss-> 0.6348, Train accuracy->   7.94%\n","Current batch: Loss-> 0.4466, Train accuracy->   8.06%\n","Current batch: Loss-> 0.5887, Train accuracy->   8.17%\n","Current batch: Loss-> 0.4356, Train accuracy->   8.29%\n","Current batch: Loss-> 0.5524, Train accuracy->   8.39%\n","Current batch: Loss-> 0.5431, Train accuracy->   8.50%\n","Current batch: Loss-> 0.7869, Train accuracy->   8.60%\n","Current batch: Loss-> 1.0377, Train accuracy->   8.70%\n","Current batch: Loss-> 0.5682, Train accuracy->   8.81%\n","Current batch: Loss-> 0.6815, Train accuracy->   8.92%\n","Current batch: Loss-> 0.4935, Train accuracy->   9.03%\n","Current batch: Loss-> 0.4923, Train accuracy->   9.14%\n","Current batch: Loss-> 0.3987, Train accuracy->   9.26%\n","Current batch: Loss-> 0.7112, Train accuracy->   9.37%\n","Current batch: Loss-> 0.5735, Train accuracy->   9.49%\n","Current batch: Loss-> 0.6524, Train accuracy->   9.59%\n","Current batch: Loss-> 0.4591, Train accuracy->   9.70%\n","Current batch: Loss-> 0.5069, Train accuracy->   9.81%\n","Current batch: Loss-> 0.6860, Train accuracy->   9.91%\n","Current batch: Loss-> 0.8269, Train accuracy->  10.00%\n","Current batch: Loss-> 0.4292, Train accuracy->  10.12%\n","Current batch: Loss-> 0.6131, Train accuracy->  10.22%\n","Current batch: Loss-> 0.4967, Train accuracy->  10.34%\n","Current batch: Loss-> 0.8084, Train accuracy->  10.44%\n","Current batch: Loss-> 0.5493, Train accuracy->  10.55%\n","Current batch: Loss-> 0.4227, Train accuracy->  10.67%\n","Current batch: Loss-> 0.7447, Train accuracy->  10.77%\n","Current batch: Loss-> 0.6961, Train accuracy->  10.88%\n","Current batch: Loss-> 0.5306, Train accuracy->  10.99%\n","Current batch: Loss-> 0.6636, Train accuracy->  11.10%\n","Current batch: Loss-> 0.6474, Train accuracy->  11.21%\n","Current batch: Loss-> 0.9132, Train accuracy->  11.31%\n","Current batch: Loss-> 0.3993, Train accuracy->  11.43%\n","Current batch: Loss-> 0.6043, Train accuracy->  11.54%\n","Current batch: Loss-> 0.4640, Train accuracy->  11.65%\n","Current batch: Loss-> 0.5085, Train accuracy->  11.76%\n","Current batch: Loss-> 0.7437, Train accuracy->  11.86%\n","Current batch: Loss-> 0.5602, Train accuracy->  11.97%\n","Current batch: Loss-> 0.6668, Train accuracy->  12.07%\n","Current batch: Loss-> 0.6054, Train accuracy->  12.18%\n","Current batch: Loss-> 0.8136, Train accuracy->  12.28%\n","Current batch: Loss-> 0.3353, Train accuracy->  12.40%\n","Current batch: Loss-> 0.3924, Train accuracy->  12.51%\n","Current batch: Loss-> 0.5814, Train accuracy->  12.62%\n","Current batch: Loss-> 0.4637, Train accuracy->  12.74%\n","Current batch: Loss-> 0.5440, Train accuracy->  12.84%\n","Current batch: Loss-> 0.5350, Train accuracy->  12.95%\n","Current batch: Loss-> 0.5319, Train accuracy->  13.06%\n","Current batch: Loss-> 0.6468, Train accuracy->  13.18%\n","Current batch: Loss-> 0.4266, Train accuracy->  13.29%\n","Current batch: Loss-> 0.5294, Train accuracy->  13.41%\n","Current batch: Loss-> 0.7376, Train accuracy->  13.51%\n","Current batch: Loss-> 0.4101, Train accuracy->  13.61%\n","Current batch: Loss-> 0.8063, Train accuracy->  13.72%\n","Current batch: Loss-> 0.6381, Train accuracy->  13.82%\n","Current batch: Loss-> 0.5317, Train accuracy->  13.93%\n","Current batch: Loss-> 0.7609, Train accuracy->  14.03%\n","Current batch: Loss-> 0.4460, Train accuracy->  14.15%\n","Current batch: Loss-> 0.6984, Train accuracy->  14.26%\n","Current batch: Loss-> 0.6917, Train accuracy->  14.36%\n","Current batch: Loss-> 0.6521, Train accuracy->  14.47%\n","Current batch: Loss-> 0.5059, Train accuracy->  14.58%\n","Current batch: Loss-> 0.5312, Train accuracy->  14.69%\n","Current batch: Loss-> 1.1645, Train accuracy->  14.78%\n","Current batch: Loss-> 0.6584, Train accuracy->  14.88%\n","Current batch: Loss-> 0.6652, Train accuracy->  14.99%\n","Current batch: Loss-> 0.7127, Train accuracy->  15.09%\n","Current batch: Loss-> 0.6765, Train accuracy->  15.21%\n","Current batch: Loss-> 0.6564, Train accuracy->  15.31%\n","Current batch: Loss-> 0.7060, Train accuracy->  15.42%\n","Current batch: Loss-> 0.6026, Train accuracy->  15.54%\n","Current batch: Loss-> 0.4307, Train accuracy->  15.65%\n","Current batch: Loss-> 0.8692, Train accuracy->  15.75%\n","Current batch: Loss-> 0.6906, Train accuracy->  15.86%\n","Current batch: Loss-> 0.4157, Train accuracy->  15.98%\n","Current batch: Loss-> 0.9820, Train accuracy->  16.08%\n","Current batch: Loss-> 0.6539, Train accuracy->  16.18%\n","Current batch: Loss-> 0.4858, Train accuracy->  16.29%\n","Current batch: Loss-> 0.5720, Train accuracy->  16.40%\n","Current batch: Loss-> 0.5641, Train accuracy->  16.50%\n","Current batch: Loss-> 0.5831, Train accuracy->  16.61%\n","Current batch: Loss-> 0.9567, Train accuracy->  16.71%\n","Current batch: Loss-> 0.7533, Train accuracy->  16.81%\n","Current batch: Loss-> 0.6027, Train accuracy->  16.92%\n","Current batch: Loss-> 0.5265, Train accuracy->  17.03%\n","Current batch: Loss-> 0.7345, Train accuracy->  17.14%\n","Current batch: Loss-> 0.7712, Train accuracy->  17.25%\n","Current batch: Loss-> 0.6689, Train accuracy->  17.36%\n","Current batch: Loss-> 0.7277, Train accuracy->  17.46%\n","Current batch: Loss-> 0.5497, Train accuracy->  17.57%\n","Current batch: Loss-> 0.6103, Train accuracy->  17.68%\n","Current batch: Loss-> 0.5610, Train accuracy->  17.78%\n","Current batch: Loss-> 0.6357, Train accuracy->  17.89%\n","Current batch: Loss-> 0.4391, Train accuracy->  18.00%\n","Current batch: Loss-> 0.7469, Train accuracy->  18.10%\n","Current batch: Loss-> 0.4369, Train accuracy->  18.21%\n","Current batch: Loss-> 0.6616, Train accuracy->  18.31%\n","Current batch: Loss-> 0.9964, Train accuracy->  18.41%\n","Current batch: Loss-> 0.5040, Train accuracy->  18.52%\n","Current batch: Loss-> 0.4778, Train accuracy->  18.64%\n","Current batch: Loss-> 0.5694, Train accuracy->  18.74%\n","Current batch: Loss-> 0.8023, Train accuracy->  18.84%\n","Current batch: Loss-> 0.8087, Train accuracy->  18.94%\n","Current batch: Loss-> 0.8700, Train accuracy->  19.04%\n","Current batch: Loss-> 0.5144, Train accuracy->  19.15%\n","Current batch: Loss-> 0.8226, Train accuracy->  19.24%\n","Current batch: Loss-> 0.7073, Train accuracy->  19.35%\n","Current batch: Loss-> 0.4937, Train accuracy->  19.47%\n","Current batch: Loss-> 0.5602, Train accuracy->  19.58%\n","Current batch: Loss-> 0.4100, Train accuracy->  19.70%\n","Current batch: Loss-> 0.4585, Train accuracy->  19.81%\n","Current batch: Loss-> 0.7471, Train accuracy->  19.92%\n","Current batch: Loss-> 0.6585, Train accuracy->  20.03%\n","Current batch: Loss-> 0.5030, Train accuracy->  20.13%\n","Current batch: Loss-> 0.7338, Train accuracy->  20.23%\n","Current batch: Loss-> 0.7436, Train accuracy->  20.33%\n","Current batch: Loss-> 0.4424, Train accuracy->  20.45%\n","Current batch: Loss-> 0.3900, Train accuracy->  20.56%\n","Current batch: Loss-> 0.4013, Train accuracy->  20.67%\n","Current batch: Loss-> 0.4489, Train accuracy->  20.79%\n","Current batch: Loss-> 0.7141, Train accuracy->  20.89%\n","Current batch: Loss-> 0.4988, Train accuracy->  21.01%\n","Current batch: Loss-> 0.3982, Train accuracy->  21.13%\n","Current batch: Loss-> 0.3656, Train accuracy->  21.24%\n","Current batch: Loss-> 0.5382, Train accuracy->  21.36%\n","Current batch: Loss-> 0.4375, Train accuracy->  21.48%\n","Current batch: Loss-> 0.4616, Train accuracy->  21.59%\n","Current batch: Loss-> 0.3627, Train accuracy->  21.71%\n","Current batch: Loss-> 0.3813, Train accuracy->  21.82%\n","Current batch: Loss-> 0.7831, Train accuracy->  21.92%\n","Current batch: Loss-> 0.6902, Train accuracy->  22.02%\n","Current batch: Loss-> 0.5296, Train accuracy->  22.14%\n","Current batch: Loss-> 0.6375, Train accuracy->  22.24%\n","Current batch: Loss-> 0.5913, Train accuracy->  22.35%\n","Current batch: Loss-> 0.8175, Train accuracy->  22.45%\n","Current batch: Loss-> 0.5167, Train accuracy->  22.55%\n","Current batch: Loss-> 0.6649, Train accuracy->  22.66%\n","Current batch: Loss-> 0.5676, Train accuracy->  22.77%\n","Current batch: Loss-> 0.7034, Train accuracy->  22.88%\n","Current batch: Loss-> 0.3168, Train accuracy->  23.00%\n","Current batch: Loss-> 0.6636, Train accuracy->  23.10%\n","Current batch: Loss-> 0.3425, Train accuracy->  23.21%\n","Current batch: Loss-> 0.3875, Train accuracy->  23.33%\n","Current batch: Loss-> 0.5024, Train accuracy->  23.45%\n","Current batch: Loss-> 0.5262, Train accuracy->  23.56%\n","Current batch: Loss-> 0.4589, Train accuracy->  23.67%\n","Current batch: Loss-> 0.4248, Train accuracy->  23.78%\n","Current batch: Loss-> 0.6237, Train accuracy->  23.88%\n","Current batch: Loss-> 0.4258, Train accuracy->  24.00%\n","Current batch: Loss-> 0.4226, Train accuracy->  24.12%\n","Current batch: Loss-> 0.4840, Train accuracy->  24.23%\n","Current batch: Loss-> 0.4377, Train accuracy->  24.35%\n","Current batch: Loss-> 0.5375, Train accuracy->  24.45%\n","Current batch: Loss-> 0.3660, Train accuracy->  24.57%\n","Current batch: Loss-> 0.6567, Train accuracy->  24.68%\n","Current batch: Loss-> 0.5715, Train accuracy->  24.77%\n","Current batch: Loss-> 0.5319, Train accuracy->  24.88%\n","Current batch: Loss-> 0.3887, Train accuracy->  24.99%\n","Current batch: Loss-> 0.7696, Train accuracy->  25.10%\n","Current batch: Loss-> 0.4790, Train accuracy->  25.21%\n","Current batch: Loss-> 0.4953, Train accuracy->  25.32%\n","Current batch: Loss-> 0.5037, Train accuracy->  25.44%\n","Current batch: Loss-> 0.5210, Train accuracy->  25.54%\n","Current batch: Loss-> 0.5278, Train accuracy->  25.65%\n","Current batch: Loss-> 0.5204, Train accuracy->  25.76%\n","Current batch: Loss-> 0.8752, Train accuracy->  25.85%\n","Current batch: Loss-> 0.5158, Train accuracy->  25.96%\n","Current batch: Loss-> 0.5656, Train accuracy->  26.07%\n","Current batch: Loss-> 0.3847, Train accuracy->  26.19%\n","Current batch: Loss-> 0.5640, Train accuracy->  26.30%\n","Current batch: Loss-> 0.4314, Train accuracy->  26.41%\n","Current batch: Loss-> 0.5854, Train accuracy->  26.52%\n","Current batch: Loss-> 0.5234, Train accuracy->  26.64%\n","Current batch: Loss-> 0.4812, Train accuracy->  26.75%\n","Current batch: Loss-> 0.4674, Train accuracy->  26.87%\n","Current batch: Loss-> 0.3833, Train accuracy->  26.99%\n","Current batch: Loss-> 0.5396, Train accuracy->  27.10%\n","Current batch: Loss-> 0.5647, Train accuracy->  27.21%\n","Current batch: Loss-> 0.4277, Train accuracy->  27.33%\n","Current batch: Loss-> 0.6577, Train accuracy->  27.44%\n","Current batch: Loss-> 0.9043, Train accuracy->  27.54%\n","Current batch: Loss-> 0.7122, Train accuracy->  27.65%\n","Current batch: Loss-> 0.4904, Train accuracy->  27.76%\n","Current batch: Loss-> 0.7374, Train accuracy->  27.86%\n","Current batch: Loss-> 0.6271, Train accuracy->  27.97%\n","Current batch: Loss-> 0.9118, Train accuracy->  28.07%\n","Current batch: Loss-> 0.4096, Train accuracy->  28.19%\n","Current batch: Loss-> 0.6659, Train accuracy->  28.29%\n","Current batch: Loss-> 0.6565, Train accuracy->  28.40%\n","Current batch: Loss-> 0.4644, Train accuracy->  28.51%\n","Current batch: Loss-> 0.6097, Train accuracy->  28.62%\n","Current batch: Loss-> 0.6555, Train accuracy->  28.73%\n","Current batch: Loss-> 0.3421, Train accuracy->  28.86%\n","Current batch: Loss-> 0.5909, Train accuracy->  28.97%\n","Current batch: Loss-> 0.6635, Train accuracy->  29.08%\n","Current batch: Loss-> 0.3661, Train accuracy->  29.20%\n","Current batch: Loss-> 0.3428, Train accuracy->  29.32%\n","Current batch: Loss-> 0.5656, Train accuracy->  29.43%\n","Current batch: Loss-> 0.6274, Train accuracy->  29.54%\n","Current batch: Loss-> 0.7328, Train accuracy->  29.65%\n","Current batch: Loss-> 0.5346, Train accuracy->  29.75%\n","Current batch: Loss-> 0.6735, Train accuracy->  29.87%\n","Current batch: Loss-> 0.5050, Train accuracy->  29.98%\n","Current batch: Loss-> 0.3009, Train accuracy->  30.10%\n","Current batch: Loss-> 0.4744, Train accuracy->  30.20%\n","Current batch: Loss-> 0.4355, Train accuracy->  30.32%\n","Current batch: Loss-> 0.6367, Train accuracy->  30.43%\n","Current batch: Loss-> 0.5795, Train accuracy->  30.53%\n","Current batch: Loss-> 0.4657, Train accuracy->  30.65%\n","Current batch: Loss-> 0.5711, Train accuracy->  30.76%\n","Current batch: Loss-> 0.4557, Train accuracy->  30.87%\n","Current batch: Loss-> 0.3932, Train accuracy->  30.98%\n","Current batch: Loss-> 0.4548, Train accuracy->  31.09%\n","Current batch: Loss-> 0.6993, Train accuracy->  31.20%\n","Current batch: Loss-> 0.6610, Train accuracy->  31.31%\n","Current batch: Loss-> 0.4467, Train accuracy->  31.42%\n","Current batch: Loss-> 0.3468, Train accuracy->  31.54%\n","Current batch: Loss-> 0.4816, Train accuracy->  31.65%\n","Current batch: Loss-> 0.6400, Train accuracy->  31.74%\n","Current batch: Loss-> 0.5319, Train accuracy->  31.85%\n","Current batch: Loss-> 0.3765, Train accuracy->  31.96%\n","Current batch: Loss-> 0.5525, Train accuracy->  32.08%\n","Current batch: Loss-> 0.5273, Train accuracy->  32.19%\n","Current batch: Loss-> 0.6253, Train accuracy->  32.30%\n","Current batch: Loss-> 0.5024, Train accuracy->  32.41%\n","Current batch: Loss-> 0.8163, Train accuracy->  32.52%\n","Current batch: Loss-> 0.4122, Train accuracy->  32.64%\n","Current batch: Loss-> 0.6306, Train accuracy->  32.76%\n","Current batch: Loss-> 0.6117, Train accuracy->  32.86%\n","Current batch: Loss-> 0.5922, Train accuracy->  32.97%\n","Current batch: Loss-> 0.5497, Train accuracy->  33.08%\n","Current batch: Loss-> 0.4616, Train accuracy->  33.20%\n","Current batch: Loss-> 0.6379, Train accuracy->  33.30%\n","Current batch: Loss-> 0.5945, Train accuracy->  33.41%\n","Current batch: Loss-> 0.6705, Train accuracy->  33.51%\n","Current batch: Loss-> 0.4897, Train accuracy->  33.62%\n","Current batch: Loss-> 0.5127, Train accuracy->  33.73%\n","Current batch: Loss-> 0.7403, Train accuracy->  33.84%\n","Current batch: Loss-> 0.6424, Train accuracy->  33.94%\n","Current batch: Loss-> 0.4643, Train accuracy->  34.04%\n","Current batch: Loss-> 0.5150, Train accuracy->  34.16%\n","Current batch: Loss-> 0.7611, Train accuracy->  34.26%\n","Current batch: Loss-> 0.4320, Train accuracy->  34.37%\n","Current batch: Loss-> 0.5969, Train accuracy->  34.49%\n","Current batch: Loss-> 0.6677, Train accuracy->  34.59%\n","Current batch: Loss-> 0.5706, Train accuracy->  34.69%\n","Current batch: Loss-> 0.5284, Train accuracy->  34.81%\n","Current batch: Loss-> 0.4111, Train accuracy->  34.92%\n","Current batch: Loss-> 0.5011, Train accuracy->  35.04%\n","Current batch: Loss-> 0.6324, Train accuracy->  35.15%\n","Current batch: Loss-> 0.6450, Train accuracy->  35.26%\n","Current batch: Loss-> 0.4799, Train accuracy->  35.37%\n","Current batch: Loss-> 0.7462, Train accuracy->  35.47%\n","Current batch: Loss-> 0.4501, Train accuracy->  35.58%\n","Current batch: Loss-> 0.4264, Train accuracy->  35.70%\n","Current batch: Loss-> 0.5510, Train accuracy->  35.81%\n","Current batch: Loss-> 0.9245, Train accuracy->  35.91%\n","Current batch: Loss-> 0.6580, Train accuracy->  36.02%\n","Current batch: Loss-> 0.7043, Train accuracy->  36.12%\n","Current batch: Loss-> 0.2796, Train accuracy->  36.25%\n","Current batch: Loss-> 0.5224, Train accuracy->  36.37%\n","Current batch: Loss-> 0.7104, Train accuracy->  36.47%\n","Current batch: Loss-> 0.7025, Train accuracy->  36.56%\n","Current batch: Loss-> 0.3907, Train accuracy->  36.68%\n","Current batch: Loss-> 0.4800, Train accuracy->  36.79%\n","Current batch: Loss-> 0.5834, Train accuracy->  36.90%\n","Current batch: Loss-> 0.5209, Train accuracy->  37.01%\n","Current batch: Loss-> 0.5161, Train accuracy->  37.12%\n","Current batch: Loss-> 0.6741, Train accuracy->  37.23%\n","Current batch: Loss-> 0.5205, Train accuracy->  37.35%\n","Current batch: Loss-> 0.5092, Train accuracy->  37.46%\n","Current batch: Loss-> 0.5148, Train accuracy->  37.58%\n","Current batch: Loss-> 0.5583, Train accuracy->  37.68%\n","Current batch: Loss-> 0.6707, Train accuracy->  37.80%\n","Current batch: Loss-> 0.7436, Train accuracy->  37.91%\n","Current batch: Loss-> 0.6022, Train accuracy->  38.01%\n","Current batch: Loss-> 0.6981, Train accuracy->  38.11%\n","Current batch: Loss-> 0.4532, Train accuracy->  38.23%\n","Current batch: Loss-> 0.8385, Train accuracy->  38.33%\n","Current batch: Loss-> 0.4893, Train accuracy->  38.45%\n","Current batch: Loss-> 0.3445, Train accuracy->  38.57%\n","Current batch: Loss-> 0.4837, Train accuracy->  38.68%\n","Current batch: Loss-> 0.4461, Train accuracy->  38.80%\n","Current batch: Loss-> 0.4350, Train accuracy->  38.91%\n","Current batch: Loss-> 0.5226, Train accuracy->  39.02%\n","Current batch: Loss-> 0.4993, Train accuracy->  39.14%\n","Current batch: Loss-> 0.3619, Train accuracy->  39.26%\n","Current batch: Loss-> 0.3976, Train accuracy->  39.38%\n","Current batch: Loss-> 0.6323, Train accuracy->  39.48%\n","Current batch: Loss-> 0.5429, Train accuracy->  39.59%\n","Current batch: Loss-> 0.5648, Train accuracy->  39.71%\n","Current batch: Loss-> 0.6239, Train accuracy->  39.81%\n","Current batch: Loss-> 0.7151, Train accuracy->  39.91%\n","Current batch: Loss-> 0.7964, Train accuracy->  40.02%\n","Current batch: Loss-> 0.3452, Train accuracy->  40.14%\n","Current batch: Loss-> 0.3508, Train accuracy->  40.25%\n","Current batch: Loss-> 0.6102, Train accuracy->  40.36%\n","Current batch: Loss-> 0.4932, Train accuracy->  40.47%\n","Current batch: Loss-> 0.4777, Train accuracy->  40.59%\n","Current batch: Loss-> 0.4877, Train accuracy->  40.71%\n","Current batch: Loss-> 0.6131, Train accuracy->  40.83%\n","Current batch: Loss-> 0.8098, Train accuracy->  40.92%\n","Current batch: Loss-> 0.6308, Train accuracy->  41.02%\n","Current batch: Loss-> 0.7773, Train accuracy->  41.12%\n","Current batch: Loss-> 0.5017, Train accuracy->  41.23%\n","Current batch: Loss-> 0.4990, Train accuracy->  41.35%\n","Current batch: Loss-> 0.2904, Train accuracy->  41.47%\n","Current batch: Loss-> 0.3653, Train accuracy->  41.58%\n","Current batch: Loss-> 0.7577, Train accuracy->  41.68%\n","Current batch: Loss-> 0.6843, Train accuracy->  41.79%\n","Current batch: Loss-> 0.5984, Train accuracy->  41.89%\n","Current batch: Loss-> 0.5225, Train accuracy->  41.99%\n","Current batch: Loss-> 0.3743, Train accuracy->  42.11%\n","Current batch: Loss-> 0.6632, Train accuracy->  42.23%\n","Current batch: Loss-> 0.7405, Train accuracy->  42.34%\n","Current batch: Loss-> 0.6486, Train accuracy->  42.45%\n","Current batch: Loss-> 0.5812, Train accuracy->  42.56%\n","Current batch: Loss-> 0.3678, Train accuracy->  42.68%\n","Current batch: Loss-> 0.6065, Train accuracy->  42.79%\n","Current batch: Loss-> 0.3134, Train accuracy->  42.91%\n","Current batch: Loss-> 0.8052, Train accuracy->  43.00%\n","Current batch: Loss-> 0.5186, Train accuracy->  43.11%\n","Current batch: Loss-> 0.6451, Train accuracy->  43.22%\n","Current batch: Loss-> 1.0294, Train accuracy->  43.31%\n","Current batch: Loss-> 0.6733, Train accuracy->  43.41%\n","Current batch: Loss-> 0.7380, Train accuracy->  43.52%\n","Current batch: Loss-> 0.8436, Train accuracy->  43.61%\n","Current batch: Loss-> 0.6835, Train accuracy->  43.72%\n","Current batch: Loss-> 0.5269, Train accuracy->  43.83%\n","Current batch: Loss-> 0.9446, Train accuracy->  43.93%\n","Current batch: Loss-> 0.7436, Train accuracy->  44.04%\n","Current batch: Loss-> 0.6819, Train accuracy->  44.14%\n","Current batch: Loss-> 0.6528, Train accuracy->  44.24%\n","Current batch: Loss-> 0.6453, Train accuracy->  44.35%\n","Current batch: Loss-> 0.7952, Train accuracy->  44.44%\n","Current batch: Loss-> 0.9208, Train accuracy->  44.52%\n","Current batch: Loss-> 0.6778, Train accuracy->  44.63%\n","Current batch: Loss-> 0.6959, Train accuracy->  44.74%\n","Current batch: Loss-> 0.8874, Train accuracy->  44.84%\n","Current batch: Loss-> 0.8141, Train accuracy->  44.93%\n","Current batch: Loss-> 0.8354, Train accuracy->  45.03%\n","Current batch: Loss-> 1.5322, Train accuracy->  45.11%\n","Current batch: Loss-> 1.2776, Train accuracy->  45.20%\n","Current batch: Loss-> 0.8307, Train accuracy->  45.30%\n","Current batch: Loss-> 0.6949, Train accuracy->  45.40%\n","Current batch: Loss-> 0.6204, Train accuracy->  45.52%\n","Current batch: Loss-> 0.5480, Train accuracy->  45.62%\n","Current batch: Loss-> 0.6352, Train accuracy->  45.72%\n","Current batch: Loss-> 0.9850, Train accuracy->  45.82%\n","Current batch: Loss-> 0.6304, Train accuracy->  45.92%\n","Current batch: Loss-> 0.7113, Train accuracy->  46.02%\n","Current batch: Loss-> 0.9093, Train accuracy->  46.11%\n","Current batch: Loss-> 0.7967, Train accuracy->  46.21%\n","Current batch: Loss-> 0.7257, Train accuracy->  46.30%\n","Current batch: Loss-> 0.8568, Train accuracy->  46.40%\n","Current batch: Loss-> 0.4122, Train accuracy->  46.52%\n","Current batch: Loss-> 0.7341, Train accuracy->  46.62%\n","Current batch: Loss-> 0.7786, Train accuracy->  46.72%\n","Current batch: Loss-> 0.5703, Train accuracy->  46.82%\n","Current batch: Loss-> 0.9695, Train accuracy->  46.91%\n","Current batch: Loss-> 0.8881, Train accuracy->  47.02%\n","Current batch: Loss-> 0.6714, Train accuracy->  47.13%\n","Current batch: Loss-> 0.8310, Train accuracy->  47.23%\n","Current batch: Loss-> 0.5056, Train accuracy->  47.34%\n","Current batch: Loss-> 0.6796, Train accuracy->  47.45%\n","Current batch: Loss-> 0.5199, Train accuracy->  47.55%\n","Current batch: Loss-> 0.5240, Train accuracy->  47.67%\n","Current batch: Loss-> 0.7718, Train accuracy->  47.78%\n","Current batch: Loss-> 0.6564, Train accuracy->  47.89%\n","Current batch: Loss-> 0.8221, Train accuracy->  48.00%\n","Current batch: Loss-> 0.5301, Train accuracy->  48.10%\n","Current batch: Loss-> 0.5328, Train accuracy->  48.21%\n","Current batch: Loss-> 0.8199, Train accuracy->  48.31%\n","Current batch: Loss-> 0.6731, Train accuracy->  48.42%\n","Current batch: Loss-> 0.9447, Train accuracy->  48.52%\n","Current batch: Loss-> 0.6872, Train accuracy->  48.61%\n","Current batch: Loss-> 0.5276, Train accuracy->  48.71%\n","Current batch: Loss-> 1.1129, Train accuracy->  48.81%\n","Current batch: Loss-> 0.6289, Train accuracy->  48.92%\n","Current batch: Loss-> 0.5663, Train accuracy->  49.03%\n","Current batch: Loss-> 0.5567, Train accuracy->  49.13%\n","Current batch: Loss-> 0.7356, Train accuracy->  49.23%\n","Current batch: Loss-> 0.5786, Train accuracy->  49.34%\n","Current batch: Loss-> 0.5092, Train accuracy->  49.45%\n","Current batch: Loss-> 0.4974, Train accuracy->  49.55%\n","Current batch: Loss-> 0.4448, Train accuracy->  49.67%\n","Current batch: Loss-> 0.8022, Train accuracy->  49.77%\n","Current batch: Loss-> 0.7206, Train accuracy->  49.88%\n","Current batch: Loss-> 0.4721, Train accuracy->  50.00%\n","Current batch: Loss-> 0.6187, Train accuracy->  50.10%\n","Current batch: Loss-> 0.6454, Train accuracy->  50.21%\n","Current batch: Loss-> 0.5847, Train accuracy->  50.32%\n","Current batch: Loss-> 0.6243, Train accuracy->  50.43%\n","Current batch: Loss-> 0.6513, Train accuracy->  50.53%\n","Current batch: Loss-> 0.4839, Train accuracy->  50.64%\n","Current batch: Loss-> 0.5986, Train accuracy->  50.75%\n","Current batch: Loss-> 0.8953, Train accuracy->  50.85%\n","Current batch: Loss-> 0.4177, Train accuracy->  50.96%\n","Current batch: Loss-> 0.7886, Train accuracy->  51.06%\n","Current batch: Loss-> 0.4409, Train accuracy->  51.17%\n","Current batch: Loss-> 1.2002, Train accuracy->  51.26%\n","Current batch: Loss-> 0.3840, Train accuracy->  51.38%\n","Current batch: Loss-> 0.5151, Train accuracy->  51.49%\n","Current batch: Loss-> 0.7339, Train accuracy->  51.59%\n","Current batch: Loss-> 0.6297, Train accuracy->  51.70%\n","Current batch: Loss-> 0.7968, Train accuracy->  51.80%\n","Current batch: Loss-> 0.7319, Train accuracy->  51.90%\n","Current batch: Loss-> 0.6158, Train accuracy->  52.01%\n","Current batch: Loss-> 0.4493, Train accuracy->  52.13%\n","Current batch: Loss-> 0.5592, Train accuracy->  52.24%\n","Current batch: Loss-> 0.4938, Train accuracy->  52.35%\n","Current batch: Loss-> 0.5330, Train accuracy->  52.45%\n","Current batch: Loss-> 0.9497, Train accuracy->  52.55%\n","Current batch: Loss-> 0.5595, Train accuracy->  52.66%\n","Current batch: Loss-> 0.5062, Train accuracy->  52.77%\n","Current batch: Loss-> 0.5735, Train accuracy->  52.88%\n","Current batch: Loss-> 1.0148, Train accuracy->  52.97%\n","Current batch: Loss-> 0.6647, Train accuracy->  53.07%\n","Current batch: Loss-> 0.4869, Train accuracy->  53.19%\n","Current batch: Loss-> 0.4824, Train accuracy->  53.30%\n","Current batch: Loss-> 0.4155, Train accuracy->  53.42%\n","Current batch: Loss-> 0.4840, Train accuracy->  53.54%\n","Current batch: Loss-> 0.5612, Train accuracy->  53.64%\n","Current batch: Loss-> 0.5957, Train accuracy->  53.74%\n","Current batch: Loss-> 0.4333, Train accuracy->  53.85%\n","Current batch: Loss-> 0.7155, Train accuracy->  53.96%\n","Current batch: Loss-> 0.5651, Train accuracy->  54.07%\n","Current batch: Loss-> 0.6278, Train accuracy->  54.18%\n","Current batch: Loss-> 0.4210, Train accuracy->  54.29%\n","Current batch: Loss-> 0.4141, Train accuracy->  54.40%\n","Current batch: Loss-> 0.5705, Train accuracy->  54.51%\n","Current batch: Loss-> 0.4589, Train accuracy->  54.63%\n","Current batch: Loss-> 0.6980, Train accuracy->  54.73%\n","Current batch: Loss-> 0.4806, Train accuracy->  54.85%\n","Current batch: Loss-> 0.3752, Train accuracy->  54.97%\n","Current batch: Loss-> 0.8331, Train accuracy->  55.07%\n","Current batch: Loss-> 0.3993, Train accuracy->  55.18%\n","Current batch: Loss-> 0.5611, Train accuracy->  55.30%\n","Current batch: Loss-> 0.7965, Train accuracy->  55.40%\n","Current batch: Loss-> 0.7277, Train accuracy->  55.50%\n","Current batch: Loss-> 0.3245, Train accuracy->  55.62%\n","Current batch: Loss-> 0.7007, Train accuracy->  55.73%\n","Current batch: Loss-> 0.5800, Train accuracy->  55.83%\n","Current batch: Loss-> 0.7965, Train accuracy->  55.94%\n","Current batch: Loss-> 0.4378, Train accuracy->  56.05%\n","Current batch: Loss-> 0.6582, Train accuracy->  56.16%\n","Current batch: Loss-> 0.6529, Train accuracy->  56.26%\n","Current batch: Loss-> 0.3748, Train accuracy->  56.38%\n","Current batch: Loss-> 0.5174, Train accuracy->  56.49%\n","Current batch: Loss-> 0.5076, Train accuracy->  56.60%\n","Current batch: Loss-> 0.7865, Train accuracy->  56.71%\n","Current batch: Loss-> 0.9148, Train accuracy->  56.81%\n","Current batch: Loss-> 0.7413, Train accuracy->  56.91%\n","Current batch: Loss-> 0.6161, Train accuracy->  57.01%\n","Current batch: Loss-> 0.5667, Train accuracy->  57.12%\n","Current batch: Loss-> 0.5695, Train accuracy->  57.23%\n","Current batch: Loss-> 0.4976, Train accuracy->  57.34%\n","Current batch: Loss-> 0.6656, Train accuracy->  57.45%\n","Current batch: Loss-> 0.4824, Train accuracy->  57.56%\n","Current batch: Loss-> 0.5334, Train accuracy->  57.67%\n","Current batch: Loss-> 0.4930, Train accuracy->  57.78%\n","Current batch: Loss-> 0.4477, Train accuracy->  57.90%\n","Current batch: Loss-> 0.7475, Train accuracy->  57.99%\n","Current batch: Loss-> 0.5506, Train accuracy->  58.10%\n","Current batch: Loss-> 0.6431, Train accuracy->  58.21%\n","Current batch: Loss-> 0.5705, Train accuracy->  58.32%\n","Current batch: Loss-> 0.4453, Train accuracy->  58.44%\n","Current batch: Loss-> 0.3059, Train accuracy->  58.55%\n","Current batch: Loss-> 0.6981, Train accuracy->  58.67%\n","Current batch: Loss-> 0.6203, Train accuracy->  58.78%\n","Current batch: Loss-> 0.4302, Train accuracy->  58.89%\n","Current batch: Loss-> 0.4590, Train accuracy->  59.00%\n","Current batch: Loss-> 0.7052, Train accuracy->  59.11%\n","Current batch: Loss-> 0.6400, Train accuracy->  59.22%\n","Current batch: Loss-> 0.6942, Train accuracy->  59.32%\n","Current batch: Loss-> 0.7442, Train accuracy->  59.43%\n","Current batch: Loss-> 0.8260, Train accuracy->  59.54%\n","Current batch: Loss-> 0.6413, Train accuracy->  59.64%\n","Current batch: Loss-> 1.0799, Train accuracy->  59.74%\n","Current batch: Loss-> 0.6163, Train accuracy->  59.84%\n","Current batch: Loss-> 0.4981, Train accuracy->  59.96%\n","Current batch: Loss-> 0.8151, Train accuracy->  60.06%\n","Current batch: Loss-> 0.6377, Train accuracy->  60.16%\n","Current batch: Loss-> 0.7169, Train accuracy->  60.26%\n","Current batch: Loss-> 0.5873, Train accuracy->  60.37%\n","Current batch: Loss-> 0.3246, Train accuracy->  60.49%\n","Current batch: Loss-> 0.6432, Train accuracy->  60.61%\n","Current batch: Loss-> 0.7748, Train accuracy->  60.71%\n","Current batch: Loss-> 0.5757, Train accuracy->  60.81%\n","Current batch: Loss-> 0.6979, Train accuracy->  60.91%\n","Current batch: Loss-> 0.6416, Train accuracy->  61.01%\n","Current batch: Loss-> 0.9354, Train accuracy->  61.11%\n","Current batch: Loss-> 1.0607, Train accuracy->  61.21%\n","Current batch: Loss-> 0.3287, Train accuracy->  61.33%\n","Current batch: Loss-> 0.5594, Train accuracy->  61.44%\n","Current batch: Loss-> 0.4318, Train accuracy->  61.55%\n","Current batch: Loss-> 0.5014, Train accuracy->  61.67%\n","Current batch: Loss-> 0.5322, Train accuracy->  61.78%\n","Current batch: Loss-> 0.8926, Train accuracy->  61.87%\n","Current batch: Loss-> 0.5045, Train accuracy->  61.98%\n","Current batch: Loss-> 0.4250, Train accuracy->  62.10%\n","Current batch: Loss-> 0.6627, Train accuracy->  62.20%\n","Current batch: Loss-> 0.7883, Train accuracy->  62.31%\n","Current batch: Loss-> 0.6711, Train accuracy->  62.41%\n","Current batch: Loss-> 0.4466, Train accuracy->  62.53%\n","Current batch: Loss-> 0.6252, Train accuracy->  62.64%\n","Current batch: Loss-> 0.5651, Train accuracy->  62.75%\n","Current batch: Loss-> 0.9392, Train accuracy->  62.84%\n","Current batch: Loss-> 0.5049, Train accuracy->  62.95%\n","Current batch: Loss-> 0.6979, Train accuracy->  63.05%\n","Current batch: Loss-> 0.4346, Train accuracy->  63.16%\n","Current batch: Loss-> 0.5964, Train accuracy->  63.28%\n","Current batch: Loss-> 0.6961, Train accuracy->  63.38%\n","Current batch: Loss-> 0.8799, Train accuracy->  63.47%\n","Current batch: Loss-> 0.6207, Train accuracy->  63.58%\n","Current batch: Loss-> 0.7084, Train accuracy->  63.69%\n","Current batch: Loss-> 0.4821, Train accuracy->  63.79%\n","Current batch: Loss-> 0.7360, Train accuracy->  63.90%\n","Current batch: Loss-> 0.5094, Train accuracy->  64.01%\n","Current batch: Loss-> 0.5767, Train accuracy->  64.12%\n","Current batch: Loss-> 0.5101, Train accuracy->  64.23%\n","Current batch: Loss-> 0.5532, Train accuracy->  64.34%\n","Current batch: Loss-> 1.0007, Train accuracy->  64.44%\n","Current batch: Loss-> 0.4749, Train accuracy->  64.56%\n","Current batch: Loss-> 0.5287, Train accuracy->  64.67%\n","Current batch: Loss-> 0.9113, Train accuracy->  64.77%\n","Current batch: Loss-> 0.4791, Train accuracy->  64.87%\n","Current batch: Loss-> 0.4890, Train accuracy->  64.98%\n","Current batch: Loss-> 0.5945, Train accuracy->  65.09%\n","Current batch: Loss-> 0.5298, Train accuracy->  65.19%\n","Current batch: Loss-> 0.6332, Train accuracy->  65.29%\n","Current batch: Loss-> 0.4598, Train accuracy->  65.40%\n","Current batch: Loss-> 0.6603, Train accuracy->  65.50%\n","Current batch: Loss-> 0.8490, Train accuracy->  65.59%\n","Current batch: Loss-> 0.8736, Train accuracy->  65.69%\n","Current batch: Loss-> 0.3467, Train accuracy->  65.80%\n","Current batch: Loss-> 0.6343, Train accuracy->  65.91%\n","Current batch: Loss-> 0.5193, Train accuracy->  66.02%\n","Current batch: Loss-> 0.7353, Train accuracy->  66.12%\n","Current batch: Loss-> 0.5293, Train accuracy->  66.24%\n","Current batch: Loss-> 0.6203, Train accuracy->  66.34%\n","Current batch: Loss-> 0.7186, Train accuracy->  66.44%\n","Current batch: Loss-> 0.8830, Train accuracy->  66.54%\n","Current batch: Loss-> 0.4512, Train accuracy->  66.65%\n","Current batch: Loss-> 0.5192, Train accuracy->  66.76%\n","Current batch: Loss-> 0.6346, Train accuracy->  66.87%\n","Current batch: Loss-> 0.7514, Train accuracy->  66.97%\n","Current batch: Loss-> 0.6859, Train accuracy->  67.07%\n","Current batch: Loss-> 0.6749, Train accuracy->  67.17%\n","Current batch: Loss-> 0.6401, Train accuracy->  67.28%\n","Current batch: Loss-> 0.5705, Train accuracy->  67.39%\n","Current batch: Loss-> 0.5606, Train accuracy->  67.51%\n","Current batch: Loss-> 0.7091, Train accuracy->  67.61%\n","Current batch: Loss-> 0.7847, Train accuracy->  67.72%\n","Current batch: Loss-> 0.7424, Train accuracy->  67.82%\n","Current batch: Loss-> 0.6902, Train accuracy->  67.93%\n","Current batch: Loss-> 0.6270, Train accuracy->  68.04%\n","Current batch: Loss-> 0.8362, Train accuracy->  68.12%\n","Current batch: Loss-> 0.4598, Train accuracy->  68.24%\n","Current batch: Loss-> 0.6517, Train accuracy->  68.34%\n","Current batch: Loss-> 0.7528, Train accuracy->  68.45%\n","Current batch: Loss-> 0.5233, Train accuracy->  68.55%\n","Current batch: Loss-> 0.4898, Train accuracy->  68.67%\n","Current batch: Loss-> 0.5452, Train accuracy->  68.77%\n","Current batch: Loss-> 0.7355, Train accuracy->  68.88%\n","Current batch: Loss-> 0.6300, Train accuracy->  68.99%\n","Current batch: Loss-> 0.8409, Train accuracy->  69.09%\n","Current batch: Loss-> 0.5525, Train accuracy->  69.20%\n","Current batch: Loss-> 0.6831, Train accuracy->  69.31%\n","Current batch: Loss-> 0.8286, Train accuracy->  69.40%\n","Current batch: Loss-> 0.6674, Train accuracy->  69.50%\n","Current batch: Loss-> 0.7802, Train accuracy->  69.61%\n","Current batch: Loss-> 0.5417, Train accuracy->  69.71%\n","Current batch: Loss-> 0.7733, Train accuracy->  69.81%\n","Current batch: Loss-> 0.6146, Train accuracy->  69.92%\n","Current batch: Loss-> 0.9031, Train accuracy->  70.03%\n","Current batch: Loss-> 0.8106, Train accuracy->  70.14%\n","Current batch: Loss-> 0.6404, Train accuracy->  70.24%\n","Current batch: Loss-> 0.5369, Train accuracy->  70.36%\n","Current batch: Loss-> 0.7914, Train accuracy->  70.46%\n","Current batch: Loss-> 0.3955, Train accuracy->  70.57%\n","Current batch: Loss-> 0.8576, Train accuracy->  70.68%\n","Current batch: Loss-> 0.5724, Train accuracy->  70.79%\n","Current batch: Loss-> 0.6069, Train accuracy->  70.90%\n","Current batch: Loss-> 0.6276, Train accuracy->  71.00%\n","Current batch: Loss-> 0.6726, Train accuracy->  71.10%\n","Current batch: Loss-> 0.8102, Train accuracy->  71.21%\n","Current batch: Loss-> 0.6214, Train accuracy->  71.32%\n","Current batch: Loss-> 0.8004, Train accuracy->  71.43%\n","Current batch: Loss-> 0.7756, Train accuracy->  71.54%\n","Current batch: Loss-> 1.0982, Train accuracy->  71.64%\n","Current batch: Loss-> 0.4744, Train accuracy->  71.76%\n","Current batch: Loss-> 0.6782, Train accuracy->  71.87%\n","Current batch: Loss-> 0.5803, Train accuracy->  71.98%\n","Current batch: Loss-> 0.6830, Train accuracy->  72.09%\n","Current batch: Loss-> 0.6451, Train accuracy->  72.20%\n","Current batch: Loss-> 0.5753, Train accuracy->  72.30%\n","Current batch: Loss-> 0.5105, Train accuracy->  72.41%\n","Current batch: Loss-> 0.4891, Train accuracy->  72.53%\n","Current batch: Loss-> 0.8364, Train accuracy->  72.64%\n","Current batch: Loss-> 0.4727, Train accuracy->  72.75%\n","Current batch: Loss-> 0.5663, Train accuracy->  72.87%\n","Current batch: Loss-> 0.6876, Train accuracy->  72.96%\n","Current batch: Loss-> 0.4032, Train accuracy->  73.07%\n","Current batch: Loss-> 0.6623, Train accuracy->  73.19%\n","Current batch: Loss-> 0.8000, Train accuracy->  73.27%\n","Current batch: Loss-> 0.3376, Train accuracy->  73.39%\n","Current batch: Loss-> 0.3839, Train accuracy->  73.51%\n","Current batch: Loss-> 0.6382, Train accuracy->  73.62%\n","Current batch: Loss-> 0.6140, Train accuracy->  73.73%\n","Current batch: Loss-> 0.4458, Train accuracy->  73.84%\n","Current batch: Loss-> 0.3588, Train accuracy->  73.96%\n","Current batch: Loss-> 0.7986, Train accuracy->  74.07%\n","Current batch: Loss-> 0.3382, Train accuracy->  74.18%\n","Current batch: Loss-> 0.3867, Train accuracy->  74.29%\n","Current batch: Loss-> 0.4385, Train accuracy->  74.41%\n","Current batch: Loss-> 0.4271, Train accuracy->  74.53%\n","Current batch: Loss-> 0.4651, Train accuracy->  74.64%\n","Current batch: Loss-> 0.6822, Train accuracy->  74.75%\n","Current batch: Loss-> 0.6393, Train accuracy->  74.86%\n","Current batch: Loss-> 0.6995, Train accuracy->  74.97%\n","Current batch: Loss-> 0.5339, Train accuracy->  75.07%\n","Current batch: Loss-> 0.3944, Train accuracy->  75.19%\n","Current batch: Loss-> 0.5053, Train accuracy->  75.30%\n","Current batch: Loss-> 0.8746, Train accuracy->  75.40%\n","Current batch: Loss-> 0.7675, Train accuracy->  75.50%\n","Current batch: Loss-> 0.4220, Train accuracy->  75.61%\n","Current batch: Loss-> 0.4372, Train accuracy->  75.72%\n","Current batch: Loss-> 0.5699, Train accuracy->  75.83%\n","Current batch: Loss-> 0.8715, Train accuracy->  75.93%\n","Current batch: Loss-> 0.5976, Train accuracy->  76.04%\n","Current batch: Loss-> 0.7068, Train accuracy->  76.15%\n","Current batch: Loss-> 0.3529, Train accuracy->  76.28%\n","Current batch: Loss-> 0.5858, Train accuracy->  76.38%\n","Current batch: Loss-> 0.4539, Train accuracy->  76.49%\n","Current batch: Loss-> 0.3975, Train accuracy->  76.61%\n","Current batch: Loss-> 0.4511, Train accuracy->  76.73%\n","Current batch: Loss-> 0.6053, Train accuracy->  76.82%\n","Current batch: Loss-> 0.5989, Train accuracy->  76.93%\n","Current batch: Loss-> 0.4090, Train accuracy->  77.05%\n","Current batch: Loss-> 0.6895, Train accuracy->  77.16%\n","Current batch: Loss-> 0.6601, Train accuracy->  77.26%\n","Current batch: Loss-> 0.3057, Train accuracy->  77.38%\n","Current batch: Loss-> 0.3903, Train accuracy->  77.50%\n","Current batch: Loss-> 0.5758, Train accuracy->  77.61%\n","Current batch: Loss-> 0.3883, Train accuracy->  77.72%\n","Current batch: Loss-> 0.5578, Train accuracy->  77.84%\n","Current batch: Loss-> 0.3751, Train accuracy->  77.95%\n","Current batch: Loss-> 0.3954, Train accuracy->  78.07%\n","Current batch: Loss-> 0.6377, Train accuracy->  78.18%\n","Current batch: Loss-> 0.4401, Train accuracy->  78.29%\n","Current batch: Loss-> 0.6574, Train accuracy->  78.40%\n","Current batch: Loss-> 0.4182, Train accuracy->  78.51%\n","Current batch: Loss-> 0.5610, Train accuracy->  78.63%\n","Current batch: Loss-> 0.8935, Train accuracy->  78.73%\n","Current batch: Loss-> 0.4264, Train accuracy->  78.85%\n","Current batch: Loss-> 0.4783, Train accuracy->  78.96%\n","Current batch: Loss-> 0.6188, Train accuracy->  79.06%\n","Current batch: Loss-> 0.5128, Train accuracy->  79.18%\n","Current batch: Loss-> 0.4855, Train accuracy->  79.29%\n","Current batch: Loss-> 0.4057, Train accuracy->  79.40%\n","Current batch: Loss-> 0.6885, Train accuracy->  79.51%\n","Current batch: Loss-> 0.8012, Train accuracy->  79.60%\n","Current batch: Loss-> 0.7056, Train accuracy->  79.70%\n","Current batch: Loss-> 0.7165, Train accuracy->  79.81%\n","Current batch: Loss-> 0.4723, Train accuracy->  79.93%\n","Current batch: Loss-> 0.5556, Train accuracy->  80.03%\n","Current batch: Loss-> 0.6244, Train accuracy->  80.13%\n","Current batch: Loss-> 0.4977, Train accuracy->  80.25%\n","Current batch: Loss-> 0.6072, Train accuracy->  80.34%\n","Current batch: Loss-> 0.5579, Train accuracy->  80.45%\n","Current batch: Loss-> 0.2683, Train accuracy->  80.58%\n","Current batch: Loss-> 0.4270, Train accuracy->  80.69%\n","Current batch: Loss-> 0.5765, Train accuracy->  80.80%\n","Current batch: Loss-> 0.5814, Train accuracy->  80.91%\n","Current batch: Loss-> 0.5623, Train accuracy->  81.03%\n","Current batch: Loss-> 0.6788, Train accuracy->  81.12%\n"],"name":"stdout"},{"output_type":"stream","text":["  3%|▎         | 5/188 [00:00<00:03, 47.63it/s]"],"name":"stderr"},{"output_type":"stream","text":["Current batch: Loss-> 0.6124, Train accuracy->  81.23%\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 188/188 [00:04<00:00, 44.70it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Avg. loss: 1.3545, Accuracy: 5508/12000 (46%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1Bhnd710ACZM","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1606584048355,"user_tz":300,"elapsed":1257895,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}},"outputId":"7f87ec78-42bf-4f20-fe3b-946bff23bf7e"},"source":["plot_metrics(train_accuracy_epochs, test_accuracy_epochs,  'Accuracy [%]')"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"cPTKw0P76_de","colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"status":"ok","timestamp":1606584049148,"user_tz":300,"elapsed":1258674,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}},"outputId":"c043735b-9c12-450a-86e3-03b80f45089f"},"source":["plot_metrics(train_losses,test_losses, 'Loss')"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"1EK0p8Gnx4m_","executionInfo":{"status":"ok","timestamp":1606584095020,"user_tz":300,"elapsed":2833,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}}},"source":["torch.save(network.state_dict(), 'models/model_N_epoch_{}_Batch_Size_{}_VGG11.pth'.format(N_EPOCHS, BATCH_SIZE))\n","torch.save(optimizer.state_dict(), 'models/optimizer_N_epoch_{}_Batch_Size_{}_VGG11.pth'.format(N_EPOCHS, BATCH_SIZE))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3rApbaX4D_K","executionInfo":{"status":"ok","timestamp":1606590616574,"user_tz":300,"elapsed":5736,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}},"outputId":"c3fe396c-3ef3-428c-ceeb-bcdf4758c625"},"source":["test_data = pickle.load( open( TEST_DATA_FILE, 'rb' ), encoding='bytes')\n","test_data_tensor = torch.zeros_like(torch.from_numpy(data))\n","predicted_targets = torch.zeros(len(data),1)\n","\n","for idx in range(len(data)):  \n","  img = Image.fromarray(data[idx].astype('uint8'), mode = 'L')\n","  test_data_tensor[idx] = img_transform(img)  \n","\n","test_data_tensor = test_data_tensor.type(torch.cuda.FloatTensor)\n","print(test_data_tensor.shape)\n","\n","for i in range(100):\n","  y_batch = network(test_data_tensor[i*100:i*100+100].view(-1,1,64,128))\n","  predicted_targets[i*100:i*100+100] = y_batch.data.max(1, keepdim=True)[1] \n","\n","\n","print(predicted_targets.shape)\n","# still need to save this to external file\n","  "],"execution_count":106,"outputs":[{"output_type":"stream","text":["torch.Size([10000, 64, 128])\n","torch.Size([10000, 1])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q1kelrjTjs3H","executionInfo":{"status":"ok","timestamp":1606584051476,"user_tz":300,"elapsed":1260994,"user":{"displayName":"Rubert Guillermo Martín Pardo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghy3gSTRsGOztcngbBRtdX14lyxuxyb11dG5pZ1yg=s64","userId":"17460270256521479479"}}},"source":["class LeNet5(nn.Module):\n","\n","    def __init__(self):\n","        super(LeNet5, self).__init__()\n","        \n","        self.in_features_to_linear = 27000\n","\n","        self.feature_extractor = nn.Sequential(            \n","            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n","            nn.Tanh(),\n","            nn.AvgPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n","            nn.Tanh(),\n","            nn.AvgPool2d(kernel_size=2),\n","            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n","            nn.Tanh()\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(in_features=self.in_features_to_linear, out_features=84),\n","            nn.Tanh(),\n","            nn.Linear(in_features=84, out_features=N_CLASSES),\n","        )\n","\n","\n","    def forward(self, x):\n","      x = self.feature_extractor(x)\n","      x = torch.flatten(x, 1)  \n","\n","      logits = self.classifier(x)\n","\n","\n","      probs = F.softmax(logits, dim=1)\n","      return probs"],"execution_count":10,"outputs":[]}]}